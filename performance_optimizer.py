"""
âš¡ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ (performance_optimizer.py)

Makenaide í”„ë¡œì íŠ¸ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ ë° ë°°ì¹˜ ì²˜ë¦¬ ê°œì„  ì‹œìŠ¤í…œ

ì£¼ìš” ê¸°ëŠ¥:
1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„
2. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”
3. ìºì‹œ ê´€ë¦¬ ê°œì„ 
4. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ìµœì í™”
5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

ì‘ì„±ì: Makenaide Development Team
ì‘ì„±ì¼: 2025-01-27
ë²„ì „: 1.0.0
"""

import psutil
import gc
import sys
import time
import threading
import pandas as pd
import numpy as np
import logging
from typing import Dict, List, Optional, Tuple, Any, Callable
from datetime import datetime, timedelta
from functools import wraps
import tracemalloc
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing as mp
from utils import setup_logger

# ë¡œê±° ì„¤ì •
logger = setup_logger()

class PerformanceOptimizer:
    """
    âš¡ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ
    
    ì£¼ìš” ìµœì í™” ì˜ì—­:
    1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
    2. ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í–¥ìƒ
    3. ìºì‹œ íš¨ìœ¨ì„± ê°œì„ 
    4. I/O ë³‘ëª© ì œê±°
    5. CPU í™œìš©ë¥  ìµœì í™”
    """
    
    def __init__(self):
        """ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.monitoring_active = False
        self.monitor_thread = None
        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥ì†Œ
        self.metrics = {
            'memory': deque(maxlen=1000),
            'cpu': deque(maxlen=1000),
            'io': deque(maxlen=1000),
            'gc': deque(maxlen=100)
        }
        
        # ë©”ëª¨ë¦¬ ì¶”ì  ì„¤ì •
        self.memory_tracker = None
        self.peak_memory = 0
        self.memory_snapshots = []
        
        # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
        self.optimal_batch_sizes = {
            'static_indicators': 50,
            'ohlcv_processing': 20,
            'indicator_calculation': 10,
            'db_operations': 100
        }
        
        # ìºì‹œ ì„¤ì •
        self.cache_stats = {
            'hits': 0,
            'misses': 0,
            'evictions': 0,
            'size': 0
        }
        
        logger.info("âœ… Performance Optimizer ì´ˆê¸°í™” ì™„ë£Œ")
    
    def start_monitoring(self, interval: int = 5):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.monitoring_active:
            logger.warning("âš ï¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        self.monitoring_active = True
        self.monitor_thread = threading.Thread(
            target=self._monitoring_loop, 
            args=(interval,), 
            daemon=True
        )
        self.monitor_thread.start()
        
        # ë©”ëª¨ë¦¬ ì¶”ì  ì‹œì‘
        tracemalloc.start()
        self.memory_tracker = tracemalloc.take_snapshot()
        
        logger.info(f"âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {interval}ì´ˆ)")
    
    def stop_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring_active = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=10)
        
        if tracemalloc.is_tracing():
            tracemalloc.stop()
        
        logger.info("â¹ï¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _monitoring_loop(self, interval: int):
        """ëª¨ë‹ˆí„°ë§ ë©”ì¸ ë£¨í”„"""
        while self.monitoring_active:
            try:
                timestamp = datetime.now()
                
                # 1. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘
                memory_info = self._collect_memory_metrics()
                self.metrics['memory'].append({
                    'timestamp': timestamp,
                    **memory_info
                })
                
                # 2. CPU ì‚¬ìš©ëŸ‰ ìˆ˜ì§‘
                cpu_info = self._collect_cpu_metrics()
                self.metrics['cpu'].append({
                    'timestamp': timestamp,
                    **cpu_info
                })
                
                # 3. I/O ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                io_info = self._collect_io_metrics()
                self.metrics['io'].append({
                    'timestamp': timestamp,
                    **io_info
                })
                
                # 4. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ í†µê³„
                gc_info = self._collect_gc_metrics()
                if gc_info:
                    self.metrics['gc'].append({
                        'timestamp': timestamp,
                        **gc_info
                    })
                
                # 5. ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· (ë§¤ 1ë¶„)
                if timestamp.second == 0:
                    self._take_memory_snapshot()
                
                time.sleep(interval)
                
            except Exception as e:
                logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ ë£¨í”„ ì˜¤ë¥˜: {e}")
                time.sleep(interval)
    
    def _collect_memory_metrics(self) -> Dict[str, float]:
        """ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            process = psutil.Process()
            memory_info = process.memory_info()
            system_memory = psutil.virtual_memory()
            
            metrics = {
                'rss_mb': memory_info.rss / 1024 / 1024,  # ë¬¼ë¦¬ ë©”ëª¨ë¦¬
                'vms_mb': memory_info.vms / 1024 / 1024,  # ê°€ìƒ ë©”ëª¨ë¦¬
                'percent': process.memory_percent(),       # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
                'available_mb': system_memory.available / 1024 / 1024,
                'system_percent': system_memory.percent
            }
            
            # í”¼í¬ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
            if metrics['rss_mb'] > self.peak_memory:
                self.peak_memory = metrics['rss_mb']
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _collect_cpu_metrics(self) -> Dict[str, float]:
        """CPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            process = psutil.Process()
            
            metrics = {
                'cpu_percent': process.cpu_percent(),
                'system_cpu_percent': psutil.cpu_percent(),
                'num_threads': process.num_threads(),
                'cpu_times_user': process.cpu_times().user,
                'cpu_times_system': process.cpu_times().system
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ CPU ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _collect_io_metrics(self) -> Dict[str, float]:
        """I/O ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            process = psutil.Process()
            io_counters = process.io_counters()
            
            metrics = {
                'read_bytes': io_counters.read_bytes,
                'write_bytes': io_counters.write_bytes,
                'read_count': io_counters.read_count,
                'write_count': io_counters.write_count
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ I/O ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _collect_gc_metrics(self) -> Optional[Dict[str, int]]:
        """ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰ (í•„ìš” ì‹œ)
            collected = gc.collect()
            
            if collected > 0:
                stats = gc.get_stats()
                return {
                    'collected_objects': collected,
                    'generation_0': stats[0]['collections'] if stats else 0,
                    'generation_1': stats[1]['collections'] if len(stats) > 1 else 0,
                    'generation_2': stats[2]['collections'] if len(stats) > 2 else 0,
                    'uncollectable': len(gc.garbage)
                }
            
            return None
            
        except Exception as e:
            logger.error(f"âŒ GC ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
    
    def _take_memory_snapshot(self):
        """ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘"""
        try:
            if not tracemalloc.is_tracing():
                return
            
            snapshot = tracemalloc.take_snapshot()
            top_stats = snapshot.statistics('lineno')
            
            # ìƒìœ„ 10ê°œ ë©”ëª¨ë¦¬ ì‚¬ìš© ë¼ì¸ ì €ì¥
            memory_snapshot = {
                'timestamp': datetime.now(),
                'total_memory': sum(stat.size for stat in top_stats),
                'top_consumers': []
            }
            
            for i, stat in enumerate(top_stats[:10]):
                memory_snapshot['top_consumers'].append({
                    'filename': stat.traceback.format()[0].split(',')[0],
                    'line': stat.traceback.format()[0].split(',')[1],
                    'size_mb': stat.size / 1024 / 1024,
                    'count': stat.count
                })
            
            self.memory_snapshots.append(memory_snapshot)
            
            # ìŠ¤ëƒ…ìƒ· ê°œìˆ˜ ì œí•œ (ìµœëŒ€ 50ê°œ)
            if len(self.memory_snapshots) > 50:
                self.memory_snapshots = self.memory_snapshots[-25:]
                
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    def optimize_batch_processing(self, operation_type: str, data_size: int) -> int:
        """
        ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” - ë°ì´í„° í¬ê¸°ì— ë”°ë¥¸ ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°
        
        Args:
            operation_type: ì‘ì—… íƒ€ì… ('static_indicators', 'ohlcv_processing' ë“±)
            data_size: ì „ì²´ ë°ì´í„° í¬ê¸°
            
        Returns:
            ìµœì  ë°°ì¹˜ í¬ê¸°
        """
        try:
            # ê¸°ë³¸ ë°°ì¹˜ í¬ê¸°
            base_batch_size = self.optimal_batch_sizes.get(operation_type, 20)
            
            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³ ë ¤
            current_memory = self._get_current_memory_usage()
            available_memory = self._get_available_memory()
            
            # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì¡°ì •
            if current_memory > 0.8:  # 80% ì´ìƒ ì‚¬ìš© ì‹œ
                batch_size = max(base_batch_size // 2, 5)
            elif current_memory < 0.5:  # 50% ë¯¸ë§Œ ì‚¬ìš© ì‹œ
                batch_size = min(base_batch_size * 2, 200)
            else:
                batch_size = base_batch_size
            
            # ë°ì´í„° í¬ê¸° ê¸°ë°˜ ì¡°ì •
            if data_size < batch_size:
                batch_size = data_size
            elif data_size > batch_size * 100:  # ë§¤ìš° í° ë°ì´í„°ì…‹
                batch_size = min(batch_size * 2, 100)
            
            logger.debug(f"âš¡ {operation_type} ìµœì  ë°°ì¹˜ í¬ê¸°: {batch_size} (ë°ì´í„°: {data_size}ê°œ)")
            return batch_size
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ìµœì í™” ì‹¤íŒ¨: {e}")
            return self.optimal_batch_sizes.get(operation_type, 20)
    
    def _get_current_memory_usage(self) -> float:
        """í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë°˜í™˜ (0.0~1.0)"""
        try:
            memory = psutil.virtual_memory()
            return memory.percent / 100.0
        except:
            return 0.5  # ê¸°ë³¸ê°’
    
    def _get_available_memory(self) -> float:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë©”ëª¨ë¦¬ (MB) ë°˜í™˜"""
        try:
            memory = psutil.virtual_memory()
            return memory.available / 1024 / 1024
        except:
            return 1024.0  # ê¸°ë³¸ê°’ 1GB
    
    def optimize_dataframe_memory(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        DataFrame ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
        
        Args:
            df: ìµœì í™”í•  DataFrame
            
        Returns:
            ë©”ëª¨ë¦¬ ìµœì í™”ëœ DataFrame
        """
        try:
            original_memory = df.memory_usage(deep=True).sum() / 1024 / 1024
            
            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ìµœì í™”
            for col in df.select_dtypes(include=['int64']).columns:
                col_min = df[col].min()
                col_max = df[col].max()
                
                if col_min >= -128 and col_max <= 127:
                    df[col] = df[col].astype('int8')
                elif col_min >= -32768 and col_max <= 32767:
                    df[col] = df[col].astype('int16')
                elif col_min >= -2147483648 and col_max <= 2147483647:
                    df[col] = df[col].astype('int32')
            
            for col in df.select_dtypes(include=['float64']).columns:
                # float32ë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
                if df[col].min() >= np.finfo(np.float32).min and df[col].max() <= np.finfo(np.float32).max:
                    df[col] = df[col].astype('float32')
            
            # ë¬¸ìì—´ ì»¬ëŸ¼ ìµœì í™”
            for col in df.select_dtypes(include=['object']).columns:
                num_unique_values = len(df[col].unique())
                num_total_values = len(df[col])
                if num_unique_values / num_total_values < 0.5:  # 50% ë¯¸ë§Œì´ ê³ ìœ ê°’
                    df[col] = df[col].astype('category')
            
            optimized_memory = df.memory_usage(deep=True).sum() / 1024 / 1024
            memory_reduction = ((original_memory - optimized_memory) / original_memory) * 100
            
            logger.debug(f"âš¡ DataFrame ë©”ëª¨ë¦¬ ìµœì í™”: {original_memory:.1f}MB â†’ {optimized_memory:.1f}MB ({memory_reduction:.1f}% ê°ì†Œ)")
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ DataFrame ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")
            return df
    
    def parallel_process_tickers(self, tickers: List[str], process_func: Callable, 
                               max_workers: Optional[int] = None) -> List[Any]:
        """
        í‹°ì»¤ ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
        
        Args:
            tickers: ì²˜ë¦¬í•  í‹°ì»¤ ëª©ë¡
            process_func: ì²˜ë¦¬ í•¨ìˆ˜
            max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ëª©ë¡
        """
        try:
            if max_workers is None:
                # CPU ì½”ì–´ ìˆ˜ ê¸°ë°˜ ìµœì  ì›Œì»¤ ìˆ˜ ê³„ì‚°
                cpu_count = psutil.cpu_count()
                current_load = psutil.cpu_percent(interval=1)
                
                if current_load > 80:
                    max_workers = max(1, cpu_count // 2)
                elif current_load > 50:
                    max_workers = max(2, cpu_count // 1.5)
                else:
                    max_workers = cpu_count
                
                max_workers = int(max_workers)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê³ ë ¤í•œ ë°°ì¹˜ í¬ê¸° ê³„ì‚°
            batch_size = self.optimize_batch_processing('ticker_processing', len(tickers))
            
            logger.info(f"âš¡ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {len(tickers)}ê°œ í‹°ì»¤, {max_workers}ê°œ ì›Œì»¤, ë°°ì¹˜ í¬ê¸°: {batch_size}")
            
            results = []
            start_time = time.time()
            
            # ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬
            for i in range(0, len(tickers), batch_size):
                batch_tickers = tickers[i:i + batch_size]
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    futures = {executor.submit(process_func, ticker): ticker for ticker in batch_tickers}
                    
                    for future in as_completed(futures):
                        ticker = futures[future]
                        try:
                            result = future.result(timeout=30)  # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
                            results.append(result)
                        except Exception as e:
                            logger.error(f"âŒ {ticker} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            results.append(None)
                
                # ë°°ì¹˜ ê°„ ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()
                
                logger.debug(f"âš¡ ë°°ì¹˜ {i//batch_size + 1} ì™„ë£Œ: {len(batch_tickers)}ê°œ í‹°ì»¤")
            
            execution_time = time.time() - start_time
            success_count = sum(1 for r in results if r is not None)
            
            logger.info(f"âœ… ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ: {success_count}/{len(tickers)} ì„±ê³µ ({execution_time:.2f}ì´ˆ)")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë³‘ë ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return [None] * len(tickers)
    
    def cleanup_memory(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ìµœì í™”"""
        try:
            logger.info("ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹œì‘")
            
            before_memory = self._get_current_memory_usage()
            
            # 1. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
            collected = gc.collect()
            
            # 2. pandas ìºì‹œ ì •ë¦¬
            try:
                import pandas as pd
                if hasattr(pd, '_cache'):
                    pd._cache.clear()
            except:
                pass
            
            # 3. matplotlib ìºì‹œ ì •ë¦¬ (ì‚¬ìš© ì¤‘ì¸ ê²½ìš°)
            try:
                import matplotlib
                matplotlib.pyplot.close('all')
            except:
                pass
            
            # 4. ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ ì œì•ˆ (Linux)
            try:
                import os
                if os.name == 'posix':
                    logger.debug("ğŸ’¡ ì‹œìŠ¤í…œ ìºì‹œ ì •ë¦¬ ê¶Œì¥: sudo sysctl vm.drop_caches=3")
            except:
                pass
            
            after_memory = self._get_current_memory_usage()
            memory_freed = (before_memory - after_memory) * 100
            
            logger.info(f"âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ: {collected}ê°œ ê°ì²´ ì •ë¦¬, {memory_freed:.1f}% ë©”ëª¨ë¦¬ í™•ë³´")
            
        except Exception as e:
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
        try:
            report = {
                'timestamp': datetime.now().isoformat(),
                'monitoring_active': self.monitoring_active,
                'peak_memory_mb': self.peak_memory,
                'current_metrics': {}
            }
            
            # í˜„ì¬ ë©”íŠ¸ë¦­
            if self.metrics['memory']:
                latest_memory = self.metrics['memory'][-1]
                report['current_metrics']['memory'] = {
                    'rss_mb': latest_memory.get('rss_mb', 0),
                    'percent': latest_memory.get('percent', 0),
                    'available_mb': latest_memory.get('available_mb', 0)
                }
            
            if self.metrics['cpu']:
                latest_cpu = self.metrics['cpu'][-1]
                report['current_metrics']['cpu'] = {
                    'process_percent': latest_cpu.get('cpu_percent', 0),
                    'system_percent': latest_cpu.get('system_cpu_percent', 0),
                    'num_threads': latest_cpu.get('num_threads', 0)
                }
            
            # ìµœê·¼ 1ì‹œê°„ í‰ê· 
            one_hour_ago = datetime.now() - timedelta(hours=1)
            
            recent_memory = [m for m in self.metrics['memory'] 
                           if m['timestamp'] >= one_hour_ago]
            if recent_memory:
                report['hourly_averages'] = {
                    'memory_mb': np.mean([m.get('rss_mb', 0) for m in recent_memory]),
                    'cpu_percent': np.mean([c.get('cpu_percent', 0) for c in self.metrics['cpu'] 
                                          if c['timestamp'] >= one_hour_ago])
                }
            
            # ìµœì í™” ê¶Œì¥ì‚¬í•­
            recommendations = []
            
            if report['current_metrics'].get('memory', {}).get('percent', 0) > 80:
                recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. cleanup_memory() ì‹¤í–‰ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            if report['current_metrics'].get('cpu', {}).get('system_percent', 0) > 90:
                recommendations.append("CPU ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ ê°ì†Œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            report['recommendations'] = recommendations
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def benchmark_function(self, func: Callable, *args, iterations: int = 10, **kwargs) -> Dict[str, Any]:
        """í•¨ìˆ˜ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        try:
            logger.info(f"ğŸš€ í•¨ìˆ˜ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘: {func.__name__} ({iterations}íšŒ ë°˜ë³µ)")
            
            execution_times = []
            memory_usages = []
            
            for i in range(iterations):
                # ë©”ëª¨ë¦¬ ì¸¡ì • ì‹œì‘
                before_memory = self._get_current_memory_usage()
                
                # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
                start_time = time.time()
                try:
                    result = func(*args, **kwargs)
                    success = True
                except Exception as e:
                    logger.error(f"âŒ ë°˜ë³µ {i+1} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    result = None
                    success = False
                
                execution_time = time.time() - start_time
                
                # ë©”ëª¨ë¦¬ ì¸¡ì • ì¢…ë£Œ
                after_memory = self._get_current_memory_usage()
                memory_delta = after_memory - before_memory
                
                if success:
                    execution_times.append(execution_time)
                    memory_usages.append(memory_delta)
                
                # ë°˜ë³µ ê°„ ì •ë¦¬
                gc.collect()
                time.sleep(0.1)
            
            if not execution_times:
                return {'error': 'ëª¨ë“  ì‹¤í–‰ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤'}
            
            benchmark_result = {
                'function_name': func.__name__,
                'iterations': len(execution_times),
                'execution_time': {
                    'min': min(execution_times),
                    'max': max(execution_times),
                    'avg': np.mean(execution_times),
                    'std': np.std(execution_times)
                },
                'memory_usage': {
                    'min_delta': min(memory_usages),
                    'max_delta': max(memory_usages),
                    'avg_delta': np.mean(memory_usages),
                    'std_delta': np.std(memory_usages)
                },
                'performance_score': self._calculate_performance_score(execution_times, memory_usages)
            }
            
            logger.info(f"âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ: í‰ê·  {benchmark_result['execution_time']['avg']:.3f}ì´ˆ")
            
            return benchmark_result
            
        except Exception as e:
            logger.error(f"âŒ í•¨ìˆ˜ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _calculate_performance_score(self, execution_times: List[float], memory_usages: List[float]) -> float:
        """ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° (0.0~10.0)"""
        try:
            # ì‹¤í–‰ ì‹œê°„ ì ìˆ˜ (ë¹ ë¥¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            avg_time = np.mean(execution_times)
            time_score = max(0, 5 - avg_time)  # 5ì´ˆ ê¸°ì¤€
            
            # ë©”ëª¨ë¦¬ ì ìˆ˜ (ì ê²Œ ì‚¬ìš©í• ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            avg_memory = np.mean([abs(m) for m in memory_usages])
            memory_score = max(0, 5 - avg_memory * 100)  # 1% ë©”ëª¨ë¦¬ ì¦ê°€ë‹¹ -1ì 
            
            # ì•ˆì •ì„± ì ìˆ˜ (í‘œì¤€í¸ì°¨ê°€ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            time_stability = max(0, 3 - np.std(execution_times))
            memory_stability = max(0, 2 - np.std([abs(m) for m in memory_usages]) * 100)
            
            total_score = time_score + memory_score + time_stability + memory_stability
            return min(total_score, 10.0)
            
        except:
            return 5.0  # ê¸°ë³¸ ì ìˆ˜

# ì „ì—­ ì„±ëŠ¥ ìµœì í™” ì¸ìŠ¤í„´ìŠ¤
performance_optimizer = PerformanceOptimizer()

def start_performance_monitoring(interval: int = 5):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
    performance_optimizer.start_monitoring(interval)

def stop_performance_monitoring():
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
    performance_optimizer.stop_monitoring()

def optimize_memory():
    """ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤í–‰"""
    performance_optimizer.cleanup_memory()

def get_performance_status():
    """í˜„ì¬ ì„±ëŠ¥ ìƒíƒœ ì¡°íšŒ"""
    return performance_optimizer.get_performance_report()

def performance_benchmark(func, *args, iterations=10, **kwargs):
    """í•¨ìˆ˜ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    return performance_optimizer.benchmark_function(func, *args, iterations=iterations, **kwargs)

# ë°ì½”ë ˆì´í„°: í•¨ìˆ˜ ì‹¤í–‰ ì‹œ ìë™ ì„±ëŠ¥ ì¸¡ì •
def monitor_performance(func):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        start_memory = performance_optimizer._get_current_memory_usage()
        
        try:
            result = func(*args, **kwargs)
            success = True
        except Exception as e:
            logger.error(f"âŒ {func.__name__} ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            result = None
            success = False
            raise
        finally:
            execution_time = time.time() - start_time
            end_memory = performance_optimizer._get_current_memory_usage()
            memory_delta = end_memory - start_memory
            
            if execution_time > 1.0:  # 1ì´ˆ ì´ìƒ ì‹¤í–‰ ì‹œ ë¡œê¹…
                logger.info(f"âš¡ {func.__name__} ì„±ëŠ¥: {execution_time:.3f}ì´ˆ, ë©”ëª¨ë¦¬ ë³€í™”: {memory_delta:+.3f}%")
        
        return result
    
    return wrapper

# ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë¡œê·¸
logger.info("âœ… Performance Optimization System ì´ˆê¸°í™” ì™„ë£Œ")
logger.info("   âš¡ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§, ë°°ì¹˜ ìµœì í™”, ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” ì‹œìŠ¤í…œ í™œì„±í™”")
logger.info("   ğŸ”§ ì‚¬ìš©ë²•: start_performance_monitoring() í˜¸ì¶œë¡œ ëª¨ë‹ˆí„°ë§ ì‹œì‘") 