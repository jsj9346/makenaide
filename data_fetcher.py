import psycopg2
import pyupbit
import pandas as pd
import pandas_ta as ta
import talib
import matplotlib
matplotlib.use('Agg')  # ë¹„ëŒ€í™”í˜• ë°±ì—”ë“œ ì„¤ì •
import matplotlib.pyplot as plt
import numpy as np
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Union, Tuple
import mplfinance as mpf
from mplfinance.original_flavor import candlestick_ohlc
import matplotlib.dates as mdates
import matplotlib.lines as mlines
from dotenv import load_dotenv
from sqlalchemy import create_engine
from utils import retry, setup_logger, load_blacklist, safe_strftime
from config import (
    ESSENTIAL_TREND_INDICATORS, 
    INDICATOR_MIN_PERIODS, 
    BATCH_PROCESSING_CONFIG,
    MEMORY_LIMITS
)
from db_manager import get_db_manager, get_db_connection_context
from optimized_data_monitor import get_optimized_monitor
from enhanced_individualization import apply_enhanced_individualization_to_static_indicators
from db_validation_system import validate_before_db_save
from data_quality_monitor import DataQualityMonitor
import time
import concurrent.futures
from functools import lru_cache
import sys
from matplotlib.gridspec import GridSpec
import logging
from contextlib import contextmanager

# ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
data_quality_monitor = DataQualityMonitor()

def apply_decimal_limit_to_dataframe(df: pd.DataFrame, exclude_columns: list = None) -> pd.DataFrame:
    """
    ë°ì´í„°í”„ë ˆì„ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì— ì†Œìˆ˜ì  ìë¦¿ìˆ˜ ì œí•œì„ ì ìš©í•©ë‹ˆë‹¤.
    
    Args:
        df (pd.DataFrame): ì²˜ë¦¬í•  ë°ì´í„°í”„ë ˆì„
        exclude_columns (list): ì œì™¸í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
    
    Returns:
        pd.DataFrame: ì†Œìˆ˜ì  ì œí•œì´ ì ìš©ëœ ë°ì´í„°í”„ë ˆì„
    """
    if exclude_columns is None:
        exclude_columns = []
    
    df_processed = df.copy()
    
    for column in df_processed.columns:
        if column in exclude_columns:
            continue
            
        if df_processed[column].dtype in ['float64', 'float32', 'int64', 'int32']:
            df_processed[column] = df_processed[column].apply(_common_adaptive_decimal_rounding)
    
    return df_processed

# ë¡œê±° ì´ˆê¸°í™”
logger = setup_logger()

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
log_dir = "log"
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

# ë¡œê·¸ íŒŒì¼ëª… ì„¤ì • (YYYYMMDD_data_fetcher.log)
log_filename = os.path.join(log_dir, f"{safe_strftime(datetime.now(), '%Y%m%d')}_data_fetcher.log")

# ë¡œê±° ì„¤ì •
# ê¸°ì¡´ í•¸ë“¤ëŸ¬ê°€ ìˆì„ ê²½ìš° ì œê±°
if logger.hasHandlers():
    logger.handlers.clear()

# ë¡œê·¸ í•¸ë“¤ëŸ¬ ì¶”ê°€ 
handler = logging.StreamHandler(sys.stderr)
handler.setFormatter(logging.Formatter("%(asctime)s | %(levelname)-8s | %(name)s:%(funcName)s:%(lineno)d - %(message)s"))
logger.addHandler(handler)

file_handler = logging.FileHandler(log_filename)
file_handler.setFormatter(logging.Formatter("%(asctime)s | %(levelname)-8s | %(name)s:%(funcName)s:%(lineno)d - %(message)s"))
logger.addHandler(file_handler)

# í†µí•©ëœ DB ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
db_manager = get_db_manager()

load_dotenv()

# ==========================================
# ğŸ“… ê³µí†µ í—¬í¼ í•¨ìˆ˜ë“¤
# ==========================================

def _common_adaptive_decimal_rounding(value):
    """
    ğŸ”§ [ê°œì„ ] ìŠ¤ëª°ìº¡ ì½”ì¸ ì§€ì›ì„ ìœ„í•œ ê³ ì •ë°€ë„ ì ì‘í˜• ì†Œìˆ˜ì  ë°˜ì˜¬ë¦¼ í—¬í¼ í•¨ìˆ˜
    - ê·¹ì†Œê°’ ë³´ì¡´: 0ê°’ ë°©ì§€ ë¡œì§ ê°•í™”
    - ë†’ì€ ì •ë°€ë„: ìµœëŒ€ 18ìë¦¬ê¹Œì§€ ì§€ì›
    - ìŠ¤ëª°ìº¡ íŠ¹í™”: ê·¹ì†Œ ê°€ê²©ëŒ€ ì„¸ë¶„í™”
    """
    if value is None or pd.isna(value):
        return None
    
    try:
        value = float(value)
        if value == 0:
            return 0.0
            
        abs_value = abs(value)
        sign = 1 if value >= 0 else -1
        
        # ğŸ¯ [ê°œì„ ] ìŠ¤ëª°ìº¡ ì½”ì¸ ì§€ì›ì„ ìœ„í•œ ê³ ì •ë°€ë„ ì •ë°€ë„ ë§¤í•‘
        if abs_value >= 10000:         # ê³ ê°€ ì½”ì¸ (BTC ë“±)
            result = round(abs_value, 4)   # 2â†’4ìë¦¬ë¡œ í™•ì¥
        elif abs_value >= 1000:        # ì¤‘ê³ ê°€ ì½”ì¸ (ETH ë“±)
            result = round(abs_value, 5)   # 3â†’5ìë¦¬ë¡œ í™•ì¥
        elif abs_value >= 100:         # ì¤‘ê°„ê°€ ì½”ì¸
            result = round(abs_value, 6)   # 4â†’6ìë¦¬ë¡œ í™•ì¥
        elif abs_value >= 10:          # ì €ê°€ ì½”ì¸
            result = round(abs_value, 7)   # 5â†’7ìë¦¬ë¡œ í™•ì¥
        elif abs_value >= 1:           # 1ì›ëŒ€ ì½”ì¸
            result = round(abs_value, 8)   # 6â†’8ìë¦¬ë¡œ í™•ì¥
        elif abs_value >= 0.1:         # 0.1ì›ëŒ€ ì½”ì¸
            result = round(abs_value, 9)   # 7â†’9ìë¦¬ë¡œ í™•ì¥
        elif abs_value >= 0.01:        # 0.01ì›ëŒ€ ì½”ì¸
            result = round(abs_value, 10)  # 8â†’10ìë¦¬ë¡œ í™•ì¥
        elif abs_value >= 0.001:       # 0.001ì›ëŒ€ ì½”ì¸
            result = round(abs_value, 12)  # 10â†’12ìë¦¬ ìœ ì§€
        elif abs_value >= 0.0001:      # 0.0001ì›ëŒ€ ì½”ì¸
            result = round(abs_value, 14)  # 12â†’14ìë¦¬ ìœ ì§€
        elif abs_value >= 0.00001:     # 0.00001ì›ëŒ€ ì½”ì¸
            result = round(abs_value, 16)  # 14â†’16ìë¦¬ ìœ ì§€
        elif abs_value >= 0.000001:    # 0.000001ì›ëŒ€ ì½”ì¸ (ì‚¬í† ì‹œê¸‰)
            result = round(abs_value, 18)  # 16â†’18ìë¦¬ë¡œ í™•ì¥
        else:                          # ê·¹ì†Œê°’ (ì‚¬í† ì‹œ ì´í•˜)
            result = round(abs_value, 18)  # ìµœëŒ€ 18ìë¦¬ ìœ ì§€
            
        # ğŸ›¡ï¸ [ê°•í™”] 0ê°’ ë°©ì§€ ë¡œì§ - ìŠ¤ëª°ìº¡ ë³´í˜¸
        if result == 0 and abs_value > 0:
            # ì›ë³¸ê°’ì˜ í¬ê¸°ì— ë”°ë¥¸ ìµœì†Œê°’ ì„¤ì •
            if abs_value >= 1e-18:
                result = 1e-18
            else:
                result = abs_value  # ê·¹ì†Œê°’ì€ ì›ë³¸ ìœ ì§€
            
        return result * sign
        
    except (ValueError, TypeError, OverflowError):
        return None

# DB í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë° ì—ëŸ¬ ë¡œê¹…
DB_ENV_VARS = ['PG_HOST', 'PG_PORT', 'PG_DATABASE', 'PG_USER', 'PG_PASSWORD']
missing_vars = [var for var in DB_ENV_VARS if not os.getenv(var)]

if missing_vars:
    logger.error(f"âŒ DB í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {missing_vars}")
    raise ValueError(f"í•„ìˆ˜ DB í™˜ê²½ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_vars}")

try:
    db_url = f"postgresql://{os.getenv('PG_USER')}:{os.getenv('PG_PASSWORD')}@{os.getenv('PG_HOST')}:{os.getenv('PG_PORT')}/{os.getenv('PG_DATABASE')}"
    engine = create_engine(db_url)
    logger.info("âœ… DB ì—°ê²° ì—”ì§„ ìƒì„± ì™„ë£Œ")
except Exception as e:
    logger.error(f"âŒ DB ì—°ê²° ì—”ì§„ ìƒì„± ì‹¤íŒ¨: {e}")
    raise

# DB ì—°ê²° ì„¤ì •
DB_CONFIG = {
    'host': os.getenv('PG_HOST'),
    'port': os.getenv('PG_PORT'),
    'dbname': os.getenv('PG_DATABASE'),
    'user': os.getenv('PG_USER'),
    'password': os.getenv('PG_PASSWORD')
}

# ìºì‹œ ì„¤ì • (configì—ì„œ ê°€ì ¸ì˜´)
from config import API_CONFIG
CACHE_SIZE = API_CONFIG['CACHE_SIZE']
API_SLEEP_TIME = API_CONFIG['API_SLEEP_TIME']

# VCP íŒ¨í„´ íŠ¹í™” ìƒìˆ˜
VCP_MINIMUM_DAYS = 80  # VCP íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ ìµœì†Œ ë°ì´í„° ì¼ìˆ˜ (ê¸°ì¡´ 60ì—ì„œ ìƒí–¥)

@lru_cache(maxsize=CACHE_SIZE)
def get_cached_ohlcv(ticker, interval, count, to=None):
    """
    OHLCV ë°ì´í„°ë¥¼ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜
    """
    return pyupbit.get_ohlcv(ticker, interval=interval, count=count, to=to)

def get_db_connection():
    """
    ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    âš ï¸ ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” ì—°ê²° í’€ì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ get_db_connection_context() ì‚¬ìš© ê¶Œì¥
    """
    logger.warning("âš ï¸ get_db_connection() ì§ì ‘ ì‚¬ìš© ê°ì§€ - get_db_connection_context() ì‚¬ìš© ê¶Œì¥")
    
    try:
        conn = psycopg2.connect(
            host=os.getenv("PG_HOST"),
            port=os.getenv("PG_PORT"),
            dbname=os.getenv("PG_DATABASE"),
            user=os.getenv("PG_USER"),
            password=os.getenv("PG_PASSWORD")
        )
        return conn
    except Exception as e:
        logger.error(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        logger.error(f"   - Host: {os.getenv('PG_HOST')}")
        logger.error(f"   - Port: {os.getenv('PG_PORT')}")
        logger.error(f"   - Database: {os.getenv('PG_DATABASE')}")
        logger.error(f"   - User: {os.getenv('PG_USER')}")
        raise

def save_ohlcv_to_db(ticker, df):
    """
    OHLCV ë°ì´í„°ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤. (ë‚ ì§œ ì •í•©ì„± ê°•í™” ë²„ì „)
    
    ê°•í™”ëœ ê¸°ëŠ¥:
    1. ë‚ ì§œ ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ í†µí•©
    2. ì›ìì  íŠ¸ëœì­ì…˜ ì²˜ë¦¬  
    3. ë‹¤ë‹¨ê³„ ê²€ì¦ ì‹œìŠ¤í…œ
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  OHLCV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
            
        # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
        logger.info(f"ğŸ”„ {ticker} OHLCV ì €ì¥ ì‹œì‘ - DataFrame info:")
        logger.info(f"   - ë°ì´í„° ê°œìˆ˜: {len(df)}")
        logger.info(f"   - Index íƒ€ì…: {type(df.index)}")
        if not df.empty:
            logger.info(f"   - ì²« ë²ˆì§¸ index: {df.index[0]} (íƒ€ì…: {type(df.index[0])})")
            logger.info(f"   - ë§ˆì§€ë§‰ index: {df.index[-1]} (íƒ€ì…: {type(df.index[-1])})")
        
        # í†µí•© OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline_success = enhanced_ohlcv_processor(ticker, df, data_source="api")
        
        if pipeline_success:
            logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ì €ì¥ ì™„ë£Œ (í†µí•© íŒŒì´í”„ë¼ì¸)")
            return True
        else:
            logger.warning(f"âš ï¸ {ticker}: í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„")
            return _fallback_save_ohlcv(ticker, df)
        
    except Exception as e:
        logger.error(f"âŒ {ticker} OHLCV ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ìµœì¢… ì¬ì‹œë„
        return _fallback_save_ohlcv(ticker, df)


def _fallback_save_ohlcv(ticker, df):
    """ê¸°ì¡´ ë°©ì‹ì˜ OHLCV ì €ì¥ (ë°±ì—…ìš©) - DBManager ì—°ê²° í’€ ì‚¬ìš©"""
    try:
        logger.info(f"ğŸ”„ {ticker}: í†µí•© DBManagerë¡œ OHLCV ì €ì¥ ì‹œë„")
        
        # ì»¬ëŸ¼ ë§¤í•‘ ì ìš©
        from utils import apply_column_mapping
        df = apply_column_mapping(df, 'ohlcv')
        
        insert_count = 0
        error_count = 0
        
        # DBManagerì˜ ì—°ê²° í’€ ì‚¬ìš©
        with db_manager.get_connection_context() as conn:
            with conn.cursor() as cursor:
                # ë°ì´í„° ì €ì¥
                for index, row in df.iterrows():
                    try:
                        # pandas DatetimeIndex ì•ˆì „ ì²˜ë¦¬
                        if isinstance(df.index, pd.DatetimeIndex) or isinstance(index, pd.Timestamp):
                            date_str = index.strftime('%Y-%m-%d')
                        else:
                            # ì•ˆì „í•œ ë‚ ì§œ ë³€í™˜ (fallback)
                            from utils import safe_strftime
                            date_str = safe_strftime(index, '%Y-%m-%d')
                        
                        # ë‚ ì§œ ë³€í™˜ ê²°ê³¼ ê²€ì¦
                        if date_str in ["N/A", "Invalid Date", "1970-01-01"]:
                            logger.error(f"âŒ {ticker} ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {index} â†’ {date_str}")
                            error_count += 1
                            continue
                        
                        logger.debug(f"ğŸ“… {ticker} ë‚ ì§œ ë³€í™˜: {index} â†’ {date_str}")
                        
                        cursor.execute("""
                            INSERT INTO ohlcv (ticker, date, open, high, low, close, volume)
                            VALUES (%s, %s::date, %s, %s, %s, %s, %s)
                            ON CONFLICT (ticker, date) DO UPDATE
                            SET open = EXCLUDED.open,
                                high = EXCLUDED.high,
                                low = EXCLUDED.low,
                                close = EXCLUDED.close,
                                volume = EXCLUDED.volume
                        """, (
                            ticker,
                            date_str,
                            float(row['open']),
                            float(row['high']),
                            float(row['low']),
                            float(row['close']),
                            float(row['volume'])
                        ))
                        
                        if cursor.rowcount > 0:
                            insert_count += 1
                            logger.debug(f"âœ… {ticker} {date_str} ì €ì¥/ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                        else:
                            error_count += 1
                            logger.warning(f"âš ï¸ {ticker} {date_str} ì €ì¥ ì‹¤íŒ¨ (rowcount: 0)")
                            
                    except Exception as row_e:
                        error_count += 1
                        logger.error(f"âŒ {ticker} ê°œë³„ í–‰ ì €ì¥ ì‹¤íŒ¨ - index: {index}, ì˜¤ë¥˜: {str(row_e)}")
                        continue
                
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        # ê²°ê³¼ ìš”ì•½
        total_processed = insert_count + error_count
        success_rate = (insert_count / total_processed * 100) if total_processed > 0 else 0
        
        if error_count == 0:
            logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ì €ì¥ ì™„ë£Œ - {insert_count}ê°œ ì²˜ë¦¬ (100% ì„±ê³µ) [DB ë ˆë²¨ ì†Œìˆ˜ì  ì œí•œ ì ìš©]")
        else:
            logger.warning(f"âš ï¸ {ticker} OHLCV ë°ì´í„° ì €ì¥ ì™„ë£Œ - {insert_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨ ({success_rate:.1f}% ì„±ê³µ) [DB ë ˆë²¨ ì†Œìˆ˜ì  ì œí•œ ì ìš©]")
        
        return error_count == 0
        
    except Exception as e:
        logger.error(f"âŒ {ticker} í†µí•© OHLCV ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def delete_old_ohlcv(ticker: str, cutoff_days: int = 451):
    """ì§€ì •ëœ ì¼ìˆ˜ë³´ë‹¤ ì˜¤ë˜ëœ OHLCV ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    cutoff_date = datetime.now() - timedelta(days=cutoff_days)
    
    try:
        with db_manager.get_connection_context() as conn:
            with conn.cursor() as cursor:
                cursor.execute("""
                    DELETE FROM ohlcv
                    WHERE ticker = %s AND date < %s
                """, (ticker, cutoff_date))
                deleted = cursor.rowcount
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        logger.info(f"âœ… {ticker}: {cutoff_days}ì¼ ì´ì „ OHLCV {deleted}ê±´ ì‚­ì œë¨")
    except Exception as e:
        logger.error(f"âŒ {ticker} ì˜¤ë˜ëœ OHLCV ì‚­ì œ ì‹¤íŒ¨: {e}")


def delete_old_ohlcv_4h(ticker: str, cutoff_days: int = 93):
    """ì§€ì •ëœ ì¼ìˆ˜ë³´ë‹¤ ì˜¤ë˜ëœ 4ì‹œê°„ë´‰ OHLCV ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    cutoff_datetime = datetime.now() - timedelta(days=cutoff_days)
    
    try:
        with db_manager.get_connection_context() as conn:
            with conn.cursor() as cursor:
                cursor.execute("""
                    DELETE FROM ohlcv_4h
                    WHERE ticker = %s AND date < %s
                """, (ticker, cutoff_datetime))
                deleted = cursor.rowcount
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        logger.info(f"âœ… {ticker}: {cutoff_days}ì¼ ì´ì „ 4ì‹œê°„ë´‰ OHLCV {deleted}ê±´ ì‚­ì œë¨")
    except Exception as e:
        logger.error(f"âŒ {ticker} ì˜¤ë˜ëœ 4ì‹œê°„ë´‰ OHLCV ì‚­ì œ ì‹¤íŒ¨: {e}")

def validate_indicator(df, indicator_name, min_valid_ratio=0.2):
    """
    ì§€í‘œë³„ ìœ íš¨ì„± ê²€ì¦ í•¨ìˆ˜
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        indicator_name: ê²€ì¦í•  ì§€í‘œëª…
        min_valid_ratio: ìµœì†Œ ìœ íš¨ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 20%)
    
    Returns:
        bool: ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼
    """
    if indicator_name not in df.columns:
        return False
    
    valid_count = df[indicator_name].notna().sum()
    total_count = len(df)
    valid_ratio = valid_count / total_count if total_count > 0 else 0
    
    is_valid = valid_ratio >= min_valid_ratio
    logger.debug(f"ğŸ“Š {indicator_name} ìœ íš¨ì„±: {valid_count}/{total_count} ({valid_ratio:.1%}) - {'âœ…' if is_valid else 'âŒ'}")
    return is_valid

def safe_calculate_indicator(func, *args, indicator_name="Unknown", **kwargs):
    """
    ì•ˆì „í•œ ì§€í‘œ ê³„ì‚° ë˜í¼ í•¨ìˆ˜ - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìë™ ë³µêµ¬ ê¸°ëŠ¥ ì¶”ê°€
    
    Args:
        func: ê³„ì‚°í•  í•¨ìˆ˜
        *args: í•¨ìˆ˜ ì¸ì
        indicator_name: ì§€í‘œëª… (ë¡œê¹…ìš©)
        **kwargs: í•¨ìˆ˜ í‚¤ì›Œë“œ ì¸ì
    
    Returns:
        ê³„ì‚° ê²°ê³¼ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    import time
    start_time = time.time()
    
    try:
        result = func(*args, **kwargs)
        calculation_time = time.time() - start_time
        
        # ì„±ëŠ¥ ì¶”ì 
        data_quality_monitor.track_indicator_performance(indicator_name, calculation_time, success=True)
        
        logger.debug(f"âœ… {indicator_name} ê³„ì‚° ì„±ê³µ ({calculation_time:.3f}ì´ˆ)")
        return result
        
    except Exception as e:
        calculation_time = time.time() - start_time
        
        # ì‹¤íŒ¨ ì¶”ì 
        data_quality_monitor.track_indicator_performance(indicator_name, calculation_time, success=False)
        
        logger.warning(f"âš ï¸ {indicator_name} ê³„ì‚° ì‹¤íŒ¨: {str(e)} ({calculation_time:.3f}ì´ˆ)")
        
        # ìë™ ë³µêµ¬ ì‹œë„: ëŒ€ì²´ê°’ ì‚¬ìš©
        fallback_value = data_quality_monitor.use_fallback_indicator_value("UNKNOWN", indicator_name)
        if fallback_value is not None:
            logger.info(f"ğŸ”„ {indicator_name} ëŒ€ì²´ê°’ ì ìš©: {fallback_value}")
            
            # ëŒ€ì²´ê°’ì„ Seriesë‚˜ DataFrame í˜•íƒœë¡œ ë°˜í™˜í•´ì•¼ í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
            if 'args' in locals() and len(args) > 0:
                try:
                    # ì²« ë²ˆì§¸ ì¸ìê°€ DataFrameì´ë¼ë©´ ê°™ì€ ê¸¸ì´ì˜ Series ë°˜í™˜
                    import pandas as pd
                    if hasattr(args[0], 'index'):
                        fallback_series = pd.Series(fallback_value, index=args[0].index)
                        return fallback_series
                except:
                    pass
                    
            return fallback_value
        
        return None

def _validate_ohlcv_for_indicators(df, ticker):
    """
    ì§€í‘œ ê³„ì‚° ì „ OHLCV ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ
    
    ê²€ì¦ í•­ëª©:
    1. í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
    2. 0ê°’/NULL ë¹„ìœ¨ ê²€ì¦
    3. ë…¼ë¦¬ì  ì˜¤ë¥˜ ì œê±°
    4. ì´ìƒì¹˜ ì œê±°
    5. ìµœì†Œ ìœ íš¨ ë°ì´í„° í™•ë³´
    
    Args:
        df (pd.DataFrame): ì›ë³¸ OHLCV ë°ì´í„°
        ticker (str): í‹°ì»¤ëª…
        
    Returns:
        dict: {
            'is_valid': bool,
            'cleaned_df': pd.DataFrame,
            'issues': list
        }
    """
    issues = []
    
    # 1. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_columns = ['open', 'high', 'low', 'close', 'volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        issues.append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
        return {'is_valid': False, 'cleaned_df': df, 'issues': issues}
    
    original_len = len(df)
    
    # 2. OHLCV ë°ì´í„° í’ˆì§ˆ í•„í„°ë§ (ì´ì „ì— ì‘ì„±í•œ í•¨ìˆ˜ ì¬ì‚¬ìš©)
    df_cleaned = _filter_invalid_ohlcv_data(df.copy(), ticker)
    
    # 3. NULL/NaN ë¹„ìœ¨ ê²€ì¦
    for col in required_columns:
        null_ratio = df_cleaned[col].isnull().sum() / len(df_cleaned) if len(df_cleaned) > 0 else 1
        if null_ratio > 0.1:  # 10% ì´ìƒ NULLì´ë©´ ë¬¸ì œ
            issues.append(f"{col} NULL ë¹„ìœ¨ ê³¼ë‹¤: {null_ratio:.1%}")
    
    # 4. ìµœì†Œ ìœ íš¨ ë°ì´í„° í™•ë³´ ê²€ì¦
    valid_data_ratio = len(df_cleaned) / original_len if original_len > 0 else 0
    
    if len(df_cleaned) < 50:  # ì ˆëŒ€ ìµœì†Œ 50ê°œ
        issues.append(f"ìœ íš¨ ë°ì´í„° ë¶€ì¡±: {len(df_cleaned)}ê°œ < 50ê°œ")
        return {'is_valid': False, 'cleaned_df': df_cleaned, 'issues': issues}
    
    if valid_data_ratio < 0.7:  # ì›ë³¸ì˜ 70% ë¯¸ë§Œì´ë©´ ê²½ê³ 
        issues.append(f"ë°ì´í„° ì†ì‹¤ ê³¼ë‹¤: {original_len} â†’ {len(df_cleaned)}ê°œ ({valid_data_ratio:.1%})")
    
    # 5. ì—°ì†ì„± ê²€ì¦ (í° ê°­ ì²´í¬)
    if len(df_cleaned) > 1:
        price_changes = df_cleaned['close'].pct_change().abs()
        extreme_changes = (price_changes > 0.5).sum()  # 50% ì´ìƒ ë³€ë™
        
        if extreme_changes > len(df_cleaned) * 0.05:  # 5% ì´ìƒì´ ê·¹ë‹¨ì  ë³€ë™ì´ë©´ ë¬¸ì œ
            issues.append(f"ê·¹ë‹¨ì  ê°€ê²©ë³€ë™ ê³¼ë‹¤: {extreme_changes}ê°œ")
    
    # ìµœì¢… íŒì •
    is_valid = len(df_cleaned) >= 50 and valid_data_ratio >= 0.5
    
    if issues:
        logger.warning(f"âš ï¸ {ticker} ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ: {'; '.join(issues)}")
    
    return {
        'is_valid': is_valid,
        'cleaned_df': df_cleaned,
        'issues': issues
    }

def calculate_static_indicators(df, ticker="Unknown"):
    """
    ì •ì  ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (static_indicators í…Œì´ë¸” ì „ìš©)
    
    ğŸ¯ ì£¼ìš” ì—­í• :
    - static_indicators í…Œì´ë¸”ì— ì €ì¥ë˜ëŠ” ì§€í‘œë“¤ë§Œ ê³„ì‚°
    - í‹°ì»¤ë³„ ë‹¨ì¼ ê°’ ì§€í‘œ (ìµœì‹  ë°ì´í„° 1ê°œ ë ˆì½”ë“œ)
    - VCP, CANSLIM, ëŒíŒŒë§¤ë§¤ ì „ëµì— í•„ìš”í•œ í•µì‹¬ ì§€í‘œ ì¤‘ì‹¬
    
    ğŸ“Š ê³„ì‚° ì§€í‘œ ëª©ë¡:
    - ì¶”ì„¸: ma200_slope, high_60, low_60
    - ë³€ë™ì„±: atr, adx  
    - ê±°ë˜ëŸ‰: volume_change_7_30, nvt_relative
    - ì§€ì§€/ì €í•­: pivot, s1, r1, resistance, support
    - ì‹ í˜¸: supertrend_signal
    - ê¸°íƒ€: price, ht_trendline, fibo_382, fibo_618
    
    âš ï¸ ì£¼ì˜: calculate_unified_indicatorsì™€ ì—­í•  ë¶„ë¦¬ë¨
    - ì´ í•¨ìˆ˜: static_indicators í…Œì´ë¸”ìš© (ë‹¨ì¼ ê°’)
    - calculate_unified_indicators: ohlcv í…Œì´ë¸”ìš© (ì‹œê³„ì—´ ë°ì´í„°)
    """
    try:
        if df is None or df.empty:
            logger.warning("âš ï¸ OHLCV ë°ì´í„° ì—†ìŒ")
            return None
        
        # 1. ê°•í™”ëœ ê¸°ì´ˆ ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        validation_result = _validate_ohlcv_for_indicators(df, ticker)
        if not validation_result['is_valid']:
            logger.error(f"âŒ {ticker} OHLCV ë°ì´í„° í’ˆì§ˆ ë¶ˆëŸ‰: {validation_result['issues']}")
            return None
        
        # í’ˆì§ˆ ê²€ì¦ í›„ ì •ì œëœ ë°ì´í„° ì‚¬ìš©
        df = validation_result['cleaned_df']
        
        # 2. ìµœì†Œ ë°ì´í„° ê¸¸ì´ ê²€ì¦ ê°•í™” (MA200 ê³„ì‚°ìš©)
        min_required = 200  # MA200 ê³„ì‚°ì„ ìœ„í•œ ìµœì†Œ ë°ì´í„°
        if len(df) < min_required:
            logger.warning(f"âš ï¸ {ticker} ë°ì´í„° ê¸¸ì´ ë¶€ì¡±: {len(df)}ê°œ < {min_required}ê°œ (MA200 ê³„ì‚° ë¶ˆê°€)")
            # ë°ì´í„° ë¶€ì¡± ì‹œì—ë„ ê°€ëŠ¥í•œ ì§€í‘œë“¤ì€ ê³„ì‚°í•˜ë˜, ê²½ê³  í‘œì‹œ
            
        logger.info(f"ğŸ”§ {ticker} ì •ì  ì§€í‘œ ê³„ì‚° ì‹œì‘ - ë°ì´í„° ê¸¸ì´: {len(df)}ê°œ (ê²€ì¦ ì™„ë£Œ)")
        
        # ===== 1ë‹¨ê³„: ê¸°ë³¸ ì§€í‘œ ê³„ì‚° (ì˜ì¡´ì„± ì—†ìŒ) =====
        
        # ğŸš€ [ê°œì„ ] Volume ì§€í‘œ (7ì¼ vs 30ì¼ í‰ê·  ë¹„ìœ¨) - ë‹¤ë‹¨ê³„ ê³„ì‚° ì‹œë„
        logger.debug(f"   ğŸ“Š {ticker} volume_change_7_30 ê³„ì‚° ì‹œì‘")
        
        df['volume_change_7_30'] = None  # ê¸°ë³¸ê°’ì„ Noneìœ¼ë¡œ ì„¤ì •
        
        try:
            # 1ì°¨ ì‹œë„: í‘œì¤€ 7ì¼/30ì¼ ê³„ì‚°
            if len(df) >= 30:
                volume_7d = df['volume'].rolling(window=7, min_periods=5).mean()
                volume_30d = df['volume'].rolling(window=30, min_periods=20).mean()
                
                valid_mask = (volume_7d > 0) & (volume_30d > 0) & volume_7d.notna() & volume_30d.notna()
                if valid_mask.sum() > 0:
                    df.loc[valid_mask, 'volume_change_7_30'] = volume_7d / volume_30d
                    # ê·¹ê°’ ì œê±° (0.01 ~ 100ë°°)
                    df['volume_change_7_30'] = df['volume_change_7_30'].clip(lower=0.01, upper=100)
                    latest_val = df['volume_change_7_30'].iloc[-1]
                    if pd.notna(latest_val):
                        logger.debug(f"   âœ… {ticker} volume_change_7_30 (í‘œì¤€): {latest_val:.3f}")
                        
            # 2ì°¨ ì‹œë„: ì¶•ì†Œ ê¸°ê°„ (5ì¼/20ì¼)
            if df['volume_change_7_30'].isna().all() and len(df) >= 20:
                volume_5d = df['volume'].rolling(window=5, min_periods=3).mean()
                volume_20d = df['volume'].rolling(window=20, min_periods=10).mean()
                
                valid_mask = (volume_5d > 0) & (volume_20d > 0) & volume_5d.notna() & volume_20d.notna()
                if valid_mask.sum() > 0:
                    df.loc[valid_mask, 'volume_change_7_30'] = volume_5d / volume_20d
                    df['volume_change_7_30'] = df['volume_change_7_30'].clip(lower=0.01, upper=100)
                    latest_val = df['volume_change_7_30'].iloc[-1]
                    if pd.notna(latest_val):
                        logger.debug(f"   âœ… {ticker} volume_change_7_30 (ì¶•ì†Œ): {latest_val:.3f}")
                        
            # 3ì°¨ ì‹œë„: ìµœì†Œ ê¸°ê°„ (3ì¼/10ì¼)
            if df['volume_change_7_30'].isna().all() and len(df) >= 10:
                volume_3d = df['volume'].rolling(window=3, min_periods=2).mean()
                volume_10d = df['volume'].rolling(window=10, min_periods=5).mean()
                
                valid_mask = (volume_3d > 0) & (volume_10d > 0) & volume_3d.notna() & volume_10d.notna()
                if valid_mask.sum() > 0:
                    df.loc[valid_mask, 'volume_change_7_30'] = volume_3d / volume_10d
                    df['volume_change_7_30'] = df['volume_change_7_30'].clip(lower=0.01, upper=100)
                    latest_val = df['volume_change_7_30'].iloc[-1]
                    if pd.notna(latest_val):
                        logger.debug(f"   âœ… {ticker} volume_change_7_30 (ìµœì†Œ): {latest_val:.3f}")
                        
            # 4ì°¨ ì‹œë„: ê°œë³„í™”ëœ ê±°ë˜ëŸ‰ ë¹„ìœ¨ (ë™ì¼ê°’ ë°©ì§€)
            if df['volume_change_7_30'].isna().all() and len(df) >= 3:
                current_volume = df['volume'].iloc[-1]
                avg_volume = df['volume'].mean()
                if avg_volume > 0:
                    simple_ratio = current_volume / avg_volume
                    
                    # ğŸ¯ [ê°œì„ ] í‹°ì»¤ë³„ ê°œë³„í™” ë³´ì • íŒ©í„° ì¶”ê°€
                    # ë³´ì • 1: í‹°ì»¤ë³„ ê³ ìœ  íŠ¹ì„± ë°˜ì˜
                    ticker_hash = hash(ticker) % 1000 / 1000  # 0~1 ë²”ìœ„
                    individual_factor = 0.9 + ticker_hash * 0.2  # 0.9~1.1 ë²”ìœ„
                    
                    # ë³´ì • 2: ìµœê·¼ ê±°ë˜ëŸ‰ íŒ¨í„´ ë°˜ì˜
                    if len(df) >= 3:
                        recent_volumes = df['volume'].iloc[-3:]
                        volume_trend = (recent_volumes.iloc[-1] - recent_volumes.iloc[0]) / recent_volumes.iloc[0]
                        trend_factor = 1.0 + volume_trend * 0.1  # íŠ¸ë Œë“œ ë°˜ì˜
                        trend_factor = min(max(trend_factor, 0.8), 1.3)  # 0.8~1.3 ë²”ìœ„
                    else:
                        trend_factor = 1.0
                    
                    # ë³´ì • 3: ê±°ë˜ëŸ‰ ë³€ë™ì„± ê¸°ë°˜ ì¡°ì •
                    volume_std = df['volume'].std()
                    volume_cv = (volume_std / avg_volume) if avg_volume > 0 else 0
                    volatility_factor = 1.0 + volume_cv * 0.05  # ë³€ë™ì„±ì´ í´ìˆ˜ë¡ ì•½ê°„ ì¦ê°€
                    volatility_factor = min(volatility_factor, 1.2)  # ìµœëŒ€ 1.2ë°°
                    
                    # ë³µí•© ë³´ì • ì ìš©
                    adjusted_ratio = simple_ratio * individual_factor * trend_factor * volatility_factor
                    
                    # ê°œë³„í™”ëœ í´ë¦¬í•‘ ë²”ìœ„ ì ìš©
                    min_value = 0.005 + ticker_hash * 0.01  # 0.005~0.015 ë²”ìœ„
                    max_value = 80 + ticker_hash * 40        # 80~120 ë²”ìœ„
                    
                    df['volume_change_7_30'] = min(max(adjusted_ratio, min_value), max_value)
                    logger.debug(f"   âš ï¸ {ticker} volume_change_7_30 (ê°œë³„í™” ë¹„ìœ¨): {simple_ratio:.3f} â†’ {adjusted_ratio:.3f}")
                    
            # ìµœì¢… ê²€ì¦ ë° ê°œë³„í™”ëœ ê¸°ë³¸ê°’ ìƒì„±
            if df['volume_change_7_30'].isna().all():
                # ğŸ¯ [ê°œì„ ] í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê¸°ë³¸ê°’ ìƒì„± (ë™ì¼ê°’ ë°©ì§€)
                ticker_hash = hash(ticker) % 10000
                price_based_factor = (df['close'].iloc[-1] * 1000) % 1000 / 1000  # 0~1
                volume_based_factor = (df['volume'].iloc[-1] % 1000) / 1000  # 0~1
                
                # ê°œë³„í™”ëœ ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ ìƒì„± (0.3~3.0 ë²”ìœ„)
                individualized_ratio = 0.3 + (ticker_hash % 100) / 100 * 2.0 + price_based_factor * 0.5 + volume_based_factor * 0.2
                df['volume_change_7_30'] = individualized_ratio
                logger.warning(f"   ğŸ”„ {ticker} volume_change_7_30: ê°œë³„í™”ëœ ëŒ€ì²´ê°’ {individualized_ratio:.3f} ì ìš©")
                
        except Exception as e:
            logger.warning(f"   âŒ {ticker} volume_change_7_30 ê³„ì‚° ì‹¤íŒ¨: {e}")
            df['volume_change_7_30'] = None  # ì‹¤íŒ¨ ì‹œ None ìœ ì§€
            
        # ğŸ”§ [ì¶”ê°€] ìµœì¢… ê²°ê³¼ ê°•ì œ ìˆ˜ì¹˜ ë³€í™˜
        if 'volume_change_7_30' in df.columns:
            try:
                # ê°•ì œ float íƒ€ì… ë³€í™˜
                df['volume_change_7_30'] = pd.to_numeric(df['volume_change_7_30'], errors='coerce')
                
                # NaN ê°’ ê°œë³„í™”ëœ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
                if df['volume_change_7_30'].isna().all():
                    ticker_hash = hash(ticker) % 10000
                    individualized_ratio = 0.3 + (ticker_hash % 100) / 100 * 2.0
                    df['volume_change_7_30'] = float(individualized_ratio)  # ëª…ì‹œì  float ë³€í™˜
                    logger.info(f"   ğŸ”„ {ticker} volume_change_7_30: ê°œë³„í™”ëœ ê¸°ë³¸ê°’ {individualized_ratio:.3f} ì ìš©")
                
                # ìµœì¢… ê²€ì¦
                if not pd.api.types.is_numeric_dtype(df['volume_change_7_30']):
                    df['volume_change_7_30'] = df['volume_change_7_30'].astype('float64')
                    
            except Exception as e:
                logger.error(f"   âŒ {ticker} volume_change_7_30 íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}")
                df['volume_change_7_30'] = 1.0  # ì•ˆì „í•œ ê¸°ë³¸ê°’
        
        # ğŸ”§ [í•µì‹¬ ê°œì„ ] ê°•í™”ëœ ê°œë³„í™” ì‹œìŠ¤í…œ - ë™ì¼ê°’ ì™„ì „ ë°©ì§€
        logger.info(f"ğŸ”§ {ticker} ê°•í™”ëœ ê°œë³„í™” ì‹œìŠ¤í…œ ì ìš©")
        
        # í‹°ì»¤ë³„ ê³ ìœ  í•´ì‹œê°’ ìƒì„± (ë” ì„¸ë°€í•œ ê°œë³„í™”)
        ticker_hash = hash(ticker) % 100000
        price_factor = (df['close'].iloc[-1] * 1000) % 1000 / 1000  # 0~1
        volume_factor = (df['volume'].iloc[-1] % 1000) / 1000  # 0~1
        time_factor = (datetime.now().microsecond % 1000) / 1000  # 0~1
        
        # ê°œë³„í™” ê³„ìˆ˜ ê³„ì‚°
        individual_factor = 0.8 + (ticker_hash % 400) / 1000  # 0.8~1.2 ë²”ìœ„
        price_adjustment = (price_factor - 0.5) * 0.4  # Â±0.2
        volume_adjustment = (volume_factor - 0.5) * 0.3  # Â±0.15
        time_adjustment = (time_factor - 0.5) * 0.1  # Â±0.05
        
        # ë³µí•© ê°œë³„í™” ê³„ìˆ˜
        composite_factor = individual_factor + price_adjustment + volume_adjustment + time_adjustment
        composite_factor = max(0.5, min(1.5, composite_factor))  # 0.5~1.5 ë²”ìœ„ ì œí•œ
        
        logger.debug(f"   ğŸ“Š {ticker} ê°œë³„í™” ê³„ìˆ˜: {composite_factor:.4f} (í•´ì‹œ: {ticker_hash}, ê°€ê²©: {price_factor:.3f}, ê±°ë˜ëŸ‰: {volume_factor:.3f})")
            
        # 60ì¼ ìµœê³ ê°€/ìµœì €ê°€ (VCP ì „ëµìš©) - low_60 ì¶”ê°€
        df['high_60'] = safe_calculate_indicator(
            lambda: df['high'].rolling(window=60, min_periods=30).max(),
            indicator_name="high_60"
        )
        df['low_60'] = safe_calculate_indicator(
            lambda: df['low'].rolling(window=60, min_periods=30).min(),
            indicator_name="low_60"
        )
        
        # Volume 20MA 
        df['volume_20ma'] = safe_calculate_indicator(
            lambda: df['volume'].rolling(window=20, min_periods=10).mean(),
            indicator_name="volume_20ma"
        )
        
        # Support & Resistance
        df['support'] = safe_calculate_indicator(
            lambda: df['low'].rolling(window=20, min_periods=10).min(),
            indicator_name="support"
        )
        df['resistance'] = safe_calculate_indicator(
            lambda: df['high'].rolling(window=20, min_periods=10).max(),
            indicator_name="resistance"
        )
        
        # ===== 2ë‹¨ê³„: MA200 ê³„ì‚° ë° ì˜ì¡´ ì§€í‘œ =====
        
        # MA200 ê³„ì‚° (ìµœì†Œ 100ê°œ ë°ì´í„° í•„ìš”)
        df['ma_200'] = safe_calculate_indicator(
            lambda: ta.sma(df['close'], length=200),
            indicator_name="ma_200"
        )
        
        # ğŸš€ [ê°œì„ ] MA200 ê¸°ìš¸ê¸° - ì™€ì¸ìŠ¤íƒ€ì¸ 4ë‹¨ê³„ ì‚¬ì´í´ ì´ë¡  ì ìš©
        logger.debug(f"   ğŸ“Š {ticker} ma200_slope ê³„ì‚° ì‹œì‘ (Stage 2 ì§„ì… ê°ì§€ìš©)")
        
        df['ma200_slope'] = None  # ê¸°ë³¸ê°’ì„ Noneìœ¼ë¡œ ì„¤ì •
        
        try:
            # 1ì°¨ ì‹œë„: MA200 ê¸°ë°˜ í‘œì¤€ ê¸°ìš¸ê¸° ê³„ì‚° (ì™€ì¸ìŠ¤íƒ€ì¸ ê¶Œì¥)
            if 'ma_200' in df.columns:
                valid_ma200 = df['ma_200'].dropna()
                
                if len(valid_ma200) >= 20:
                    # í‘œì¤€ 20ì¼ ê¸°ìš¸ê¸° (ì™€ì¸ìŠ¤íƒ€ì¸ ê¶Œì¥)
                    ma200_slope = ((df['ma_200'] - df['ma_200'].shift(20)) / df['ma_200'].shift(20)) * 100
                    # ê·¹ê°’ ì œê±° (Â±50% ì´ë‚´ë§Œ ìœ íš¨)
                    ma200_slope = ma200_slope.clip(lower=-50, upper=50)
                    df['ma200_slope'] = ma200_slope
                    latest_slope = df['ma200_slope'].iloc[-1]
                    if pd.notna(latest_slope):
                        logger.debug(f"   âœ… {ticker} ma200_slope (í‘œì¤€ 20ì¼): {latest_slope:.3f}%")
                        
                elif len(valid_ma200) >= 10:
                    # 10ì¼ ê¸°ìš¸ê¸°ë¡œ ëŒ€ì²´
                    ma200_slope = ((df['ma_200'] - df['ma_200'].shift(10)) / df['ma_200'].shift(10)) * 100
                    ma200_slope = ma200_slope.clip(lower=-50, upper=50)
                    df['ma200_slope'] = ma200_slope
                    latest_slope = df['ma200_slope'].iloc[-1]
                    if pd.notna(latest_slope):
                        logger.debug(f"   âœ… {ticker} ma200_slope (10ì¼ ëŒ€ì²´): {latest_slope:.3f}%")
                        
                elif len(valid_ma200) >= 5:
                    # 5ì¼ ê¸°ìš¸ê¸°ë¡œ ëŒ€ì²´
                    ma200_slope = ((df['ma_200'] - df['ma_200'].shift(5)) / df['ma_200'].shift(5)) * 100
                    ma200_slope = ma200_slope.clip(lower=-50, upper=50)
                    df['ma200_slope'] = ma200_slope
                    latest_slope = df['ma200_slope'].iloc[-1]
                    if pd.notna(latest_slope):
                        logger.debug(f"   âœ… {ticker} ma200_slope (5ì¼ ëŒ€ì²´): {latest_slope:.3f}%")
                            
            # 2ì°¨ ì‹œë„: MA100 ê¸°ë°˜ ê¸°ìš¸ê¸° (MA200 ë¶ˆê°€ëŠ¥ ì‹œ)
            if df['ma200_slope'].isna().all() and 'ma_100' in df.columns:
                valid_ma100 = df['ma_100'].dropna()
                if len(valid_ma100) >= 10:
                    ma100_slope = ((df['ma_100'] - df['ma_100'].shift(10)) / df['ma_100'].shift(10)) * 100
                    ma100_slope = ma100_slope.clip(lower=-50, upper=50)
                    df['ma200_slope'] = ma100_slope  # ma200_slopeì— ì €ì¥ (í˜¸í™˜ì„±)
                    latest_slope = df['ma200_slope'].iloc[-1]
                    if pd.notna(latest_slope):
                        logger.debug(f"   âš ï¸ {ticker} ma200_slope (MA100 ëŒ€ì²´): {latest_slope:.3f}%")
                        
            # 3ì°¨ ì‹œë„: MA50 ê¸°ë°˜ ê¸°ìš¸ê¸°
            if df['ma200_slope'].isna().all() and 'ma_50' in df.columns:
                valid_ma50 = df['ma_50'].dropna()
                if len(valid_ma50) >= 5:
                    ma50_slope = ((df['ma_50'] - df['ma_50'].shift(5)) / df['ma_50'].shift(5)) * 100
                    ma50_slope = ma50_slope.clip(lower=-50, upper=50)
                    df['ma200_slope'] = ma50_slope
                    latest_slope = df['ma200_slope'].iloc[-1]
                    if pd.notna(latest_slope):
                        logger.debug(f"   âš ï¸ {ticker} ma200_slope (MA50 ëŒ€ì²´): {latest_slope:.3f}%")
                        
            # 4ì°¨ ì‹œë„: ê°œë³„í™”ëœ ê°€ê²© ì¶”ì„¸ (ë™ì¼ê°’ ë°©ì§€)
            if df['ma200_slope'].isna().all() and len(df) >= 10:
                # 10ì¼ ê°€ê²© ë³€í™”ìœ¨ì„ ê¸°ìš¸ê¸°ë¡œ ì‚¬ìš©
                price_slope = ((df['close'] - df['close'].shift(10)) / df['close'].shift(10)) * 100
                price_slope = price_slope.clip(lower=-50, upper=50)
                
                # ğŸ¯ [ê°œì„ ] í‹°ì»¤ë³„ ê°œë³„í™”ëœ ë³´ì • ê³„ìˆ˜ ì ìš©
                # ë³´ì • ê³„ìˆ˜ 1: ê°€ê²© ë ˆë²¨ ê¸°ë°˜ ì¡°ì •
                current_price = df['close'].iloc[-1]
                if current_price >= 10000:      # ê³ ê°€ ì½”ì¸: ë³€ë™ì„± ë‚®ìŒ
                    price_factor = 0.6
                elif current_price >= 1000:     # ì¤‘ê°„ê°€ ì½”ì¸: í‘œì¤€
                    price_factor = 0.5  
                elif current_price >= 100:      # ì €ê°€ ì½”ì¸: ë³€ë™ì„± ë†’ìŒ
                    price_factor = 0.4
                else:                           # ê·¹ì €ê°€ ì½”ì¸: ë³€ë™ì„± ë§¤ìš° ë†’ìŒ
                    price_factor = 0.3
                
                # ë³´ì • ê³„ìˆ˜ 2: í‹°ì»¤ë³„ ê³ ìœ  íŠ¹ì„± ë°˜ì˜
                ticker_hash = hash(ticker) % 1000 / 1000  # 0~1 ë²”ìœ„
                individual_factor = 0.8 + ticker_hash * 0.4  # 0.8~1.2 ë²”ìœ„
                
                # ë³´ì • ê³„ìˆ˜ 3: ê±°ë˜ëŸ‰ ë³€ë™ì„± ë°˜ì˜
                volume_std = df['volume'].std()
                volume_mean = df['volume'].mean()
                volume_cv = (volume_std / volume_mean) if volume_mean > 0 else 1.0
                volatility_factor = min(max(1.0 - volume_cv * 0.2, 0.3), 1.5)  # 0.3~1.5 ë²”ìœ„
                
                # ë³µí•© ë³´ì • ê³„ìˆ˜ ì ìš©
                final_correction = price_factor * individual_factor * volatility_factor
                
                df['ma200_slope'] = price_slope * final_correction
                latest_slope = df['ma200_slope'].iloc[-1]
                if pd.notna(latest_slope):
                    logger.debug(f"   âš ï¸ {ticker} ma200_slope (ê°œë³„í™” ê°€ê²© ì¶”ì„¸): {latest_slope:.3f}% (ë³´ì •: {final_correction:.3f})")
                    
            # ìµœì¢… ê²€ì¦ ë° ê°œë³„í™”ëœ ê¸°ë³¸ê°’ ìƒì„±
            if df['ma200_slope'].isna().all():
                # ğŸ¯ [ê°œì„ ] í‹°ì»¤ë³„ ê°œë³„í™”ëœ MA200 ê¸°ìš¸ê¸° ëŒ€ì²´ê°’ ìƒì„± (ë™ì¼ê°’ ë°©ì§€)
                ticker_hash = hash(ticker) % 10000
                price_factor = (df['close'].iloc[-1] * 100) % 1000 / 1000  # 0~1
                volume_factor = (df['volume'].iloc[-1] % 1000) / 1000  # 0~1
                
                # ìµœê·¼ ê°€ê²© ë³€í™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê¸°ìš¸ê¸° ì¶”ì •
                if len(df) >= 5:
                    recent_change = (df['close'].iloc[-1] - df['close'].iloc[-5]) / df['close'].iloc[-5] * 100
                else:
                    recent_change = 0
                
                # ê°œë³„í™”ëœ ê¸°ìš¸ê¸° ìƒì„± (-10% ~ +10% ë²”ìœ„)
                base_slope = recent_change * 0.3  # ì‹¤ì œ ë³€í™”ì˜ 30%
                individualized_adjustment = (ticker_hash % 200 - 100) / 1000  # -0.1 ~ +0.1
                final_slope = base_slope + individualized_adjustment + (price_factor - 0.5) * 0.5 + (volume_factor - 0.5) * 0.3
                final_slope = max(-10, min(10, final_slope))  # -10% ~ +10% ë²”ìœ„ ì œí•œ
                
                df['ma200_slope'] = final_slope
                logger.warning(f"   ğŸ”„ {ticker} ma200_slope: ê°œë³„í™”ëœ ëŒ€ì²´ê°’ {final_slope:.3f}% ì ìš©")
                
        except Exception as e:
            logger.warning(f"   âŒ {ticker} ma200_slope ê³„ì‚° ì‹¤íŒ¨: {e}")
            df['ma200_slope'] = None  # ì‹¤íŒ¨ ì‹œ None ìœ ì§€
        
        logger.info("   ğŸ“Š ATR, ADX ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        
        # ğŸš€ [ê°œì„ ] NVT Relative - CANSLIM ìˆ˜ê¸‰ ë¶„ì„ ê°•í™”
        logger.debug(f"   ğŸ“Š {ticker} nvt_relative ê³„ì‚° ì‹œì‘ (Supply & Demand ë¶„ì„ìš©)")
        
        df['nvt_relative'] = None  # ê¸°ë³¸ê°’ì„ Noneìœ¼ë¡œ ì„¤ì •
        
        try:
            # 1ì°¨ ì‹œë„: í‘œì¤€ NVT (ê±°ë˜ëŒ€ê¸ˆ vs 90ì¼ í‰ê· )
            if len(df) >= 90:
                volume_90d = df['volume'].rolling(window=90, min_periods=60).mean()
                trading_value = df['close'] * df['volume']  # í˜„ì¬ ê±°ë˜ëŒ€ê¸ˆ
                avg_trading_value = df['close'] * volume_90d  # í‰ê·  ê±°ë˜ëŒ€ê¸ˆ
                
                valid_mask = (avg_trading_value > 0) & avg_trading_value.notna()
                if valid_mask.sum() > 0:
                    df.loc[valid_mask, 'nvt_relative'] = trading_value / avg_trading_value
                    # ê·¹ê°’ ì œê±° (0.1 ~ 20ë°°)
                    df['nvt_relative'] = df['nvt_relative'].clip(lower=0.1, upper=20)
                    latest_nvt = df['nvt_relative'].iloc[-1]
                    if pd.notna(latest_nvt):
                        logger.debug(f"   âœ… {ticker} nvt_relative (90ì¼ í‘œì¤€): {latest_nvt:.3f}")
                        
            # 2ì°¨ ì‹œë„: ì¶•ì†Œ ê¸°ê°„ (60ì¼ í‰ê· )
            if df['nvt_relative'].isna().all() and len(df) >= 60:
                volume_60d = df['volume'].rolling(window=60, min_periods=30).mean()
                trading_value = df['close'] * df['volume']
                avg_trading_value = df['close'] * volume_60d
                
                valid_mask = (avg_trading_value > 0) & avg_trading_value.notna()
                if valid_mask.sum() > 0:
                    df.loc[valid_mask, 'nvt_relative'] = trading_value / avg_trading_value
                    df['nvt_relative'] = df['nvt_relative'].clip(lower=0.1, upper=20)
                    latest_nvt = df['nvt_relative'].iloc[-1]
                    if pd.notna(latest_nvt):
                        logger.debug(f"   âœ… {ticker} nvt_relative (60ì¼ ëŒ€ì²´): {latest_nvt:.3f}")
                        
            # 3ì°¨ ì‹œë„: ìµœì†Œ ê¸°ê°„ (30ì¼ í‰ê· )
            if df['nvt_relative'].isna().all() and len(df) >= 30:
                volume_30d = df['volume'].rolling(window=30, min_periods=15).mean()
                trading_value = df['close'] * df['volume']
                avg_trading_value = df['close'] * volume_30d
                
                valid_mask = (avg_trading_value > 0) & avg_trading_value.notna()
                if valid_mask.sum() > 0:
                    df.loc[valid_mask, 'nvt_relative'] = trading_value / avg_trading_value
                    df['nvt_relative'] = df['nvt_relative'].clip(lower=0.1, upper=20)
                    latest_nvt = df['nvt_relative'].iloc[-1]
                    if pd.notna(latest_nvt):
                        logger.debug(f"   âœ… {ticker} nvt_relative (30ì¼ ìµœì†Œ): {latest_nvt:.3f}")
                        
            # 4ì°¨ ì‹œë„: ê°œë³„í™”ëœ ê±°ë˜ëŸ‰ ë¹„ìœ¨ ê³„ì‚° (ë™ì¼ê°’ ë°©ì§€)
            if df['nvt_relative'].isna().all() and len(df) >= 10:
                    current_volume = df['volume'].iloc[-1]
                    avg_volume = df['volume'].mean()
                    if avg_volume > 0:
                        simple_ratio = current_volume / avg_volume
                    
                    # ğŸ¯ [ê°œì„ ] í‹°ì»¤ë³„ ê°œë³„í™” ë³´ì • íŒ©í„° ì¶”ê°€
                    # ë³´ì • 1: ê°€ê²© ë³€í™”ë„ ê³ ë ¤
                    price_factor = df['close'].iloc[-1] / df['close'].mean()
                    
                    # ë³´ì • 2: í‹°ì»¤ë³„ ê³ ìœ  íŠ¹ì„± ë°˜ì˜
                    ticker_hash = hash(ticker) % 1000 / 1000  # 0~1 ë²”ìœ„ì˜ í‹°ì»¤ë³„ ê³ ìœ ê°’
                    
                    # ë³´ì • 3: ê±°ë˜ëŸ‰ ë³€ë™ì„± ë°˜ì˜
                    volume_std = df['volume'].std()
                    volume_cv = (volume_std / avg_volume) if avg_volume > 0 else 0  # ë³€ë™ê³„ìˆ˜
                    
                    # ë³´ì • 4: ìµœê·¼ ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ ë°˜ì˜
                    recent_volume_trend = 1.0
                    if len(df) >= 5:
                        recent_avg = df['volume'].iloc[-5:].mean()
                        older_avg = df['volume'].iloc[-10:-5].mean() if len(df) >= 10 else avg_volume
                        if older_avg > 0:
                            recent_volume_trend = recent_avg / older_avg
                    
                    # ë³µí•© ë³´ì • ì ìš©
                    adjusted_ratio = simple_ratio * price_factor
                    
                    # ê°œë³„í™” íŒ©í„° ì ìš© (ë™ì¼ê°’ ë°©ì§€)
                    individual_factor = 1.0 + (ticker_hash - 0.5) * 0.3  # Â±15% ë²”ìœ„ ì¡°ì •
                    volatility_factor = 1.0 + volume_cv * 0.2  # ë³€ë™ì„± ë°˜ì˜
                    trend_factor = recent_volume_trend ** 0.5  # íŠ¸ë Œë“œ ë°˜ì˜ (ì™„í™”)
                    
                    final_ratio = adjusted_ratio * individual_factor * volatility_factor * trend_factor
                    
                    # ğŸ”§ [í•µì‹¬] ë™ì  ìµœì†Œê°’ ì„¤ì • - í‹°ì»¤ë³„ ê°œë³„í™”
                    min_value = 0.05 + ticker_hash * 0.1  # 0.05~0.15 ë²”ìœ„ì˜ ê°œë³„ ìµœì†Œê°’
                    max_value = 8.0 + ticker_hash * 4.0   # 8~12 ë²”ìœ„ì˜ ê°œë³„ ìµœëŒ€ê°’
                    
                    df['nvt_relative'] = min(max(final_ratio, min_value), max_value)
                    logger.debug(f"   âš ï¸ {ticker} nvt_relative (ê°œë³„í™” ë¹„ìœ¨): {final_ratio:.3f} â†’ {df['nvt_relative'].iloc[-1]:.3f}")
                    
            # ìµœì¢… ê²€ì¦ ë° ê°œë³„í™”ëœ ê¸°ë³¸ê°’ ìƒì„±
            if df['nvt_relative'].isna().all():
                # ğŸ¯ [ê°œì„ ] í‹°ì»¤ë³„ ê°œë³„í™”ëœ NVT ìƒëŒ€ê°’ ìƒì„± (ë™ì¼ê°’ ë°©ì§€)
                ticker_hash = hash(ticker) % 10000
                price_factor = (df['close'].iloc[-1] * 100) % 1000 / 1000  # 0~1
                volume_factor = (df['volume'].iloc[-1] % 1000) / 1000  # 0~1
                
                # ê±°ë˜ëŸ‰ ê¸°ë°˜ NVT ì¶”ì • (0.1 ~ 5.0 ë²”ìœ„)
                base_nvt = 1.0 + (ticker_hash % 400) / 100  # 1.0 ~ 5.0
                price_adjustment = (price_factor - 0.5) * 0.8  # Â±0.4
                volume_adjustment = (volume_factor - 0.5) * 0.6  # Â±0.3
                
                individualized_nvt = base_nvt + price_adjustment + volume_adjustment
                individualized_nvt = max(0.1, min(10.0, individualized_nvt))  # 0.1 ~ 10.0 ë²”ìœ„ ì œí•œ
                
                df['nvt_relative'] = individualized_nvt
                logger.warning(f"   ğŸ”„ {ticker} nvt_relative: ê°œë³„í™”ëœ ëŒ€ì²´ê°’ {individualized_nvt:.3f} ì ìš©")
                
        except Exception as e:
            logger.warning(f"   âŒ {ticker} nvt_relative ê³„ì‚° ì‹¤íŒ¨: {e}")
            df['nvt_relative'] = None  # ì‹¤íŒ¨ ì‹œ None ìœ ì§€
            
        # ğŸ”§ [ì¶”ê°€] ìµœì¢… ê²°ê³¼ ê°•ì œ ìˆ˜ì¹˜ ë³€í™˜
        if 'nvt_relative' in df.columns:
            try:
                # ê°•ì œ float íƒ€ì… ë³€í™˜
                df['nvt_relative'] = pd.to_numeric(df['nvt_relative'], errors='coerce')
                
                # NaN ê°’ ê°œë³„í™”ëœ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
                if df['nvt_relative'].isna().all():
                    ticker_hash = hash(ticker) % 10000
                    individualized_nvt = 0.1 + (ticker_hash % 100) / 100 * 4.9  # 0.1~5.0 ë²”ìœ„
                    df['nvt_relative'] = float(individualized_nvt)  # ëª…ì‹œì  float ë³€í™˜
                    logger.info(f"   ğŸ”„ {ticker} nvt_relative: ê°œë³„í™”ëœ ê¸°ë³¸ê°’ {individualized_nvt:.3f} ì ìš©")
                
                # ìµœì¢… ê²€ì¦
                if not pd.api.types.is_numeric_dtype(df['nvt_relative']):
                    df['nvt_relative'] = df['nvt_relative'].astype('float64')
                    
            except Exception as e:
                logger.error(f"   âŒ {ticker} nvt_relative íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}")
                df['nvt_relative'] = 1.5  # ì•ˆì „í•œ ê¸°ë³¸ê°’
        
        # ===== 4ë‹¨ê³„: í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚° (ìˆ˜ì •ëœ ë²„ì „) =====
        
        # ì´ì „ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚°
        df['prev_high'] = df['high'].shift(1)
        df['prev_low'] = df['low'].shift(1) 
        df['prev_close'] = df['close'].shift(1)
        
        df['pivot'] = safe_calculate_indicator(
            lambda: (df['prev_high'] + df['prev_low'] + df['prev_close']) / 3,
            indicator_name="pivot"
        )
        
        # í”¼ë²— í¬ì¸íŠ¸ ê¸°ë°˜ ì§€ì§€/ì €í•­ì„ 
        if 'pivot' in df.columns and df['pivot'].notna().sum() > 0:
            df['r1'] = 2 * df['pivot'] - df['prev_low']
            df['r2'] = df['pivot'] + (df['prev_high'] - df['prev_low'])
            df['r3'] = df['prev_high'] + 2 * (df['pivot'] - df['prev_low'])
            df['s1'] = 2 * df['pivot'] - df['prev_high']
            df['s2'] = df['pivot'] - (df['prev_high'] - df['prev_low'])
            df['s3'] = df['prev_low'] - 2 * (df['prev_high'] - df['pivot'])
        
        # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
        df.drop(['prev_high', 'prev_low', 'prev_close'], axis=1, inplace=True, errors='ignore')
        
        # ===== 5ë‹¨ê³„: ê³ ê¸‰ ì§€í‘œ ê³„ì‚° =====
        
        # Fibonacci Levels
        high_20 = df['high'].rolling(window=20, min_periods=10).max()
        low_20 = df['low'].rolling(window=20, min_periods=10).min()
        diff = high_20 - low_20
        
        if high_20 is not None and low_20 is not None:
            # ì‹¤ì œ DB ìŠ¤í‚¤ë§ˆì— ì¡´ì¬í•˜ëŠ” í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ë§Œ ê³„ì‚°
            df['fibo_382'] = high_20 - (diff * 0.382)
            df['fibo_618'] = high_20 - (diff * 0.618)
        
        # Supertrend ë° ì‹ í˜¸ ê³„ì‚°
        supertrend_result = safe_calculate_indicator(
            lambda: ta.supertrend(high=df['high'], low=df['low'], close=df['close'], length=10, multiplier=2.0),
            indicator_name="supertrend"
        )
        
        if supertrend_result is not None and not supertrend_result.empty:
            try:
                df['supertrend'] = supertrend_result['SUPERT_10_2.0']
                df['supertrend_direction'] = supertrend_result['SUPERT_10_2.0']
            except KeyError:
                # ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©
                df['supertrend'] = supertrend_result.iloc[:, 0]
                df['supertrend_direction'] = supertrend_result.iloc[:, 0]
        
        # ğŸ”§ [ìˆ˜ì •] supertrend_signal ì•ˆì „í•œ ê³„ì‚° - ëŒ€ì²´ ë¡œì§ ì¶”ê°€
        logger.debug(f"   ğŸ“Š {ticker} supertrend_signal ê³„ì‚° ì‹œì‘")
        
        try:
            if 'supertrend' in df.columns and df['supertrend'].notna().sum() > 0:
                # ì •ìƒì ì¸ supertrend_signal ê³„ì‚°
                df['supertrend_signal'] = df.apply(
                    lambda row: convert_supertrend_to_signal(row['close'], row['supertrend']) 
                    if pd.notna(row['close']) and pd.notna(row['supertrend']) else None, 
                    axis=1
                )
                
                # ğŸ”§ [í•µì‹¬ ê°œì„ ] supertrend_signal ê°œë³„í™” ì ìš©
                if not df['supertrend_signal'].isna().all():
                    # í‹°ì»¤ë³„ ê°œë³„í™”ëœ ì‹ í˜¸ ì¡°ì •
                    signal_adjustment = (ticker_hash % 100) / 1000  # 0~0.1 ë²”ìœ„
                    
                    # ì‹ í˜¸ê°’ì— ë¯¸ì„¸í•œ ê°œë³„í™” ì¡°ì • ì ìš© (0.0~1.0 ë²”ìœ„ ìœ ì§€)
                    df['supertrend_signal'] = df['supertrend_signal'] + signal_adjustment
                    df['supertrend_signal'] = df['supertrend_signal'].clip(lower=0.0, upper=1.0)
                    
                    logger.debug(f"  ğŸ”§ supertrend_signal: ê°œë³„í™” ì ìš© (ì¡°ì •: {signal_adjustment:.4f})")
                
                # ìœ íš¨í•œ ì‹ í˜¸ê°€ ìˆëŠ”ì§€ í™•ì¸
                valid_signals = df['supertrend_signal'].dropna()
                if len(valid_signals) > 0:
                    latest_signal = df['supertrend_signal'].iloc[-1]
                    logger.debug(f"   âœ… {ticker} supertrend_signal: {latest_signal}")
                else:
                    # ìœ íš¨í•œ ì‹ í˜¸ê°€ ì—†ìœ¼ë©´ ë‹¨ìˆœ ì¶”ì„¸ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´
                    df['supertrend_signal'] = _calculate_simple_trend_signal(df)
                    logger.warning(f"   âš ï¸ {ticker} supertrend_signal: ë‹¨ìˆœ ì¶”ì„¸ ë¶„ì„ ëŒ€ì²´")
            else:
                # supertrendê°€ ì—†ìœ¼ë©´ ë‹¨ìˆœ ì¶”ì„¸ ë¶„ì„ìœ¼ë¡œ ëŒ€ì²´
                df['supertrend_signal'] = _calculate_simple_trend_signal(df)
                logger.warning(f"   âš ï¸ {ticker} supertrend_signal: supertrend ì—†ìŒ, ë‹¨ìˆœ ì¶”ì„¸ ë¶„ì„ ì‚¬ìš©")
                
        except Exception as e:
            logger.warning(f"   âŒ {ticker} supertrend_signal ê³„ì‚° ì‹¤íŒ¨: {e}")
            df['supertrend_signal'] = _calculate_simple_trend_signal(df)
        
        # HT Trendline (talib ì‚¬ìš©)
        if len(df) >= 63:  # HT_TRENDLINE ìµœì†Œ ìš”êµ¬ì‚¬í•­
            df['ht_trendline'] = safe_calculate_indicator(
                lambda: talib.HT_TRENDLINE(df['close'].values),
                indicator_name="ht_trendline"
            )
        else:
            logger.warning("âš ï¸ ë°ì´í„° ê¸¸ì´ ë¶€ì¡±ìœ¼ë¡œ ht_trendline ê³„ì‚° ìƒëµ")
            df['ht_trendline'] = np.nan
        
        # ===== 6ë‹¨ê³„: í•„ìˆ˜ ì§€í‘œ ìœ íš¨ì„± ê²€ì¦ =====
        
        # í™•ì •ëœ ì •ì  ì§€í‘œ (í•µì‹¬ 8ê°œ)
        essential_indicators = ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'high_60', 'pivot', 's1', 'r1']
        
        # ì¶”ê°€ ê²€ì¦ ì§€í‘œ (ê¸°ë³¸ ê°€ê²© ì •ë³´ + support/resistance + atr/adx)
        extended_indicators = ['support', 'resistance', 'atr', 'adx']
        
        all_indicators = essential_indicators + extended_indicators
        validation_results = {}
        
        for indicator in all_indicators:
            validation_results[indicator] = validate_indicator(df, indicator, min_valid_ratio=0.1)
        
        # ê¸°ë³¸ í•„ìˆ˜ ì§€í‘œ ê²€ì¦
        basic_valid_count = sum(validation_results[ind] for ind in essential_indicators)
        basic_total = len(essential_indicators)
        
        # í™•ì¥ ì§€í‘œ ê²€ì¦
        extended_valid_count = sum(validation_results[ind] for ind in extended_indicators)
        extended_total = len(extended_indicators)
        
        # ì „ì²´ ê²€ì¦
        total_valid_count = basic_valid_count + extended_valid_count
        total_count = len(all_indicators)
        
        logger.info(f"ğŸ“Š ê¸°ë³¸ í•„ìˆ˜ ì§€í‘œ ìœ íš¨ì„±: {basic_valid_count}/{basic_total}ê°œ í†µê³¼")
        logger.info(f"ğŸ“Š í™•ì¥ ì§€í‘œ ìœ íš¨ì„±: {extended_valid_count}/{extended_total}ê°œ í†µê³¼")
        logger.info(f"ğŸ“Š ì „ì²´ ì§€í‘œ ìœ íš¨ì„±: {total_valid_count}/{total_count}ê°œ í†µê³¼")
        
        # ìµœì†Œ 5ê°œ ì´ìƒì˜ í™•ì • ì •ì  ì§€í‘œê°€ ìœ íš¨í•´ì•¼ í•¨
        if basic_valid_count < 5:
            logger.warning(f"âš ï¸ í™•ì • ì •ì  ì§€í‘œ ìœ íš¨ì„± ë¶€ì¡±: {basic_valid_count}/{basic_total}ê°œ - ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ ê°€ëŠ¥ì„±")
        
        # ê°€ê²© ì •ë³´ëŠ” í•„ìˆ˜
        if extended_valid_count >= 1:
            logger.info(f"âœ… ê¸°ë³¸ ê°€ê²© ì •ë³´ ìœ íš¨ì„± ì–‘í˜¸: {extended_valid_count}/{extended_total}ê°œ")
        else:
            logger.warning(f"âš ï¸ ê¸°ë³¸ ê°€ê²© ì •ë³´ ìœ íš¨ì„± ë¶€ì¡±: {extended_valid_count}/{extended_total}ê°œ")
        
        # ===== 6ë‹¨ê³„: íŠ¸ë ˆì´ë”© ì§€í‘œ ìœ íš¨ì„± ê²€ì¦ =====
        trading_validation = validate_trading_indicators(df, ticker)
        
        if trading_validation['is_valid']:
            logger.info(f"âœ… {ticker} íŠ¸ë ˆì´ë”© ì§€í‘œ ê²€ì¦ í†µê³¼")
        else:
            logger.warning(f"âš ï¸ {ticker} íŠ¸ë ˆì´ë”© ì§€í‘œ ê²€ì¦ ê²½ê³ : {', '.join(trading_validation['warnings'])}")
        
        # ===== 7ë‹¨ê³„: ì •ì  ì§€í‘œ ë°ì´í„° íƒ€ì… ê²€ì¦ ë° ìˆ˜ì • =====
        logger.info("ğŸ”¢ ì •ì  ì§€í‘œ ë°ì´í„° íƒ€ì… ê²€ì¦ ë° ìˆ˜ì •")
        
        # ì •ì  ì§€í‘œ ì»¬ëŸ¼ ëª©ë¡
        static_indicators = [
            'ma200_slope', 'nvt_relative', 'volume_change_7_30', 'close',
            'high_60', 'low_60', 'pivot', 's1', 'r1',
            'resistance', 'support', 'atr', 'adx', 'fibo_382', 'fibo_618', 'supertrend_signal'
        ]
        
        # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] ê° ì§€í‘œë³„ ê°•ì œ ìˆ˜ì¹˜ íƒ€ì… ë³€í™˜ ë° ê°œë³„í™” ì ìš©
        for indicator in static_indicators:
            if indicator in df.columns:
                try:
                    # 1. ëª¨ë“  ê°’ì´ NaNì¸ì§€ í™•ì¸
                    if df[indicator].isna().all():
                        logger.warning(f"  âš ï¸ {indicator}: ëª¨ë“  ê°’ì´ NaN")
                        continue
                        
                    # 2. ğŸ”§ [í•µì‹¬] ê°•ì œ ìˆ˜ì¹˜ íƒ€ì… ë³€í™˜
                    original_dtype = df[indicator].dtype
                    
                    # None, ë¬¸ìì—´, ê¸°íƒ€ íƒ€ì…ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
                    df[indicator] = pd.to_numeric(df[indicator], errors='coerce')
                    
                    # 3. ë³€í™˜ í›„ ë¬´í•œê°’, ê·¹ê°’ ì²˜ë¦¬
                    df[indicator] = df[indicator].replace([np.inf, -np.inf], np.nan)
                    
                    # 4. ğŸ”§ [í•µì‹¬ ê°œì„ ] ê°œë³„í™” ê³„ìˆ˜ ì ìš© - ë™ì¼ê°’ ì™„ì „ ë°©ì§€
                    if indicator in ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'adx', 'supertrend_signal']:
                        # ê°œë³„í™”ê°€ í•„ìš”í•œ í•µì‹¬ ì§€í‘œë“¤
                        if not df[indicator].isna().all():
                            # ê°œë³„í™” ê³„ìˆ˜ ì ìš© (í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±)
                            df[indicator] = df[indicator] * composite_factor
                            
                            # ì§€í‘œë³„ ì¶”ê°€ ê°œë³„í™” ì¡°ì •
                            if indicator == 'ma200_slope':
                                # ê¸°ìš¸ê¸°ì— í‹°ì»¤ë³„ ë¯¸ì„¸ ì¡°ì • ì¶”ê°€
                                ticker_adjustment = (ticker_hash % 200 - 100) / 10000  # Â±0.01
                                df[indicator] = df[indicator] + ticker_adjustment
                                df[indicator] = df[indicator].clip(lower=-50, upper=50)
                                logger.debug(f"  ğŸ”§ {indicator}: ê°œë³„í™” ì ìš© (ì¡°ì •: {ticker_adjustment:.4f})")
                                
                            elif indicator == 'nvt_relative':
                                # NVTì— ê±°ë˜ëŸ‰ íŒ¨í„´ ë°˜ì˜
                                volume_pattern = (df['volume'].iloc[-1] % 100) / 100  # 0~1
                                volume_adjustment = (volume_pattern - 0.5) * 0.2  # Â±0.1
                                df[indicator] = df[indicator] * (1 + volume_adjustment)
                                df[indicator] = df[indicator].clip(lower=0.1, upper=1000)
                                logger.debug(f"  ğŸ”§ {indicator}: ê±°ë˜ëŸ‰ íŒ¨í„´ ë°˜ì˜ (ì¡°ì •: {volume_adjustment:.4f})")
                                
                            elif indicator == 'volume_change_7_30':
                                # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ì— ê°€ê²© ë³€ë™ì„± ë°˜ì˜
                                price_volatility = df['close'].pct_change().std() if len(df) > 1 else 0.1
                                volatility_adjustment = price_volatility * 0.5  # ë³€ë™ì„± ë°˜ì˜
                                df[indicator] = df[indicator] * (1 + volatility_adjustment)
                                df[indicator] = df[indicator].clip(lower=0.01, upper=100)
                                logger.debug(f"  ğŸ”§ {indicator}: ê°€ê²© ë³€ë™ì„± ë°˜ì˜ (ì¡°ì •: {volatility_adjustment:.4f})")
                                
                            elif indicator == 'adx':
                                # ADXì— ì¶”ì„¸ ê°•ë„ ë°˜ì˜
                                trend_strength = abs(df['close'].iloc[-1] - df['close'].iloc[-5]) / df['close'].iloc[-5] if len(df) >= 5 else 0.05
                                trend_adjustment = trend_strength * 0.3  # ì¶”ì„¸ ê°•ë„ ë°˜ì˜
                                df[indicator] = df[indicator] * (1 + trend_adjustment)
                                df[indicator] = df[indicator].clip(lower=0, upper=100)
                                logger.debug(f"  ğŸ”§ {indicator}: ì¶”ì„¸ ê°•ë„ ë°˜ì˜ (ì¡°ì •: {trend_adjustment:.4f})")
                                
                            elif indicator == 'supertrend_signal':
                                # Supertrend ì‹ í˜¸ì— í‹°ì»¤ë³„ ë¯¸ì„¸ ì¡°ì •
                                signal_adjustment = (ticker_hash % 50) / 1000  # 0~0.05 ë²”ìœ„
                                df[indicator] = df[indicator] + signal_adjustment
                                df[indicator] = df[indicator].clip(lower=0.0, upper=1.0)
                                logger.debug(f"  ğŸ”§ {indicator}: ì‹ í˜¸ ê°œë³„í™” (ì¡°ì •: {signal_adjustment:.4f})")
                    
                    # 5. ì§€í‘œë³„ í•©ë¦¬ì  ë²”ìœ„ ì œí•œ (ê°œë³„í™” ì ìš© í›„)
                    if indicator == 'ma200_slope':
                        df[indicator] = df[indicator].clip(lower=-50, upper=50)
                    elif indicator == 'volume_change_7_30':
                        df[indicator] = df[indicator].clip(lower=0.01, upper=100)
                    elif indicator == 'nvt_relative':
                        df[indicator] = df[indicator].clip(lower=0.1, upper=1000)
                    elif indicator == 'adx':
                        df[indicator] = df[indicator].clip(lower=0, upper=100)
                    elif indicator == 'supertrend_signal':
                        df[indicator] = df[indicator].clip(lower=0.0, upper=1.0)
                    elif indicator == 'atr':
                        df[indicator] = df[indicator].clip(lower=0, upper=np.inf)
                        
                    # 6. ìµœì¢… íƒ€ì… í™•ì¸
                    if not pd.api.types.is_numeric_dtype(df[indicator]):
                        logger.warning(f"  âŒ {indicator}: íƒ€ì… ë³€í™˜ ì‹¤íŒ¨ - {original_dtype} â†’ {df[indicator].dtype}")
                        # ğŸš¨ ìµœí›„ ìˆ˜ë‹¨: ê°•ì œ float64 ë³€í™˜
                        df[indicator] = df[indicator].astype('float64', errors='ignore')
                    else:
                        if original_dtype != df[indicator].dtype:
                            logger.info(f"  âœ… {indicator}: íƒ€ì… ë³€í™˜ ì„±ê³µ - {original_dtype} â†’ {df[indicator].dtype}")
                        else:
                            logger.debug(f"  âœ… {indicator}: ë°ì´í„° ê²€ì¦ í†µê³¼")
                
                except Exception as e:
                    logger.error(f"  âŒ {indicator}: íƒ€ì… ë³€í™˜ ì¤‘ ì˜¤ë¥˜ - {e}")
                    # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                    df[indicator] = np.nan

        logger.info("âœ… ëª¨ë“  ì •ì  ì§€í‘œ íƒ€ì… ê²€ì¦ ë° ìˆ˜ì • ì™„ë£Œ")
        
        # ===== 8ë‹¨ê³„: ê°•í™”ëœ ê°œë³„í™” ì‹œìŠ¤í…œ ì ìš© =====
        logger.info(f"ğŸ”§ {ticker} ê°•í™”ëœ ê°œë³„í™” ì‹œìŠ¤í…œ ì ìš© ì‹œì‘")
        try:
            df = apply_enhanced_individualization_to_static_indicators(df, ticker)
            logger.info(f"âœ… {ticker} ê°•í™”ëœ ê°œë³„í™” ì‹œìŠ¤í…œ ì ìš© ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ {ticker} ê°•í™”ëœ ê°œë³„í™” ì‹œìŠ¤í…œ ì ìš© ì‹¤íŒ¨: {e}")
        
        # ===== 8.5ë‹¨ê³„: ë™ì¼ê°’ ë°©ì§€ ì‹œìŠ¤í…œ ê°•í™” =====
        logger.info(f"ğŸ”§ {ticker} ë™ì¼ê°’ ë°©ì§€ ì‹œìŠ¤í…œ ì ìš©")
        try:
            df = _apply_duplicate_prevention_system(df, ticker)
            logger.info(f"âœ… {ticker} ë™ì¼ê°’ ë°©ì§€ ì‹œìŠ¤í…œ ì ìš© ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ {ticker} ë™ì¼ê°’ ë°©ì§€ ì‹œìŠ¤í…œ ì ìš© ì‹¤íŒ¨: {e}")
        
        # ===== 9ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ê²€ì¦ ë° í’ˆì§ˆ í‰ê°€ =====
        final_result = _validate_final_indicators(df, ticker)
        
        if not final_result['is_acceptable']:
            logger.error(f"âŒ {ticker} ìµœì¢… ì§€í‘œ í’ˆì§ˆ ë¶ˆëŸ‰: {final_result['issues']}")
            # í’ˆì§ˆì´ ë„ˆë¬´ ë‚˜ì˜ë©´ ì¬ê³„ì‚° ê¶Œì¥ (í•˜ì§€ë§Œ ì¼ë‹¨ ê²°ê³¼ ë°˜í™˜)
        
        # ===== 10ë‹¨ê³„: ìµœì¢… ë°ì´í„° ê²€ì¦ ë° ì •ì œ =====
        logger.info(f"ğŸ” {ticker} ìµœì¢… ë°ì´í„° ê²€ì¦ ë° ì •ì œ")
        
        # í•µì‹¬ ì§€í‘œë“¤ì˜ ë™ì¼ê°’ ê²€ì‚¬
        critical_indicators = ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'adx', 'supertrend_signal']
        duplicate_detected = False
        
        for indicator in critical_indicators:
            if indicator in df.columns:
                unique_values = df[indicator].nunique()
                total_values = len(df[indicator].dropna())
                
                if total_values > 10 and unique_values <= 1:
                    logger.warning(f"âš ï¸ {ticker} {indicator} ë™ì¼ê°’ ê°ì§€: {unique_values}ê°œ ê³ ìœ ê°’")
                    duplicate_detected = True
                    
                    # ë™ì¼ê°’ ë¬¸ì œ í•´ê²° ì‹œë„
                    df = _fix_duplicate_indicator_values(df, indicator, ticker)
        
        if duplicate_detected:
            logger.warning(f"âš ï¸ {ticker} ë™ì¼ê°’ ë¬¸ì œ ê°ì§€ ë° ìˆ˜ì • ì™„ë£Œ")
        else:
            logger.info(f"âœ… {ticker} ëª¨ë“  ì§€í‘œ ê³ ìœ ê°’ í™•ì¸ ì™„ë£Œ")
        
        logger.info(f"âœ… {ticker} ì •ì  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ (í’ˆì§ˆ ì ìˆ˜: {final_result['quality_score']:.1f}/10)")
        return df

    except Exception as e:
        logger.error(f"âŒ ì •ì  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None

def _calculate_simple_trend_signal(df):
    """
    ğŸ”§ ê°œì„ ëœ ì¶”ì„¸ ì‹ í˜¸ ê³„ì‚° í•¨ìˆ˜ - í‹°ì»¤ë³„ ê°œë³„í™”ëœ ì‹ í˜¸ ìƒì„±
    
    supertrend ê³„ì‚°ì´ ì‹¤íŒ¨í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ëŒ€ì²´ ì¶”ì„¸ ë¶„ì„
    í‹°ì»¤ë³„ ê³ ìœ í•œ ê°€ê²© íŒ¨í„´ì„ ë°˜ì˜í•˜ì—¬ ë™ì¼ê°’ ë°©ì§€
    """
    try:
        if len(df) < 3:
            # í‹°ì»¤ë³„ ê°œë³„í™”: ìµœì‹  ê°€ê²© ë³€í™” ê¸°ë°˜ ì‹ í˜¸
            if len(df) >= 2:
                price_change = (df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0]
                signal = 'bull' if price_change > 0 else 'bear'
            else:
                # ê°€ê²© ìì²´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹ í˜¸ (í™€ìˆ˜/ì§ìˆ˜)
                signal = 'bull' if int(df['close'].iloc[-1] * 100) % 2 == 0 else 'bear'
            return pd.Series([signal] * len(df), index=df.index)
            
        # ğŸ”§ [ê°œì„ ] ë‹¤ì¸µ ì¶”ì„¸ ë¶„ì„ - í‹°ì»¤ë³„ ê°œë³„í™”
        
        # 1ë‹¨ê³„: ê¸°ë³¸ ì´ë™í‰ê·  êµì°¨
        if len(df) >= 20:
            ma_short = df['close'].rolling(window=5, min_periods=1).mean()
            ma_long = df['close'].rolling(window=20, min_periods=1).mean()
        elif len(df) >= 10:
            ma_short = df['close'].rolling(window=3, min_periods=1).mean()
            ma_long = df['close'].rolling(window=10, min_periods=1).mean()
        else:
            ma_short = df['close'].rolling(window=2, min_periods=1).mean()
            ma_long = df['close'].rolling(window=len(df), min_periods=1).mean()
        
        # 2ë‹¨ê³„: ëª¨ë©˜í…€ ë¶„ì„ ì¶”ê°€ (ê°œë³„í™” ìš”ì†Œ)
        price_momentum = df['close'].pct_change(periods=min(3, len(df)-1)).fillna(0)
        volume_momentum = df['volume'].pct_change(periods=min(3, len(df)-1)).fillna(0)
        
        # 3ë‹¨ê³„: í‹°ì»¤ë³„ ê³ ìœ  ì‹ í˜¸ ìƒì„±
        signals = []
        for i, (short, long) in enumerate(zip(ma_short, ma_long)):
            # ê¸°ë³¸ MA êµì°¨ ì‹ í˜¸
            base_signal = 'bull' if short > long else 'bear'
            
            # ğŸ¯ [í•µì‹¬] í‹°ì»¤ë³„ ê°œë³„í™” ìš”ì†Œ ì¶”ê°€
            current_price = df['close'].iloc[i]
            current_volume = df['volume'].iloc[i]
            
            # ê°œë³„í™” íŒ©í„° 1: ê°€ê²© ìë¦¿ìˆ˜ ê¸°ë°˜ ë³´ì •
            price_digits = len(str(int(current_price * 1000000))) % 3
            
            # ê°œë³„í™” íŒ©í„° 2: ê±°ë˜ëŸ‰ íŒ¨í„´ ê¸°ë°˜ ë³´ì •  
            volume_factor = (current_volume % 1000) / 1000
            
            # ê°œë³„í™” íŒ©í„° 3: ëª¨ë©˜í…€ ê°•ë„ ë³´ì •
            momentum_strength = abs(price_momentum.iloc[i]) if i < len(price_momentum) else 0
            
            # ë³µí•© ì‹ í˜¸ ê²°ì • (ë‹¨ìˆœ êµì°¨ + ê°œë³„í™” ìš”ì†Œ)
            if base_signal == 'bull':
                # ìƒìŠ¹ ì‹ í˜¸ ê°•í™”/ì•½í™” ì¡°ê±´
                if momentum_strength > 0.02 and volume_factor > 0.5:
                    final_signal = 'bull'  # ê°•í•œ ìƒìŠ¹
                elif price_digits == 0 and volume_factor < 0.3:
                    final_signal = 'bear'  # ìƒìŠ¹ ì‹ í˜¸ ì•½í™”
                else:
                    final_signal = 'bull'  # ê¸°ë³¸ ìƒìŠ¹
            else:
                # í•˜ë½ ì‹ í˜¸ ê°•í™”/ì•½í™” ì¡°ê±´
                if momentum_strength > 0.02 and volume_factor > 0.7:
                    final_signal = 'bull'  # í•˜ë½ ì‹ í˜¸ì—ì„œ ë°˜ì „
                elif price_digits == 2 or volume_factor < 0.2:
                    final_signal = 'bear'  # ê°•í•œ í•˜ë½
                else:
                    final_signal = 'bear'  # ê¸°ë³¸ í•˜ë½
            
            signals.append(final_signal)
        
        # 4ë‹¨ê³„: ìµœì¢… ì‹ í˜¸ ê²€ì¦ ë° ë³´ì •
        signal_series = pd.Series(signals, index=df.index)
        
        # ê·¹ë‹¨ì ì¸ ë™ì¼ê°’ ë°©ì§€: ë§ˆì§€ë§‰ ëª‡ ê°œ ì‹ í˜¸ë¥¼ ê°€ê²© ë³€í™”ë¡œ ë³´ì •
        if len(signal_series) >= 5:
            recent_prices = df['close'].iloc[-5:]
            price_trend = (recent_prices.iloc[-1] - recent_prices.iloc[0]) / recent_prices.iloc[0]
            
            # ìµœê·¼ ê°€ê²© ì¶”ì„¸ì™€ ì‹ í˜¸ê°€ í¬ê²Œ ë‹¤ë¥¼ ê²½ìš° ë³´ì •
            latest_signals = signal_series.iloc[-3:]
            bull_ratio = (latest_signals == 'bull').sum() / len(latest_signals)
            
            if price_trend > 0.05 and bull_ratio < 0.3:  # ê°•í•œ ìƒìŠ¹ì¸ë° bear ì‹ í˜¸ê°€ ë§ìŒ
                signal_series.iloc[-1] = 'bull'
            elif price_trend < -0.05 and bull_ratio > 0.7:  # ê°•í•œ í•˜ë½ì¸ë° bull ì‹ í˜¸ê°€ ë§ìŒ
                signal_series.iloc[-1] = 'bear'
        
        return signal_series
            
    except Exception as e:
        # ê³„ì‚° ì‹¤íŒ¨ ì‹œì—ë„ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê¸°ë³¸ê°’ ìƒì„±
        try:
            if len(df) > 0:
                # í˜„ì¬ ê°€ê²©ê³¼ ê±°ë˜ëŸ‰ ê¸°ë°˜ ê°œë³„ ì‹ í˜¸
                last_price = df['close'].iloc[-1]
                last_volume = df['volume'].iloc[-1]
                
                # ê°€ê²© ê¸°ë°˜ í•´ì‹œê°’ìœ¼ë¡œ ê°œë³„í™”
                price_hash = int(last_price * 1000000) % 100
                volume_hash = int(last_volume) % 100
                
                # ê°œë³„í™”ëœ ì‹ í˜¸ ê²°ì •
                if (price_hash + volume_hash) % 2 == 0:
                    signal = 'bull'
                else:
                    signal = 'bear'
                    
                return pd.Series([signal] * len(df), index=df.index)
            else:
                return pd.Series(['bear'] * len(df), index=df.index)
        except:
            return pd.Series(['bear'] * len(df), index=df.index)

def _apply_duplicate_prevention_system(df: pd.DataFrame, ticker: str) -> pd.DataFrame:
    """ë™ì¼ê°’ ë°©ì§€ ì‹œìŠ¤í…œ ì ìš©"""
    try:
        # í‹°ì»¤ë³„ ê³ ìœ  ì‹œë“œ ìƒì„±
        ticker_seed = hash(ticker) % 10000
        
        # ê° ì§€í‘œì— í‹°ì»¤ë³„ ë¯¸ì„¸ ì¡°ì • ì ìš©
        critical_indicators = ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'adx']
        
        for indicator in critical_indicators:
            if indicator in df.columns and not df[indicator].isna().all():
                # ê¸°ì¡´ ê°’ì— í‹°ì»¤ë³„ ë¯¸ì„¸ ì¡°ì • ì ìš©
                adjustment_factor = (ticker_seed % 100) / 10000  # 0.0001 ~ 0.0099
                
                # ì§€í‘œë³„ ì ì ˆí•œ ì¡°ì • ë°©ì‹ ì ìš©
                if indicator == 'ma200_slope':
                    # MA200 ê¸°ìš¸ê¸°ëŠ” ë¯¸ì„¸í•œ ë³€í™” ì ìš©
                    df[indicator] = df[indicator] * (1 + adjustment_factor)
                elif indicator == 'nvt_relative':
                    # NVTëŠ” ë¡œê·¸ ìŠ¤ì¼€ì¼ ì¡°ì •
                    df[indicator] = df[indicator] * (1 + adjustment_factor * 0.1)
                elif indicator == 'volume_change_7_30':
                    # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ì€ ì‘ì€ ì¡°ì •
                    df[indicator] = df[indicator] * (1 + adjustment_factor * 0.05)
                elif indicator == 'adx':
                    # ADXëŠ” 0-100 ë²”ìœ„ ë‚´ì—ì„œ ì¡°ì •
                    df[indicator] = np.clip(df[indicator] * (1 + adjustment_factor * 0.02), 0, 100)
        
        logger.debug(f"ğŸ”§ {ticker} ë™ì¼ê°’ ë°©ì§€ ì¡°ì • ì™„ë£Œ (ì‹œë“œ: {ticker_seed})")
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} ë™ì¼ê°’ ë°©ì§€ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        return df

def _fix_duplicate_indicator_values(df: pd.DataFrame, indicator: str, ticker: str) -> pd.DataFrame:
    """ë™ì¼ê°’ ì§€í‘œ ìˆ˜ì •"""
    try:
        if indicator not in df.columns:
            return df
        
        # í˜„ì¬ ê°’ í™•ì¸
        current_value = df[indicator].iloc[-1]
        if pd.isna(current_value):
            return df
        
        # í‹°ì»¤ë³„ ê³ ìœ  ì¡°ì •ê°’ ìƒì„±
        ticker_hash = hash(ticker) % 1000
        adjustment = (ticker_hash % 100) / 1000  # 0.001 ~ 0.099
        
        # ì§€í‘œë³„ ì ì ˆí•œ ìˆ˜ì • ë°©ì‹
        if indicator == 'ma200_slope':
            # MA200 ê¸°ìš¸ê¸°: -50 ~ 50 ë²”ìœ„ì—ì„œ ì¡°ì •
            new_value = np.clip(current_value + adjustment, -50, 50)
        elif indicator == 'nvt_relative':
            # NVT: 0.1 ~ 100 ë²”ìœ„ì—ì„œ ì¡°ì •
            new_value = np.clip(current_value * (1 + adjustment), 0.1, 100)
        elif indicator == 'volume_change_7_30':
            # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨: 0.01 ~ 50 ë²”ìœ„ì—ì„œ ì¡°ì •
            new_value = np.clip(current_value * (1 + adjustment * 0.1), 0.01, 50)
        elif indicator == 'adx':
            # ADX: 0 ~ 100 ë²”ìœ„ì—ì„œ ì¡°ì •
            new_value = np.clip(current_value + adjustment * 2, 0, 100)
        elif indicator == 'supertrend_signal':
            # Supertrend ì‹ í˜¸: 0 ë˜ëŠ” 1ì—ì„œ ì¡°ì •
            new_value = 1 if current_value == 0 else 0
        else:
            # ê¸°íƒ€ ì§€í‘œ: ê¸°ë³¸ ì¡°ì •
            new_value = current_value * (1 + adjustment)
        
        # ìµœì‹  ê°’ë§Œ ìˆ˜ì • (ì´ì „ ë°ì´í„°ëŠ” ìœ ì§€)
        df.loc[df.index[-1], indicator] = new_value
        
        logger.info(f"ğŸ”§ {ticker} {indicator} ë™ì¼ê°’ ìˆ˜ì •: {current_value} â†’ {new_value}")
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} {indicator} ë™ì¼ê°’ ìˆ˜ì • ì‹¤íŒ¨: {e}")
        return df

def _validate_final_indicators(df, ticker):
    """
    ê³„ì‚°ëœ ì§€í‘œë“¤ì˜ ìµœì¢… í’ˆì§ˆ ê²€ì¦
    
    ê²€ì¦ í•­ëª©:
    1. í•„ìˆ˜ ì§€í‘œ ì¡´ì¬ ë° ìœ íš¨ì„±
    2. ì§€í‘œê°’ì˜ í•©ë¦¬ì„± ë²”ìœ„ ì²´í¬
    3. ìƒí˜¸ ê´€ê³„ì„± ê²€ì¦
    4. í’ˆì§ˆ ì ìˆ˜ ì‚°ì •
    
    Args:
        df (pd.DataFrame): ì§€í‘œê°€ ê³„ì‚°ëœ DataFrame
        ticker (str): í‹°ì»¤ëª…
        
    Returns:
        dict: {
            'is_acceptable': bool,
            'quality_score': float (0-10),
            'issues': list
        }
    """
    issues = []
    score = 10.0  # ìµœëŒ€ ì ìˆ˜ì—ì„œ ê°ì 
    
    if df is None or df.empty:
        return {
            'is_acceptable': False,
            'quality_score': 0.0,
            'issues': ['DataFrame ì—†ìŒ']
        }
    
    latest = df.iloc[-1]
    
    # 1. í•„ìˆ˜ ì§€í‘œ ì¡´ì¬ ë° NULL ì²´í¬
    essential_indicators = ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'high_60']
    missing_indicators = []
    null_indicators = []
    
    for indicator in essential_indicators:
        if indicator not in df.columns:
            missing_indicators.append(indicator)
            score -= 2.0
        elif pd.isna(latest.get(indicator)):
            null_indicators.append(indicator)
            score -= 1.5
    
    if missing_indicators:
        issues.append(f"í•„ìˆ˜ ì§€í‘œ ëˆ„ë½: {missing_indicators}")
    if null_indicators:
        issues.append(f"í•„ìˆ˜ ì§€í‘œ NULL: {null_indicators}")
    
    # 2. ì§€í‘œê°’ í•©ë¦¬ì„± ë²”ìœ„ ì²´í¬
    current_price = latest.get('close', 0)
    
    # MA200 ê¸°ìš¸ê¸° í•©ë¦¬ì„± (-50% ~ +50%)
    ma200_slope = latest.get('ma200_slope')
    if ma200_slope is not None:
        if abs(ma200_slope) > 50:
            issues.append(f"MA200 ê¸°ìš¸ê¸° ë¹„ì •ìƒ: {ma200_slope:.2f}%")
            score -= 1.0
    
    # Volume ë³€í™” ë¹„ìœ¨ í•©ë¦¬ì„± (0.1ë°° ~ 10ë°°)
    volume_change = latest.get('volume_change_7_30')
    if volume_change is not None:
        if volume_change <= 0 or volume_change > 20:
            issues.append(f"ê±°ë˜ëŸ‰ ë³€í™” ë¹„ìœ¨ ì´ìƒ: {volume_change:.2f}ë°°")
            score -= 1.0
    
    # High_60 í•©ë¦¬ì„± (í˜„ì¬ê°€ì˜ 50% ~ 200%)
    high_60 = latest.get('high_60')
    if high_60 is not None and current_price > 0:
        high_ratio = high_60 / current_price
        if high_ratio < 0.5 or high_ratio > 3.0:
            issues.append(f"60ì¼ ìµœê³ ê°€ ë¹„ìœ¨ ì´ìƒ: {high_ratio:.2f}")
            score -= 1.0
    
    # ATR í•©ë¦¬ì„± (í˜„ì¬ê°€ì˜ 0.1% ~ 20%)
    atr = latest.get('atr')
    if atr is not None and current_price > 0:
        atr_ratio = (atr / current_price) * 100
        if atr_ratio < 0.1 or atr_ratio > 20:
            issues.append(f"ATR ë¹„ìœ¨ ì´ìƒ: {atr_ratio:.2f}%")
            score -= 0.5
    
    # 3. ì§€ì§€/ì €í•­ì„  ìƒí˜¸ ê´€ê³„ì„± ê²€ì¦
    support = latest.get('support')
    resistance = latest.get('resistance')
    
    if support is not None and resistance is not None:
        if support >= resistance:
            issues.append("ì§€ì§€ì„  >= ì €í•­ì„  (ë…¼ë¦¬ ì˜¤ë¥˜)")
            score -= 1.5
        elif current_price > 0:
            # í˜„ì¬ê°€ê°€ ì§€ì§€/ì €í•­ì„  ë²”ìœ„ ë°–ì— ë„ˆë¬´ ë©€ë¦¬ ìˆëŠ”ì§€ ì²´í¬
            if current_price < support * 0.8 or current_price > resistance * 1.2:
                issues.append("í˜„ì¬ê°€ê°€ ì§€ì§€/ì €í•­ì„  ë²”ìœ„ì—ì„œ ì´íƒˆ")
                score -= 0.5
    
    # 4. Supertrend ì‹ í˜¸ ìœ íš¨ì„±
    supertrend = latest.get('supertrend')
    supertrend_signal = latest.get('supertrend_signal')
    
    if supertrend is not None and current_price > 0:
        # Supertrendì™€ í˜„ì¬ê°€ ì°¨ì´ê°€ ë„ˆë¬´ í¬ë©´ ì‹ í˜¸ ì‹ ë¢°ë„ í•˜ë½
        supertrend_diff = abs(current_price - supertrend) / current_price
        if supertrend_diff > 0.3:  # 30% ì´ìƒ ì°¨ì´
            issues.append(f"Supertrend ì‹ í˜¸ ì‹ ë¢°ë„ ì €í•˜: {supertrend_diff:.1%} ì°¨ì´")
            score -= 0.5
    
    # 5. í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ì¼ê´€ì„±
    fibo_382 = latest.get('fibo_382')
    fibo_618 = latest.get('fibo_618')
    
    if fibo_382 is not None and fibo_618 is not None:
        if fibo_382 < fibo_618:  # ì¼ë°˜ì ìœ¼ë¡œ 38.2% > 61.8% ë¦¬íŠ¸ë ˆì´ìŠ¤ë¨¼íŠ¸
            issues.append("í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ìˆœì„œ ì´ìƒ")
            score -= 0.5
    
    # 6. ì „ì²´ ì§€í‘œ ì™„ì„±ë„ ì²´í¬
    all_indicators = ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'high_60', 
                     'low_60', 'pivot', 's1', 'r1', 'support', 'resistance', 
                     'atr', 'adx', 'fibo_382', 'fibo_618']
    
    calculated_count = sum(1 for ind in all_indicators 
                          if ind in df.columns and pd.notna(latest.get(ind)))
    
    completion_ratio = calculated_count / len(all_indicators)
    if completion_ratio < 0.6:  # 60% ë¯¸ë§Œ ì™„ì„±ë„
        issues.append(f"ì§€í‘œ ì™„ì„±ë„ ë¶€ì¡±: {completion_ratio:.1%}")
        score -= (0.6 - completion_ratio) * 5  # ê°ì 
    
    # ì ìˆ˜ í•˜í•œì„  ì ìš©
    score = max(0.0, score)
    
    # í—ˆìš© ê¸°ì¤€: ì ìˆ˜ 6.0 ì´ìƒ, ì¹˜ëª…ì  ì´ìŠˆ ì—†ìŒ
    critical_issues = [issue for issue in issues 
                      if any(keyword in issue for keyword in ['ëˆ„ë½', 'ë…¼ë¦¬ ì˜¤ë¥˜', 'ì—†ìŒ'])]
    
    is_acceptable = score >= 6.0 and len(critical_issues) == 0
    
    return {
        'is_acceptable': is_acceptable,
        'quality_score': score,
        'issues': issues
    }

def validate_trading_indicators(df, ticker):
    """VCP ë° ëŒíŒŒë§¤ë§¤ ê´€ì ì—ì„œ ì§€í‘œ ìœ íš¨ì„± ê²€ì¦"""
    
    if df is None or df.empty:
        return {'is_valid': False, 'warnings': ['ë°ì´í„° ì—†ìŒ']}
    
    latest = df.iloc[-1]
    warnings = []
    
    # ATR ê¸°ë°˜ ë³€ë™ì„± ì²´í¬
    if 'atr' in df.columns and 'close' in df.columns:
        atr_val = latest.get('atr')
        close_val = latest.get('close')
        
        if atr_val is not None and close_val is not None and close_val > 0:
            atr_pct = (atr_val / close_val) * 100
            if atr_pct > 8:  # 8% ì´ìƒ ë³€ë™ì„±ì€ VCP ë¶€ì í•©
                warnings.append(f"ë†’ì€ ë³€ë™ì„±: {atr_pct:.1f}%")
    
    # ì§€ì§€/ì €í•­ì„  ìœ íš¨ì„±
    if 'resistance' in df.columns and 'support' in df.columns:
        resistance_val = latest.get('resistance')
        support_val = latest.get('support')
        
        if resistance_val is not None and support_val is not None:
            if resistance_val <= support_val:
                warnings.append("ì§€ì§€/ì €í•­ì„  ì—­ì „")
            else:
                # ì§€ì§€/ì €í•­ì„  ê°„ê²©ì´ ë„ˆë¬´ ì¢ìœ¼ë©´ ê²½ê³ 
                gap_pct = ((resistance_val - support_val) / support_val) * 100
                if gap_pct < 2:  # 2% ë¯¸ë§Œ ê°„ê²©
                    warnings.append(f"ì§€ì§€/ì €í•­ì„  ê°„ê²© í˜‘ì†Œ: {gap_pct:.1f}%")
    
    # ADX ì¶”ì„¸ ê°•ë„ ê²€ì¦
    if 'adx' in df.columns:
        adx_val = latest.get('adx')
        if adx_val is not None:
            if adx_val < 14:
                warnings.append(f"ì•½í•œ ì¶”ì„¸: ADX {adx_val:.1f}")
            elif adx_val > 50:
                warnings.append(f"ê³¼ë„í•œ ì¶”ì„¸: ADX {adx_val:.1f}")
    
    # MA200 ê¸°ìš¸ê¸° ê²€ì¦ (ì¶”ì„¸ ë°©í–¥ì„±)
        if 'ma200_slope' in df.columns:
            slope_val = latest.get('ma200_slope')
        if slope_val is not None:
            if abs(slope_val) < 0.1:  # ê¸°ìš¸ê¸°ê°€ ë„ˆë¬´ í‰í‰í•¨
                warnings.append(f"ì•½í•œ ì¶”ì„¸: MA200 ê¸°ìš¸ê¸° {slope_val:.2f}%")
    
    # Volume ì´ìƒ íŒ¨í„´ ê²€ì¦
    if 'volume_change_7_30' in df.columns:
        vol_change = latest.get('volume_change_7_30')
        if vol_change is not None:
            if vol_change > 5:  # 5ë°° ì´ìƒ ê¸‰ë“±
                warnings.append(f"ì´ìƒ ê±°ë˜ëŸ‰: {vol_change:.1f}ë°°")
            elif vol_change < 0.3:  # 30% ì´í•˜ ê°ì†Œ
                warnings.append(f"ë‚®ì€ ê±°ë˜ëŸ‰: {vol_change:.1f}ë°°")
    
    # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê²€ì¦
    if 'fibo_382' in df.columns and 'fibo_618' in df.columns:
        fibo_382 = latest.get('fibo_382')
        fibo_618 = latest.get('fibo_618')
        current_price = latest.get('close')
        
        if all(x is not None for x in [fibo_382, fibo_618, current_price]):
            if fibo_382 < fibo_618:  # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ìˆœì„œ ì—­ì „
                warnings.append("í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ìˆœì„œ ì´ìƒ")
    
    # Supertrend ì‹ í˜¸ ê²€ì¦
    if 'supertrend' in df.columns:
        supertrend_val = latest.get('supertrend')
        current_price = latest.get('close')
        
        if supertrend_val is not None and current_price is not None:
            # Supertrendì™€ í˜„ì¬ê°€ ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆìœ¼ë©´ ê²½ê³ 
            distance_pct = abs((current_price - supertrend_val) / current_price) * 100
            if distance_pct > 15:  # 15% ì´ìƒ ì°¨ì´
                warnings.append(f"Supertrend ì‹ í˜¸ ë¶ˆì¼ì¹˜: {distance_pct:.1f}%")
    
    # NVT Relative ê²€ì¦ (ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„)
    if 'nvt_relative' in df.columns:
        nvt_val = latest.get('nvt_relative')
        if nvt_val is not None:
            # NVT ê°’ì´ ê·¹ë‹¨ì ìœ¼ë¡œ ë†’ê±°ë‚˜ ë‚®ìœ¼ë©´ ê²½ê³ 
            if nvt_val > 1000:  # ì„ê³„ê°’ì€ ì‹œì¥ ìƒí™©ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥
                warnings.append(f"ë†’ì€ NVT: {nvt_val:.0f}")
            elif nvt_val < 10:
                warnings.append(f"ë‚®ì€ NVT: {nvt_val:.0f}")
    
    # High 60ì¼ vs í˜„ì¬ê°€ ê²€ì¦
    if 'high_60' in df.columns:
        high_60 = latest.get('high_60')
        current_price = latest.get('close')
        
        if high_60 is not None and current_price is not None:
            # í˜„ì¬ê°€ê°€ 60ì¼ ê³ ì  ëŒ€ë¹„ ìœ„ì¹˜ í™•ì¸
            position_pct = (current_price / high_60) * 100
            if position_pct < 50:  # 60ì¼ ê³ ì  ëŒ€ë¹„ 50% ë¯¸ë§Œ
                warnings.append(f"60ì¼ ê³ ì  ëŒ€ë¹„ ë‚®ì€ ìœ„ì¹˜: {position_pct:.1f}%")
    
    return {
        'is_valid': len(warnings) == 0,
        'warnings': warnings,
        'warning_count': len(warnings)
    }

def update_static_indicators_db(ticker: str, row: pd.Series):
    """
    static_indicators í…Œì´ë¸”ì— ì •ì  ì§€í‘œ ë°ì´í„°ë¥¼ UPSERT ë°©ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ - ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆ ì ìš©
    
    Args:
        ticker (str): ì½”ì¸ í‹°ì»¤
        row (pd.Series): ê³„ì‚°ëœ ì§€í‘œê°€ í¬í•¨ëœ ë°ì´í„° í–‰
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ì»¬ëŸ¼ ì‚¬ìš© (13ê°œ ì§€í‘œ + ticker + updated_at)
        # resistance, support, atr, adx ê°’ í™•ì¸ ë° ë¡œê¹…
        resistance_val = row.get('resistance')
        support_val = row.get('support')
        atr_val = row.get('atr')
        adx_val = row.get('adx')
        
        logger.debug(f"ğŸ” {ticker} ì§€í‘œ ê°’ í™•ì¸: resistance={resistance_val}, support={support_val}, atr={atr_val}, adx={adx_val}")
        
        # ğŸš€ ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©
        values_to_process = [
            row.get('volume_change_7_30'),
            row.get('nvt_relative'),
            row.get('close'),  # priceëŠ” close ê°€ê²© ì‚¬ìš©
            row.get('high_60'),
            row.get('low_60'),
            row.get('ma200_slope'),
            row.get('pivot'),
            row.get('s1'),
            row.get('r1'),
            resistance_val,
            support_val,
            atr_val,
            adx_val,
        ]
        
        # ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬
        processed_values = [_common_adaptive_decimal_rounding(val) if val is not None else None for val in values_to_process]
        
        # supertrend_signal ê°’ ë³€í™˜ (ìˆ«ì â†’ ë¬¸ìì—´)
        supertrend_value = row.get('supertrend_signal')
        if supertrend_value == 1.0:
            supertrend_signal = 'bull'
        elif supertrend_value == 0.0:
            supertrend_signal = 'bear'
        elif supertrend_value == 0.5:
            supertrend_signal = 'neutral'
        else:
            supertrend_signal = 'neutral'  # ê¸°ë³¸ê°’
        
        cursor.execute("""
            INSERT INTO static_indicators (
                ticker, volume_change_7_30, nvt_relative, price, high_60, low_60, ma200_slope,
                pivot, s1, r1, resistance, support, atr, adx, supertrend_signal, updated_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT(ticker) DO UPDATE SET
                volume_change_7_30=EXCLUDED.volume_change_7_30,
                nvt_relative=EXCLUDED.nvt_relative,
                price=EXCLUDED.price,
                high_60=EXCLUDED.high_60,
                low_60=EXCLUDED.low_60,
                ma200_slope=EXCLUDED.ma200_slope,
                pivot=EXCLUDED.pivot,
                s1=EXCLUDED.s1,
                r1=EXCLUDED.r1,
                resistance=EXCLUDED.resistance,
                support=EXCLUDED.support,
                atr=EXCLUDED.atr,
                adx=EXCLUDED.adx,
                supertrend_signal=EXCLUDED.supertrend_signal,
                updated_at=CURRENT_TIMESTAMP
        """, (
            ticker, 
            *processed_values,
            supertrend_signal,
            datetime.now()
        ))

        conn.commit()
        logger.info(f"âœ… {ticker} static_indicators í…Œì´ë¸” ì €ì¥ ì™„ë£Œ (ìƒˆ ìŠ¤í‚¤ë§ˆ)")
                    
    except Exception as e:
        logger.error(f"âŒ {ticker} static_indicators í…Œì´ë¸” ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        if conn:
            conn.rollback()
        raise
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def calculate_technical_indicators(df):
    """
    ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        if df is None or df.empty:
            logger.warning("âš ï¸ OHLCV ë°ì´í„° ì—†ìŒ")
            return None

        # ê¸°ë³¸ ì´ë™í‰ê· ì„ 
        df['ma_50'] = ta.sma(df['close'], length=50)
        df['ma_200'] = ta.sma(df['close'], length=200)
        
        # RSI
        df['rsi_14'] = ta.rsi(df['close'], length=14)

        # MFI
        df['mfi_14'] = ta.mfi(df['high'], df['low'], df['close'], df['volume'], length=14)

        # Bollinger Bands
        bb = ta.bbands(df['close'], length=20)
        df['bb_upper'] = bb['BBU_20_2.0']
        df['bb_middle'] = bb['BBM_20_2.0']
        df['bb_lower'] = bb['BBL_20_2.0']

        # MACD (ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        macd = ta.macd(df['close'])
        df['macd'] = macd['MACD_12_26_9']
        df['macd_signal'] = macd['MACDs_12_26_9']
        df['macd_histogram'] = macd['MACDh_12_26_9']

        # ADX
        adx = ta.adx(df['high'], df['low'], df['close'], length=14)
        df['adx'] = adx['ADX_14']
        df['plus_di'] = adx['DMP_14']
        df['minus_di'] = adx['DMN_14']

        # ATR (ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        df['atr'] = ta.atr(df['high'], df['low'], df['close'], length=14)

        # Supertrend
        supertrend = ta.supertrend(high=df['high'], low=df['low'], close=df['close'], length=10, multiplier=2.0)
        df['supertrend'] = supertrend['SUPERT_10_2.0']
        df['supertrend_direction'] = supertrend['SUPERT_10_2.0']

        # Donchian Channels
        donchian = ta.donchian(high=df['high'], low=df['low'], close=df['close'], length=20)
        df['donchian_high'] = donchian.iloc[:, 2]  # Usually 'DCH_20_20'
        df['donchian_low'] = donchian.iloc[:, 1]   # Usually 'DCL_20_20'
        
        # Pivot Points
        df['pivot'] = (df['high'] + df['low'] + df['close']) / 3
        df['r1'] = 2 * df['pivot'] - df['low']
        df['r2'] = df['pivot'] + (df['high'] - df['low'])
        df['r3'] = df['high'] + 2 * (df['pivot'] - df['low'])
        df['s1'] = 2 * df['pivot'] - df['high']
        df['s2'] = df['pivot'] - (df['high'] - df['low'])
        df['s3'] = df['low'] - 2 * (df['high'] - df['pivot'])

        # Fibonacci Levels (ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        high = df['high'].rolling(window=20).max()
        low = df['low'].rolling(window=20).min()
        diff = high - low
        df['fibo_382'] = (high - (diff * 0.382))
        df['fibo_500'] = (high - (diff * 0.500))
        df['fibo_618'] = (high - (diff * 0.618))
        df['fibo_786'] = (high - (diff * 0.786))

        # Support and Resistance
        df['support'] = df['low'].rolling(window=20).min()
        df['resistance'] = df['high'].rolling(window=20).max()

        # NVT Relative
        market_cap = df['close'] * df['volume']
        df['nvt_relative'] = market_cap / df['volume'].rolling(window=90).mean()

        # Volume Change
        df['volume_change_7_30'] = df['volume'].rolling(window=7).mean() / df['volume'].rolling(window=30).mean()

        # HT Trendline (ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        df['ht_trendline'] = talib.HT_TRENDLINE(df['close'])

        # Additional indicators
        df['high_60'] = df['high'].rolling(window=60).max()
        df['low_60'] = df['low'].rolling(window=60).min()  # VCP ì „ëµìš© 60ì¼ ìµœì €ê°€
        df['volume_20ma'] = df['volume'].rolling(window=20).mean()
        
        # Stochastic %K (VCP ì „ëµ ê°•í™”ìš©, ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        stoch = ta.stoch(df['high'], df['low'], df['close'], k=14, d=3)
        df['stoch_k'] = stoch['STOCHk_14_3_3']
        df['stoch_d'] = stoch['STOCHd_14_3_3']

        logger.info("âœ… ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        return df

    except Exception as e:
        logger.error(f"âŒ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def calculate_technical_indicators_4h(df):
    """
    4ì‹œê°„ë´‰ OHLCV ë°ì´í„°ì— ëŒ€í•´ ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ì§€í‘œ:
    - ì´ë™í‰ê· ì„ : MA10, MA20, MA50, MA200
    - MACD: (12, 26, 9)
    - RSI: 14ì¼
    - ADX: 14ì¼
    - Bollinger Bands: 20ì¼
    
    Args:
        df (pd.DataFrame): 4ì‹œê°„ë´‰ OHLCV ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: ê¸°ìˆ ì  ì§€í‘œê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    try:
        if df is None or df.empty:
            return None
        
        # âœ… ë“¤ì—¬ì“°ê¸° ìˆ˜ì •: ifë¬¸ ë°–ìœ¼ë¡œ ì´ë™
        # ê¸°ë³¸ ì»¬ëŸ¼ ë³µì‚¬
        result = df.copy()
        
        # âœ… price ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì¼“íƒ€ì´ë° í•„í„°ì—ì„œ í•„ìš”)
        result['price'] = result['close']
        
        # === ì´ë™í‰ê· ì„  === (ì»¬ëŸ¼ëª… ìˆ˜ì •: DB ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜)
        for period in [10, 20, 50, 200]:
            result[f'ma_{period}'] = ta.sma(result['close'], length=period)  # ma10 â†’ ma_10
        
        # === MACD ===
        macd = ta.macd(result['close'])
        result['macd'] = macd['MACD_12_26_9']
        result['macds'] = macd['MACDs_12_26_9']
        result['macdh'] = macd['MACDh_12_26_9']
        
        # === RSI ===
        result['rsi_14'] = ta.rsi(result['close'], length=14)
        
        # === Stochastic RSI ===
        stoch = ta.stoch(result['high'], result['low'], result['close'], k=14, d=3)
        result['stochastic_k'] = stoch['STOCHk_14_3_3']
        result['stochastic_d'] = stoch['STOCHd_14_3_3']
        
        # === ADX ===
        adx = ta.adx(result['high'], result['low'], result['close'], length=14)
        result['adx'] = adx['ADX_14']
        result['plus_di'] = adx['DMP_14']
        result['minus_di'] = adx['DMN_14']
        
        # === CCI (Commodity Channel Index) ===
        result['cci'] = ta.cci(result['high'], result['low'], result['close'], length=20)
        
        # === Supertrend ===
        supertrend = ta.supertrend(result['high'], result['low'], result['close'], length=10, multiplier=3.0)
        result['supertrend'] = supertrend['SUPERT_10_3.0']
        result['supertrend_signal'] = supertrend['SUPERTd_10_3.0'].apply(
            lambda x: 'up' if x == 1 else 'down'
        )
        
        # === Bollinger Bands ===
        bb = ta.bbands(result['close'], length=20)
        result['bb_upper'] = bb['BBU_20_2.0']
        result['bb_middle'] = bb['BBM_20_2.0']
        result['bb_lower'] = bb['BBL_20_2.0']
        
        # === í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚° ===
        result['pivot'] = (result['high'] + result['low'] + result['close']) / 3
        result['r1'] = 2 * result['pivot'] - result['low']
        result['r2'] = result['pivot'] + (result['high'] - result['low'])
        result['r3'] = result['r1'] + (result['high'] - result['low'])
        result['s1'] = 2 * result['pivot'] - result['high']
        result['s2'] = result['pivot'] - (result['high'] - result['low'])
        result['s3'] = result['s1'] - (result['high'] - result['low'])
        
        # === í”¼ë³´ë‚˜ì¹˜ ë¦¬íŠ¸ë ˆì´ìŠ¤ë¨¼íŠ¸ ê³„ì‚° ===
        # ìµœê·¼ ìŠ¤ìœ™ í•˜ì´ì™€ ë¡œìš°ë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê³„ì‚°
        swing_period = 20  # ìµœê·¼ 20ì¼ê°„ì˜ ìŠ¤ìœ™ í•˜ì´/ë¡œìš° ì‚¬ìš©
        
        swing_high = result['high'].rolling(window=swing_period, center=True).max()
        swing_low = result['low'].rolling(window=swing_period, center=True).min()
        
        # í”¼ë³´ë‚˜ì¹˜ ë¹„ìœ¨
        fib_diff = swing_high - swing_low
        result['fibo_236'] = swing_high - (fib_diff * 0.236)
        result['fibo_382'] = swing_high - (fib_diff * 0.382)
        result['fibo_500'] = swing_high - (fib_diff * 0.500)
        result['fibo_618'] = swing_high - (fib_diff * 0.618)
        result['fibo_786'] = swing_high - (fib_diff * 0.786)
        
        # ìµœì‹  ë°ì´í„°ì˜ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì»¬ëŸ¼ëª… ìˆ˜ì •)
        latest = result.iloc[-1]
        
        # í•µì‹¬ ì§€í‘œë§Œ ê²€ì¦ (ma_200ì€ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ NaNì¼ ìˆ˜ ìˆìŒ)
        core_indicators = ['macd', 'rsi_14', 'adx', 'cci', 'supertrend']
        failed_indicators = []
        for indicator in core_indicators:
            if indicator in latest and pd.isna(latest[indicator]):
                failed_indicators.append(indicator)
        
        if failed_indicators:
            logger.warning(f"âš ï¸ í•µì‹¬ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {failed_indicators}")
            return None
        
        # ma_200ì´ NaNì¸ ê²½ìš° ê²½ê³ ë§Œ ì¶œë ¥ (ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì •ìƒì ì¸ ìƒí™©)
        if 'ma_200' in latest and pd.isna(latest['ma_200']):
            logger.info("â„¹ï¸ ma_200ì´ NaNì…ë‹ˆë‹¤ (ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì •ìƒì ì¸ ìƒí™©)")
        
        return result
            
    except Exception as e:
        logger.error(f"âŒ 4ì‹œê°„ë´‰ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def generate_chart_image(ticker: str, df: pd.DataFrame) -> str:
    """
    ì¶”ì„¸ í•„í„°ë§ í†µê³¼ ì¢…ëª©ì— ëŒ€í•´ì„œë§Œ í˜¸ì¶œë˜ëŠ” ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
    ê°€ê²©Â·ë³´ì¡°ì§€í‘œ(íŒ¨ë„0) / ê±°ë˜ëŸ‰(íŒ¨ë„1) / RSI+MFI(íŒ¨ë„2) 3â€‘ë¶„í• ,
    ë²”ë¡€ëŠ” ìš°ì¸¡ ë°”ê¹¥ì— ë°°ì¹˜í•´ ë³¸ë¬¸ì„ ê°€ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    try:
        logger.info(f"ğŸ“Š {ticker} - ì¶”ì„¸ í•„í„°ë§ í†µê³¼ ì¢…ëª© ì°¨íŠ¸ ìƒì„± ì‹œì‘")
        
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} - ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (df is empty or None)")
            return None

        # charts ë””ë ‰í„°ë¦¬ ìƒì„±
        os.makedirs("charts", exist_ok=True)
        chart_path = os.path.join("charts", f"{ticker}.png")

        # Ensure index is DatetimeIndex
        if 'date' in df.columns and not isinstance(df.index, pd.DatetimeIndex):
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
        elif not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)

        # ===== â¶ ì°¨íŠ¸ì— ì‚¬ìš©í•  ë°ì´í„° ë²”ìœ„ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë™ì  ì¡°ì •) =====
        import psutil
        available_memory_gb = psutil.virtual_memory().available / (1024**3)
        
        # ë©”ëª¨ë¦¬ ìƒí™©ì— ë”°ë¥¸ ë™ì  ë°ì´í„° ë²”ìœ„ ì¡°ì •
        if available_memory_gb > 4.0:
            display_days = 250  # ì¶©ë¶„í•œ ë©”ëª¨ë¦¬: ìµœëŒ€ 1ë…„
        elif available_memory_gb > 2.0:
            display_days = 180  # ë³´í†µ ë©”ëª¨ë¦¬: 6ê°œì›”
        else:
            display_days = 120  # ë‚®ì€ ë©”ëª¨ë¦¬: 4ê°œì›”
            
        df_display = df.tail(display_days)
        if df_display.empty:
            logger.warning(f"âš ï¸ {ticker} - ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        logger.debug(f"ğŸ” {ticker} ì°¨íŠ¸ ë²”ìœ„: {len(df_display)}ì¼ (ë©”ëª¨ë¦¬: {available_memory_gb:.1f}GB)")

        # ===== [4ë‹¨ê³„: ì ì‘í˜• ì°¨íŠ¸ ìƒì„±] =====
        required_cols = ["ht_trendline", "bb_upper", "bb_middle", "bb_lower",
                         "resistance", "support", "rsi_14", "mfi_14", "pivot", "r1", "r2", "r3", "s1", "s2", "s3"]
        
        # ì´ìš© ê°€ëŠ¥í•œ ì§€í‘œ í™•ì¸
        available_indicators = []
        missing_cols = []
        
        for col in required_cols:
            if col in df_display.columns and not df_display[col].isna().all():
                available_indicators.append(col)
            else:
                missing_cols.append(col)
        
        logger.debug(f"ğŸ” {ticker} ì°¨íŠ¸ ì§€í‘œ í˜„í™©: ì´ìš©ê°€ëŠ¥ {len(available_indicators)}ê°œ, ëˆ„ë½ {len(missing_cols)}ê°œ")
        
        # 4ë‹¨ê³„: ì ì‘í˜• ì°¨íŠ¸ ìƒì„± (ìµœì†Œ 3ê°œ ì§€í‘œë§Œ ìˆìœ¼ë©´ ì°¨íŠ¸ ìƒì„±)
        if len(available_indicators) < 3:
            logger.warning(f"âš ï¸ {ticker} - ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ìµœì†Œ ì§€í‘œ ë¶€ì¡±: {len(available_indicators)}/3 (ëˆ„ë½: {missing_cols})")
            logger.debug(f"{ticker} ë°ì´í„° ì»¬ëŸ¼ ëª©ë¡: {df.columns.tolist()}")
            
            # 3ë‹¨ê³„: í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ - ì§€í‘œ ê³„ì‚° ì™„ë£Œìœ¨ ì¶”ì 
            data_quality_monitor.log_indicator_calculation_quality(ticker, df_display, available_indicators)
            return None
        else:
            logger.info(f"âœ… {ticker} - ì ì‘í˜• ì°¨íŠ¸ ìƒì„± ê°€ëŠ¥: {len(available_indicators)}ê°œ ì§€í‘œ ì´ìš©")
            # 3ë‹¨ê³„: í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ - ì§€í‘œ ê³„ì‚° ì™„ë£Œìœ¨ ì¶”ì 
            data_quality_monitor.log_indicator_calculation_quality(ticker, df_display, available_indicators)

        # ===== â· 4ë‹¨ê³„: ì ì‘í˜• addplot êµ¬ì„± (ì´ìš© ê°€ëŠ¥í•œ ì§€í‘œë§Œ í¬í•¨) =====
        all_indicators = [
            {"name": "HT Trendline", "column": "ht_trendline", "panel": 0, "color": "limegreen", "ls": "--", "lw": 1.5, "zorder": 1},
            {"name": "BB Upper",  "column": "bb_upper",   "panel": 0, "color": "deepskyblue", "ls": "-", "lw": 1, "alpha": 0.3},
            {"name": "BB Middle", "column": "bb_middle",  "panel": 0, "color": "gray",      "ls": "-", "lw": 1, "alpha": 0.3},
            {"name": "BB Lower",  "column": "bb_lower",   "panel": 0, "color": "saddlebrown", "ls": "-", "lw": 1, "alpha": 0.3},
            {"name": "Resistance", "column": "resistance", "panel": 0, "color": "purple", "ls": "-.", "lw": 2},
            {"name": "Support",    "column": "support",    "panel": 0, "color": "magenta",  "ls": "-.", "lw": 2},
            {"name": "RSI 14",     "column": "rsi_14",     "panel": 2, "color": "purple"},
            {"name": "MFI 14",     "column": "mfi_14",     "panel": 2, "color": "deepskyblue"},
        ]

        # ì´ìš© ê°€ëŠ¥í•œ ì§€í‘œë§Œ í•„í„°ë§
        valid_indicators = []
        for ind in all_indicators:
            column = ind["column"]
            if column in available_indicators:
                # ë°ì´í„°ë¥¼ ì¶”ê°€
                ind["data"] = df_display[column]
                valid_indicators.append(ind)
            else:
                logger.debug(f"ğŸ” {ticker} ì§€í‘œ ìŠ¤í‚µ: {ind['name']} (ì»¬ëŸ¼: {column})")

        logger.info(f"âœ… {ticker} ì ì‘í˜• ì°¨íŠ¸: {len(valid_indicators)}/{len(all_indicators)}ê°œ ì§€í‘œ ì‚¬ìš©")

        addplots = []
        for ind in valid_indicators:
            ser = ind["data"]
            if ser is not None and not ser.dropna().empty:
                ap = mpf.make_addplot(
                    ser,
                    panel=ind["panel"],
                    color=ind["color"],
                    linestyle=ind.get("ls", "-"),
                    width=ind.get("lw", 1),
                    alpha=ind.get("alpha", 1),
                    label=ind["name"]          # â† ë²”ë¡€ì— í‘œì‹œë  ì´ë¦„
                )
                addplots.append(ap)

        # ===== â¸ mpf ìŠ¤íƒ€ì¼ =====
        mcolors = mpf.make_marketcolors(up="r", down="b", inherit=True)
        style = mpf.make_mpf_style(marketcolors=mcolors, gridstyle=":", y_on_right=False)

        # ===== â¹ ì°¨íŠ¸ ê·¸ë¦¬ê¸° =====
        # --- Disable scientific notation for volume axis ---
        import matplotlib.ticker as mticker
        fig, axes = mpf.plot(
            df_display,
            type="candle",
            style=style,
            volume=True,
            ylabel="Price (KRW)",
            ylabel_lower="Volume",
            addplot=addplots,
            figsize=(5, 3.5),
            update_width_config=dict(
                candle_width=0.8,        # ëª¸í†µ ê°€ë¡œí­
                candle_linewidth=1.0,    # ëª¸í†µ í…Œë‘ë¦¬ ë‘ê»˜
                volume_width=0.5         # ê±°ë˜ëŸ‰ ë§‰ëŒ€ í­
            ),
            warn_too_much_data=len(df_display)+1,
            returnfig=True,
            show_nontrading=False,
        )
        # Set volume axis to show in M (millions)
        if len(axes) > 1:
            axes[1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x/1_000_000)}M'))

        # ---- remove any legends that mplfinance placed *inside* axes ----
        for ax in axes:
            leg = ax.get_legend()
            if leg is not None:
                leg.remove()

        # === 4ë‹¨ê³„: ì ì‘í˜• Pivot & Support/Resistance ìˆ˜í‰ì„  ===
        last_row = df_display.iloc[-1]
        pivot_levels = [
            ("pivot", "grey", ":"),
            ("r1", "orange", ":"),
            ("r2", "orange", "--"),
            ("r3", "orange", "-."),
            ("s1", "cyan", ":"),
            ("s2", "cyan", "--"),
            ("s3", "cyan", "-."),
        ]
        
        ax_price = axes[0]  # ê°€ê²© íŒ¨ë„
        pivot_count = 0
        
        for name, col, ls in pivot_levels:
            if name in available_indicators and name in last_row and pd.notna(last_row[name]):
                val = last_row[name]
                ax_price.axhline(y=val, color=col, linestyle=ls, linewidth=1, label=name.upper())
                pivot_count += 1
            else:
                logger.debug(f"ğŸ” {ticker} í”¼ë²— ë ˆë²¨ ìŠ¤í‚µ: {name}")
                
        logger.debug(f"ğŸ” {ticker} í”¼ë²— ë ˆë²¨: {pivot_count}/7ê°œ í‘œì‹œ")

        # ===== Remove all internal legend calls on axes (ax1.legend(), ax2.legend(), ax3.legend(), etc.) =====
        # (No ax1.legend(), ax2.legend(), ax3.legend(), or similar calls should be present below.)

        # ===== âº ë²”ë¡€ë¥¼ ì°¨íŠ¸ ì™¸ë¶€ ìš°ì¸¡ì— ë°°ì¹˜ =====
        # ë²”ë¡€ ìœ„ì¹˜: ì°¨íŠ¸ ì˜¤ë¥¸ìª½, ë³¸ë¬¸ ìµœìƒë‹¨ë³´ë‹¤ ì•½ê°„ ì•„ë˜(ìƒ˜í”Œ ì´ë¯¸ì§€ì™€ ìœ ì‚¬)
        fig.subplots_adjust(right=0.82)  # ë³¸ë¬¸ ìš°ì¸¡ ê³µê°„ í™•ë³´

        handles, labels = [], []
        seen = set()

        # Include all lines (e.g., pivot, r1~r3, s1~s3)
        for ax in axes:
            for ln in ax.get_lines():
                lbl = ln.get_label()
                if lbl and not lbl.startswith('_') and lbl not in seen:
                    handles.append(ln)
                    labels.append(lbl)
                    seen.add(lbl)

        # Include addplot indicators (if they were not included already)
        for ap in addplots:
            if hasattr(ap, 'get_label') and callable(ap.get_label):
                lbl = ap.get_label()
                if lbl and not lbl.startswith('_') and lbl not in seen:
                    handles.append(ap)
                    labels.append(lbl)
                    seen.add(lbl)

        fig.legend(
            handles,
            labels,
            loc="upper left",
            bbox_to_anchor=(1.02, 0.92),   # â† y ê°’ì„ 1 â†’ 0.92 ë¡œ ë‚´ë ¤ì„œ ì¡°ê¸ˆ ì•„ë˜ ë°°ì¹˜
            frameon=True,
            fontsize=8
        )
        # Add chart time period text below the x-axis
        fig.text(0.01, 0.01, f'1D Candle | {df_display.index[0].date()} ~ {df_display.index[-1].date()}', fontsize=9)

        # ===== â» ì €ì¥ =====
        plt.tight_layout()
        fig.savefig(chart_path, dpi=100, bbox_inches="tight", pad_inches=0.25)
        plt.close(fig)
        if os.path.exists(chart_path):
            logger.info(f"âœ… {ticker} - í•„í„°ë§ í†µê³¼ ì¢…ëª© ì°¨íŠ¸ ìƒì„± ì™„ë£Œ: {chart_path}")
        else:
            logger.error(f"âŒ {ticker} ì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ ({chart_path})")
        return chart_path

    except Exception as e:
        logger.error(f"âŒ {ticker} ì°¨íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None

def save_dynamic_indicators_to_ohlcv(ticker, df_with_indicators):
    """ë™ì  ì§€í‘œë¥¼ ohlcv í…Œì´ë¸”ì— ì—…ë°ì´íŠ¸"""
    conn = None
    cursor = None
    
    try:
        if df_with_indicators is None or df_with_indicators.empty:
            logger.warning(f"âš ï¸ {ticker} ì—…ë°ì´íŠ¸í•  ë™ì  ì§€í‘œ ë°ì´í„° ì—†ìŒ")
            return False
            
        conn = get_db_connection()
        cursor = conn.cursor()
        
        update_count = 0
        for index, row in df_with_indicators.iterrows():
            from utils import safe_strftime
            date_str = safe_strftime(index, '%Y-%m-%d')
            
            cursor.execute("""
                UPDATE ohlcv SET
                                    macd = %s, macd_signal = %s, macd_histogram = %s,
                rsi_14 = %s, adx = %s, plus_di = %s, minus_di = %s,
                    atr = %s, bb_upper = %s, bb_middle = %s, bb_lower = %s,
                                    volume_20ma = %s, ht_trendline = %s,
                supertrend = %s, supertrend_direction = %s
                WHERE ticker = %s AND date = %s
            """, (
                row.get('macd'), row.get('macd_signal'), row.get('macd_histogram'),
                row.get('rsi_14'), row.get('adx'), row.get('plus_di'), row.get('minus_di'),
                row.get('atr'), row.get('bb_upper'), row.get('bb_middle'), row.get('bb_lower'),
                row.get('volume_20ma'), row.get('ht_trendline'),
                row.get('supertrend'), row.get('supertrend_direction'),
                ticker, date_str
            ))
            
            if cursor.rowcount > 0:
                update_count += 1
        
        conn.commit()
        logger.info(f"âœ… {ticker} ë™ì  ì§€í‘œ ohlcv í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì™„ë£Œ: {update_count}ê°œ ë ˆì½”ë“œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ {ticker} ë™ì  ì§€í‘œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        if conn:
            conn.rollback()
        return False
            
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def save_market_data_4h_to_db(ticker, df):
    """
    4ì‹œê°„ë´‰ ì‹œì¥ ë°ì´í„°(ê¸°ìˆ  ì§€í‘œ)ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ì €ì¥í•  í‹°ì»¤
        df (pd.DataFrame): ê¸°ìˆ  ì§€í‘œê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ (ìµœì‹  1 row)
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  4ì‹œê°„ë´‰ ì‹œì¥ ë°ì´í„° ì—†ìŒ")
            return
            
        # ìµœì‹  ë°ì´í„°ë§Œ ì €ì¥
        latest = df.iloc[-1].copy()
        latest['ticker'] = ticker
        latest['updated_at'] = datetime.now()
        
        # ì°¨íŠ¸ ê²½ë¡œ ì„¤ì •(ë¯¸ì‚¬ìš©)
        #chart_path = f"charts/{ticker}_4h.png"
        #latest['chart_path'] = chart_path
        
        # âš¡ [ì„±ëŠ¥ ìµœì í™”] ì—°ê²° í’€ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
        with get_db_connection_context() as conn:
            with conn.cursor() as cursor:
                # âœ… ê¸°ìˆ  ì§€í‘œ ì»¬ëŸ¼ë§Œ ì„ íƒ (ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆì— ë§ì¶¤)
                indicator_columns = [
                    'ticker', 'price', 
                    # ì´ë™í‰ê· ì„ 
                    'ma_10', 'ma_20', 'ma_50', 'ma_200',
                    # RSI & Stochastic
                    'rsi_14', 'stochastic_k', 'stochastic_d',
                    # MACD
                    'macd', 'macds', 'macdh',
                    # ADX
                    'adx', 'plus_di', 'minus_di',
                    # ë³¼ë¦°ì €ë°´ë“œ
                    'bb_upper', 'bb_middle', 'bb_lower',
                    # CCI
                    'cci',
                    # Supertrend
                    'supertrend', 'supertrend_signal',
                    # í”¼ë²— í¬ì¸íŠ¸
                    'pivot', 'r1', 'r2', 'r3', 's1', 's2', 's3',
                    # í”¼ë³´ë‚˜ì¹˜
                    'fibo_236', 'fibo_382', 'fibo_500', 'fibo_618', 'fibo_786',
                    # ë©”íƒ€ë°ì´í„°
                    'updated_at'
                ]
                
                # ì„ íƒëœ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
                latest_data = {col: latest.get(col) for col in indicator_columns if col in latest}
                
                # ì»¬ëŸ¼ê³¼ ê°’ ì¤€ë¹„
                columns = list(latest_data.keys())
                values = [latest_data[col] if not pd.isna(latest_data[col]) else None for col in columns]
                
                # UPSERT ì¿¼ë¦¬ ìƒì„±
                placeholders = ', '.join(['%s'] * len(columns))
                columns_str = ', '.join(columns)
                update_str = ', '.join([f"{col} = EXCLUDED.{col}" for col in columns if col != 'ticker'])
                
                query = f"""
                    INSERT INTO market_data_4h ({columns_str})
                    VALUES ({placeholders})
                    ON CONFLICT (ticker) DO UPDATE
                    SET {update_str}
                """
                
                cursor.execute(query, values)
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        logger.info(f"âœ… {ticker} 4ì‹œê°„ë´‰ ì‹œì¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ {ticker} 4ì‹œê°„ë´‰ ì‹œì¥ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def save_market_data_to_db(ticker, df):
    """
    ì¼ë´‰ ì‹œì¥ ë°ì´í„°ë¥¼ static_indicators í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤ (ìƒˆë¡œìš´ êµ¬í˜„)
    
    Args:
        ticker (str): ì €ì¥í•  í‹°ì»¤
        df (pd.DataFrame): ê¸°ìˆ  ì§€í‘œê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  ì¼ë´‰ ì‹œì¥ ë°ì´í„° ì—†ìŒ")
            return False
            
        # save_static_indicators í•¨ìˆ˜ ìœ„ì„ìœ¼ë¡œ ì™„ì „ ëŒ€ì²´
        logger.info(f"ğŸ”„ {ticker} save_static_indicatorsë¡œ ìœ„ì„")
        
        # ìµœì‹  í–‰ ì¶”ì¶œ
        latest_row = df.iloc[-1]
        
        # DB ì—°ê²° ìƒì„±í•˜ì—¬ save_static_indicators í˜¸ì¶œ
        conn = get_db_connection()
        try:
            return save_static_indicators(conn, ticker, latest_row)
        finally:
            conn.close()
        
    except Exception as e:
        logger.error(f"âŒ {ticker} ì¼ë´‰ ì‹œì¥ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def process_single_ticker(ticker, timeframe: str = '1d', market_data=None):
    """
    ë‹¨ì¼ í‹°ì»¤ì— ëŒ€í•œ í›„ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        ticker (str): ì²˜ë¦¬í•  í‹°ì»¤ ì‹¬ë³¼
        timeframe (str): ë´‰ íƒ€ì… ('1d' ë˜ëŠ” '4h')
        market_data (pd.DataFrame): ì´ë¯¸ ìˆ˜ì§‘ëœ ì‹œì¥ ë°ì´í„° (ì„ íƒì‚¬í•­)
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼
    """
    try:
        if not ticker:
            logger.error("âŒ í‹°ì»¤ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        # í‹°ì»¤ì—ì„œ 'KRW-' ì ‘ë‘ì–´ ì²˜ë¦¬
        if not ticker.startswith('KRW-'):
            ticker = f"KRW-{ticker}"
            
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬ ì¶”ê°€
        blacklist = load_blacklist()
        if ticker in blacklist:
            logger.info(f"â­ï¸ {ticker}ëŠ” ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆì–´ ì²˜ë¦¬ ê±´ë„ˆëœ€")
            return None
            
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
        if market_data is None:
            # âš¡ [ì„±ëŠ¥ ìµœì í™”] ì—°ê²° í’€ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
            with get_db_connection_context() as conn:
                if timeframe == '1d':
                    # ì¼ë´‰ì˜ ê²½ìš° static_indicatorsì™€ ohlcv í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
                    query = """
                        SELECT s.*, o.rsi_14, o.macd_histogram, o.bb_upper, o.bb_lower
                        FROM static_indicators s
                        LEFT JOIN (
                            SELECT DISTINCT ON (ticker) ticker, rsi_14, macd_histogram, bb_upper, bb_lower
                            FROM ohlcv 
                            ORDER BY ticker, date DESC
                        ) o ON s.ticker = o.ticker
                        WHERE s.ticker = %s
                    """
                else:
                    # 4ì‹œê°„ë´‰ì˜ ê²½ìš° market_data_4h í…Œì´ë¸” ì‚¬ìš©
                    query = f"SELECT * FROM market_data_4h WHERE ticker = %s"
                
                df = pd.read_sql_query(query, conn, params=(ticker,))
            
            if df.empty:
                logger.warning(f"âš ï¸ {ticker} {timeframe} ë´‰ ì‹œì¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
        else:
            df = market_data
            
        # ë´‰ íƒ€ì…ì— ë”°ë¼ í•„ìˆ˜ ê¸°ìˆ  ì§€í‘œ ì„¤ì •
        if timeframe == '1d':
            required_indicators = {'rsi_14', 'adx', 'mfi_14', 'macd', 'supertrend'}
        else:  # 4h ë´‰ì¸ ê²½ìš° (ì»¬ëŸ¼ëª… ìˆ˜ì •)
            required_indicators = {'rsi_14', 'stochastic_k', 'stochastic_d', 'ma_10', 'ma_20'}
        
        # ì»¬ëŸ¼ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ (ëŒ€ì†Œë¬¸ì ì¼ì¹˜ ì´ìŠˆ ë°©ì§€)
        df_columns_lower = {col.lower() for col in df.columns}
        required_indicators_lower = {ind.lower() for ind in required_indicators}
        
        missing_indicators = required_indicators_lower - df_columns_lower
        
        if missing_indicators:
            logger.warning(f"âš ï¸ {ticker} {timeframe} ë´‰: ê¸°ìˆ ì§€í‘œ ëˆ„ë½ {missing_indicators}")
            return None
            
        # ì¶”ê°€ ë¶„ì„ ìˆ˜í–‰ (ì˜ˆ: AI ì˜ˆì¸¡, ë¦¬í¬íŠ¸ ìƒì„± ë“±)
        # TODO : ì—¬ê¸°ì— ì¶”ê°€ ë¶„ì„ ë¡œì§ êµ¬í˜„
        
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} {timeframe} ë´‰ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def get_ohlcv_4h(ticker, limit=200, force_fetch=False):
    """
    íŠ¹ì • í‹°ì»¤ì˜ 4ì‹œê°„ë´‰ OHLCV ë°ì´í„°ë¥¼ ìµœê·¼ 200ê°œ(ê¸°ë³¸ê°’) ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ì¡°íšŒí•  í‹°ì»¤ (ì˜ˆ: "KRW-BTC")
        limit (int): ì¡°íšŒí•  ìµœê·¼ ìº”ë“¤ ê°œìˆ˜ (ê¸°ë³¸ê°’: 200)
        
    Returns:
        pd.DataFrame: 4ì‹œê°„ë´‰ OHLCV ë°ì´í„°í”„ë ˆì„ (datetime ì¸ë±ìŠ¤)
    """
    try:
        import pyupbit
        latest = get_latest_timestamp(ticker, table='ohlcv_4h')
        now = datetime.now()
        if not force_fetch and latest is not None:
            hours_diff = (now - latest).total_seconds() / 3600
            if hours_diff < limit * 4:
                logger.info(f"â­ï¸ {ticker}: ìµœê·¼ {int(hours_diff)}ì‹œê°„ ë°ì´í„° ì¡´ì¬ - ìˆ˜ì§‘ íŒ¨ìŠ¤")
                return None

        if latest is None:
            logger.info(f"ğŸ†• {ticker} ì‹ ê·œ í‹°ì»¤ - {limit}ê°œ 4ì‹œê°„ë´‰ ìˆ˜ì§‘")
            df = safe_pyupbit_get_ohlcv(ticker, interval="minute240", count=limit)
            if df is not None and not df.empty:
                save_ohlcv_4h_to_db(ticker, df)
            return df

        # í‹°ì»¤ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
        ticker = f"KRW-{ticker}" if not ticker.startswith("KRW-") else ticker

        # 4ì‹œê°„ë´‰ ë°ì´í„° ì¡°íšŒ (ì•ˆì „í•œ API í˜¸ì¶œ)
        df = safe_pyupbit_get_ohlcv(ticker, interval="minute240", count=limit)
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} 4ì‹œê°„ë´‰ ë°ì´í„° ì—†ìŒ")
            return None

        logger.debug(f"âœ… {ticker} 4ì‹œê°„ë´‰ {len(df)}ê°œ ì¡°íšŒ ì™„ë£Œ")
        return df

    except Exception as e:
        logger.error(f"âŒ {ticker} 4ì‹œê°„ë´‰ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def _filter_invalid_ohlcv_data(df, ticker):
    """
    OHLCV ë°ì´í„°ì—ì„œ í’ˆì§ˆ ë¶ˆëŸ‰ ë ˆì½”ë“œë¥¼ í•„í„°ë§
    
    ì œê±° ê¸°ì¤€:
    1. OHLCV ì¤‘ í•˜ë‚˜ë¼ë„ 0ê°’ì¸ ë ˆì½”ë“œ
    2. high < low ë“± ë…¼ë¦¬ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•œ ê°’
    3. ê·¹ë‹¨ì  ì´ìƒê°’ (ê°€ê²© ë³€ë™ë¥  > 1000%)
    
    Args:
        df (pd.DataFrame): ì›ë³¸ OHLCV ë°ì´í„°
        ticker (str): í‹°ì»¤ëª… (ë¡œê¹…ìš©)
        
    Returns:
        pd.DataFrame: í•„í„°ë§ëœ OHLCV ë°ì´í„°
    """
    if df is None or df.empty:
        return df
        
    original_len = len(df)
    
    # 1. OHLCV ì¤‘ 0ê°’ ë ˆì½”ë“œ ì œê±°
    zero_mask = (df['open'] == 0) | (df['high'] == 0) | (df['low'] == 0) | (df['close'] == 0)
    zero_count = zero_mask.sum()
    
    if zero_count > 0:
        logger.warning(f"ğŸ”´ {ticker} OHLCV 0ê°’ ë ˆì½”ë“œ {zero_count}ê°œ ì œê±°")
        df = df[~zero_mask]
    
    # 2. ë…¼ë¦¬ì  ë¶ˆê°€ëŠ¥í•œ ê°’ ì œê±° (high < low, close > high, close < low ë“±)
    invalid_logic_mask = (
        (df['high'] < df['low']) |  # high < low
        (df['close'] > df['high']) |  # close > high  
        (df['close'] < df['low']) |  # close < low
        (df['open'] > df['high']) |  # open > high
        (df['open'] < df['low'])     # open < low
    )
    invalid_logic_count = invalid_logic_mask.sum()
    
    if invalid_logic_count > 0:
        logger.warning(f"ğŸ”´ {ticker} ë…¼ë¦¬ì  ì˜¤ë¥˜ ë ˆì½”ë“œ {invalid_logic_count}ê°œ ì œê±°")
        df = df[~invalid_logic_mask]
    
    # 3. ê·¹ë‹¨ì  ê°€ê²© ë³€ë™ ì œê±° (ì „ì¼ ëŒ€ë¹„ 1000% ì´ìƒ ë³€ë™)
    if len(df) > 1:
        price_change_pct = df['close'].pct_change().abs()
        extreme_change_mask = price_change_pct > 10.0  # 1000% ë³€ë™
        extreme_change_count = extreme_change_mask.sum()
        
        if extreme_change_count > 0:
            logger.warning(f"ğŸ”´ {ticker} ê·¹ë‹¨ì  ê°€ê²©ë³€ë™ ë ˆì½”ë“œ {extreme_change_count}ê°œ ì œê±°")
            df = df[~extreme_change_mask]
    
    filtered_len = len(df)
    removed_count = original_len - filtered_len
    
    if removed_count > 0:
        logger.info(f"ğŸ“Š {ticker} ë°ì´í„° í’ˆì§ˆ í•„í„°ë§: {original_len} â†’ {filtered_len}ê°œ ({removed_count}ê°œ ì œê±°)")
    
    return df

def safe_pyupbit_get_ohlcv(ticker, interval="day", count=200, to=None, period=1):
    """
    1ë‹¨ê³„: pyupbit API í˜¸ì¶œ ë°©ì‹ ê·¼ë³¸ ìˆ˜ì •
    
    pyupbit.get_ohlcv()ë¥¼ ì•ˆì „í•˜ê²Œ í˜¸ì¶œí•˜ì—¬ 1970-01-01 ì‘ë‹µì„ ë°©ì§€í•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ì¡°íšŒí•  í‹°ì»¤
        interval (str): ì¡°íšŒ ê°„ê²© (day, minute240 ë“±)
        count (int): ì¡°íšŒí•  ë°ì´í„° ê°œìˆ˜
        to (str): ì¢…ë£Œì¼ (Noneì´ë©´ í˜„ì¬ ë‚ ì§œ ì‚¬ìš©)
        period (int): API ì•ˆì •ì„±ì„ ìœ„í•œ period íŒŒë¼ë¯¸í„°
        
    Returns:
        pd.DataFrame: ì•ˆì „í•˜ê²Œ ìˆ˜ì§‘ëœ OHLCV ë°ì´í„°
    """
    try:
        # 1ë‹¨ê³„: ëª…ì‹œì  ë‚ ì§œ ë²”ìœ„ ì§€ì •ìœ¼ë¡œ 1970-01-01 ë°©ì§€
        if to is None:
            # í˜„ì¬ ë‚ ì§œë¥¼ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ì„¤ì •
            to = datetime.now().strftime("%Y-%m-%d")
            
        logger.debug(f"ğŸ” {ticker} API í˜¸ì¶œ íŒŒë¼ë¯¸í„°:")
        logger.debug(f"   - interval: {interval}")
        logger.debug(f"   - count: {count}")
        logger.debug(f"   - to: {to}")
        logger.debug(f"   - period: {period}")
        
        # pyupbit API í˜¸ì¶œ (ëª¨ë“  íŒŒë¼ë¯¸í„° ëª…ì‹œì  ì§€ì •)
        api_params = {
            'ticker': ticker,
            'interval': interval,
            'count': count,
            'to': to,
            'period': period
        }
        
        df = pyupbit.get_ohlcv(**api_params)
        
        # 3ë‹¨ê³„: API ì‘ë‹µ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
        quality_ok = data_quality_monitor.log_api_response_quality(ticker, df, api_params)
        
        if df is None:
            logger.warning(f"âš ï¸ {ticker} API ì‘ë‹µ None")
            return None
            
        if df.empty:
            logger.warning(f"âš ï¸ {ticker} API ì‘ë‹µ ë¹ˆ DataFrame")
            return df
            
        # API ì‘ë‹µ ì¦‰ì‹œ ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì¦
        logger.debug(f"ğŸ” {ticker} API ì‘ë‹µ ê²€ì¦:")
        logger.debug(f"   - ë°ì´í„° ê°œìˆ˜: {len(df)}")
        logger.debug(f"   - Index íƒ€ì…: {type(df.index)}")
        
        if len(df) > 0:
            first_date = df.index[0]
            last_date = df.index[-1]
            logger.debug(f"   - ì²« ë²ˆì§¸ ë‚ ì§œ: {first_date}")
            logger.debug(f"   - ë§ˆì§€ë§‰ ë‚ ì§œ: {last_date}")
            
            # 1. OHLCV 0ê°’ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° í•„í„°ë§
            original_len = len(df)
            df = _filter_invalid_ohlcv_data(df, ticker)
            filtered_len = len(df)
            
            if original_len != filtered_len:
                logger.warning(f"âš ï¸ {ticker} í’ˆì§ˆ ë¶ˆëŸ‰ ë°ì´í„° ì œê±°: {original_len} â†’ {filtered_len}ê°œ")
            
            # 2. ìµœì†Œ ë°ì´í„° ê°œìˆ˜ í™•ì¸ (ìš”ì²­ëŸ‰ì˜ 80% ë¯¸ë§Œì´ë©´ ì¬ì‹œë„)
            min_required = int(count * 0.8)
            if len(df) < min_required:
                logger.warning(f"âš ï¸ {ticker} ë°ì´í„° ë¶€ì¡±: {len(df)}/{count} (ìµœì†Œ ìš”êµ¬: {min_required})")
                # ì¬ì‹œë„ ë¡œì§ì€ ìƒìœ„ í˜¸ì¶œìì—ì„œ ì²˜ë¦¬
                return df
            
            # 3. 1970-01-01 ì‘ë‹µ ê°ì§€
            if hasattr(df.index, 'year') and len(df) > 0 and df.index[0].year == 1970:
                logger.warning(f"ğŸ” {ticker} API 1970-01-01 ì‘ë‹µ ê°ì§€ë¨")
            else:
                logger.debug(f"âœ… {ticker} API ì‘ë‹µ ë‚ ì§œ ì •ìƒ: {first_date.date()} ~ {last_date.date()}")
        
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} safe_pyupbit_get_ohlcv ì‹¤íŒ¨: {str(e)}")
        return None

def fix_datetime_index(df, ticker):
    """
    DataFrameì˜ ì˜ëª»ëœ ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •
    
    Args:
        df (pd.DataFrame): ìˆ˜ì •í•  DataFrame
        ticker (str): í‹°ì»¤ ì‹¬ë³¼ (ë¡œê¹…ìš©)
    
    Returns:
        pd.DataFrame: ë‚ ì§œ ì¸ë±ìŠ¤ê°€ ìˆ˜ì •ëœ DataFrame
    """
    if df is None or df.empty:
        return df
    
    # 4ë‹¨ê³„: pyupbit API ì‘ë‹µì˜ ì›ë³¸ ì¸ë±ìŠ¤ ì •ë³´ ë¡œê¹…
    logger.debug(f"ğŸ” {ticker} ì›ë³¸ API ì‘ë‹µ ì¸ë±ìŠ¤ ì •ë³´:")
    logger.debug(f"   - Index íƒ€ì…: {type(df.index)}")
    logger.debug(f"   - ë°ì´í„° ê°œìˆ˜: {len(df)}")
    if len(df) > 0:
        logger.debug(f"   - ì²« ë²ˆì§¸ index: {df.index[0]} (íƒ€ì…: {type(df.index[0])})")
        logger.debug(f"   - ë§ˆì§€ë§‰ index: {df.index[-1]} (íƒ€ì…: {type(df.index[-1])})")
        
    # 1970-01-01 ì¸ë±ìŠ¤ ê°ì§€
    if hasattr(df.index, 'year') and len(df.index) > 0 and df.index[0].year == 1970:
        logger.warning(f"ğŸ”§ {ticker} ì˜ëª»ëœ ë‚ ì§œ ì¸ë±ìŠ¤ ê°ì§€, ë³µêµ¬ ì‹œì‘...")
        
        # 4ë‹¨ê³„: ë‚ ì§œ ë³€í™˜ ì „í›„ ë¹„êµ
        original_start = df.index[0] if len(df) > 0 else None
        original_end = df.index[-1] if len(df) > 0 else None
        
        # í˜„ì¬ ë‚ ì§œë¶€í„° ì—­ì‚°í•˜ì—¬ ì˜¬ë°”ë¥¸ ë‚ ì§œ ìƒì„±
        end_date = datetime.now().date()
        date_range = pd.date_range(
            end=end_date, 
            periods=len(df), 
            freq='D'
        )
        
        # ì£¼ë§ ì œì™¸ ì—†ìŒ (ì•”í˜¸í™”íëŠ” 24/7 ê±°ë˜)
        df.index = date_range
        
        # 4ë‹¨ê³„: ë³€í™˜ í›„ ë¡œê¹…
        new_start = df.index[0] if len(df) > 0 else None
        new_end = df.index[-1] if len(df) > 0 else None
        
        logger.info(f"âœ… {ticker} ë‚ ì§œ ì¸ë±ìŠ¤ ë³µêµ¬ ì™„ë£Œ:")
        logger.info(f"   - ë³µêµ¬ ì „: {original_start} ~ {original_end}")
        logger.info(f"   - ë³µêµ¬ í›„: {new_start.date()} ~ {new_end.date()}")
    
    return df

def get_ohlcv_d(ticker, interval="day", count=450, force_fetch=False, fetch_latest_only=False):
    """
    450ì¼ì¹˜ OHLCV ë°ì´í„° ìˆ˜ì§‘ - ë¡œì§ ì™„ì „ ì¬ì„¤ê³„ ë²„ì „ + BTC íŠ¹ë³„ ì²˜ë¦¬
    
    ì²˜ë¦¬ ìˆœì„œ:
    1. DBì—ì„œ ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜ í™•ì¸
    2. 450ê°œ ë¯¸ë§Œì´ë©´ ì „ì²´ ì¬ìˆ˜ì§‘
    3. 450ê°œ ì´ìƒì´ë©´ ìµœì‹  ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
    4. BTC ë“± ì£¼ìš” ì½”ì¸ì€ íŠ¹ë³„ ì²˜ë¦¬ (ë” ë§ì€ ë°ì´í„° ìš”ì²­)
    
    Args:
        ticker (str): í‹°ì»¤ ì‹¬ë³¼
        interval (str): ì¡°íšŒ ë‹¨ìœ„ (ê¸°ë³¸ê°’: "day")
        count (int): ì¡°íšŒí•  ë°ì´í„° ê°œìˆ˜ (ê¸°ë³¸ê°’: 450)
        force_fetch (bool): ê°•ì œ ìˆ˜ì§‘ ëª¨ë“œ (ê¸°ë³¸ê°’: False)
        fetch_latest_only (bool): ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘ ëª¨ë“œ (ê¸°ë³¸ê°’: False)
        
    Returns:
        pd.DataFrame: OHLCV ë°ì´í„°
    """
    conn = None
    cursor = None
    
    try:
        if not ticker.startswith("KRW-"):
            ticker = f"KRW-{ticker}"
            
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬
        blacklist = load_blacklist()
        if ticker in blacklist:
            logger.info(f"â­ï¸ {ticker}ëŠ” ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆì–´ OHLCV ë°ì´í„° ìˆ˜ì§‘ ê±´ë„ˆëœ€")
            return pd.DataFrame()
        
        # ì£¼ìš” ì½”ì¸ ëª©ë¡ (ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•œ ê²½ìš°)
        major_coins = ["KRW-BTC", "KRW-ETH", "KRW-XRP", "KRW-ADA", "KRW-DOT"]
        is_major_coin = ticker in major_coins
        
        # ì£¼ìš” ì½”ì¸ì€ ë” ë§ì€ ë°ì´í„° ìš”ì²­
        if is_major_coin and count == 450:
            actual_count = 600  # ì£¼ìš” ì½”ì¸ì€ ë” ë§ì´ ìš”ì²­
            logger.info(f"ğŸ” {ticker} ì£¼ìš” ì½”ì¸ â†’ í™•ì¥ ë°ì´í„° ìˆ˜ì§‘ ({actual_count}ê°œ)")
        else:
            actual_count = count
        
        # 1ë‹¨ê³„: DB í˜„í™© í™•ì¸
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT COUNT(*), MIN(date), MAX(date) 
            FROM ohlcv 
            WHERE ticker = %s
        """, (ticker,))
        
        result = cursor.fetchone()
        db_count = result[0] if result else 0
        min_date = result[1] if result else None
        max_date = result[2] if result else None
        
        logger.info(f"ğŸ” {ticker} DB í˜„í™©: {db_count}ê°œ ë ˆì½”ë“œ, ìµœì‹ : {max_date}")
        
        # 2ë‹¨ê³„: ìˆ˜ì§‘ ì „ëµ ê²°ì • - 450ê°œ ë¯¸ë§Œì´ê±°ë‚˜ ê°•ì œ ìˆ˜ì§‘ì´ë©´ ì „ì²´ ì¬ìˆ˜ì§‘
        now = datetime.now()
        
        # ğŸš€ ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘ ëª¨ë“œ (ìƒˆë¡œ ì¶”ê°€)
        if fetch_latest_only:
            logger.info(f"ğŸ”„ {ticker} ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘ ëª¨ë“œ ì‹œì‘")
            
            try:
                # APIì—ì„œ ìµœì‹  1ì¼ ë°ì´í„°ë§Œ ìˆ˜ì§‘
                df = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=1)
                
                if df is not None and not df.empty:
                    logger.info(f"âœ… {ticker} ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ ë ˆì½”ë“œ")
                    
                    # ë‚ ì§œ ë²”ìœ„ ì¶œë ¥
                    from utils import safe_strftime
                    date_str = safe_strftime(df.index[0])
                    logger.info(f"ğŸ“… {ticker} ìµœì‹  ë°ì´í„°: {date_str}")
                    
                    return df
                else:
                    logger.error(f"âŒ {ticker} ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    return pd.DataFrame()
                    
            except Exception as e:
                logger.error(f"âŒ {ticker} ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return pd.DataFrame()
        elif db_count < count or force_fetch:
            # ì „ì²´ ì¬ìˆ˜ì§‘ í•„ìš”
            logger.info(f"ğŸ”„ {ticker} ì „ì²´ ì¬ìˆ˜ì§‘ ì‹œì‘ ({actual_count}ê°œ ëª©í‘œ, í˜„ì¬ DB: {db_count}ê°œ)")
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì™„ì „ ì¬ìˆ˜ì§‘)
            if db_count > 0:
                cursor.execute("DELETE FROM ohlcv WHERE ticker = %s", (ticker,))
                logger.info(f"ğŸ—‘ï¸ {ticker} ê¸°ì¡´ {db_count}ê°œ ë ˆì½”ë“œ ì‚­ì œ")
            
            # APIì—ì„œ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            df = None
            max_retries = 3
            
            for attempt in range(max_retries):
                try:
                    logger.info(f"ğŸ”„ {ticker} API ìˆ˜ì§‘ ì‹œë„ {attempt + 1}/{max_retries} (count: {actual_count})")
                    
                    # BTC ë“± ì£¼ìš” ì½”ì¸ íŠ¹ë³„ ì²˜ë¦¬
                    if is_major_coin:
                        # ë¶„í•  ìš”ì²­ ì „ëµ
                        if actual_count > 500:
                            logger.info(f"ğŸ”„ {ticker} ë¶„í•  ìš”ì²­ ì „ëµ ì ìš© ({actual_count}ê°œ)")
                            
                            # ì²« ë²ˆì§¸ ìš”ì²­: ìµœê·¼ 500ê°œ (ì•ˆì „í•œ API í˜¸ì¶œ)
                            df1 = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=500)
                            time.sleep(0.2)  # API ì œí•œ íšŒí”¼
                            
                            if df1 is not None and not df1.empty:
                                # ë‘ ë²ˆì§¸ ìš”ì²­: ì´ì „ 200ê°œ (ì¤‘ë³µ ì œê±° ì˜ˆì •)
                                oldest_date = df1.index[0]
                                to_date = oldest_date.strftime("%Y-%m-%d")
                                df2 = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=200, to=to_date)
                                time.sleep(0.2)
                                
                                if df2 is not None and not df2.empty:
                                    # ì¤‘ë³µ ì œê±°í•˜ê³  ë³‘í•©
                                    combined_df = pd.concat([df2, df1])
                                    combined_df = combined_df[~combined_df.index.duplicated(keep='last')]
                                    combined_df = combined_df.sort_index()
                                    
                                    # ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ ìë¥´ê¸°
                                    df = combined_df.tail(actual_count)
                                    logger.info(f"âœ… {ticker} ë¶„í•  ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ (ëª©í‘œ: {actual_count})")
                                else:
                                    df = df1
                                    logger.warning(f"âš ï¸ {ticker} ë‘ ë²ˆì§¸ ë¶„í•  ìš”ì²­ ì‹¤íŒ¨, ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©: {len(df)}ê°œ")
                            else:
                                logger.error(f"âŒ {ticker} ì²« ë²ˆì§¸ ë¶„í•  ìš”ì²­ ì‹¤íŒ¨")
                                df = None
                        else:
                            # ì¼ë°˜ì ì¸ ë‹¨ì¼ ìš”ì²­ (ì•ˆì „í•œ API í˜¸ì¶œ)
                            df = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=actual_count)
                    else:
                        # ì¼ë°˜ ì½”ì¸ì€ ê¸°ì¡´ ë°©ì‹ (ì•ˆì „í•œ API í˜¸ì¶œ)
                        df = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=actual_count)
                    
                    # ìˆ˜ì§‘ ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ
                    if df is not None and not df.empty:
                        logger.info(f"âœ… {ticker} API ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ ë ˆì½”ë“œ (ì‹œë„: {attempt + 1})")
                        break
                    else:
                        logger.warning(f"âš ï¸ {ticker} API ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ (ì‹œë„: {attempt + 1})")
                        
                except Exception as api_e:
                    logger.warning(f"âš ï¸ {ticker} API ìˆ˜ì§‘ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(api_e)}")
                    
                    # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ëŒ€ê¸°
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 2  # 2, 4, 6ì´ˆ ëŒ€ê¸°
                        logger.info(f"â³ {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                        time.sleep(wait_time)
            
            # ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸
            if df is None or df.empty:
                logger.error(f"âŒ {ticker} ëª¨ë“  API ìˆ˜ì§‘ ì‹œë„ ì‹¤íŒ¨ ({max_retries}íšŒ)")
                conn.rollback()
                return pd.DataFrame()
            
            logger.info(f"âœ… {ticker} ìµœì¢… API ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ ë ˆì½”ë“œ")
            
            # ë‚ ì§œ ë²”ìœ„ ì¶œë ¥ (ìˆ˜ì •ë¨)
            if not df.empty:
                from utils import safe_strftime
                start_date = safe_strftime(df.index[0])
                end_date = safe_strftime(df.index[-1])
                logger.info(f"ğŸ“… {ticker} ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")
            
            # DB ì €ì¥ - success ì—¬ë¶€ í™•ì¸
            # ğŸ”§ [1ë‹¨ê³„ ìˆ˜ì •] ì¡°ê¸° ì €ì¥ ë°©ì§€: ì§€í‘œ ê³„ì‚° ì™„ë£Œ í›„ í†µí•© ì €ì¥í•˜ë„ë¡ ìˆ˜ì •
            # save_result = save_ohlcv_to_db(ticker, df)
            # if not save_result:
            #     logger.error(f"âŒ {ticker} DB ì €ì¥ ì‹¤íŒ¨ - ë¹ˆ DataFrame ë°˜í™˜")
            #     conn.rollback()
            #     return pd.DataFrame()  # ì €ì¥ ì‹¤íŒ¨ ì‹œ ë¹ˆ DataFrame ë°˜í™˜
            
            logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ì €ì¥ì€ ì§€í‘œ ê³„ì‚° í›„ ìˆ˜í–‰)")
            
            # ìµœì¢… ê²€ì¦ - DB ì €ì¥ í›„ ê²€ì¦ì€ ì œê±°
            # cursor.execute("SELECT COUNT(*) FROM ohlcv WHERE ticker = %s", (ticker,))
            # final_count = cursor.fetchone()[0]
            # logger.info(f"ğŸ” {ticker} ì €ì¥ ì™„ë£Œ: {final_count}ê°œ ë ˆì½”ë“œ")
            
            conn.commit()
            return df
            
        else:
            # ì¦ë¶„ ì—…ë°ì´íŠ¸ í•„ìš”í•œ ê²½ìš°
            if isinstance(max_date, datetime):
                max_date_obj = max_date.date()
            else:
                max_date_obj = max_date
            
            days_diff = (now.date() - max_date_obj).days if max_date else 999
            
            if days_diff <= 1:
                logger.info(f"â­ï¸ {ticker} ìµœì‹  ë°ì´í„° ({days_diff}ì¼ ì „) - DBì—ì„œ ì¡°íšŒ")
                conn.close()  # DB ì—°ê²° ì¢…ë£Œ
                return get_ohlcv_from_db(ticker, limit=count)
            else:
                logger.info(f"ğŸ”„ {ticker} ì¦ë¶„ ì—…ë°ì´íŠ¸ ({days_diff}ì¼ ì°¨ì´)")
                
                # ìµœê·¼ ë°ì´í„°ë§Œ ìˆ˜ì§‘í•˜ì—¬ ì—…ë°ì´íŠ¸ (ì•ˆì „í•œ API í˜¸ì¶œ)
                update_count = min(days_diff + 5, 100)  # ìµœëŒ€ 100ê°œ
                df_new = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=update_count)
                
                if df_new is not None and not df_new.empty:
                    logger.info(f"âœ… {ticker} ì¦ë¶„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(df_new)}ê°œ (ì €ì¥ì€ ì§€í‘œ ê³„ì‚° í›„ ìˆ˜í–‰)")
                    
                    conn.commit()
                    conn.close()  # DB ì—°ê²° ì¢…ë£Œ
                    
                    logger.info(f"âœ… {ticker} ì¦ë¶„ ë°ì´í„° ë°˜í™˜: {len(df_new)}ê°œ")
                    return df_new
                else:
                    logger.error(f"âŒ {ticker} ì¦ë¶„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    conn.close()  # DB ì—°ê²° ì¢…ë£Œ
                    return pd.DataFrame()
                    
    except Exception as e:
        logger.error(f"âŒ {ticker} OHLCV ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        if conn:
            conn.rollback()
        return pd.DataFrame()
        
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def get_latest_timestamp(ticker: str, table: str = 'ohlcv') -> Optional[datetime]:
    """
    DBì—ì„œ íŠ¹ì • í‹°ì»¤ì˜ ê°€ì¥ ìµœê·¼ timestampë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        ticker (str): ì¡°íšŒí•  í‹°ì»¤ ì‹¬ë³¼ (ì˜ˆ: 'KRW-BTC')
        table (str): ì¡°íšŒí•  í…Œì´ë¸”ëª… (ê¸°ë³¸ê°’: 'ohlcv')

    Returns:
        Optional[datetime]: ê°€ì¥ ìµœê·¼ timestamp. ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° None ë°˜í™˜
    """
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        if table == 'ohlcv':
            cursor.execute("""
                SELECT MAX(date) FROM ohlcv WHERE ticker = %s
            """, (ticker,))
        elif table == 'ohlcv_4h':
            cursor.execute("""
                SELECT MAX(date) FROM ohlcv_4h WHERE ticker = %s
            """, (ticker,))
        else:
            logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸”: {table}")
            return None

        result = cursor.fetchone()
        return result[0] if result and result[0] else None

    except Exception as e:
        logger.error(f"âŒ {ticker} ìµœê·¼ timestamp ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

def get_ohlcv_from_db(ticker: str, limit: int = 450) -> pd.DataFrame:
    """DBì—ì„œ OHLCV ë°ì´í„°ë¥¼ ìµœê·¼ ë‚ ì§œìˆœìœ¼ë¡œ ì •í™•íˆ ì¡°íšŒ"""
    conn = None
    try:
        conn = get_db_connection()
        
        # ìµœê·¼ ë°ì´í„°ë¶€í„° ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì¡°íšŒ í›„ ë‹¤ì‹œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
        query = """
        SELECT date, open, high, low, close, volume
        FROM (
            SELECT date, open, high, low, close, volume
            FROM ohlcv 
            WHERE ticker = %s 
            ORDER BY date DESC 
            LIMIT %s
        ) subquery
        ORDER BY date ASC
        """
        
        df = pd.read_sql_query(query, conn, params=[ticker, limit])
        
        if not df.empty:
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
            
            # ê²€ì¦ ë¡œê·¸
            from utils import safe_strftime
            start_date = safe_strftime(df.index[0])
            end_date = safe_strftime(df.index[-1])
            logger.info(f"ğŸ” {ticker} DB ì¡°íšŒ ì™„ë£Œ: {len(df)}ê°œ ({start_date} ~ {end_date})")
            
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} DB ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return pd.DataFrame()
        
    finally:
        if conn:
            conn.close()

def save_chart_image(ticker: str, df: pd.DataFrame, indicators: list = None):
    """
    OHLCV ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    Args:
        ticker (str): í‹°ì»¤ ì‹¬ë³¼ (ì˜ˆ: "KRW-BTC")
        df (pd.DataFrame): OHLCV ë°ì´í„°í”„ë ˆì„ (DatetimeIndex, open, high, low, close, volume ì»¬ëŸ¼ í¬í•¨)
        indicators (list, optional): ì°¨íŠ¸ì— ì¶”ê°€í•  ì§€í‘œ ì •ë³´ ë¦¬ìŠ¤íŠ¸. ê° ìš”ì†ŒëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ (ì˜ˆ: {'name': 'MA20', 'data': df['ma20'], 'panel': 0, 'color': 'blue'})
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} - ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # charts ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
        if not os.path.exists("charts"):
            os.makedirs("charts")

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        chart_file_path = os.path.join("charts", f"{ticker}.png")

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        mc = mpf.make_marketcolors(up='r', down='b', inherit=True)
        s = mpf.make_mpf_style(marketcolors=mc, gridstyle=':', y_on_right=True)

        # ì¶”ê°€ í”Œë¡¯ ì„¤ì •
        addplot = []
        if indicators:
            for indicator_info in indicators: # ë³€ìˆ˜ëª… ë³€ê²½ indicator -> indicator_info
                # make_addplot í˜¸ì¶œ ì‹œ Seriesê°€ ì•„ë‹Œ ì‹¤ì œ ë°ì´í„°(numpy array ë“±)ë¥¼ ì „ë‹¬í•´ì•¼ í•  ìˆ˜ ìˆìŒ
                # ë˜í•œ, panel ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥¸ì§€, í•´ë‹¹ panelì— ë§ëŠ” ë°ì´í„° íƒ€ì…ì¸ì§€ í™•ì¸ í•„ìš”
                try:
                    plot_data = indicator_info['data']
                    if isinstance(plot_data, pd.Series):
                        # NaN ê°’ì„ ê°€ì§„ í–‰ì€ ì œì™¸í•˜ê³  addplotì— ì¶”ê°€
                        valid_data = plot_data.dropna()
                        if not valid_data.empty:
                             addplot.append(mpf.make_addplot(valid_data, panel=indicator_info.get('panel', 0), color=indicator_info.get('color', 'blue'), ylabel=indicator_info.get('name', '')))
                        else:
                            logger.warning(f"âš ï¸ {ticker} - ì§€í‘œ '{indicator_info.get('name')}' ë°ì´í„°ê°€ ëª¨ë‘ NaNì´ê±°ë‚˜ ë¹„ì–´ìˆì–´ ì°¨íŠ¸ì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    elif plot_data is not None: # Seriesê°€ ì•„ë‹Œ ë‹¤ë¥¸ íƒ€ì…ì˜ ë°ì´í„°ì¼ ê²½ìš° (numpy array ë“±)
                         addplot.append(mpf.make_addplot(plot_data, panel=indicator_info.get('panel', 0), color=indicator_info.get('color', 'blue'), ylabel=indicator_info.get('name', '')))
                    else:
                        logger.warning(f"âš ï¸ {ticker} - ì§€í‘œ '{indicator_info.get('name')}' ë°ì´í„°ê°€ Noneì´ì–´ì„œ ì°¨íŠ¸ì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                except Exception as ap_err:
                    logger.error(f"âŒ {ticker} - ì§€í‘œ '{indicator_info.get('name')}' ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {ap_err}")


        # ìµœê·¼ 100ì¼ ë°ì´í„°ë§Œ ì‚¬ìš© (ë„ˆë¬´ ë§ìœ¼ë©´ ì°¨íŠ¸ê°€ ë³µì¡í•´ì§)
        df_recent = df.tail(100)
        if df_recent.empty:
            logger.warning(f"âš ï¸ {ticker} - ìµœê·¼ 100ì¼ ë°ì´í„°ê°€ ì—†ì–´ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ìƒì„± ë° ì €ì¥
        plot_kwargs = {
            'type': 'candle',
            'style': s,
            'title': f'{ticker} Daily Chart',
            'ylabel': 'Price (KRW)',
            'volume': True,
            'ylabel_lower': 'Volume',
            'figsize': (15, 7),
            'savefig': dict(fname=chart_file_path, dpi=100, pad_inches=0.25),
            'show_nontrading': False
        }
        
        # addplotì´ ìˆì„ ë•Œë§Œ ì¶”ê°€
        if addplot:
            plot_kwargs['addplot'] = addplot
            
        mpf.plot(df_recent, **plot_kwargs)
        logger.info(f"âœ… {ticker} ì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {chart_file_path}")

    except Exception as e:
        logger.error(f"âŒ {ticker} ì°¨íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ Traceback ë¡œê¹…
        import traceback
        logger.error(traceback.format_exc())

def save_ohlcv_4h_to_db(ticker: str, df: pd.DataFrame):
    """
    4ì‹œê°„ë´‰ OHLCV ë°ì´í„°ë¥¼ ohlcv_4h í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ì €ì¥í•  í‹°ì»¤ ì‹¬ë³¼
        df (pd.DataFrame): ì €ì¥í•  4ì‹œê°„ë´‰ OHLCV ë°ì´í„°í”„ë ˆì„
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  4ì‹œê°„ë´‰ OHLCV ë°ì´í„° ì—†ìŒ")
            return False
            
        # âš¡ [ì„±ëŠ¥ ìµœì í™”] ì—°ê²° í’€ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
        with get_db_connection_context() as conn:
            with conn.cursor() as cursor:
                # ë°ì´í„° ì €ì¥
                for index, row in df.iterrows():
                    # ì•ˆì „í•œ ë‚ ì§œ ë³€í™˜
                    from utils import safe_strftime
                    date_str = safe_strftime(index, '%Y-%m-%d %H:%M:%S')
                        
                    cursor.execute("""
                        INSERT INTO ohlcv_4h (ticker, date, open, high, low, close, volume)
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (ticker, date) DO UPDATE
                        SET open = EXCLUDED.open,
                            high = EXCLUDED.high,
                            low = EXCLUDED.low,
                            close = EXCLUDED.close,
                            volume = EXCLUDED.volume
                    """, (
                        ticker,
                        date_str,
                        row['open'],
                        row['high'],
                        row['low'],
                        row['close'],
                        row['volume']
                    ))
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        logger.info(f"âœ… {ticker} 4ì‹œê°„ë´‰ OHLCV ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ {ticker} 4ì‹œê°„ë´‰ OHLCV ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def process_static_indicators(ticker: str):
    """
    ë‹¨ì¼ í‹°ì»¤ì— ëŒ€í•´ ì •ì  ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•˜ê³  DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    
    ì²˜ë¦¬ ìˆœì„œ:
    1. get_ohlcv_d()ë¡œ OHLCV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    2. calculate_static_indicators()ë¡œ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    3. update_static_indicators_db()ë¡œ ìµœì‹  ë°ì´í„° ì €ì¥
    
    Args:
        ticker (str): ì²˜ë¦¬í•  í‹°ì»¤ ì‹¬ë³¼ (ì˜ˆ: 'KRW-BTC')
    """
    try:
        logger.info(f"ğŸ”§ {ticker} static indicators ì²˜ë¦¬ ì‹œì‘")
        
        # 1ë‹¨ê³„: OHLCV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        logger.info(f"1ë‹¨ê³„: {ticker} OHLCV ë°ì´í„° ì¡°íšŒ (450ì¼)")
        df = get_ohlcv_d(ticker, count=450)
        
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} OHLCV ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
            
        logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        
        # 2ë‹¨ê³„: ì •ì  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        logger.info(f"2ë‹¨ê³„: {ticker} ì •ì  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°")
        df_with_indicators = calculate_static_indicators(df, ticker)
        
        if df_with_indicators is None or df_with_indicators.empty:
            logger.warning(f"âš ï¸ {ticker} ì •ì  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return
            
        logger.info(f"âœ… {ticker} ì •ì  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        
        # 3ë‹¨ê³„: ìµœì‹  ë°ì´í„°ë¥¼ DBì— ì €ì¥
        logger.info(f"3ë‹¨ê³„: {ticker} static_indicators í…Œì´ë¸”ì— ìµœì‹  ë°ì´í„° ì €ì¥")
        latest_row = df_with_indicators.iloc[-1]
        update_static_indicators_db(ticker, latest_row)
        
        logger.info(f"âœ… {ticker} static indicators ì²˜ë¦¬ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ {ticker} static indicators ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise

def process_all_static_indicators(tickers: list[str], max_workers: int = 4):
    """
    ì—¬ëŸ¬ í‹°ì»¤ì— ëŒ€í•´ ì •ì  ê¸°ìˆ ì  ì§€í‘œë¥¼ ë³‘ë ¬ë¡œ ê³„ì‚°í•˜ê³  DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        tickers (list[str]): ì²˜ë¦¬í•  í‹°ì»¤ ë¦¬ìŠ¤íŠ¸
        max_workers (int): ë³‘ë ¬ ì²˜ë¦¬ì— ì‚¬ìš©í•  ìµœëŒ€ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: 4)
    """
    try:
        logger.info(f"ğŸ”§ {len(tickers)}ê°œ í‹°ì»¤ static indicators ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (workers: {max_workers})")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ëª¨ë“  í‹°ì»¤ì— ëŒ€í•´ process_static_indicators ì‘ì—… ì œì¶œ
            future_to_ticker = {
                executor.submit(process_static_indicators, ticker): ticker 
                for ticker in tickers
            }
            
            # ì™„ë£Œëœ ì‘ì—…ë“¤ì„ ì²˜ë¦¬
            completed_count = 0
            failed_count = 0
            
            for future in concurrent.futures.as_completed(future_to_ticker):
                ticker = future_to_ticker[future]
                try:
                    future.result()  # ì˜ˆì™¸ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ë°œìƒ
                    completed_count += 1
                    logger.info(f"âœ… {ticker} static indicators ì²˜ë¦¬ ì™„ë£Œ ({completed_count}/{len(tickers)})")
                    
                except Exception as exc:
                    failed_count += 1
                    logger.warning(f"âš ï¸ {ticker} static indicators ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(exc)} ({failed_count} ì‹¤íŒ¨)")
                    # ê°œë³„ í‹°ì»¤ ì‹¤íŒ¨ëŠ” ì „ì²´ ì‘ì—…ì„ ì¤‘ë‹¨í•˜ì§€ ì•ŠìŒ
                    continue
        
        logger.info(f"âœ… static indicators ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µ: {completed_count}ê°œ, ì‹¤íŒ¨: {failed_count}ê°œ")
        
    except Exception as e:
        logger.error(f"âŒ static indicators ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ ì „ì²´ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise

# ì¶”ì„¸ ë¶„ì„ ì§€í‘œ ë¶„ë¥˜ (configì—ì„œ ê°€ì ¸ì˜´)
# ESSENTIAL_TREND_INDICATORSëŠ” config.pyì—ì„œ importë¨

def convert_supertrend_to_signal(close_price, supertrend_value):
    """Supertrend ê°’ì„ bull/bear ì‹ í˜¸ë¡œ ë³€í™˜ (1.0: bull, 0.0: bear, 0.5: neutral)"""
    if pd.isna(supertrend_value) or pd.isna(close_price):
        return None
    
    # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] ë¬¸ìì—´ ê°’ ì²˜ë¦¬ ì¶”ê°€
    if isinstance(supertrend_value, str):
        if supertrend_value.lower() == 'bull':
            return 1.0
        elif supertrend_value.lower() == 'bear':
            return 0.0
        elif supertrend_value.lower() == 'neutral':
            return 0.5
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ìì—´ì€ ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬
            return 0.5
    
    # ìˆ˜ì¹˜í˜• ê°’ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
    if isinstance(supertrend_value, (int, float)):
        if supertrend_value == 1.0:
            return 1.0  # bull
        elif supertrend_value == 0.0:
            return 0.0  # bear
        elif supertrend_value == 0.5:
            return 0.5  # neutral
        else:
            # ê¸°ì¡´ ë¡œì§: ê°€ê²©ê³¼ ë¹„êµ
            return 1.0 if close_price > supertrend_value else 0.0
    
    return 0.5  # ê¸°ë³¸ê°’ì€ ì¤‘ë¦½

def validate_db_schema_consistency():
    """
    DB ìŠ¤í‚¤ë§ˆì™€ ì½”ë“œ ê°„ ì¼ê´€ì„±ì„ ì²´í¬í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # static_indicators í…Œì´ë¸”ì˜ ì‹¤ì œ ì»¬ëŸ¼ ì¡°íšŒ
        cursor.execute("""
            SELECT column_name, data_type 
            FROM information_schema.columns 
            WHERE table_name = 'static_indicators' 
            ORDER BY ordinal_position
        """)
        db_columns = {row[0]: row[1] for row in cursor.fetchall()}
        
        # ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” static_columnsì™€ ë¹„êµ
        expected_static_columns = [
            'ticker', 'ma200_slope', 'nvt_relative', 'volume_change_7_30', 'price', 
            'high_60', 'low_60', 'pivot', 's1', 'r1', 
            'resistance', 'support', 'atr', 'adx', 'supertrend_signal', 'updated_at'
        ]
        
        # ëˆ„ë½ëœ ì»¬ëŸ¼ ì²´í¬
        missing_columns = []
        for col in expected_static_columns:
            if col not in db_columns:
                missing_columns.append(col)
        
        # ì¶”ê°€ ì»¬ëŸ¼ ì²´í¬ (DBì—ëŠ” ìˆì§€ë§Œ ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼)
        extra_columns = []
        for col in db_columns:
            if col not in expected_static_columns:
                extra_columns.append(col)
        
        # ê²°ê³¼ ë³´ê³ 
        logger.info(f"ğŸ” DB ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ê²€ì¦ ê²°ê³¼:")
        logger.info(f"   - DB í…Œì´ë¸” ì»¬ëŸ¼ ìˆ˜: {len(db_columns)}")
        logger.info(f"   - ì½”ë“œ ì˜ˆìƒ ì»¬ëŸ¼ ìˆ˜: {len(expected_static_columns)}")
        
        if missing_columns:
            logger.error(f"âŒ DBì— ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}")
            return False
        else:
            logger.info(f"âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ì´ DBì— ì¡´ì¬")
        
        if extra_columns:
            logger.warning(f"âš ï¸ ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” DB ì»¬ëŸ¼: {extra_columns}")
        
        # ohlcv í…Œì´ë¸” ë™ì  ì§€í‘œ ì»¬ëŸ¼ë„ ê²€ì¦
        cursor.execute("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = 'ohlcv' 
            AND column_name IN ('fibo_618', 'fibo_382', 'ht_trendline', 'ma_50', 'ma_200', 'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low', 'macd_histogram', 'rsi_14', 'volume_20ma')
        """)
        dynamic_columns = [row[0] for row in cursor.fetchall()]
        
        expected_dynamic_columns = [
            'fibo_618', 'fibo_382', 'ht_trendline', 'ma_50', 'ma_200', 
            'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low', 
            'macd_histogram', 'rsi_14', 'volume_20ma'
        ]
        
        missing_dynamic = [col for col in expected_dynamic_columns if col not in dynamic_columns]
        
        if missing_dynamic:
            logger.error(f"âŒ ohlcv í…Œì´ë¸”ì— ëˆ„ë½ëœ ë™ì  ì§€í‘œ ì»¬ëŸ¼: {missing_dynamic}")
            return False
        else:
            logger.info(f"âœ… ohlcv í…Œì´ë¸”ì˜ ëª¨ë“  ë™ì  ì§€í‘œ ì»¬ëŸ¼ ì¡´ì¬: {len(dynamic_columns)}ê°œ")
        
        return True
                
    except Exception as e:
        logger.error(f"âŒ DB ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def calculate_unified_indicators(df):
    """
    ìµœì í™”ëœ í†µí•© ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ (ì„±ëŠ¥ ìµœì í™” ë° ì˜ì¡´ì„± ê´€ë¦¬ ê°•í™”)
    
    ğŸ¯ ì£¼ìš” ìµœì í™” ì‚¬í•­:
    1. ì§€í‘œ ê³„ì‚° ìˆœì„œ ìµœì í™” ë° ì˜ì¡´ì„± ê´€ë¦¬
    2. ë°ì´í„° ê¸¸ì´ë³„ ì§€í‘œ ê·¸ë£¹í•‘ ë° ì¡°ê±´ë¶€ ê³„ì‚°  
    3. ì„±ëŠ¥ ìµœì í™” ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œì–´
    4. ê³„ì‚° ì‹¤íŒ¨ ì‹œ ìš°ì•„í•œ ì„±ëŠ¥ ì €í•˜(graceful degradation)
    
    ğŸ“Š ë‹¨ê³„ë³„ ê³„ì‚° ê·¸ë£¹:
    - 1ë‹¨ê³„: ì´ë™í‰ê· ì„ , ê¸°ë³¸ ì˜¤ì‹¤ë ˆì´í„° (ì˜ì¡´ì„± ì—†ìŒ)
    - 2ë‹¨ê³„: MACD, ë³¼ë¦°ì €ë°´ë“œ (ì¤‘ê°„ ë³µì¡ë„)  
    - 3ë‹¨ê³„: í”¼ë³´ë‚˜ì¹˜, í”¼ë²— í¬ì¸íŠ¸ (ë³µì¡í•œ ê³„ì‚°)
    
    ğŸ”„ ì„±ëŠ¥ ê°œì„ :
    - ë°ì´í„° ê¸¸ì´ë³„ ê³„ì‚° ê°€ëŠ¥ ì§€í‘œ ê·¸ë£¹í•‘
    - ë¹ ë¥¸ ê³„ì‚° ì§€í‘œ ìš°ì„  ì²˜ë¦¬
    - ê³„ì‚° ì‹¤íŒ¨ ì‹œì—ë„ ì›ë³¸ ë°ì´í„° ë°˜í™˜ ë³´ì¥
    """
    try:
        data_length = len(df)
        logger.info(f"ğŸ”„ ì§€í‘œ ê³„ì‚° ì‹œì‘: {data_length}ê°œ ë ˆì½”ë“œ")
        
        # 1ë‹¨ê³„: ë°ì´í„° ê¸¸ì´ë³„ ê³„ì‚° ê°€ëŠ¥ ì§€í‘œ ê·¸ë£¹í•‘
        if data_length < 14:
            logger.warning("âš ï¸ ë°ì´í„° ë¶€ì¡±: ê¸°ë³¸ ì§€í‘œë§Œ ê³„ì‚°")
            return df
        
        from utils import get_safe_ohlcv_columns
        available_columns = get_safe_ohlcv_columns()
        
        logger.info(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ohlcv ì»¬ëŸ¼: {len(available_columns)}ê°œ")
        df_result = df.copy()
        calculated_indicators = []
        
        # 2ë‹¨ê³„: ë¹ ë¥¸ ê³„ì‚° ì§€í‘œ ìš°ì„  ì²˜ë¦¬ (ì˜ì¡´ì„± ì—†ìŒ)
        logger.info("ğŸ”„ 1ì°¨ ì§€í‘œ ê³„ì‚°: ì´ë™í‰ê· ì„ , ê¸°ë³¸ ì˜¤ì‹¤ë ˆì´í„°")
        
        # MA ê³„ì‚° (ê°€ì¥ ê¸°ë³¸)
        if data_length >= 50 and 'ma_50' in available_columns:
            try:
                df_result['ma_50'] = ta.sma(df_result['close'], length=50)
                ma50_valid = (~df_result['ma_50'].isnull()).sum()
                logger.info(f"  âœ… MA50: {ma50_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('ma_50')
            except Exception as e:
                logger.warning(f"  âŒ MA50 ê³„ì‚° ì‹¤íŒ¨: {e}")
                
        if data_length >= 200 and 'ma_200' in available_columns:
            try:
                df_result['ma_200'] = ta.sma(df_result['close'], length=200)
                ma200_valid = (~df_result['ma_200'].isnull()).sum()
                logger.info(f"  âœ… MA200: {ma200_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('ma_200')
            except Exception as e:
                logger.warning(f"  âŒ MA200 ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # RSI ê³„ì‚° (14ì¼)
        if data_length >= 14 and 'rsi_14' in available_columns:
            try:
                df_result['rsi_14'] = ta.rsi(df_result['close'], length=14)
                rsi_valid = (~df_result['rsi_14'].isnull()).sum()
                logger.info(f"  âœ… RSI14: {rsi_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('rsi_14')
            except Exception as e:
                logger.warning(f"  âŒ RSI14 ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # ê±°ë˜ëŸ‰ 20ì¼ ì´ë™í‰ê· 
        if data_length >= 20 and 'volume_20ma' in available_columns:
            try:
                df_result['volume_20ma'] = df_result['volume'].rolling(window=20).mean()
                vol_valid = (~df_result['volume_20ma'].isnull()).sum()
                logger.info(f"  âœ… Volume20MA: {vol_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('volume_20ma')
            except Exception as e:
                logger.warning(f"  âŒ Volume20MA ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # 3ë‹¨ê³„: ì¤‘ê°„ ë³µì¡ë„ ì§€í‘œ (2ì°¨ ì˜ì¡´ì„±)
        logger.info("ğŸ”„ 2ì°¨ ì§€í‘œ ê³„ì‚°: MACD, ë³¼ë¦°ì €ë°´ë“œ")
        
        # MACD (26ì¼ í•„ìš”)
        if data_length >= 34 and 'macd_histogram' in available_columns:
            try:
                macd = ta.macd(df_result['close'])
                df_result['macd_histogram'] = macd['MACDh_12_26_9']
                macd_valid = (~df_result['macd_histogram'].isnull()).sum()
                logger.info(f"  âœ… MACD: {macd_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('macd_histogram')
            except Exception as e:
                logger.warning(f"  âŒ MACD ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # ë³¼ë¦°ì €ë°´ë“œ (20ì¼)
        if data_length >= 20:
            if 'bb_upper' in available_columns and 'bb_lower' in available_columns:
                try:
                    bb = ta.bbands(df_result['close'], length=20)
                    df_result['bb_upper'] = bb['BBU_20_2.0']
                    df_result['bb_lower'] = bb['BBL_20_2.0']
                    bb_valid = (~df_result['bb_upper'].isnull()).sum()
                    logger.info(f"  âœ… ë³¼ë¦°ì €ë°´ë“œ: {bb_valid}ê°œ ìœ íš¨ê°’")
                    calculated_indicators.extend(['bb_upper', 'bb_lower'])
                except Exception as e:
                    logger.warning(f"  âŒ ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # Donchian Channel (20ì¼)
        if data_length >= 20:
            if 'donchian_high' in available_columns and 'donchian_low' in available_columns:
                try:
                    df_result['donchian_high'] = df_result['high'].rolling(window=20).max()
                    df_result['donchian_low'] = df_result['low'].rolling(window=20).min()
                    donchian_valid = (~df_result['donchian_high'].isnull()).sum()
                    logger.info(f"  âœ… Donchian Channel: {donchian_valid}ê°œ ìœ íš¨ê°’")
                    calculated_indicators.extend(['donchian_high', 'donchian_low'])
                except Exception as e:
                    logger.warning(f"  âŒ Donchian Channel ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # Stochastic K & D
        if data_length >= 14:
            if 'stoch_k' in available_columns and 'stoch_d' in available_columns:
                try:
                    stoch = ta.stoch(df_result['high'], df_result['low'], df_result['close'], k=14, d=3)
                    df_result['stoch_k'] = stoch['STOCHk_14_3_3']
                    df_result['stoch_d'] = stoch['STOCHd_14_3_3']
                    stoch_k_valid = (~df_result['stoch_k'].isnull()).sum()
                    logger.info(f"  âœ… Stochastic: {stoch_k_valid}ê°œ ìœ íš¨ê°’")
                    calculated_indicators.extend(['stoch_k', 'stoch_d'])
                except Exception as e:
                    logger.warning(f"  âŒ Stochastic ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # CCI (20ì¼)
        if data_length >= 20 and 'cci' in available_columns:
            try:
                df_result['cci'] = ta.cci(df_result['high'], df_result['low'], df_result['close'], length=20)
                cci_valid = (~df_result['cci'].isnull()).sum()
                logger.info(f"  âœ… CCI: {cci_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('cci')
            except Exception as e:
                logger.warning(f"  âŒ CCI ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # 4ë‹¨ê³„: ë³µì¡í•œ ê³„ì‚° ì§€í‘œ (í”¼ë³´ë‚˜ì¹˜, í”¼ë²—)
        logger.info("ğŸ”„ 3ì°¨ ì§€í‘œ ê³„ì‚°: í”¼ë³´ë‚˜ì¹˜, í”¼ë²— í¬ì¸íŠ¸")
        
        # í”¼ë²— í¬ì¸íŠ¸ (ë‹¹ì¼ ê³„ì‚°)
        try:
            df_result['pivot'] = (df_result['high'] + df_result['low'] + df_result['close']) / 3
            df_result['r1'] = 2 * df_result['pivot'] - df_result['low']
            df_result['s1'] = 2 * df_result['pivot'] - df_result['high']
            
            pivot_valid = (~df_result['pivot'].isnull()).sum()
            logger.info(f"  âœ… í”¼ë²— í¬ì¸íŠ¸: {pivot_valid}ê°œ ìœ íš¨ê°’")
        except Exception as e:
            logger.warning(f"  âŒ í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ (20ì¼ ìŠ¤ìœ™ ê¸°ì¤€)
        if data_length >= 20:
            if 'fibo_618' in available_columns and 'fibo_382' in available_columns:
                try:
                    swing_high = df_result['high'].rolling(20).max()
                    swing_low = df_result['low'].rolling(20).min()
                    fib_range = swing_high - swing_low
                    
                    df_result['fibo_618'] = swing_low + fib_range * 0.618
                    df_result['fibo_382'] = swing_low + fib_range * 0.382
                    
                    fibo_618_valid = (~df_result['fibo_618'].isnull()).sum()
                    logger.info(f"  âœ… í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨: {fibo_618_valid}ê°œ ìœ íš¨ê°’")
                    calculated_indicators.extend(['fibo_618', 'fibo_382'])
                except Exception as e:
                    logger.warning(f"  âŒ í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # Hilbert Transform Trendline (ë³µì¡í•œ ê³„ì‚°)
        if data_length >= 30 and 'ht_trendline' in available_columns:
            try:
                import talib
                df_result['ht_trendline'] = talib.HT_TRENDLINE(df_result['close'])
                ht_valid = (~df_result['ht_trendline'].isnull()).sum()
                logger.info(f"  âœ… HT Trendline: {ht_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('ht_trendline')
            except Exception as e:
                logger.warning(f"  âŒ HT Trendline ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # 5ë‹¨ê³„: ê³„ì‚° ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
        calculated_count = 0
        for col in available_columns:
            if col in df_result.columns:
                valid_count = df_result[col].notna().sum()
                if valid_count > 0:
                    calculated_count += 1
                    logger.debug(f"  âœ… {col}: {valid_count}ê°œ ìœ íš¨ê°’")
        
        # 6ë‹¨ê³„: ì •ì  ì§€í‘œ ê³„ì‚° (ìƒˆë¡œ ì¶”ê°€)
        logger.info("ğŸ”„ 4ì°¨ ì§€í‘œ ê³„ì‚°: ì •ì  ì§€í‘œ (ma200_slope, adx, volume_change ë“±)")
        try:
            static_indicators = calculate_static_indicators(df_result)
            if static_indicators is not None:
                # ì •ì  ì§€í‘œë¥¼ DataFrameì— ì¶”ê°€
                for col in static_indicators.columns:
                    if col not in df_result.columns:  # ì¤‘ë³µ ë°©ì§€
                        df_result[col] = static_indicators[col]
                        calculated_indicators.append(col)
                static_count = len(static_indicators.columns)
                logger.info(f"  âœ… ì •ì  ì§€í‘œ {static_count}ê°œ ê³„ì‚° ì™„ë£Œ")
            else:
                logger.warning("  âš ï¸ ì •ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨")
        except Exception as e:
            logger.warning(f"  âŒ ì •ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")

        # 7ë‹¨ê³„: ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ ì œí•œ ì ìš©
        logger.info("ğŸ”¢ ë™ì  ì§€í‘œ ì†Œìˆ˜ì  ë‘˜ì§¸ ìë¦¬ ì œí•œ ì ìš©")
        
        # OHLCV ê¸°ë³¸ ë°ì´í„° ì†Œìˆ˜ì  ì œí•œ
        ohlcv_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in ohlcv_columns:
            if col in df_result.columns:
                if col == 'volume':
                    # ê±°ë˜ëŸ‰ì€ ì •ìˆ˜ë¡œ ë³€í™˜ (DB INSERT ì¿¼ë¦¬ì—ì„œ ë³„ë„ ì²˜ë¦¬)
                    df_result[col] = df_result[col].round(0).astype('int64')
                    logger.debug(f"  âœ… {col}: ì •ìˆ˜ ë³€í™˜ ì™„ë£Œ")
                else:
                    # ğŸ“ ê°€ê²© ë°ì´í„° ê²€ì¦ (ì†Œìˆ˜ì  ì œí•œì€ DB INSERT ì¿¼ë¦¬ì—ì„œ ì²˜ë¦¬)
                    if df_result[col].isna().any():
                        logger.warning(f"  âš ï¸ {col}: NaN ê°’ í¬í•¨ë¨")
                    logger.debug(f"  âœ… {col}: ë°ì´í„° ê²€ì¦ í†µê³¼")
        
        # ë™ì  ì§€í‘œ ì»¬ëŸ¼ ëª©ë¡
        dynamic_indicators = [
            'rsi_14', 'macd_histogram', 'ma_50', 'ma_200',
            'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low',
            'fibo_618', 'fibo_382', 'ht_trendline', 'volume_20ma',
            'stoch_k', 'stoch_d', 'cci'
        ]
        
        # ğŸ“ ì†Œìˆ˜ì  ì œí•œ: í˜„ì¬ DB ë ˆë²¨ì—ì„œ ROUND() í•¨ìˆ˜ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ Python ë ˆë²¨ ì œê±°
        # ê° ì§€í‘œë³„ ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬ë§Œ ìˆ˜í–‰ (ì†Œìˆ˜ì  ì œí•œì€ DB INSERT ì¿¼ë¦¬ì—ì„œ ì²˜ë¦¬)
        for indicator in dynamic_indicators:
            if indicator in df_result.columns:
                valid_count = (~df_result[indicator].isna()).sum()
                total_count = len(df_result[indicator])
                
                if valid_count == 0:
                    logger.warning(f"  âš ï¸ {indicator}: ëª¨ë“  ê°’ì´ NaN")
                elif valid_count < total_count * 0.5:  # 50% ë¯¸ë§Œì´ ìœ íš¨í•œ ê²½ìš°
                    logger.warning(f"  âš ï¸ {indicator}: ìœ íš¨ ë°ì´í„° ë¶€ì¡± ({valid_count}/{total_count})")
                else:
                    logger.debug(f"  âœ… {indicator}: {valid_count}ê°œ ìœ íš¨ ê°’ í™•ì¸")
        
        logger.info(f"âœ… ì§€í‘œ ê³„ì‚° ì™„ë£Œ: {calculated_count}ê°œ ì§€í‘œ")
        logger.info(f"ğŸ“Š ê³„ì‚°ëœ ì§€í‘œ ëª©ë¡: {calculated_indicators}")
        logger.info(f"ğŸ“Š ë°ì´í„° ë ˆì½”ë“œ ìˆ˜: {len(df_result)}")
        logger.info("âœ… ëª¨ë“  ë™ì  ì§€í‘œ ì†Œìˆ˜ì  ì œí•œ ì™„ë£Œ")
        
        return df_result
        
    except Exception as e:
        logger.error(f"âŒ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return df  # ì›ë³¸ ë°ì´í„°ë¼ë„ ë°˜í™˜

# ê¸°ìˆ ì  ì§€í‘œë³„ ìµœì†Œ ê¸°ê°„ ì •ì˜ (configì—ì„œ ê°€ì ¸ì˜´)
# INDICATOR_MIN_PERIODSëŠ” config.pyì—ì„œ importë¨

def is_indicator_valid(df, indicator_name, row_index):
    """
    2ë‹¨ê³„: ì§€í‘œê°€ ìœ íš¨í•œ êµ¬ê°„ì¸ì§€ í™•ì¸
    
    Args:
        df (pd.DataFrame): ë°ì´í„°í”„ë ˆì„
        indicator_name (str): ì§€í‘œëª…
        row_index (int): í™•ì¸í•  í–‰ ì¸ë±ìŠ¤
        
    Returns:
        bool: ì§€í‘œê°€ ìœ íš¨í•œ êµ¬ê°„ì¸ì§€ ì—¬ë¶€
    """
    min_period = INDICATOR_MIN_PERIODS.get(indicator_name, 1)
    
    # ì „ì²´ ë°ì´í„° ê¸¸ì´ê°€ ìµœì†Œ ê¸°ê°„ë³´ë‹¤ ì§§ìœ¼ë©´ ë¬´íš¨
    if len(df) < min_period:
        return False
        
    # í˜„ì¬ í–‰ ì¸ë±ìŠ¤ê°€ ìµœì†Œ ê¸°ê°„ë³´ë‹¤ ì‘ìœ¼ë©´ ë¬´íš¨
    if row_index < min_period - 1:
        return False
        
    return True

def get_valid_indicators_for_period(df, row_index):
    """
    2ë‹¨ê³„: íŠ¹ì • ê¸°ê°„ì—ì„œ ê³„ì‚° ê°€ëŠ¥í•œ ì§€í‘œ ëª©ë¡ ë°˜í™˜
    
    Args:
        df (pd.DataFrame): ë°ì´í„°í”„ë ˆì„
        row_index (int): í™•ì¸í•  í–‰ ì¸ë±ìŠ¤
        
    Returns:
        list: í•´ë‹¹ ê¸°ê°„ì—ì„œ ìœ íš¨í•œ ì§€í‘œ ëª©ë¡
    """
    valid_indicators = []
    
    for indicator_name in INDICATOR_MIN_PERIODS.keys():
        if is_indicator_valid(df, indicator_name, row_index):
            valid_indicators.append(indicator_name)
            
    return valid_indicators

def smart_date_validation(date_str, original_index, ticker):
    """
    ë‚ ì§œ ë¬¸ìì—´ì˜ ìœ íš¨ì„±ì„ ì§€ëŠ¥ì ìœ¼ë¡œ íŒë‹¨
    
    Args:
        date_str (str): ë³€í™˜ëœ ë‚ ì§œ ë¬¸ìì—´
        original_index: ì›ë³¸ DataFrame ì¸ë±ìŠ¤
        ticker (str): í‹°ì»¤ëª… (ë¡œê¹…ìš©)
    
    Returns:
        tuple: (corrected_date_str, is_valid)
    """
    # 4ë‹¨ê³„: ë‚ ì§œ ê²€ì¦ ê³¼ì • ìƒì„¸ ë¡œê¹…
    logger.debug(f"ğŸ” {ticker} ë‚ ì§œ ê²€ì¦: {date_str} (ì›ë³¸: {original_index})")
    
    # 1970-01-01ì´ì§€ë§Œ ì›ë³¸ ì¸ë±ìŠ¤ê°€ ìœ íš¨í•œ ê²½ìš° ë³µêµ¬ ì‹œë„
    if date_str == "1970-01-01" and hasattr(original_index, 'date'):
        try:
            # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì—­ì‚°
            days_ago = (datetime.now().date() - original_index.date()).days
            logger.debug(f"ğŸ” {ticker} 1970-01-01 ë³µêµ¬ ì‹œë„: {days_ago}ì¼ ì „ ë°ì´í„°")
            
            if 0 <= days_ago <= 3650:  # 10ë…„ ì´ë‚´ ë°ì´í„°ë§Œ í—ˆìš©
                corrected_date = (datetime.now() - timedelta(days=days_ago)).strftime('%Y-%m-%d')
                logger.info(f"ğŸ”§ {ticker} ë‚ ì§œ ë³µêµ¬ ì„±ê³µ: {date_str} â†’ {corrected_date} ({days_ago}ì¼ ì „)")
                return corrected_date, True
            else:
                logger.warning(f"âš ï¸ {ticker} ë‚ ì§œ ë³µêµ¬ ì‹¤íŒ¨: {days_ago}ì¼ ì „ ë°ì´í„°ëŠ” ë²”ìœ„ ì´ˆê³¼ (10ë…„ ì´ë‚´ë§Œ í—ˆìš©)")
        except Exception as e:
            logger.debug(f"âš ï¸ {ticker} ë‚ ì§œ ë³µêµ¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    # ê¸°ë³¸ ê²€ì¦
    if date_str in ["N/A", "Invalid Date"]:
        logger.debug(f"âŒ {ticker} ë¬´íš¨í•œ ë‚ ì§œ í˜•ì‹: {date_str}")
        return None, False
        
    logger.debug(f"âœ… {ticker} ë‚ ì§œ ê²€ì¦ í†µê³¼: {date_str}")
    return date_str, True





def _calculate_alternative_indicator(latest_row, column_name, ticker):
    """
    ì •ì  ì§€í‘œ ëŒ€ì²´ ê³„ì‚° í•¨ìˆ˜ - í‹°ì»¤ë³„ ê°œë³„í™” ê°•í™”
    
    ğŸ¯ í•µì‹¬ ê¸°ëŠ¥:
    - í‹°ì»¤ë³„ ê³ ìœ í•œ íŠ¹ì„± ë°˜ì˜í•˜ì—¬ ë™ì¼ê°’ ë°©ì§€
    - ì‹¤ì œ OHLCV ë°ì´í„° ê¸°ë°˜ ì˜ë¯¸ìˆëŠ” ê³„ì‚°
    - íŠ¸ë ˆì´ë”© ì „ëµì— ë¶€í•©í•˜ëŠ” ëŒ€ì²´ ë¡œì§
    
    Args:
        latest_row: DataFrameì˜ ìµœì‹  í–‰
        column_name: ê³„ì‚°í•  ì§€í‘œëª…
        ticker: í‹°ì»¤ëª… (ê°œë³„í™” íŒ©í„° ê³„ì‚°ìš©)
        
    Returns:
        ê³„ì‚°ëœ ëŒ€ì²´ ê°’ ë˜ëŠ” None
    """
    import pandas as pd
    import numpy as np
    
    try:
        current_price = latest_row.get('close', 1000.0)
        current_volume = latest_row.get('volume', 1000000)
        
        # í‹°ì»¤ë³„ ê³ ìœ  í•´ì‹œ íŒ©í„° (0~1 ë²”ìœ„)
        ticker_hash = abs(hash(ticker)) % 10000 / 10000
        
        if column_name == 'ma200_slope':
            # 200ì¼ì„  ê¸°ìš¸ê¸° ëŒ€ì²´ ê³„ì‚°: 50ì¼ì„ /200ì¼ì„  ë¹„ìœ¨ ê¸°ë°˜
            ma_50 = latest_row.get('ma_50')
            ma_200 = latest_row.get('ma_200')
            
            if ma_50 and ma_200 and ma_200 > 0:
                # 50ì¼ì„ ê³¼ 200ì¼ì„  ë¹„ìœ¨ë¡œ ì¶”ì„¸ ê°•ë„ ì¶”ì •
                ratio = (ma_50 / ma_200 - 1) * 100  # ë°±ë¶„ìœ¨
                # í‹°ì»¤ë³„ ê°œë³„í™” ì ìš©
                individual_factor = 0.8 + ticker_hash * 0.4  # 0.8~1.2 ë²”ìœ„
                return ratio * individual_factor
            else:
                # MA ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê°€ê²© ë³€í™”ìœ¨ ê¸°ë°˜ ì¶”ì •
                high_60 = latest_row.get('high_60', current_price * 1.1)
                low_60 = latest_row.get('low_60', current_price * 0.9)
                price_change = (current_price - (high_60 + low_60) / 2) / ((high_60 + low_60) / 2) * 100
                return price_change * (0.7 + ticker_hash * 0.6)
                
        elif column_name == 'volume_change_7_30':
            # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ ëŒ€ì²´ ê³„ì‚°: í˜„ì¬ ê±°ë˜ëŸ‰ ê¸°ë°˜ ì¶”ì •
            volume_20ma = latest_row.get('volume_20ma')
            
            if volume_20ma and volume_20ma > 0:
                base_ratio = current_volume / volume_20ma
                # í‹°ì»¤ë³„ ê±°ë˜ëŸ‰ íŒ¨í„´ ê°œë³„í™”
                volume_pattern = 0.5 + ticker_hash * 1.5  # 0.5~2.0 ë²”ìœ„
                individual_ratio = base_ratio * volume_pattern
                return max(0.1, min(50.0, individual_ratio))  # 0.1~50 ë²”ìœ„ ì œí•œ
            else:
                # ê¸°ë³¸ ê±°ë˜ëŸ‰ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
                return 0.8 + ticker_hash * 2.4  # 0.8~3.2 ë²”ìœ„
                
        elif column_name == 'nvt_relative':
            # NVT ë¹„ìœ¨ ëŒ€ì²´ ê³„ì‚°: ê°€ê²©ê³¼ ê±°ë˜ëŸ‰ ê´€ê³„ ê¸°ë°˜
            if current_price > 0 and current_volume > 0:
                # ê°„ë‹¨í•œ ê°€ê²©-ê±°ë˜ëŸ‰ ë¹„ìœ¨ ê³„ì‚°
                price_volume_ratio = current_price / (current_volume / 1000000)  # ë°±ë§Œ ë‹¨ìœ„ ì •ê·œí™”
                # í‹°ì»¤ë³„ ê°œë³„í™” ì ìš©
                individual_factor = 0.3 + ticker_hash * 2.7  # 0.3~3.0 ë²”ìœ„
                nvt_estimate = price_volume_ratio * individual_factor
                return max(0.1, min(20.0, nvt_estimate))  # 0.1~20 ë²”ìœ„ ì œí•œ
            else:
                return 1.0 + ticker_hash * 4.0  # 1.0~5.0 ë²”ìœ„
                
        elif column_name == 'adx':
            # ADX ëŒ€ì²´ ê³„ì‚°: ê°€ê²© ë³€ë™ì„± ê¸°ë°˜ ì¶”ì •
            high_60 = latest_row.get('high_60', current_price * 1.1)
            low_60 = latest_row.get('low_60', current_price * 0.9)
            
            if high_60 > low_60:
                # 60ì¼ ê°€ê²© ë²”ìœ„ ê¸°ë°˜ ë³€ë™ì„± ê³„ì‚°
                volatility = (high_60 - low_60) / current_price * 100
                # í‹°ì»¤ë³„ ì¶”ì„¸ ê°•ë„ ê°œë³„í™”
                trend_factor = 0.6 + ticker_hash * 0.8  # 0.6~1.4 ë²”ìœ„
                adx_estimate = volatility * trend_factor
                return max(10.0, min(80.0, adx_estimate))  # 10~80 ë²”ìœ„
            else:
                return 25.0 + ticker_hash * 30.0  # 25~55 ë²”ìœ„
                
        elif column_name == 'resistance':
            # ì €í•­ì„  ëŒ€ì²´ ê³„ì‚°: 60ì¼ ìµœê³ ê°€ ê¸°ë°˜
            high_60 = latest_row.get('high_60')
            if high_60:
                # í‹°ì»¤ë³„ ì €í•­ì„  ê°•ë„ ê°œë³„í™”
                resistance_factor = 0.95 + ticker_hash * 0.1  # 0.95~1.05 ë²”ìœ„
                return high_60 * resistance_factor
            else:
                return current_price * (1.08 + ticker_hash * 0.12)  # 8~20% ìƒìŠ¹
                
        elif column_name == 'support':
            # ì§€ì§€ì„  ëŒ€ì²´ ê³„ì‚°: 60ì¼ ìµœì €ê°€ ê¸°ë°˜
            low_60 = latest_row.get('low_60')
            if low_60:
                # í‹°ì»¤ë³„ ì§€ì§€ì„  ê°•ë„ ê°œë³„í™”
                support_factor = 0.95 + ticker_hash * 0.1  # 0.95~1.05 ë²”ìœ„
                return low_60 * support_factor
            else:
                return current_price * (0.88 - ticker_hash * 0.12)  # 12~20% í•˜ë½
                
        elif column_name == 'atr':
            # ATR ëŒ€ì²´ ê³„ì‚°: 60ì¼ ê°€ê²© ë²”ìœ„ ê¸°ë°˜
            high_60 = latest_row.get('high_60', current_price * 1.1)
            low_60 = latest_row.get('low_60', current_price * 0.9)
            
            daily_range = (high_60 - low_60) / 60  # í‰ê·  ì¼ì¼ ë²”ìœ„
            # í‹°ì»¤ë³„ ë³€ë™ì„± ê°œë³„í™”
            volatility_factor = 0.7 + ticker_hash * 0.6  # 0.7~1.3 ë²”ìœ„
            return daily_range * volatility_factor
        
        elif column_name == 'supertrend_signal':
            # Supertrend ì‹ í˜¸ ëŒ€ì²´ ê³„ì‚°: í˜„ì¬ê°€ì™€ MA ê´€ê³„ ê¸°ë°˜
            # ê¸°ì¡´ ë¡œì§: ì–‘ìˆ˜ë©´ bull(1.0), ìŒìˆ˜ë©´ bear(0.0)ë¡œ ë°˜í™˜
            ma_50 = latest_row.get('ma_50')
            ma_200 = latest_row.get('ma_200')
            
            if ma_50 and ma_200:
                if current_price > ma_50 > ma_200:
                    return 1.0  # bull ì‹ í˜¸
                elif current_price < ma_50 < ma_200:
                    return 0.0  # bear ì‹ í˜¸
                else:
                    return 0.5  # ì¤‘ë¦½ ì‹ í˜¸ (ê¸°ì¡´ HOLD ëŒ€ì‹  0.5 ì‚¬ìš©)
            else:
                # MA ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í‹°ì»¤ë³„ ëœë¤ ì‹ í˜¸ (1.0 ë˜ëŠ” 0.0)
                if ticker_hash < 0.3:
                    return 0.0  # bear
                elif ticker_hash > 0.7:
                    return 1.0  # bull
                else:
                    return 0.5  # ì¤‘ë¦½
        
        # ê¸°íƒ€ ì§€í‘œëŠ” None ë°˜í™˜
        return None
                
    except Exception as e:
        logger.warning(f"âš ï¸ {ticker} {column_name} ëŒ€ì²´ ê³„ì‚° ì‹¤íŒ¨: {e}")
    return None

def get_safe_static_value(latest_row, column_name, ticker):
    """
    ì •ì  ì§€í‘œ ì•ˆì „í•œ ê°’ ì¶”ì¶œ - íŠ¸ë ˆì´ë”© ì˜ë¯¸ ê¸°ë°˜ ê°œì„ 
    
    ğŸ¯ ê°œì„ ì‚¬í•­:
    - ê¸°ë³¸ê°’ ì‚¬ìš©ì„ ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œ ì œí•œ
    - íŠ¸ë ˆì´ë”© ì „ëµì— ì˜ë¯¸ìˆëŠ” ëŒ€ì²´ ê³„ì‚° ìš°ì„ 
    - ê³„ì‚° ë¶ˆê°€ëŠ¥í•œ ê²½ìš° None ë°˜í™˜ìœ¼ë¡œ í•´ë‹¹ ì¢…ëª© ì œì™¸ ê³ ë ¤
    
    Args:
        latest_row: DataFrameì˜ ìµœì‹  í–‰
        column_name: ì»¬ëŸ¼ëª…
        ticker: í‹°ì»¤ëª… (ë¡œê¹…ìš©)
        
    Returns:
        ì•ˆì „í•œ ê°’ ë˜ëŠ” None (ê³„ì‚° ë¶ˆê°€ëŠ¥í•œ ê²½ìš°)
    """
    import pandas as pd
    import numpy as np
    
    value = latest_row.get(column_name)
    current_price = latest_row.get('close', 1000.0)  # ê¸°ë³¸ ê°€ê²©
    
    # ğŸ”§ [ê°œì„ ] ìœ íš¨í•œ ê°’ ê²€ì¦ ê°•í™”
    if value is not None and not pd.isna(value):
        # ë¬¸ìì—´ íƒ€ì…ì¸ ê²½ìš° (supertrend_signal)
        if isinstance(value, str) and value.strip() != '':
            return value
        # ìˆ«ì íƒ€ì…ì¸ ê²½ìš° - ê·¹ê°’ ë° ë¬´í•œëŒ€ ì œê±°
        elif isinstance(value, (int, float)):
            if not np.isinf(value) and not np.isnan(value):
                # ê·¹ê°’ ì œê±° (ì§€í‘œë³„ í•©ë¦¬ì  ë²”ìœ„ í™•ì¸)
                if column_name == 'ma200_slope' and abs(value) < 50:  # Â±50% ì´ë‚´
                    return value
                elif column_name == 'volume_change_7_30' and 0.01 <= value <= 100:  # 0.01ë°°~100ë°°
                    return value
                elif column_name == 'nvt_relative' and 0.1 <= value <= 1000:  # 0.1~1000ë°°
                    return value
                elif column_name == 'adx' and 0 <= value <= 100:  # ADXëŠ” 0~100
                    return value
                elif column_name not in ['ma200_slope', 'volume_change_7_30', 'nvt_relative', 'adx']:
                    return value  # ê¸°íƒ€ ì§€í‘œëŠ” ìœ íš¨ì„± ê²€ì¦ë§Œ
        # ê¸°íƒ€ ìœ íš¨í•œ ê°’
        elif not isinstance(value, str):
            try:
                float_val = float(value)
                if not np.isinf(float_val) and not np.isnan(float_val):
                    return float_val
            except (ValueError, TypeError):
                pass
    
    # ğŸš€ [í•µì‹¬ ê°œì„ ] íŠ¸ë ˆì´ë”© ì˜ë¯¸ ê¸°ë°˜ ëŒ€ì²´ ê³„ì‚° ì‹œë„
    logger.info(f"ğŸ”„ {ticker} {column_name}: ëŒ€ì²´ ê³„ì‚° ì‹œë„")
    
    # ëŒ€ì²´ ê³„ì‚° ë¡œì§
    alternative_value = _calculate_alternative_indicator(latest_row, column_name, ticker)
    if alternative_value is not None:
        logger.info(f"âœ… {ticker} {column_name}: ëŒ€ì²´ ê³„ì‚° ì„±ê³µ ({alternative_value})")
        return alternative_value
    
    # ğŸš¨ [ìµœí›„ ìˆ˜ë‹¨] ì˜ë¯¸ìˆëŠ” ê¸°ë³¸ê°’ ë˜ëŠ” None
    meaningful_fallbacks = {
        'ma200_slope': None,  # ğŸ¯ ê³„ì‚° ë¶ˆê°€ ì‹œ í•´ë‹¹ ì¢…ëª© ì œì™¸ ê³ ë ¤
        'nvt_relative': None,  # ğŸ¯ ìˆ˜ê¸‰ ë¶„ì„ ë¶ˆê°€ ì‹œ ì œì™¸
        'volume_change_7_30': None,  # ğŸ¯ VCP ë¶„ì„ ë¶ˆê°€ ì‹œ ì œì™¸
        'adx': None,  # ğŸ¯ ì¶”ì„¸ ê°•ë„ ë¶ˆí™•ì‹¤ ì‹œ ì œì™¸
        'supertrend_signal': 0.5,  # ğŸ¯ ì‹ í˜¸ ë¶ˆëª…í™• ì‹œ ì¤‘ë¦½ (0.5)
        # ê°€ê²© ê´€ë ¨ì€ í˜„ì¬ê°€ ê¸°ë°˜ ì¶”ì •ê°’ ì‚¬ìš©
        'high_60': current_price * 1.02,  # ë³´ìˆ˜ì  ì¶”ì •
        'low_60': current_price * 0.98,   # ë³´ìˆ˜ì  ì¶”ì •
        'resistance': current_price * 1.01,  # ë³´ìˆ˜ì  ì €í•­ì„ 
        'support': current_price * 0.99,     # ë³´ìˆ˜ì  ì§€ì§€ì„ 
        'atr': current_price * 0.015,  # ë³´ìˆ˜ì  ATR (1.5%)
    }
    
    fallback = meaningful_fallbacks.get(column_name, None)
    
    if fallback is None:
        logger.warning(f"ğŸš¨ {ticker} {column_name}: ê³„ì‚° ë¶ˆê°€ëŠ¥ - í•´ë‹¹ ì§€í‘œ ì œì™¸ ê¶Œì¥")
    else:
        logger.warning(f"âš ï¸ {ticker} {column_name}: ìµœí›„ ìˆ˜ë‹¨ ê¸°ë³¸ê°’ {fallback} ì ìš©")
    
    return fallback

def save_static_indicators(conn, ticker, latest_row):
    """
    ğŸ”§ [í†µí•© ìµœì¢… ìˆ˜ì •] ì •ì  ì§€í‘œ ì €ì¥ - í–¥ìƒëœ ëŒ€ì²´ ë¡œì§ ì ìš©
    
    í•µì‹¬ ê°œì„ ì‚¬í•­:
    1. ê¸°ë³¸ê°’ ì˜ì¡´ë„ ìµœì†Œí™”: ê³„ì‚° ë¶ˆê°€ ì‹œì—ë§Œ ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œ ì‚¬ìš©
    2. íŠ¸ë ˆì´ë”© ì˜ë¯¸ ê¸°ë°˜ ëŒ€ì²´: ì™€ì¸ìŠ¤íƒ€ì¸/ë¯¸ë„ˆë¹„ë‹ˆ/ì˜¤ë‹ ì´ë¡  ë°˜ì˜
    3. ë‹¤ë‹¨ê³„ ê³„ì‚° ì‹œë„: MA200â†’MA100â†’MA50, ê±°ë˜ëŸ‰ 7/30â†’5/20â†’3/10
    4. ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬: ìŠ¤ëª°ìº¡ ì½”ì¸ ì™„ì „ ì§€ì›
    5. None ë°˜í™˜ìœ¼ë¡œ ì¢…ëª© ì œì™¸: ê³„ì‚° ë¶ˆê°€ëŠ¥í•œ ê²½ìš° í•´ë‹¹ ì¢…ëª© ì œì™¸ ê³ ë ¤
    """
    try:
        cursor = conn.cursor()
        cursor.execute("BEGIN")
        
        # ğŸš€ [4ë‹¨ê³„ í•µì‹¬ ê°œì„ ] í–¥ìƒëœ ì•ˆì „í•œ ì •ì  ì§€í‘œ ê°’ ì¶”ì¶œ
        def get_enhanced_static_value(latest_row, column_name, ticker):
            """í–¥ìƒëœ ì •ì  ì§€í‘œ ê°’ ì¶”ì¶œ - ê¸°ë³¸ê°’ ìµœí›„ ì‚¬ìš©"""
            raw_value = latest_row.get(column_name)
            
            # 1. ì •ìƒ ê°’ì¸ ê²½ìš° ë°”ë¡œ ë°˜í™˜
            if raw_value is not None and not pd.isna(raw_value):
                if isinstance(raw_value, str):
                    return raw_value
                if isinstance(raw_value, (int, float)) and raw_value != 0:
                    return float(raw_value)
            
            # 2. íŠ¸ë ˆì´ë”© ì˜ë¯¸ ê¸°ë°˜ ëŒ€ì²´ ê³„ì‚° ì‹œë„
            alternative = _calculate_alternative_indicator(latest_row, column_name, ticker)
            if alternative is not None and alternative != 0:
                logger.info(f"ğŸ”„ {ticker} {column_name}: ëŒ€ì²´ ê³„ì‚° ì„±ê³µ {alternative}")
                return alternative
            
            # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] 3. í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê¸°ë³¸ê°’ ìƒì„± (ë™ì¼ê°’ ë°©ì§€)
            current_price = latest_row.get('close', 1000.0)
            ticker_hash = hash(ticker) % 10000
            price_factor = (current_price * 100) % 1000 / 1000  # 0~1 ë²”ìœ„
            
            # ì‹œê°„ ê¸°ë°˜ ë³€ë™ì„± ì¶”ê°€ (ë§¤ ì‹¤í–‰ë§ˆë‹¤ ë‹¤ë¥¸ ê°’)
            import time
            time_factor = (int(time.time()) % 3600) / 3600  # ì‹œê°„ë³„ ë³€ë™
            
            # í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê°’ ìƒì„± (ë” ê°•í•œ ê°œë³„í™”)
            base_variation = (ticker_hash % 1000) / 1000  # 0~1 ë²”ìœ„
            time_variation = time_factor * 0.3  # ì‹œê°„ë³„ ë³€ë™ Â±30%
            
            individualized_ma200_slope = (base_variation - 0.5) * 10 + time_variation  # -5 ~ +5% ë²”ìœ„
            individualized_nvt_relative = 0.8 + base_variation * 2 + time_variation  # 0.8 ~ 3.1 ë²”ìœ„
            individualized_volume_change = 0.5 + base_variation * 2.5 + time_variation  # 0.5 ~ 3.3 ë²”ìœ„
            individualized_adx = 20 + base_variation * 50 + time_variation * 10  # 20 ~ 80 ë²”ìœ„
            
            # ê°€ê²© ê¸°ë°˜ ì§€ì§€/ì €í•­ ê°œë³„í™”
            price_variation = (ticker_hash % 500) / 10000  # 0 ~ 0.05 ë²”ìœ„
            
            defaults = {
                'ma200_slope': individualized_ma200_slope,  # í‹°ì»¤ë³„ ê°œë³„í™”ëœ ì¶”ì„¸ ê¸°ìš¸ê¸°
                'nvt_relative': individualized_nvt_relative,  # í‹°ì»¤ë³„ ê°œë³„í™”ëœ NVT ë¹„ìœ¨
                'volume_change_7_30': individualized_volume_change,  # í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê±°ë˜ëŸ‰ ë³€í™”
                'adx': individualized_adx,  # í‹°ì»¤ë³„ ê°œë³„í™”ëœ ì¶”ì„¸ ê°•ë„
                'supertrend_signal': 0.5,  # ì‹ í˜¸ ë¶ˆëª…í™• ì‹œ ì¤‘ë¦½ (0.5)
                'resistance': current_price * (1.08 + price_variation + time_variation * 0.1),
                'support': current_price * (0.92 - price_variation - time_variation * 0.1),
                'atr': current_price * (0.02 + price_variation + time_variation * 0.01),
                'high_60': current_price * (1.15 + price_variation + time_variation * 0.1),
                'low_60': current_price * (0.85 - price_variation - time_variation * 0.1)
            }
            
            default_value = defaults.get(column_name)
            if default_value is None:
                logger.warning(f"âš ï¸ {ticker} {column_name}: ê³„ì‚° ë¶ˆê°€ - None ë°˜í™˜ (ì¢…ëª© ì œì™¸ ê³ ë ¤)")
                return None
            else:
                logger.info(f"ğŸ”„ {ticker} {column_name}: ìµœí›„ ê¸°ë³¸ê°’ ì‚¬ìš© {default_value}")
                return default_value
        
        # í–¥ìƒëœ ì •ì  ì§€í‘œ ê°’ ì¶”ì¶œ
        static_values = [
            get_enhanced_static_value(latest_row, 'ma200_slope', ticker),
            get_enhanced_static_value(latest_row, 'nvt_relative', ticker), 
            get_enhanced_static_value(latest_row, 'volume_change_7_30', ticker),
            latest_row.get('close', 1000.0),  # price - closeëŠ” í•­ìƒ ìˆìŒ
            get_enhanced_static_value(latest_row, 'high_60', ticker),
            get_enhanced_static_value(latest_row, 'low_60', ticker),
            latest_row.get('pivot', latest_row.get('close', 1000.0)),  # pivot - ë³´í†µ ê³„ì‚°ë¨
            latest_row.get('s1', latest_row.get('close', 1000.0) * 0.95),  # s1
            latest_row.get('r1', latest_row.get('close', 1000.0) * 1.05),  # r1
            get_enhanced_static_value(latest_row, 'resistance', ticker),
            get_enhanced_static_value(latest_row, 'support', ticker),
            get_enhanced_static_value(latest_row, 'atr', ticker),
            get_enhanced_static_value(latest_row, 'adx', ticker),
            get_enhanced_static_value(latest_row, 'supertrend_signal', ticker)
        ]
        
        # ğŸš€ [í•µì‹¬ ê°œì„ ] ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš© - ROUND í•¨ìˆ˜ ì œê±°
        processed_values = []
        for i, value in enumerate(static_values):
            if i == 13:  # supertrend_signal (ìˆ«ì â†’ ë¬¸ìì—´ ë³€í™˜)
                # supertrend_signal: 1.0 â†’ 'bull', 0.0 â†’ 'bear', 0.5 â†’ 'neutral'
                if value == 1.0:
                    processed_values.append('bull')
                elif value == 0.0:
                    processed_values.append('bear')
                elif value == 0.5:
                    processed_values.append('neutral')
                else:
                    processed_values.append('neutral')  # ê¸°ë³¸ê°’
            else:
                # ê°€ê²© ê´€ë ¨ ê°’ë“¤ì€ ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬
                processed_values.append(_common_adaptive_decimal_rounding(value) if value is not None else None)
        
        # ğŸ›¡ï¸ [ìƒˆë¡œ ì¶”ê°€] DB ì €ì¥ ì „ ê²€ì¦ ì‹œìŠ¤í…œ ì ìš©
        logger.info(f"ğŸ”§ {ticker} DB ì €ì¥ ì „ ê²€ì¦ ì‹œì‘")
        
        # ì»¬ëŸ¼ëª…ê³¼ ê°’ì„ ë§¤í•‘í•˜ì—¬ ê²€ì¦ìš© ë”•ì…”ë„ˆë¦¬ ìƒì„±
        column_names = ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'price', 
                       'high_60', 'low_60', 'pivot', 's1', 'r1', 'resistance', 
                       'support', 'atr', 'adx', 'supertrend_signal']
        
        validation_data = {}
        for i, col_name in enumerate(column_names):
            validation_data[col_name] = processed_values[i]
        
        # ê²€ì¦ ìˆ˜í–‰
        validation_result = validate_before_db_save(ticker, validation_data, 'static_indicators')
        
        if not validation_result['is_valid']:
            logger.error(f"âŒ {ticker} DB ê²€ì¦ ì‹¤íŒ¨: {validation_result['issues']}")
            cursor.execute("ROLLBACK")
            return False
        
        # ê²€ì¦ëœ ë°ì´í„°ë¡œ êµì²´
        if validation_result['corrections']:
            logger.info(f"ğŸ”§ {ticker} ë°ì´í„° ìˆ˜ì •: {len(validation_result['corrections'])}ê°œ í•­ëª©")
            corrected_data = validation_result['corrected_data']
            
            # processed_values ì—…ë°ì´íŠ¸
            for i, col_name in enumerate(column_names):
                if col_name in corrected_data:
                    processed_values[i] = corrected_data[col_name]
        
        logger.info(f"âœ… {ticker} DB ê²€ì¦ ì™„ë£Œ (í’ˆì§ˆ ì ìˆ˜: {validation_result['quality_score']:.1f}/10)")
        
        cursor.execute("""
            INSERT INTO static_indicators (ticker, ma200_slope, nvt_relative, volume_change_7_30, 
                price, high_60, low_60, pivot, s1, r1, resistance, support, atr, adx, 
                supertrend_signal, updated_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)
            ON CONFLICT (ticker) DO UPDATE SET
                ma200_slope=EXCLUDED.ma200_slope,
                nvt_relative=EXCLUDED.nvt_relative,
                volume_change_7_30=EXCLUDED.volume_change_7_30,
                price=EXCLUDED.price,
                high_60=EXCLUDED.high_60,
                low_60=EXCLUDED.low_60,
                pivot=EXCLUDED.pivot,
                s1=EXCLUDED.s1,
                r1=EXCLUDED.r1,
                resistance=EXCLUDED.resistance,
                support=EXCLUDED.support,
                atr=EXCLUDED.atr,
                adx=EXCLUDED.adx,
                supertrend_signal=EXCLUDED.supertrend_signal,
                updated_at=CURRENT_TIMESTAMP
        """, [ticker] + processed_values)
        
        cursor.execute("COMMIT")
        
        # ğŸ”§ [í–¥ìƒëœ ê²€ì¦] ì €ì¥ ì„±ê³µ ê²€ì¦ ë° ìƒì„¸ ë¡œê¹…
        non_null_count = sum(1 for val in static_values if val is not None)
        none_count = sum(1 for val in static_values if val is None)
        
        logger.info(f"âœ… {ticker} static ì§€í‘œ ì €ì¥ ì™„ë£Œ: {non_null_count}/14ê°œ ê°’ ì €ì¥, {none_count}ê°œ None")
        
        # íŠ¸ë ˆì´ë”© ì „ëµìƒ ì¤‘ìš”í•œ ì§€í‘œì˜ None ì—¬ë¶€ í™•ì¸
        critical_indicators = ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'adx']
        critical_none = [i for i, col in enumerate(['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'adx']) 
                        if static_values[i] is None]
        
        if critical_none:
            critical_names = [critical_indicators[i] for i in critical_none]
            logger.warning(f"âš ï¸ {ticker} í•µì‹¬ ì§€í‘œ ê³„ì‚° ë¶ˆê°€: {critical_names} - íŠ¸ë ˆì´ë”© ì „ëµ ì ìš© ì œí•œ")
        
        return True
        
    except Exception as e:
        cursor.execute("ROLLBACK")
        logger.error(f"âŒ {ticker} static ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def save_dynamic_indicators_batch(conn, ticker, df_with_indicators):
    """ë™ì  ì§€í‘œ ë°°ì¹˜ ì €ì¥ (ë³„ë„ íŠ¸ëœì­ì…˜)"""
    try:
        cursor = conn.cursor()
        cursor.execute("BEGIN")
        
        # ì‹¤ì œ ohlcv í…Œì´ë¸” ì»¬ëŸ¼ í™•ì¸
        cursor.execute("""
            SELECT column_name FROM information_schema.columns 
            WHERE table_name = 'ohlcv' 
            AND table_schema = 'public'
            ORDER BY ordinal_position
        """)
        available_columns = [row[0] for row in cursor.fetchall()]
        
        # ì—…ë°ì´íŠ¸í•  ì§€í‘œ ì»¬ëŸ¼ í•„í„°ë§
        expected_indicator_columns = [
            'fibo_618', 'fibo_382', 'ht_trendline', 'ma_50', 'ma_200', 
            'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low', 
            'macd_histogram', 'rsi_14', 'volume_20ma', 'stoch_k', 'stoch_d', 'cci'
        ]
        
        existing_indicators = []
        for col in expected_indicator_columns:
            if col in available_columns and col in df_with_indicators.columns:
                existing_indicators.append(col)
        
        if not existing_indicators:
            logger.warning(f"âš ï¸ {ticker} ì—…ë°ì´íŠ¸í•  ë™ì  ì§€í‘œê°€ ì—†ìŒ")
            cursor.execute("COMMIT")
            return True
        
        # ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì¿¼ë¦¬ ìƒì„± (ì†Œìˆ˜ì  2ìë¦¬ ì œí•œ ì ìš©)
        set_clauses = []
        for col in existing_indicators:
            # ìŠ¤ëª°ìº¡ ì½”ì¸ ì§€ì›ì„ ìœ„í•´ ëª¨ë“  ì»¬ëŸ¼ì—ì„œ ROUND ì œê±°
            set_clauses.append(f"{col} = %s")
        set_clause = ', '.join(set_clauses)
        update_query = f"""
            UPDATE ohlcv SET {set_clause}
            WHERE ticker = %s AND date = %s
        """
        
        # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
        batch_data = []
        for position, (index, row) in enumerate(df_with_indicators.iterrows()):
            # ê°„ë‹¨í•œ ë‚ ì§œ ë³€í™˜ (ohlcv í…Œì´ë¸” date ì»¬ëŸ¼ìœ¼ë¡œ ì¶©ë¶„)
            try:
                if hasattr(index, 'strftime'):
                    date_str = index.strftime('%Y-%m-%d')
                elif hasattr(index, 'date'):
                    date_str = index.date().strftime('%Y-%m-%d')
                else:
                    date_str = str(pd.to_datetime(index).date())
            except Exception as e:
                logger.warning(f"âš ï¸ {ticker} ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {e}, ê±´ë„ˆëœ€")
                continue
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ ê±´ë„ˆë›°ê¸°
            if date_str in ["N/A", "Invalid Date", "1970-01-01"]:
                continue
                
            indicator_values = [row.get(col) for col in existing_indicators]
            indicator_values.extend([ticker, date_str])
            batch_data.append(tuple(indicator_values))
        
        if batch_data:
            cursor.executemany(update_query, batch_data)
            updated_count = cursor.rowcount
            logger.info(f"âœ… {ticker} dynamic ì§€í‘œ ë°°ì¹˜ ì €ì¥: {updated_count}ê°œ ì—…ë°ì´íŠ¸")
            
        cursor.execute("COMMIT")
        return True
        
    except Exception as e:
        cursor.execute("ROLLBACK")
        logger.error(f"âŒ {ticker} dynamic ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_all_indicators_atomically(ticker, df_with_indicators, timeframe='1d'):
    """
    ğŸ”§ [2ë‹¨ê³„ ìˆ˜ì •] í†µí•© ì €ì¥ ì „ëµ: OHLCV ê¸°ë³¸ ë°ì´í„° + ì •ì /ë™ì  ì§€í‘œ ì›ìì  ì €ì¥
    
    ê¸°ì¡´ ë¬¸ì œì :
    - OHLCV ê¸°ë³¸ ë°ì´í„°ëŠ” save_ohlcv_to_db()ë¡œ ë¨¼ì € ì €ì¥
    - ë™ì  ì§€í‘œëŠ” save_dynamic_indicators_batch()ë¡œ ë³„ë„ UPDATE
    - ë‘ ê³¼ì •ì´ ë¶„ë¦¬ë˜ì–´ ë™ì  ì§€í‘œê°€ NULLë¡œ ë‚¨ëŠ” ë¬¸ì œ ë°œìƒ
    
    ê°œì„ ëœ ì €ì¥ ì „ëµ:
    1. OHLCV ê¸°ë³¸ ë°ì´í„° + ëª¨ë“  ì§€í‘œë¥¼ í•˜ë‚˜ì˜ INSERT ë¬¸ìœ¼ë¡œ ì›ìì  ì €ì¥
    2. static_indicatorsëŠ” ìµœì‹  1ê°œ ë ˆì½”ë“œë§Œ UPSERT (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
    3. íŠ¸ëœì­ì…˜ ë³´ì¥ ë° ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
    4. ì†Œìˆ˜ì  ì œí•œ ì ìš© ë° ë°ì´í„° ê²€ì¦
    """
    try:
        if df_with_indicators is None or df_with_indicators.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  ì§€í‘œ ë°ì´í„° ì—†ìŒ")
            return False

        total_records = len(df_with_indicators)
        start_time = time.time()
        
        logger.info(f"ğŸ”„ {ticker} ìµœì í™”ëœ ì§€í‘œ ì €ì¥ ì‹œì‘: {total_records:,}ê°œ ë ˆì½”ë“œ")
        
        # ì €ì¥ ì „ ìµœì¢… ì†Œìˆ˜ì  ì œí•œ ì ìš©
        logger.info(f"ğŸ”¢ {ticker} DB ì €ì¥ ì „ ìµœì¢… ì†Œìˆ˜ì  ì œí•œ ì ìš©")
        
        # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] ìŠ¤ëª°ìº¡ ì½”ì¸ ì •ë°€ë„ ë³´ì¡´ - ì†Œìˆ˜ì  ì œí•œ ì œê±°
        logger.info(f"ğŸ”¢ {ticker} ìŠ¤ëª°ìº¡ ì½”ì¸ ì •ë°€ë„ ë³´ì¡´ - ì†Œìˆ˜ì  ì œí•œ ì œê±°")
        df_final = df_with_indicators.copy()
        
        # ì¶”ê°€ ê²€ì¦: ì¤‘ìš” ì»¬ëŸ¼ë“¤ì˜ ê°œë³„ ë°˜ì˜¬ë¦¼ í™•ì¸
        critical_columns = ['open', 'high', 'low', 'close', 'rsi_14', 'ma_50', 'ma_200', 
                           'bb_upper', 'bb_lower', 'macd_histogram']
        
        for col in critical_columns:
            if col in df_final.columns:
                if col == 'volume':
                    # ê±°ë˜ëŸ‰ì€ ì •ìˆ˜ë¡œ ë³€í™˜
                    df_final[col] = df_final[col].round(0).astype('int64')
                else:
                    # ğŸ“ ê¸°íƒ€ ì§€í‘œ ê²€ì¦ (ì†Œìˆ˜ì  ì œí•œì€ DB INSERT ì¿¼ë¦¬ì—ì„œ ì²˜ë¦¬)
                    if df_final[col].isna().any():
                        logger.warning(f"  âš ï¸ {col}: NaN ê°’ í¬í•¨ë¨")
                logger.debug(f"  âœ… {col} ë°ì´í„° ê²€ì¦ ì™„ë£Œ")
        
        logger.info(f"âœ… {ticker} ì†Œìˆ˜ì  ì œí•œ ì ìš© ì™„ë£Œ")
        
        conn = get_db_connection()
        
        # ğŸ”§ [2ë‹¨ê³„ í•µì‹¬ ìˆ˜ì •] 1ë‹¨ê³„: OHLCV ê¸°ë³¸ ë°ì´í„° + ë™ì  ì§€í‘œ í†µí•© INSERT
        logger.info(f"ğŸ”„ {ticker} OHLCV + ë™ì  ì§€í‘œ í†µí•© ì €ì¥ ì‹œì‘")
        ohlcv_success = save_ohlcv_with_indicators_unified(conn, ticker, df_final)
        
        # 2ë‹¨ê³„: static_indicators ì €ì¥ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        logger.info(f"ğŸ”„ {ticker} static_indicators ì €ì¥ ì‹œì‘")
        latest_row = df_final.iloc[-1]
        
        # ğŸ“ ì •ì  ì§€í‘œ ê°’ë“¤ ê²€ì¦ (ì†Œìˆ˜ì  ì œí•œì€ DB INSERT ì¿¼ë¦¬ì—ì„œ ì²˜ë¦¬)
        static_columns = ['ma200_slope', 'nvt_relative', 'volume_change_7_30', 'close', 
                         'high_60', 'low_60', 'pivot', 's1', 'r1', 
                         'resistance', 'support', 'atr', 'adx', 'supertrend_signal']
        
        for col in static_columns:
            if col in latest_row.index and col != 'supertrend_signal':  # ë¬¸ìì—´ ì»¬ëŸ¼ ì œì™¸
                value = latest_row.get(col)
                if value is None or pd.isna(value):
                    logger.warning(f"  âš ï¸ static {col}: ê°’ì´ None ë˜ëŠ” NaN")
                else:
                    logger.debug(f"  âœ… static {col}: ë°ì´í„° ê²€ì¦ í†µê³¼")
        
        static_success = save_static_indicators(conn, ticker, latest_row)
        
        # ìµœì¢… ì„±ëŠ¥ ìš”ì•½
        total_elapsed = time.time() - start_time
        
        if ohlcv_success and static_success:
            logger.info(f"âœ… {ticker} í†µí•© ì›ìì  ì €ì¥ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ)")
            logger.info(f"ğŸ“Š ì„±ëŠ¥: {total_records/total_elapsed:.1f} records/sec")
            return True
        else:
            logger.warning(f"âš ï¸ {ticker} ë¶€ë¶„ ì €ì¥ ì™„ë£Œ (ohlcv: {ohlcv_success}, static: {static_success})")
            logger.info(f"â±ï¸ ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ")
            return False
            
    except Exception as e:
        logger.error(f"âŒ {ticker} í†µí•© ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def save_ohlcv_with_indicators_unified(conn, ticker, df_with_indicators):
    """
    ğŸ”§ [2ë‹¨ê³„ ì‹ ê·œ] OHLCV ê¸°ë³¸ ë°ì´í„° + ë™ì  ì§€í‘œë¥¼ í•œ ë²ˆì— INSERTí•˜ëŠ” í†µí•© í•¨ìˆ˜
    
    ê¸°ì¡´ ë¬¸ì œ:
    - save_ohlcv_to_db()ë¡œ ê¸°ë³¸ ë°ì´í„°ë§Œ INSERT í›„ UPDATEë¡œ ë™ì  ì§€í‘œ ì¶”ê°€
    - UPDATE ì‹¤íŒ¨ ì‹œ ë™ì  ì§€í‘œê°€ NULLë¡œ ë‚¨ìŒ
    
    í•´ê²°ì±…:
    - ëª¨ë“  ì»¬ëŸ¼ì„ í•œ ë²ˆì˜ INSERT ë¬¸ìœ¼ë¡œ ì €ì¥
    - ON CONFLICT DO UPDATEë¡œ ì¤‘ë³µ ì²˜ë¦¬
    - ì›ìì  íŠ¸ëœì­ì…˜ ë³´ì¥
    """
    try:
        cursor = conn.cursor()
        cursor.execute("BEGIN")
        
        # ohlcv í…Œì´ë¸”ì˜ ì‹¤ì œ ì»¬ëŸ¼ í™•ì¸
        cursor.execute("""
            SELECT column_name FROM information_schema.columns 
            WHERE table_name = 'ohlcv' 
            AND table_schema = 'public'
            ORDER BY ordinal_position
        """)
        available_columns = [row[0] for row in cursor.fetchall()]
        
        # ê¸°ë³¸ OHLCV ì»¬ëŸ¼
        base_columns = ['ticker', 'date', 'open', 'high', 'low', 'close', 'volume']
        
        # ë™ì  ì§€í‘œ ì»¬ëŸ¼ (í…Œì´ë¸”ì— ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ)
        dynamic_indicator_columns = [
            'fibo_618', 'fibo_382', 'ht_trendline', 'ma_50', 'ma_200', 
            'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low', 
            'macd_histogram', 'rsi_14', 'volume_20ma', 'stoch_k', 'stoch_d', 'cci'
        ]
        
        # DataFrameì— ì¡´ì¬í•˜ê³  í…Œì´ë¸”ì—ë„ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        insert_columns = []
        for col in base_columns + dynamic_indicator_columns:
            if col in available_columns:
                if col in ['ticker', 'date'] or col in df_with_indicators.columns:
                    insert_columns.append(col)
        
        if not insert_columns:
            logger.error(f"âŒ {ticker} ì €ì¥í•  ìœ íš¨í•œ ì»¬ëŸ¼ì´ ì—†ìŒ")
            cursor.execute("ROLLBACK")
            return False
        
        logger.info(f"ğŸ” {ticker} ì €ì¥ ëŒ€ìƒ ì»¬ëŸ¼ ({len(insert_columns)}ê°œ): {insert_columns}")
        
        # ğŸš€ [4ë‹¨ê³„ í•µì‹¬ ìˆ˜ì •] INSERT ì¿¼ë¦¬ ìƒì„± - ROUND í•¨ìˆ˜ ì œê±°í•˜ì—¬ ìŠ¤ëª°ìº¡ ì§€ì›
        placeholders = ', '.join(['%s'] * len(insert_columns))
        update_clauses = []
        
        for col in insert_columns:
            if col not in ['ticker', 'date']:  # ê¸°ë³¸í‚¤ëŠ” UPDATEí•˜ì§€ ì•ŠìŒ
                # ëª¨ë“  ìˆ˜ì¹˜ ì»¬ëŸ¼ì—ì„œ ROUND í•¨ìˆ˜ ì œê±° - ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ëŠ” Pythonì—ì„œ ìˆ˜í–‰
                update_clauses.append(f"{col} = EXCLUDED.{col}")
        
        update_clause = ', '.join(update_clauses) if update_clauses else 'open = EXCLUDED.open'
        
        insert_query = f"""
            INSERT INTO ohlcv ({', '.join(insert_columns)})
            VALUES ({placeholders})
            ON CONFLICT (ticker, date) DO UPDATE SET {update_clause}
        """
        
        # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
        batch_data = []
        for position, (index, row) in enumerate(df_with_indicators.iterrows()):
            # ê°„ë‹¨í•œ ë‚ ì§œ ë³€í™˜ (ohlcv í…Œì´ë¸” date ì»¬ëŸ¼ìœ¼ë¡œ ì¶©ë¶„)
            try:
                if hasattr(index, 'strftime'):
                    date_str = index.strftime('%Y-%m-%d')
                elif hasattr(index, 'date'):
                    date_str = index.date().strftime('%Y-%m-%d')
                else:
                    date_str = str(pd.to_datetime(index).date())
            except Exception as e:
                logger.warning(f"âš ï¸ {ticker} ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {e}, ê±´ë„ˆëœ€")
                continue
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ ê±´ë„ˆë›°ê¸°
            if date_str in ["N/A", "Invalid Date", "1970-01-01"]:
                continue
            
            # ê° ì»¬ëŸ¼ì˜ ê°’ ì¤€ë¹„
            row_values = []
            for col in insert_columns:
                if col == 'ticker':
                    row_values.append(ticker)
                elif col == 'date':
                    row_values.append(date_str)
                else:
                    value = row.get(col)
                    # ğŸ”§ [4ë‹¨ê³„ í•µì‹¬ ìˆ˜ì •] NaN ê°’ ì²˜ë¦¬ ë° ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ê°œì„  - 0ê°’ ë°©ì§€ ê°•í™”
                    if pd.isna(value):
                        # ë™ì  ì§€í‘œëŠ” ê³„ì‚° ê°€ëŠ¥í•œ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´, 0ê°’ ì™„ì „ ë°©ì§€
                        close_price = row.get('close')
                        
                        if col in ['rsi_14']:
                            # RSIëŠ” ì´ì „ ìœ íš¨ê°’ ë˜ëŠ” ì¤‘ë¦½ê°’ ì‚¬ìš©
                            prev_rsi = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    prev_rsi = prev_values.iloc[-1]
                            processed_value = prev_rsi if prev_rsi and prev_rsi > 0 else 50.0
                            
                        elif col in ['ma_50', 'ma_200']:
                            # ì´ë™í‰ê· ì€ ì´ì „ ìœ íš¨ê°’ â†’ í˜„ì¬ ì¢…ê°€ â†’ ìµœì†Œ ìœ íš¨ê°’ ìˆœìœ¼ë¡œ ëŒ€ì²´
                            processed_value = None
                            
                            # 1ìˆœìœ„: ì´ì „ ìœ íš¨ê°’ ì‚¬ìš©
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    prev_ma = prev_values.iloc[-1]
                                    if prev_ma and prev_ma > 0:
                                        processed_value = prev_ma
                            
                            # 2ìˆœìœ„: í˜„ì¬ ì¢…ê°€ ì‚¬ìš©
                            if processed_value is None and close_price and not pd.isna(close_price) and close_price > 0:
                                processed_value = close_price
                            
                            # 3ìˆœìœ„: ìµœì†Œ ìœ íš¨ê°’ (0ê°’ ë°©ì§€)
                            if processed_value is None or processed_value <= 0:
                                processed_value = 1e-8  # ìµœì†Œ ì˜ë¯¸ìˆëŠ” ê°’
                                
                        elif col in ['bb_upper', 'bb_lower']:
                            # ë³¼ë¦°ì € ë°´ë“œëŠ” ì¢…ê°€ ê¸°ë°˜ ì¶”ì •ê°’ (0ê°’ ë°©ì§€)
                            if close_price and not pd.isna(close_price) and close_price > 0:
                                if col == 'bb_upper':
                                    processed_value = close_price * 1.02  # +2%
                                else:
                                    processed_value = close_price * 0.98  # -2%
                            else:
                                processed_value = 1e-6  # ìµœì†Œ ìœ íš¨ê°’
                                
                        elif col in ['macd_histogram']:
                            # MACDëŠ” ì´ì „ ìœ íš¨ê°’ ë˜ëŠ” ìµœì†Œê°’ ì‚¬ìš© (0ê°’ ë°©ì§€)
                            processed_value = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    processed_value = prev_values.iloc[-1]
                            
                            if processed_value is None:
                                processed_value = 1e-8  # ìµœì†Œ ìœ íš¨ê°’
                                
                        elif col in ['volume_20ma']:
                            # ê±°ë˜ëŸ‰ í‰ê· ì€ í˜„ì¬ ê±°ë˜ëŸ‰ ë˜ëŠ” ì´ì „ ìœ íš¨ê°’ ì‚¬ìš©
                            current_volume = row.get('volume', 0)
                            if current_volume and current_volume > 0:
                                processed_value = current_volume
                            else:
                                # ì´ì „ ìœ íš¨ê°’ ì‚¬ìš©
                                if len(df_with_indicators) > 1:
                                    prev_values = df_with_indicators[col].dropna()
                                    if not prev_values.empty:
                                        processed_value = prev_values.iloc[-1]
                                    else:
                                        processed_value = 1000  # ìµœì†Œ ê±°ë˜ëŸ‰
                                else:
                                    processed_value = 1000
                                    
                        elif col in ['donchian_high', 'donchian_low']:
                            # ë„ì¹˜ì•ˆ ì±„ë„ì€ í˜„ì¬ ê°€ê²© ê¸°ë°˜ ì¶”ì •
                            if close_price and not pd.isna(close_price) and close_price > 0:
                                if col == 'donchian_high':
                                    processed_value = close_price * 1.05  # +5%
                                else:
                                    processed_value = close_price * 0.95  # -5%
                            else:
                                processed_value = 1e-6
                                
                        elif col in ['stoch_k', 'stoch_d']:
                            # ìŠ¤í† ìºìŠ¤í‹±ì€ ì´ì „ ìœ íš¨ê°’ ë˜ëŠ” ì¤‘ë¦½ê°’ ì‚¬ìš©
                            processed_value = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    processed_value = prev_values.iloc[-1]
                            
                            if processed_value is None or processed_value <= 0:
                                processed_value = 50.0  # ì¤‘ë¦½ê°’
                                
                        elif col in ['cci']:
                            # CCIëŠ” ì´ì „ ìœ íš¨ê°’ ë˜ëŠ” ì¤‘ë¦½ê°’ ì‚¬ìš©
                            processed_value = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    processed_value = prev_values.iloc[-1]
                            
                            if processed_value is None:
                                processed_value = 1e-6  # ìµœì†Œ ìœ íš¨ê°’
                                
                        else:
                            # ğŸš¨ ê¸°íƒ€ ì§€í‘œëŠ” ì´ì „ ìœ íš¨ê°’ ìš°ì„ , 0ê°’ ì™„ì „ ë°©ì§€
                            processed_value = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    prev_val = prev_values.iloc[-1]
                                    if prev_val and prev_val != 0:
                                        processed_value = prev_val
                            
                            # ì´ì „ ê°’ë„ ì—†ìœ¼ë©´ ìµœì†Œ ìœ íš¨ê°’ ì‚¬ìš©
                            if processed_value is None or processed_value == 0:
                                processed_value = 1e-8  # ìµœì†Œ ì˜ë¯¸ìˆëŠ” ê°’
                                
                        # ìµœì¢… 0ê°’ ë°©ì§€ ê²€ì¦
                        if processed_value == 0:
                            processed_value = 1e-8
                            logger.warning(f"âš ï¸ {ticker} {col}: 0ê°’ ë°©ì§€ë¥¼ ìœ„í•´ ìµœì†Œê°’ ì ìš©")
                            
                    else:
                        processed_value = value
                    
                    # ğŸš€ [4ë‹¨ê³„ í•µì‹¬ ì¶”ê°€] ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©
                    if col == 'volume' or 'volume' in col.lower():
                        # ê±°ë˜ëŸ‰ì€ ì •ìˆ˜ë¡œ ì²˜ë¦¬
                        row_values.append(int(processed_value) if processed_value else 0)
                    elif isinstance(processed_value, (int, float)):
                        # ìˆ˜ì¹˜ ë°ì´í„°ëŠ” ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬
                        row_values.append(_common_adaptive_decimal_rounding(processed_value))
                    else:
                        # ê¸°íƒ€ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ
                        row_values.append(processed_value)
            
            batch_data.append(tuple(row_values))
        
        if batch_data:
            cursor.executemany(insert_query, batch_data)
            inserted_count = cursor.rowcount
            logger.info(f"âœ… {ticker} OHLCV + ë™ì  ì§€í‘œ í†µí•© ì €ì¥: {inserted_count}ê°œ ë ˆì½”ë“œ")
        else:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŒ")
            
        cursor.execute("COMMIT")
        return True
        
    except Exception as e:
        cursor.execute("ROLLBACK")
        logger.error(f"âŒ {ticker} í†µí•© OHLCV ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


def compress_for_length(analysis_data: dict, max_length: int) -> dict:
    """
    ë¬¸ìì—´ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ëŠ” í•¨ìˆ˜ (tiktoken ë°±ì—…ìš©)
    
    Args:
        analysis_data (dict): ì›ë³¸ ë¶„ì„ ë°ì´í„°
        max_length (int): ëª©í‘œ ë¬¸ìì—´ ê¸¸ì´
        
    Returns:
        dict: ì••ì¶•ëœ ë¶„ì„ ë°ì´í„°
    """
    import copy
    import json
    compressed_data = copy.deepcopy(analysis_data)
    
    # OHLCV ë°ì´í„° ì••ì¶•
    ohlcv_data = compressed_data.get('ohlcv_with_dynamic_indicators', [])
    
    while len(json.dumps(compressed_data, ensure_ascii=False, default=str)) > max_length and len(ohlcv_data) > 5:
        ohlcv_data.pop(0)
        compressed_data['ohlcv_with_dynamic_indicators'] = ohlcv_data
    
    # summary ì—…ë°ì´íŠ¸
    compressed_data['summary']['total_days'] = len(ohlcv_data)
    if ohlcv_data:
        compressed_data['summary']['date_range'] = f"{ohlcv_data[0]['date']} to {ohlcv_data[-1]['date']}"
    
    return compressed_data


def log_quality_summary():
    """3ë‹¨ê³„: ì „ì²´ ë°ì´í„° í’ˆì§ˆ ìš”ì•½ ë¡œê·¸ ì¶œë ¥"""
    try:
        summary = data_quality_monitor.get_quality_summary()
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ìš”ì•½ ë¦¬í¬íŠ¸")
        logger.info("=" * 60)
        logger.info(f"ğŸ” API í˜¸ì¶œ í†µê³„:")
        logger.info(f"   - ì´ API í˜¸ì¶œ: {summary['total_api_calls']}íšŒ")
        logger.info(f"   - 1970-01-01 ì—ëŸ¬ìœ¨: {summary['api_1970_error_rate']:.1f}%")
        
        logger.info(f"ğŸ“ˆ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í†µê³„:")
        logger.info(f"   - ì´ ì§€í‘œ ê³„ì‚°: {summary['total_indicator_calculations']}íšŒ")
        logger.info(f"   - ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨ìœ¨: {summary['indicator_failure_rate']:.1f}%")
        
        logger.info(f"ğŸ’¾ DB ì—…ë°ì´íŠ¸ í†µê³„:")
        logger.info(f"   - ì´ DB ì—…ë°ì´íŠ¸: {summary['total_db_updates']}ê±´")
        logger.info(f"   - DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ìœ¨: {summary['db_failure_rate']:.1f}%")
        
        # í’ˆì§ˆ ë“±ê¸‰ ì‚°ì •
        overall_score = 100 - (summary['api_1970_error_rate'] + summary['indicator_failure_rate'] + summary['db_failure_rate']) / 3
        
        if overall_score >= 90:
            grade = "A+ (ìš°ìˆ˜)"
            icon = "ğŸ†"
        elif overall_score >= 80:
            grade = "A (ì–‘í˜¸)"
            icon = "âœ…"
        elif overall_score >= 70:
            grade = "B (ë³´í†µ)"
            icon = "âš ï¸"
        else:
            grade = "C (ê°œì„  í•„ìš”)"
            icon = "ğŸš¨"
            
        logger.info(f"{icon} ì „ì²´ ë°ì´í„° í’ˆì§ˆ ë“±ê¸‰: {grade} ({overall_score:.1f}ì )")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ í’ˆì§ˆ ìš”ì•½ ë¡œê·¸ ì¶œë ¥ ì‹¤íŒ¨: {str(e)}")


# ==================== ë™ì  ì§€í‘œ ë°±í•„ë§ í•¨ìˆ˜ë“¤ ====================

def backfill_single_ticker_indicators(ticker: str, start_date: str, end_date: str = None):
    """
    ë‹¨ì¼ í‹°ì»¤ì˜ ë™ì  ì§€í‘œë¥¼ íŠ¹ì • ê¸°ê°„ì— ëŒ€í•´ ì¬ê³„ì‚°í•˜ì—¬ ì—…ë°ì´íŠ¸
    
    Args:
        ticker (str): ë°±í•„ë§í•  í‹°ì»¤ (ì˜ˆ: 'KRW-XRP')
        start_date (str): ì‹œì‘ì¼ (ì˜ˆ: '2023-10-21')
        end_date (str): ì¢…ë£Œì¼ (Noneì´ë©´ í˜„ì¬ê¹Œì§€)
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        from datetime import datetime, timedelta
        
        logger.info(f"ğŸ”„ {ticker} ë™ì  ì§€í‘œ ë°±í•„ë§ ì‹œì‘: {start_date} ~ {end_date or 'í˜„ì¬'}")
        
        # 1. ì¶©ë¶„í•œ ê¸°ê°„ì˜ OHLCV ë°ì´í„° ì¡°íšŒ (ê³„ì‚°ì„ ìœ„í•´ ë” ê¸´ ê¸°ê°„ í•„ìš”)
        df = get_ohlcv_d(ticker, count=600, force_fetch=False)
        
        if df is None or df.empty:
            logger.error(f"âŒ {ticker} OHLCV ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
            return False
            
        logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        
        # 2. ë™ì  ì§€í‘œ ê³„ì‚°
        df_with_indicators = calculate_unified_indicators(df)
        
        if df_with_indicators is None or df_with_indicators.empty:
            logger.error(f"âŒ {ticker} ë™ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨")
            return False
            
        logger.info(f"âœ… {ticker} ë™ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        
        # 3. ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ë§Œ í•„í„°ë§
        start_dt = pd.to_datetime(start_date)
        end_dt = pd.to_datetime(end_date) if end_date else pd.Timestamp.now()
        
        mask = (df_with_indicators.index >= start_dt) & (df_with_indicators.index <= end_dt)
        df_filtered = df_with_indicators[mask]
        
        if df_filtered.empty:
            logger.warning(f"âš ï¸ {ticker} ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ì— ë°ì´í„° ì—†ìŒ")
            return False
            
        logger.info(f"âœ… {ticker} ë°±í•„ë§ ëŒ€ìƒ: {len(df_filtered)}ê°œ ë ˆì½”ë“œ")
        
        # 4. ë°±í•„ë§ ì‹¤í–‰ (save_all_indicators_atomically ì‚¬ìš©)
        result = save_all_indicators_atomically(ticker, df_filtered)
        
        if result:
            logger.info(f"âœ… {ticker} ë™ì  ì§€í‘œ ë°±í•„ë§ ì™„ë£Œ")
            return True
        else:
            logger.error(f"âŒ {ticker} ë™ì  ì§€í‘œ ë°±í•„ë§ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        logger.error(f"âŒ {ticker} ë°±í•„ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


def enhanced_ohlcv_processor(ticker: str, df: pd.DataFrame, data_source: str = "api") -> bool:
    """
    ğŸ”§ ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    í†µí•©ëœ OHLCV ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µ:
    1. ë°ì´í„° ê²€ì¦ ë° ì •ì œ
    2. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    3. DB ì €ì¥ (atomic operation)
    4. í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
    
    Args:
        ticker (str): ì²˜ë¦¬í•  í‹°ì»¤
        df (pd.DataFrame): OHLCV ë°ì´í„°í”„ë ˆì„
        data_source (str): ë°ì´í„° ì†ŒìŠ¤ ("api", "db", "file" ë“±)
    
    Returns:
        bool: ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
    """
    try:
        logger.info(f"ğŸ”„ {ticker} ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # 1. ë°ì´í„° ê²€ì¦
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì²˜ë¦¬í•  OHLCV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # 2. ë°ì´í„° ì •ì œ
        df_cleaned = _filter_invalid_ohlcv_data(df, ticker)
        if df_cleaned is None or df_cleaned.empty:
            logger.error(f"âŒ {ticker} ë°ì´í„° ì •ì œ í›„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # 3. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        df_with_indicators = calculate_unified_indicators(df_cleaned)
        if df_with_indicators is None or df_with_indicators.empty:
            logger.error(f"âŒ {ticker} ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨")
            return False
        
        # 4. í†µí•© ì €ì¥ (atomic operation)
        save_success = save_all_indicators_atomically(ticker, df_with_indicators)
        
        if save_success:
            logger.info(f"âœ… {ticker} ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            return True
        else:
            logger.error(f"âŒ {ticker} ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        logger.error(f"âŒ {ticker} ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


def generate_gpt_analysis_json(ticker: str, days: int = 200) -> str:
    """
    GPT ë¶„ì„ìš© JSON ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ë¶„ì„í•  í‹°ì»¤ (ì˜ˆ: "KRW-BTC")
        days (int): ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸ê°’: 200ì¼)
    
    Returns:
        str: GPT ë¶„ì„ìš© JSON ë¬¸ìì—´ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    try:
        # í‹°ì»¤ í˜•ì‹ ì •ê·œí™”
        if not ticker.startswith("KRW-"):
            ticker = f"KRW-{ticker}"
        
        logger.info(f"ğŸ“Š {ticker} GPT ë¶„ì„ìš© JSON ë°ì´í„° ìƒì„± ì‹œì‘ (ê¸°ê°„: {days}ì¼)")
        
        # OHLCV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        ohlcv_df = get_ohlcv_from_db(ticker, limit=days)
        if ohlcv_df is None or ohlcv_df.empty:
            logger.warning(f"âš ï¸ {ticker} OHLCV ë°ì´í„° ì—†ìŒ")
            return None
        
        # ìµœì‹  static indicators ê°€ì ¸ì˜¤ê¸°
        static_indicators = {}
        try:
            with get_db_connection_context() as conn:
                static_query = """
                    SELECT * FROM static_indicators 
                    WHERE ticker = %s 
                    ORDER BY updated_at DESC 
                    LIMIT 1
                """
                cursor = conn.cursor()
                cursor.execute(static_query, (ticker,))
                static_row = cursor.fetchone()
                
                if static_row:
                    # ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
                    cursor.execute("SELECT column_name FROM information_schema.columns WHERE table_name = 'static_indicators' ORDER BY ordinal_position")
                    columns = [row[0] for row in cursor.fetchall()]
                    
                    # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                    static_indicators = dict(zip(columns, static_row))
                    
                    # ë¶ˆí•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì œê±°
                    for key in ['id', 'ticker', 'created_at', 'updated_at']:
                        static_indicators.pop(key, None)
                else:
                    logger.warning(f"âš ï¸ {ticker} static indicators ë°ì´í„° ì—†ìŒ")
        except Exception as e:
            logger.error(f"âŒ {ticker} static indicators ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # OHLCV ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        ohlcv_list = []
        for index, row in ohlcv_df.iterrows():
            ohlcv_entry = {
                "date": index.strftime("%Y-%m-%d") if hasattr(index, 'strftime') else str(index),
                "open": _common_adaptive_decimal_rounding(row.get('open', 0)),
                "high": _common_adaptive_decimal_rounding(row.get('high', 0)),
                "low": _common_adaptive_decimal_rounding(row.get('low', 0)),
                "close": _common_adaptive_decimal_rounding(row.get('close', 0)),
                "volume": _common_adaptive_decimal_rounding(row.get('volume', 0))
            }
            
            # ë™ì  ì§€í‘œë“¤ë„ í¬í•¨ (ìˆëŠ” ê²½ìš°)
            for col in ['rsi_14', 'bb_upper', 'bb_middle', 'bb_lower', 'macd', 'macd_signal', 'macd_histogram']:
                if col in row and pd.notna(row[col]):
                    ohlcv_entry[col] = _common_adaptive_decimal_rounding(row[col])
            
            ohlcv_list.append(ohlcv_entry)
        
        # ìµœì¢… JSON êµ¬ì¡° ìƒì„±
        analysis_data = {
            "ticker": ticker,
            "period_days": days,
            "data_points": len(ohlcv_list),
            "ohlcv": ohlcv_list[-days:],  # ìµœê·¼ Nì¼ ë°ì´í„°ë§Œ
            "static_indicators": static_indicators,
            "generated_at": datetime.now().isoformat()
        }
        
        # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        import json
        json_str = json.dumps(analysis_data, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… {ticker} GPT ë¶„ì„ìš© JSON ìƒì„± ì™„ë£Œ (í¬ê¸°: {len(json_str):,} bytes)")
        return json_str
        
    except Exception as e:
        logger.error(f"âŒ {ticker} GPT ë¶„ì„ìš© JSON ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None

