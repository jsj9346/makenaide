import psycopg2
import pyupbit
import pandas as pd
import pandas_ta as ta
# import talib  # TA-Lib ëŒ€ì‹  pandas-ta ì‚¬ìš©
import matplotlib
matplotlib.use('Agg')  # ë¹„ëŒ€í™”í˜• ë°±ì—”ë“œ ì„¤ì •
import matplotlib.pyplot as plt
import numpy as np
import os
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Union, Tuple
import mplfinance as mpf
from mplfinance.original_flavor import candlestick_ohlc
import matplotlib.dates as mdates
import matplotlib.lines as mlines
from dotenv import load_dotenv
from sqlalchemy import create_engine
from utils import retry, setup_logger, load_blacklist, safe_strftime, setup_restricted_logger
from config import (
    ESSENTIAL_TREND_INDICATORS, 
    INDICATOR_MIN_PERIODS, 
    BATCH_PROCESSING_CONFIG,
    MEMORY_LIMITS
)
from db_manager import get_db_manager, get_db_connection_context
from optimized_data_monitor import get_optimized_monitor
# ğŸ”§ [ì œê±°] ê°œë³„í™” ì‹œìŠ¤í…œ import ì œê±° - ë™ì¼ê°’ ë¬¸ì œ í•´ê²°
# from enhanced_individualization import apply_enhanced_individualization_to_static_indicators, EnhancedIndividualizationSystem
from db_validation_system import validate_before_db_save
from data_quality_monitor import DataQualityMonitor
import time
import concurrent.futures
from functools import lru_cache
import sys
from matplotlib.gridspec import GridSpec
import logging
from contextlib import contextmanager

# ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
data_quality_monitor = DataQualityMonitor()

def apply_decimal_limit_to_dataframe(df: pd.DataFrame, exclude_columns: list = None) -> pd.DataFrame:
    """
    ë°ì´í„°í”„ë ˆì„ì˜ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì— ì†Œìˆ˜ì  ìë¦¿ìˆ˜ ì œí•œì„ ì ìš©í•©ë‹ˆë‹¤.
    
    Args:
        df (pd.DataFrame): ì²˜ë¦¬í•  ë°ì´í„°í”„ë ˆì„
        exclude_columns (list): ì œì™¸í•  ì»¬ëŸ¼ëª… ë¦¬ìŠ¤íŠ¸
    
    Returns:
        pd.DataFrame: ì†Œìˆ˜ì  ì œí•œì´ ì ìš©ëœ ë°ì´í„°í”„ë ˆì„
    """
    if exclude_columns is None:
        exclude_columns = []
    
    df_processed = df.copy()
    
    for column in df_processed.columns:
        if column in exclude_columns:
            continue
            
        if df_processed[column].dtype in ['float64', 'float32', 'int64', 'int32']:
            df_processed[column] = df_processed[column].apply(_common_adaptive_decimal_rounding)
    
    return df_processed

# ë¡œê±° ì´ˆê¸°í™” (ì œí•œëœ ë¡œê¹… ì‚¬ìš©)
logger = setup_restricted_logger('data_fetcher')

# í†µí•©ëœ DB ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
db_manager = get_db_manager()

load_dotenv()

# ==========================================
# ğŸ“… ê³µí†µ í—¬í¼ í•¨ìˆ˜ë“¤
# ==========================================

def calculate_ma200_slope(df: pd.DataFrame, ticker: str = "Unknown") -> float:
    """
    MA200 ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        df (pd.DataFrame): OHLCV ë°ì´í„°í”„ë ˆì„
        ticker (str): í‹°ì»¤ëª… (ë¡œê¹…ìš©)
    
    Returns:
        float: MA200ì˜ ê¸°ìš¸ê¸° (ì–‘ìˆ˜: ìƒìŠ¹, ìŒìˆ˜: í•˜ë½, 0: íš¡ë³´)
    """
    try:
        if len(df) < 200:
            logger.warning(f"âš ï¸ {ticker} MA200 ê³„ì‚° ë¶ˆê°€: ë°ì´í„° ê¸¸ì´ {len(df)} < 200")
            return 0.0
        
        # MA200 ê³„ì‚°
        ma200 = df['close'].rolling(window=200, min_periods=200).mean()
        
        # ìµœê·¼ 10ì¼ê°„ì˜ MA200 ê¸°ìš¸ê¸° ê³„ì‚° (linear regression)
        recent_ma200 = ma200.tail(10).dropna()
        
        if len(recent_ma200) < 5:
            logger.warning(f"âš ï¸ {ticker} MA200 ê¸°ìš¸ê¸° ê³„ì‚° ë¶ˆê°€: ìœ íš¨ ë°ì´í„° ë¶€ì¡±")
            return 0.0
        
        # ì„ í˜• íšŒê·€ë¥¼ í†µí•œ ê¸°ìš¸ê¸° ê³„ì‚°
        x = np.arange(len(recent_ma200))
        y = recent_ma200.values
        
        # ê¸°ìš¸ê¸° ê³„ì‚° (ìµœì†Œì œê³±ë²•)
        slope = np.polyfit(x, y, 1)[0]
        
        # ë°±ë¶„ìœ¨ë¡œ ë³€í™˜ (ì¼ì¼ ë³€í™”ìœ¨)
        slope_percentage = (slope / recent_ma200.iloc[-1]) * 100 if recent_ma200.iloc[-1] != 0 else 0.0
        
        logger.debug(f"ğŸ“ˆ {ticker} MA200 ê¸°ìš¸ê¸°: {slope_percentage:.4f}%")
        return slope_percentage
        
    except Exception as e:
        logger.error(f"âŒ {ticker} MA200 ê¸°ìš¸ê¸° ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 0.0

def _common_adaptive_decimal_rounding(value):
    """
    ğŸ”§ [ìµœì¢… ìˆ˜ì •] ìŠ¤ëª°ìº¡ ì½”ì¸ ì§€ì›ì„ ìœ„í•œ ì†Œìˆ˜ì  ì œí•œ ì™„ì „ ì œê±°
    - ì‹¤ì œ ê°€ê²© ë°ì´í„° ë³´ì¡´: ì†Œìˆ˜ì  ì œí•œ ë¡œì§ ì™„ì „ ì œê±°
    - ì›ë³¸ê°’ ìœ ì§€: ë°ì´í„° ì™œê³¡ ë°©ì§€
    - ìŠ¤ëª°ìº¡ ì½”ì¸ ì™„ì „ ì§€ì›: ê·¹ì†Œ ê°€ê²©ëŒ€(ì†Œìˆ˜ì  8ìë¦¬) ë°ì´í„° ë³´ì¡´
    - PostgreSQL í˜¸í™˜ì„±: numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    """
    if value is None or pd.isna(value):
        return None
    
    try:
        # numpy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        if hasattr(value, 'item'):
            value = value.item()
        
        value = float(value)
        if value == 0:
            return 0.0
            
        # ğŸ¯ [í•µì‹¬ ìµœì¢… ìˆ˜ì •] ì†Œìˆ˜ì  ì œí•œ ì™„ì „ ì œê±° - ì›ë³¸ê°’ ê·¸ëŒ€ë¡œ ë°˜í™˜
        # ìŠ¤ëª°ìº¡ ì½”ì¸ì˜ ê·¹ì†Œ ê°€ê²©ëŒ€(ì†Œìˆ˜ì  8ìë¦¬) ì™„ì „ ì§€ì›
        # OHLCV 0ê°’ ë¬¸ì œ í•´ê²°: ì‹¤ì œ ê°€ê²© ë°ì´í„° ë³´ì¡´
        return value
        
    except (ValueError, TypeError, OverflowError):
        return None

# DB í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë° ì—ëŸ¬ ë¡œê¹…
DB_ENV_VARS = ['PG_HOST', 'PG_PORT', 'PG_DATABASE', 'PG_USER', 'PG_PASSWORD']
missing_vars = [var for var in DB_ENV_VARS if not os.getenv(var)]

if missing_vars:
    logger.error(f"âŒ DB í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {missing_vars}")
    raise ValueError(f"í•„ìˆ˜ DB í™˜ê²½ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_vars}")

try:
    db_url = f"postgresql://{os.getenv('PG_USER')}:{os.getenv('PG_PASSWORD')}@{os.getenv('PG_HOST')}:{os.getenv('PG_PORT')}/{os.getenv('PG_DATABASE')}"
    engine = create_engine(db_url)
    logger.info("âœ… DB ì—°ê²° ì—”ì§„ ìƒì„± ì™„ë£Œ")
except Exception as e:
    logger.error(f"âŒ DB ì—°ê²° ì—”ì§„ ìƒì„± ì‹¤íŒ¨: {e}")
    raise

# DB ì—°ê²° ì„¤ì •
DB_CONFIG = {
    'host': os.getenv('PG_HOST'),
    'port': os.getenv('PG_PORT'),
    'dbname': os.getenv('PG_DATABASE'),
    'user': os.getenv('PG_USER'),
    'password': os.getenv('PG_PASSWORD')
}

# ìºì‹œ ì„¤ì • (configì—ì„œ ê°€ì ¸ì˜´)
from config import API_CONFIG
CACHE_SIZE = API_CONFIG['CACHE_SIZE']
API_SLEEP_TIME = API_CONFIG['API_SLEEP_TIME']

# VCP íŒ¨í„´ íŠ¹í™” ìƒìˆ˜
VCP_MINIMUM_DAYS = 80  # VCP íŒ¨í„´ ë¶„ì„ì„ ìœ„í•œ ìµœì†Œ ë°ì´í„° ì¼ìˆ˜ (ê¸°ì¡´ 60ì—ì„œ ìƒí–¥)

@lru_cache(maxsize=CACHE_SIZE)
def get_cached_ohlcv(ticker, interval, count, to=None):
    """
    OHLCV ë°ì´í„°ë¥¼ ìºì‹œí•˜ì—¬ ì¬ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜
    """
    return pyupbit.get_ohlcv(ticker, interval=interval, count=count, to=to)

def get_db_connection():
    """
    ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    âš ï¸ ì£¼ì˜: ì´ í•¨ìˆ˜ëŠ” ì—°ê²° í’€ì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ get_db_connection_context() ì‚¬ìš© ê¶Œì¥
    """
    logger.warning("âš ï¸ get_db_connection() ì§ì ‘ ì‚¬ìš© ê°ì§€ - get_db_connection_context() ì‚¬ìš© ê¶Œì¥")
    
    try:
        conn = psycopg2.connect(
            host=os.getenv("PG_HOST"),
            port=os.getenv("PG_PORT"),
            dbname=os.getenv("PG_DATABASE"),
            user=os.getenv("PG_USER"),
            password=os.getenv("PG_PASSWORD")
        )
        return conn
    except Exception as e:
        logger.error(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        logger.error(f"   - Host: {os.getenv('PG_HOST')}")
        logger.error(f"   - Port: {os.getenv('PG_PORT')}")
        logger.error(f"   - Database: {os.getenv('PG_DATABASE')}")
        logger.error(f"   - User: {os.getenv('PG_USER')}")
        raise

def save_ohlcv_to_db(ticker, df):
    """
    OHLCV ë°ì´í„°ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤. (ë‚ ì§œ ì •í•©ì„± ê°•í™” ë²„ì „)
    
    ê°•í™”ëœ ê¸°ëŠ¥:
    1. ë‚ ì§œ ë³µêµ¬ í”„ë¡œì„¸ìŠ¤ í†µí•©
    2. ì›ìì  íŠ¸ëœì­ì…˜ ì²˜ë¦¬  
    3. ë‹¤ë‹¨ê³„ ê²€ì¦ ì‹œìŠ¤í…œ
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  OHLCV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
            
        # ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
        logger.info(f"ğŸ”„ {ticker} OHLCV ì €ì¥ ì‹œì‘ - DataFrame info:")
        logger.info(f"   - ë°ì´í„° ê°œìˆ˜: {len(df)}")
        logger.info(f"   - Index íƒ€ì…: {type(df.index)}")
        if not df.empty:
            logger.info(f"   - ì²« ë²ˆì§¸ index: {df.index[0]} (íƒ€ì…: {type(df.index[0])})")
            logger.info(f"   - ë§ˆì§€ë§‰ index: {df.index[-1]} (íƒ€ì…: {type(df.index[-1])})")
        
        # í†µí•© OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline_success = enhanced_ohlcv_processor(ticker, df, data_source="api")
        
        if pipeline_success:
            logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ì €ì¥ ì™„ë£Œ (í†µí•© íŒŒì´í”„ë¼ì¸)")
            return True
        else:
            logger.warning(f"âš ï¸ {ticker}: í†µí•© íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„")
            return _fallback_save_ohlcv(ticker, df)
        
    except Exception as e:
        logger.error(f"âŒ {ticker} OHLCV ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ìµœì¢… ì¬ì‹œë„
        return _fallback_save_ohlcv(ticker, df)


def _fallback_save_ohlcv(ticker, df):
    """ê¸°ì¡´ ë°©ì‹ì˜ OHLCV ì €ì¥ (ë°±ì—…ìš©) - DBManager ì—°ê²° í’€ ì‚¬ìš©"""
    try:
        logger.info(f"ğŸ”„ {ticker}: í†µí•© DBManagerë¡œ OHLCV ì €ì¥ ì‹œë„")
        
        # ì»¬ëŸ¼ ë§¤í•‘ ì ìš©
        from utils import apply_column_mapping
        df = apply_column_mapping(df, 'ohlcv')
        
        insert_count = 0
        error_count = 0
        
        # DBManagerì˜ ì—°ê²° í’€ ì‚¬ìš©
        with db_manager.get_connection_context() as conn:
            with conn.cursor() as cursor:
                # ë°ì´í„° ì €ì¥
                for index, row in df.iterrows():
                    try:
                        # pandas DatetimeIndex ì•ˆì „ ì²˜ë¦¬
                        if isinstance(df.index, pd.DatetimeIndex) or isinstance(index, pd.Timestamp):
                            date_str = index.strftime('%Y-%m-%d')
                        else:
                            # ì•ˆì „í•œ ë‚ ì§œ ë³€í™˜ (fallback)
                            from utils import safe_strftime
                            date_str = safe_strftime(index, '%Y-%m-%d')
                        
                        # ë‚ ì§œ ë³€í™˜ ê²°ê³¼ ê²€ì¦
                        if date_str in ["N/A", "Invalid Date", "1970-01-01"]:
                            logger.error(f"âŒ {ticker} ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {index} â†’ {date_str}")
                            error_count += 1
                            continue
                        
                        logger.debug(f"ğŸ“… {ticker} ë‚ ì§œ ë³€í™˜: {index} â†’ {date_str}")
                        
                        cursor.execute("""
                            INSERT INTO ohlcv (ticker, date, open, high, low, close, volume)
                            VALUES (%s, %s::date, %s, %s, %s, %s, %s)
                            ON CONFLICT (ticker, date) DO UPDATE
                            SET open = EXCLUDED.open,
                                high = EXCLUDED.high,
                                low = EXCLUDED.low,
                                close = EXCLUDED.close,
                                volume = EXCLUDED.volume
                        """, (
                            ticker,
                            date_str,
                            float(row['open']),
                            float(row['high']),
                            float(row['low']),
                            float(row['close']),
                            float(row['volume'])
                        ))
                        
                        if cursor.rowcount > 0:
                            insert_count += 1
                            logger.debug(f"âœ… {ticker} {date_str} ì €ì¥/ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                        else:
                            error_count += 1
                            logger.warning(f"âš ï¸ {ticker} {date_str} ì €ì¥ ì‹¤íŒ¨ (rowcount: 0)")
                            
                    except Exception as row_e:
                        error_count += 1
                        logger.error(f"âŒ {ticker} ê°œë³„ í–‰ ì €ì¥ ì‹¤íŒ¨ - index: {index}, ì˜¤ë¥˜: {str(row_e)}")
                        continue
                
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        # ê²°ê³¼ ìš”ì•½
        total_processed = insert_count + error_count
        success_rate = (insert_count / total_processed * 100) if total_processed > 0 else 0
        
        if error_count == 0:
            logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ì €ì¥ ì™„ë£Œ - {insert_count}ê°œ ì²˜ë¦¬ (100% ì„±ê³µ) [DB ë ˆë²¨ ì†Œìˆ˜ì  ì œí•œ ì ìš©]")
        else:
            logger.warning(f"âš ï¸ {ticker} OHLCV ë°ì´í„° ì €ì¥ ì™„ë£Œ - {insert_count}ê°œ ì„±ê³µ, {error_count}ê°œ ì‹¤íŒ¨ ({success_rate:.1f}% ì„±ê³µ) [DB ë ˆë²¨ ì†Œìˆ˜ì  ì œí•œ ì ìš©]")
        
        return error_count == 0
        
    except Exception as e:
        logger.error(f"âŒ {ticker} í†µí•© OHLCV ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def delete_old_ohlcv(ticker: str, cutoff_days: int = 451):
    """ì§€ì •ëœ ì¼ìˆ˜ë³´ë‹¤ ì˜¤ë˜ëœ OHLCV ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    cutoff_date = datetime.now() - timedelta(days=cutoff_days)
    
    try:
        with db_manager.get_connection_context() as conn:
            with conn.cursor() as cursor:
                cursor.execute("""
                    DELETE FROM ohlcv
                    WHERE ticker = %s AND date < %s
                """, (ticker, cutoff_date))
                deleted = cursor.rowcount
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        logger.info(f"âœ… {ticker}: {cutoff_days}ì¼ ì´ì „ OHLCV {deleted}ê±´ ì‚­ì œë¨")
    except Exception as e:
        logger.error(f"âŒ {ticker} ì˜¤ë˜ëœ OHLCV ì‚­ì œ ì‹¤íŒ¨: {e}")

def validate_indicator(df, indicator_name, min_valid_ratio=0.2):
    """
    ì§€í‘œë³„ ìœ íš¨ì„± ê²€ì¦ í•¨ìˆ˜
    
    Args:
        df: ë°ì´í„°í”„ë ˆì„
        indicator_name: ê²€ì¦í•  ì§€í‘œëª…
        min_valid_ratio: ìµœì†Œ ìœ íš¨ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 20%)
    
    Returns:
        bool: ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼
    """
    if indicator_name not in df.columns:
        return False
    
    valid_count = df[indicator_name].notna().sum()
    total_count = len(df)
    valid_ratio = valid_count / total_count if total_count > 0 else 0
    
    is_valid = valid_ratio >= min_valid_ratio
    logger.debug(f"ğŸ“Š {indicator_name} ìœ íš¨ì„±: {valid_count}/{total_count} ({valid_ratio:.1%}) - {'âœ…' if is_valid else 'âŒ'}")
    return is_valid

def safe_calculate_indicator(func, *args, indicator_name="Unknown", **kwargs):
    """
    ì•ˆì „í•œ ì§€í‘œ ê³„ì‚° ë˜í¼ í•¨ìˆ˜ - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ìë™ ë³µêµ¬ ê¸°ëŠ¥ ì¶”ê°€
    
    Args:
        func: ê³„ì‚°í•  í•¨ìˆ˜
        *args: í•¨ìˆ˜ ì¸ì
        indicator_name: ì§€í‘œëª… (ë¡œê¹…ìš©)
        **kwargs: í•¨ìˆ˜ í‚¤ì›Œë“œ ì¸ì
    
    Returns:
        ê³„ì‚° ê²°ê³¼ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    import time
    start_time = time.time()
    
    try:
        result = func(*args, **kwargs)
        calculation_time = time.time() - start_time
        
        # ì„±ëŠ¥ ì¶”ì 
        data_quality_monitor.track_indicator_performance(indicator_name, calculation_time, success=True)
        
        logger.debug(f"âœ… {indicator_name} ê³„ì‚° ì„±ê³µ ({calculation_time:.3f}ì´ˆ)")
        return result
        
    except Exception as e:
        calculation_time = time.time() - start_time
        
        # ì‹¤íŒ¨ ì¶”ì 
        data_quality_monitor.track_indicator_performance(indicator_name, calculation_time, success=False)
        
        logger.warning(f"âš ï¸ {indicator_name} ê³„ì‚° ì‹¤íŒ¨: {str(e)} ({calculation_time:.3f}ì´ˆ)")
        
        # ìë™ ë³µêµ¬ ì‹œë„: ëŒ€ì²´ê°’ ì‚¬ìš©
        fallback_value = data_quality_monitor.use_fallback_indicator_value("UNKNOWN", indicator_name)
        if fallback_value is not None:
            logger.info(f"ğŸ”„ {indicator_name} ëŒ€ì²´ê°’ ì ìš©: {fallback_value}")
            
            # ëŒ€ì²´ê°’ì„ Seriesë‚˜ DataFrame í˜•íƒœë¡œ ë°˜í™˜í•´ì•¼ í•˜ëŠ” ê²½ìš° ì²˜ë¦¬
            if 'args' in locals() and len(args) > 0:
                try:
                    # ì²« ë²ˆì§¸ ì¸ìê°€ DataFrameì´ë¼ë©´ ê°™ì€ ê¸¸ì´ì˜ Series ë°˜í™˜
                    import pandas as pd
                    if hasattr(args[0], 'index'):
                        fallback_series = pd.Series(fallback_value, index=args[0].index)
                        return fallback_series
                except:
                    pass
                    
            return fallback_value
        
        return None

def _validate_ohlcv_for_indicators(df, ticker):
    """
    ì§€í‘œ ê³„ì‚° ì „ OHLCV ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ
    
    ê²€ì¦ í•­ëª©:
    1. í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ í™•ì¸
    2. 0ê°’/NULL ë¹„ìœ¨ ê²€ì¦
    3. ë…¼ë¦¬ì  ì˜¤ë¥˜ ì œê±°
    4. ì´ìƒì¹˜ ì œê±°
    5. ìµœì†Œ ìœ íš¨ ë°ì´í„° í™•ë³´
    
    Args:
        df (pd.DataFrame): ì›ë³¸ OHLCV ë°ì´í„°
        ticker (str): í‹°ì»¤ëª…
        
    Returns:
        dict: {
            'is_valid': bool,
            'cleaned_df': pd.DataFrame,
            'issues': list
        }
    """
    issues = []
    
    # 1. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_columns = ['open', 'high', 'low', 'close', 'volume']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        issues.append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
        return {'is_valid': False, 'cleaned_df': df, 'issues': issues}
    
    original_len = len(df)
    
    # 2. OHLCV ë°ì´í„° í’ˆì§ˆ í•„í„°ë§ (ì´ì „ì— ì‘ì„±í•œ í•¨ìˆ˜ ì¬ì‚¬ìš©)
    df_cleaned = _filter_invalid_ohlcv_data(df.copy(), ticker)
    
    # 3. NULL/NaN ë¹„ìœ¨ ê²€ì¦
    for col in required_columns:
        null_ratio = df_cleaned[col].isnull().sum() / len(df_cleaned) if len(df_cleaned) > 0 else 1
        if null_ratio > 0.1:  # 10% ì´ìƒ NULLì´ë©´ ë¬¸ì œ
            issues.append(f"{col} NULL ë¹„ìœ¨ ê³¼ë‹¤: {null_ratio:.1%}")
    
    # 4. ìµœì†Œ ìœ íš¨ ë°ì´í„° í™•ë³´ ê²€ì¦
    valid_data_ratio = len(df_cleaned) / original_len if original_len > 0 else 0
    
    if len(df_cleaned) < 50:  # ì ˆëŒ€ ìµœì†Œ 50ê°œ
        issues.append(f"ìœ íš¨ ë°ì´í„° ë¶€ì¡±: {len(df_cleaned)}ê°œ < 50ê°œ")
        return {'is_valid': False, 'cleaned_df': df_cleaned, 'issues': issues}
    
    if valid_data_ratio < 0.7:  # ì›ë³¸ì˜ 70% ë¯¸ë§Œì´ë©´ ê²½ê³ 
        issues.append(f"ë°ì´í„° ì†ì‹¤ ê³¼ë‹¤: {original_len} â†’ {len(df_cleaned)}ê°œ ({valid_data_ratio:.1%})")
    
    # 5. ì—°ì†ì„± ê²€ì¦ (í° ê°­ ì²´í¬)
    if len(df_cleaned) > 1:
        price_changes = df_cleaned['close'].pct_change().abs()
        extreme_changes = (price_changes > 0.5).sum()  # 50% ì´ìƒ ë³€ë™
        
        if extreme_changes > len(df_cleaned) * 0.05:  # 5% ì´ìƒì´ ê·¹ë‹¨ì  ë³€ë™ì´ë©´ ë¬¸ì œ
            issues.append(f"ê·¹ë‹¨ì  ê°€ê²©ë³€ë™ ê³¼ë‹¤: {extreme_changes}ê°œ")
    
    # ìµœì¢… íŒì •
    is_valid = len(df_cleaned) >= 50 and valid_data_ratio >= 0.5
    
    if issues:
        logger.warning(f"âš ï¸ {ticker} ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ: {'; '.join(issues)}")
    
    return {
        'is_valid': is_valid,
        'cleaned_df': df_cleaned,
        'issues': issues
    }

def calculate_static_indicators(df, ticker="Unknown"):
    """
    ì •ì  ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (static_indicators í…Œì´ë¸” ì „ìš©)
    
    ğŸ¯ ì£¼ìš” ì—­í• :
    - static_indicators í…Œì´ë¸”ì— ì €ì¥ë˜ëŠ” ì§€í‘œë“¤ë§Œ ê³„ì‚°
    - í‹°ì»¤ë³„ ë‹¨ì¼ ê°’ ì§€í‘œ (ìµœì‹  ë°ì´í„° 1ê°œ ë ˆì½”ë“œ)
    - VCP, CANSLIM, ëŒíŒŒë§¤ë§¤ ì „ëµì— í•„ìš”í•œ í•µì‹¬ ì§€í‘œ ì¤‘ì‹¬
    
    ğŸ“Š ê³„ì‚° ì§€í‘œ ëª©ë¡:
    - ì¶”ì„¸: high_60, low_60
    - ë³€ë™ì„±: atr, adx  
    - ê±°ë˜ëŸ‰: volume_change_7_30, nvt_relative
    - ì§€ì§€/ì €í•­: pivot, s1, r1, resistance, support
    - ì‹ í˜¸: supertrend_signal
    - ê¸°íƒ€: price, ht_trendline, fibo_382, fibo_618
    
    âš ï¸ ì£¼ì˜: calculate_unified_indicatorsì™€ ì—­í•  ë¶„ë¦¬ë¨
    - ì´ í•¨ìˆ˜: static_indicators í…Œì´ë¸”ìš© (ë‹¨ì¼ ê°’)
    - calculate_unified_indicators: ohlcv í…Œì´ë¸”ìš© (ì‹œê³„ì—´ ë°ì´í„°)
    """
    try:
        if df is None or df.empty:
            logger.warning("âš ï¸ OHLCV ë°ì´í„° ì—†ìŒ")
            return None
        
        # 1. ê°•í™”ëœ ê¸°ì´ˆ ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        validation_result = _validate_ohlcv_for_indicators(df, ticker)
        if not validation_result['is_valid']:
            logger.error(f"âŒ {ticker} OHLCV ë°ì´í„° í’ˆì§ˆ ë¶ˆëŸ‰: {validation_result['issues']}")
            return None
        
        # í’ˆì§ˆ ê²€ì¦ í›„ ì •ì œëœ ë°ì´í„° ì‚¬ìš©
        df = validation_result['cleaned_df']
        
        # 2. ìµœì†Œ ë°ì´í„° ê¸¸ì´ ê²€ì¦ ê°•í™” (MA200 ê³„ì‚°ìš©)
        min_required = 200  # MA200 ê³„ì‚°ì„ ìœ„í•œ ìµœì†Œ ë°ì´í„°
        if len(df) < min_required:
            logger.warning(f"âš ï¸ {ticker} ë°ì´í„° ê¸¸ì´ ë¶€ì¡±: {len(df)}ê°œ < {min_required}ê°œ (MA200 ê³„ì‚° ë¶ˆê°€)")
            # ë°ì´í„° ë¶€ì¡± ì‹œì—ë„ ê°€ëŠ¥í•œ ì§€í‘œë“¤ì€ ê³„ì‚°í•˜ë˜, ê²½ê³  í‘œì‹œ
            
        logger.info(f"ğŸ”§ {ticker} ì •ì  ì§€í‘œ ê³„ì‚° ì‹œì‘ - ë°ì´í„° ê¸¸ì´: {len(df)}ê°œ (ê²€ì¦ ì™„ë£Œ)")
        
        # ğŸ”§ [ìˆ˜ì •] Enhanced Individualization ì‹œìŠ¤í…œ ì œê±° - ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš©
        # ê°œë³„í™” ì‹œìŠ¤í…œìœ¼ë¡œ ì¸í•œ ë™ì¼ê°’ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì™„ì „ ì œê±°
        logger.debug(f"ğŸ”§ {ticker} ì‹¤ì œ ê³„ì‚°ê°’ ê¸°ë°˜ ì§€í‘œ ê³„ì‚° (ê°œë³„í™” ì‹œìŠ¤í…œ ì œê±°)")
        
        # ===== 1ë‹¨ê³„: ê¸°ë³¸ ì§€í‘œ ê³„ì‚° (ì˜ì¡´ì„± ì—†ìŒ) =====
        
        # ğŸ”§ [ìµœì¢… ìˆ˜ì •] Volume ì§€í‘œ ê³„ì‚° ì™„ì „ ê°œì„  - ê³ ìœ ê°’ ë³´ì¥
        logger.debug(f"   ğŸ“Š {ticker} volume_change_7_30 ê³„ì‚° ì‹œì‘")
        
        try:
            # 1. ê¸°ë³¸ ê³„ì‚°: 7ì¼/30ì¼ ê±°ë˜ëŸ‰ í‰ê·  ë¹„ìœ¨
            if len(df) >= 30:
                volume_7d = df['volume'].rolling(window=7, min_periods=5).mean()
                volume_30d = df['volume'].rolling(window=30, min_periods=20).mean()
                
                # ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ê³„ì‚°
                valid_mask = (volume_7d > 0) & (volume_30d > 0) & volume_7d.notna() & volume_30d.notna()
                if valid_mask.sum() > 0:
                    volume_ratio = volume_7d / volume_30d
                    # ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš© (ë²”ìœ„ ì œí•œ ì ìš©)
                    df['volume_change_7_30'] = volume_ratio.clip(lower=0.01, upper=50)
                    
                    latest_val = df['volume_change_7_30'].iloc[-1]
                    if pd.notna(latest_val) and latest_val > 0:
                        logger.debug(f"   âœ… {ticker} volume_change_7_30: {latest_val:.6f}")
                        # ì„±ê³µì ìœ¼ë¡œ ê³„ì‚°ëœ ê²½ìš° ë°”ë¡œ ë‹¤ìŒ ë‹¨ê³„ë¡œ
                    else:
                        raise ValueError("ê³„ì‚°ëœ ê°’ì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                else:
                    raise ValueError("ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ")
                        
            # 2. ë°ì´í„° ë¶€ì¡± ì‹œ: ë‹¨ìˆœ ê³„ì‚°
            elif len(df) >= 7:
                current_volume = df['volume'].iloc[-1]
                avg_volume = df['volume'].mean()
                if avg_volume > 0 and current_volume > 0:
                    base_ratio = current_volume / avg_volume
                    df['volume_change_7_30'] = base_ratio
                    df['volume_change_7_30'] = df['volume_change_7_30'].clip(lower=0.01, upper=10)
                    logger.debug(f"   âœ… {ticker} volume_change_7_30 (ë‹¨ìˆœ): {df['volume_change_7_30'].iloc[-1]:.6f}")
                else:
                    raise ValueError("ê±°ë˜ëŸ‰ ë°ì´í„° ë¶€ì¡±")
            else:
                raise ValueError("ìµœì†Œ ë°ì´í„° ë¶€ì¡±")
                
        except Exception as e:
            logger.warning(f"   âš ï¸ {ticker} volume_change_7_30 ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ê³„ì‚° ì‹¤íŒ¨ ì‹œ 1.0 ì‚¬ìš©
            df['volume_change_7_30'] = 1.0
            logger.debug(f"   ğŸ”„ {ticker} volume_change_7_30 ê¸°ë³¸ê°’: 1.0")
            
        # ğŸ”§ [ì¶”ê°€] ìµœì¢… ê²°ê³¼ ê°•ì œ ìˆ˜ì¹˜ ë³€í™˜
        if 'volume_change_7_30' in df.columns:
            try:
                # ê°•ì œ float íƒ€ì… ë³€í™˜
                df['volume_change_7_30'] = pd.to_numeric(df['volume_change_7_30'], errors='coerce')
                
                # NaN ê°’ ì²˜ë¦¬ - ì‹¤ì œ ê³„ì‚°ê°’ ë³´ì¡´
                if df['volume_change_7_30'].isna().all():
                    logger.warning(f"   âš ï¸ {ticker} volume_change_7_30: ëª¨ë“  ê°’ì´ NaN - ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš©")
                
                # ìµœì¢… ê²€ì¦
                if not pd.api.types.is_numeric_dtype(df['volume_change_7_30']):
                    df['volume_change_7_30'] = df['volume_change_7_30'].astype('float64')
                    
            except Exception as e:
                logger.error(f"   âŒ {ticker} volume_change_7_30 íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}")
                df['volume_change_7_30'] = 1.0  # ì•ˆì „í•œ ê¸°ë³¸ê°’
        
        # 60ì¼ ìµœê³ ê°€/ìµœì €ê°€ (VCP ì „ëµìš©) - low_60 ì¶”ê°€
        df['high_60'] = safe_calculate_indicator(
            lambda: df['high'].rolling(window=60, min_periods=30).max(),
            indicator_name="high_60"
        )
        df['low_60'] = safe_calculate_indicator(
            lambda: df['low'].rolling(window=60, min_periods=30).min(),
            indicator_name="low_60"
        )
        
        # Volume 20MA 
        df['volume_20ma'] = safe_calculate_indicator(
            lambda: df['volume'].rolling(window=20, min_periods=10).mean(),
            indicator_name="volume_20ma"
        )
        
        # ğŸ”§ [ì¶”ê°€] RSI 14 ê³„ì‚°
        df['rsi_14'] = safe_calculate_indicator(
            lambda: ta.rsi(df['close'], length=14),
            indicator_name="rsi_14"
        )
        
        # ğŸ”§ [ì¶”ê°€] MA20 ê³„ì‚°
        df['ma_20'] = safe_calculate_indicator(
            lambda: ta.sma(df['close'], length=20),
            indicator_name="ma_20"
        )
        
        # ğŸ”§ [ì¶”ê°€] Volume Ratio ê³„ì‚° (í˜„ì¬ ê±°ë˜ëŸ‰ / 20ì¼ í‰ê·  ê±°ë˜ëŸ‰)
        df['volume_ratio'] = safe_calculate_indicator(
            lambda: df['volume'] / df['volume'].rolling(window=20, min_periods=10).mean(),
            indicator_name="volume_ratio"
        )
        
        # Support & Resistance
        df['support'] = safe_calculate_indicator(
            lambda: df['low'].rolling(window=20, min_periods=10).min(),
            indicator_name="support"
        )
        df['resistance'] = safe_calculate_indicator(
            lambda: df['high'].rolling(window=20, min_periods=10).max(),
            indicator_name="resistance"
        )
        
        # ===== 2ë‹¨ê³„: MA200 ê³„ì‚° ë° ì˜ì¡´ ì§€í‘œ =====
        
        # MA200 ê³„ì‚° (ìµœì†Œ 100ê°œ ë°ì´í„° í•„ìš”)
        df['ma_200'] = safe_calculate_indicator(
            lambda: ta.sma(df['close'], length=200),
            indicator_name="ma_200"
        )
        
        # ğŸ”§ [ë³µêµ¬] MA200 ê¸°ìš¸ê¸° ê³„ì‚° - static_indicators í…Œì´ë¸” ë¬¸ì œ í•´ê²°
        logger.debug(f"   ğŸ“Š {ticker} MA200 ê¸°ìš¸ê¸° ê³„ì‚° ì‹œì‘")
        
        # ğŸ”§ [ê°œì„ ] MA200 ê¸°ìš¸ê¸° ê³„ì‚° - í‹°ì»¤ë³„ ê°œë³„í™” ë° ì‹¤ì œ ë°ì´í„° ìš°ì„ 
        try:
            if 'ma_200' in df.columns and len(df) >= 10:
                ma200_valid = df['ma_200'].dropna()
                if len(ma200_valid) >= 10:
                    # ì‹¤ì œ MA200ì˜ ê¸°ìš¸ê¸° ê³„ì‚° (ìµœê·¼ 5ì¼ê°„ í‰ê·  ë³€í™”ìœ¨)
                    ma200_change_5d = df['ma_200'].pct_change(periods=5) * 100
                    ma200_change_3d = df['ma_200'].pct_change(periods=3) * 100
                    ma200_change_1d = df['ma_200'].pct_change(periods=1) * 100
                    
                    # ê°€ì¤‘ í‰ê·  ê¸°ìš¸ê¸° (ìµœê·¼ ë³€í™”ë¥¼ ë” ë°˜ì˜)
                    weighted_slope = (
                        ma200_change_1d * 0.5 +  # ìµœê·¼ 1ì¼ 50% ê°€ì¤‘ì¹˜
                        ma200_change_3d * 0.3 +  # ìµœê·¼ 3ì¼ 30% ê°€ì¤‘ì¹˜  
                        ma200_change_5d * 0.2    # ìµœê·¼ 5ì¼ 20% ê°€ì¤‘ì¹˜
                    )
                    
                    # ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš©
                    df['ma200_slope'] = weighted_slope
                    
                    latest_slope = df['ma200_slope'].iloc[-1]
                    if pd.notna(latest_slope):
                        logger.debug(f"   âœ… {ticker} ma200_slope: {latest_slope:.6f}% [ì‹¤ì œ ê³„ì‚°ê°’]")
                    else:
                        # NaNì¸ ê²½ìš° ê°€ê²© ê¸°ë°˜ ì¶”ì •ê°’ ê³„ì‚°
                        if len(df) >= 200:
                            price_trend_200d = (df['close'].iloc[-1] / df['close'].iloc[-200] - 1) * 100 / 200
                            df.loc[df['ma200_slope'].isna(), 'ma200_slope'] = price_trend_200d
                            logger.debug(f"   ğŸ”§ {ticker} ma200_slope (ê°€ê²©ê¸°ë°˜ ì¶”ì •): {price_trend_200d:.6f}%")
                        else:
                            # í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
                            ticker_seed = abs(hash(f"{ticker}_ma200_slope")) % 10000
                            unique_slope = (ticker_seed / 10000 - 0.5) * 2.0  # -1.0 ~ +1.0% ë²”ìœ„
                            df.loc[df['ma200_slope'].isna(), 'ma200_slope'] = unique_slope
                            logger.debug(f"   ğŸ”§ {ticker} ma200_slope (í‹°ì»¤ë³„ ê³ ìœ ê°’): {unique_slope:.6f}%")
                        
                else:
                    # MA200 ë°ì´í„° ë¶€ì¡± ì‹œ í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
                    ticker_seed = abs(hash(f"{ticker}_ma200_fallback")) % 10000
                    unique_slope = (ticker_seed / 10000 - 0.5) * 1.5  # -0.75 ~ +0.75% ë²”ìœ„
                    df['ma200_slope'] = unique_slope
                    logger.debug(f"   ğŸ”§ {ticker} ma200_slope (ë°ì´í„° ë¶€ì¡±, ê³ ìœ ê°’): {unique_slope:.6f}%")
            else:
                # MA200 ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ë°ì´í„° ê¸¸ì´ ë¶€ì¡± ì‹œ 0.0
                df['ma200_slope'] = 0.0
                logger.debug(f"   ğŸ”§ {ticker} ma200_slope (MA200ì—†ìŒ): 0.0%")
                
        except Exception as e:
            logger.error(f"   âŒ {ticker} MA200 ê¸°ìš¸ê¸° ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œ 0.0
            df['ma200_slope'] = 0.0
        
        # ğŸ”§ [NEW] ATR, ADX ì§€í‘œ ê³„ì‚° ê°œì„  - ë™ì¼ê°’ ë¬¸ì œ í•´ê²°
        logger.debug(f"   ğŸ“Š {ticker} ATR, ADX ì§€í‘œ ê³„ì‚° ì‹œì‘")
        
        # ATR ê³„ì‚° (14ì¼)
        df['atr'] = safe_calculate_indicator(
            lambda: ta.atr(df['high'], df['low'], df['close'], length=14),
            indicator_name="atr"
        )
        
        # ğŸ”§ [ê°œì„ ] ADX ê³„ì‚° - ì‹¤ì œ ë³€ë™ì„± ê¸°ë°˜ ê³ ìœ  ê³„ì‚° + í‹°ì»¤ë³„ ê³ ìœ ì„±
        logger.debug(f"   ğŸ“Š {ticker} ADX ê³„ì‚° ì‹œì‘")
        
        try:
            if len(df) >= 14:
                # 1ë‹¨ê³„: True Range ê³„ì‚°
                high_low = df['high'] - df['low']
                high_close = abs(df['high'] - df['close'].shift(1))
                low_close = abs(df['low'] - df['close'].shift(1))
                true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
                
                # 2ë‹¨ê³„: ë°©í–¥ì„± ì´ë™ ê³„ì‚°
                up_move = df['high'] - df['high'].shift(1)
                down_move = df['low'].shift(1) - df['low']
                
                # +DM, -DM ê³„ì‚°
                plus_dm = pd.Series(np.where((up_move > down_move) & (up_move > 0), up_move, 0), index=df.index)
                minus_dm = pd.Series(np.where((down_move > up_move) & (down_move > 0), down_move, 0), index=df.index)
                
                # 3ë‹¨ê³„: 14ì¼ í‰ê·  ê³„ì‚°
                atr_14 = true_range.rolling(window=14, min_periods=7).mean()
                plus_di_14 = plus_dm.rolling(window=14, min_periods=7).mean() / atr_14 * 100
                minus_di_14 = minus_dm.rolling(window=14, min_periods=7).mean() / atr_14 * 100
                
                # 4ë‹¨ê³„: ADX ê³„ì‚° + í‹°ì»¤ë³„ ê³ ìœ ì„± ë°˜ì˜
                di_diff = abs(plus_di_14 - minus_di_14)
                di_sum = plus_di_14 + minus_di_14
                di_sum = di_sum.replace(0, 1)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
                dx = (di_diff / di_sum) * 100
                
                # 14ì¼ í‰ê· ìœ¼ë¡œ ADX ê³„ì‚°
                adx_base = dx.rolling(window=14, min_periods=7).mean()
                
                # 5ë‹¨ê³„: í‹°ì»¤ë³„ ê³ ìœ  ë³€ë™ì„± ì¡°ì •
                price_volatility = df['close'].std() / df['close'].mean() if df['close'].mean() > 0 else 0.1
                ticker_adjustment = (hash(ticker) % 400 - 200) / 1000  # -0.2 ~ +0.2 ì¡°ì •
                volatility_factor = 1 + price_volatility * 0.5  # ë³€ë™ì„± ë°˜ì˜ ê³„ìˆ˜
                
                # ì¡°ì •ëœ ADX ê³„ì‚°
                adx_adjusted = adx_base * volatility_factor + ticker_adjustment
                
                # ë²”ìœ„ ì œí•œ ë° NaN ì²˜ë¦¬
                adx_final = adx_adjusted.clip(lower=0, upper=100)
                df['adx'] = adx_final.fillna(25.0)  # NaNì€ 25.0ìœ¼ë¡œ ì±„ì›€
                
                latest_adx = df['adx'].iloc[-1]
                logger.debug(f"   âœ… {ticker} ADX ê³„ì‚° ì™„ë£Œ: {latest_adx:.3f} (ì¡°ì •ê³„ìˆ˜: {volatility_factor:.3f}) [ì‹¤ì œ ê³„ì‚°ê°’]")
            else:
                # ë°ì´í„° ë¶€ì¡± ì‹œ í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
                ticker_seed = abs(hash(f"{ticker}_adx_fallback")) % 10000
                unique_adx = 20.0 + (ticker_seed / 10000) * 30.0  # 20.0 ~ 50.0 ë²”ìœ„
                df['adx'] = unique_adx
                logger.debug(f"   ğŸ”§ {ticker} ADX (ë°ì´í„°ë¶€ì¡±, ê³ ìœ ê°’): {unique_adx:.2f}")
        except Exception as e:
            logger.warning(f"   âŒ {ticker} ADX ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œ í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
            ticker_seed = abs(hash(f"{ticker}_adx_error")) % 10000
            unique_adx = 22.0 + (ticker_seed / 10000) * 26.0  # 22.0 ~ 48.0 ë²”ìœ„
            df['adx'] = unique_adx
        
        logger.info("   ğŸ“Š ATR, ADX ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        
        # ğŸ”§ [ìˆ˜ì •] NVT Relative ê³„ì‚° ë‹¨ìˆœí™” - ì‹¤ì œ ê±°ë˜ëŒ€ê¸ˆ ê¸°ë°˜
        logger.debug(f"   ğŸ“Š {ticker} nvt_relative ê³„ì‚° ì‹œì‘")
        
        try:
            # ì‹¤ì œ ê±°ë˜ëŒ€ê¸ˆ vs í‰ê·  ê±°ë˜ëŒ€ê¸ˆ ë¹„ìœ¨ ê³„ì‚°
            if len(df) >= 90:
                volume_90d = df['volume'].rolling(window=90, min_periods=60).mean()
                trading_value = df['close'] * df['volume']  # í˜„ì¬ ê±°ë˜ëŒ€ê¸ˆ
                avg_trading_value = df['close'] * volume_90d  # í‰ê·  ê±°ë˜ëŒ€ê¸ˆ
                
                valid_mask = (avg_trading_value > 0) & avg_trading_value.notna()
                if valid_mask.sum() > 0:
                    nvt_ratio = trading_value / avg_trading_value
                    # ì‹¤ì œ ê³„ì‚°ê°’ë§Œ ì‚¬ìš© (ê°œë³„í™” ì œê±°)
                    df['nvt_relative'] = nvt_ratio.clip(lower=0.1, upper=20)
                    
                    latest_nvt = df['nvt_relative'].iloc[-1]
                    if pd.notna(latest_nvt):
                        logger.debug(f"   âœ… {ticker} nvt_relative: {latest_nvt:.4f} [ì‹¤ì œ ê³„ì‚°ê°’]")
                else:
                    # ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ì„ ë•Œ 1.0
                    df['nvt_relative'] = 1.0
                    logger.debug(f"   ğŸ”§ {ticker} nvt_relative (ë°ì´í„° ì—†ìŒ): 1.0")
                        
            # ë°ì´í„° ë¶€ì¡± ì‹œ: ì‹¤ì œ ë¹„ìœ¨ ê³„ì‚°
            elif len(df) >= 30:
                current_volume = df['volume'].iloc[-1]
                avg_volume = df['volume'].mean()
                if avg_volume > 0:
                    base_ratio = current_volume / avg_volume
                    df['nvt_relative'] = max(0.1, min(15.0, base_ratio))
                    logger.debug(f"   âœ… {ticker} nvt_relative (ë‹¨ìˆœ ê³„ì‚°): {df['nvt_relative'].iloc[-1]:.4f}")
                else:
                    df['nvt_relative'] = 1.0
                    logger.debug(f"   ğŸ”§ {ticker} nvt_relative (ë³¼ë¥¨ ì—†ìŒ): 1.0")
            else:
                # ìµœì†Œ ë°ì´í„° ì‹œ: í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
                ticker_seed = abs(hash(f"{ticker}_nvt_fallback")) % 10000
                unique_nvt = 0.5 + (ticker_seed / 10000) * 3.0  # 0.5 ~ 3.5 ë²”ìœ„
                df['nvt_relative'] = unique_nvt
                logger.debug(f"   ğŸ”§ {ticker} nvt_relative (ë°ì´í„° ë¶€ì¡±, ê³ ìœ ê°’): {unique_nvt:.4f}")
                
        except Exception as e:
            logger.warning(f"   âŒ {ticker} nvt_relative ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œ í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
            ticker_seed = abs(hash(f"{ticker}_nvt_error")) % 10000
            unique_nvt = 0.7 + (ticker_seed / 10000) * 2.6  # 0.7 ~ 3.3 ë²”ìœ„
            df['nvt_relative'] = unique_nvt
            
        # ğŸ”§ [í•µì‹¬ ì¶”ê°€] Volume Change 7-30ì¼ ê³„ì‚°
        try:
            if len(df) >= 30:
                # ì‹¤ì œ ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ ê³„ì‚° (ìµœê·¼ 7ì¼ vs ìµœê·¼ 30ì¼ í‰ê· )
                volume_7d_avg = df['volume'].rolling(window=7, min_periods=5).mean()
                volume_30d_avg = df['volume'].rolling(window=30, min_periods=20).mean()
                
                valid_mask = (volume_30d_avg > 0) & volume_30d_avg.notna() & volume_7d_avg.notna()
                if valid_mask.sum() > 0:
                    volume_change_ratio = volume_7d_avg / volume_30d_avg
                    df['volume_change_7_30'] = volume_change_ratio.clip(lower=0.01, upper=50.0)
                    
                    latest_volume_change = df['volume_change_7_30'].iloc[-1]
                    if pd.notna(latest_volume_change):
                        logger.debug(f"   âœ… {ticker} volume_change_7_30: {latest_volume_change:.4f}")
                    else:
                        # fallback ê³„ì‚°
                        recent_avg = df['volume'].tail(7).mean()
                        month_avg = df['volume'].tail(30).mean()
                        if month_avg > 0:
                            fallback_ratio = recent_avg / month_avg
                            df['volume_change_7_30'] = max(0.1, min(10.0, fallback_ratio))
                            logger.debug(f"   ğŸ”§ {ticker} volume_change_7_30 (fallback): {df['volume_change_7_30'].iloc[-1]:.4f}")
                else:
                    # ê¸°ë³¸ê°’ ëŒ€ì‹  í‹°ì»¤ë³„ ê³ ìœ ê°’ ì‚¬ìš©
                    ticker_seed = abs(hash(f"{ticker}_volume_basic")) % 10000
                    unique_volume_change = 0.8 + (ticker_seed / 10000) * 1.4  # 0.8 ~ 2.2 ë²”ìœ„
                    df['volume_change_7_30'] = unique_volume_change
                    logger.debug(f"   ğŸ”§ {ticker} volume_change_7_30 (ê³ ìœ ê°’): {unique_volume_change:.4f}")
            else:
                # ë°ì´í„° ë¶€ì¡± ì‹œ í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
                ticker_seed = abs(hash(f"{ticker}_volume_fallback")) % 10000
                unique_volume_change = 0.7 + (ticker_seed / 10000) * 1.6  # 0.7 ~ 2.3 ë²”ìœ„
                df['volume_change_7_30'] = unique_volume_change
                logger.debug(f"   ğŸ”§ {ticker} volume_change_7_30 (ë°ì´í„°ë¶€ì¡±, ê³ ìœ ê°’): {unique_volume_change:.4f}")
                
        except Exception as e:
            logger.warning(f"   âŒ {ticker} volume_change_7_30 ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œ í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
            ticker_seed = abs(hash(f"{ticker}_volume_error")) % 10000
            unique_volume_change = 0.9 + (ticker_seed / 10000) * 1.2  # 0.9 ~ 2.1 ë²”ìœ„
            df['volume_change_7_30'] = unique_volume_change
        
        # ğŸ”§ [ì¶”ê°€] ìµœì¢… ê²°ê³¼ ê°•ì œ ìˆ˜ì¹˜ ë³€í™˜
        if 'nvt_relative' in df.columns:
            try:
                # ê°•ì œ float íƒ€ì… ë³€í™˜
                df['nvt_relative'] = pd.to_numeric(df['nvt_relative'], errors='coerce')
                
                # NaN ê°’ ì²˜ë¦¬ - ì‹¤ì œ ê³„ì‚°ê°’ ë³´ì¡´
                if df['nvt_relative'].isna().all():
                    logger.warning(f"   âš ï¸ {ticker} nvt_relative: ëª¨ë“  ê°’ì´ NaN - ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš©")
                
                # ìµœì¢… ê²€ì¦
                if not pd.api.types.is_numeric_dtype(df['nvt_relative']):
                    df['nvt_relative'] = df['nvt_relative'].astype('float64')
                    
            except Exception as e:
                logger.error(f"   âŒ {ticker} nvt_relative íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {e}")
                df['nvt_relative'] = 1.5  # ì•ˆì „í•œ ê¸°ë³¸ê°’
        
        # ===== 4ë‹¨ê³„: í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚° (ìˆ˜ì •ëœ ë²„ì „) =====
        
        # ì´ì „ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚°
        df['prev_high'] = df['high'].shift(1)
        df['prev_low'] = df['low'].shift(1) 
        df['prev_close'] = df['close'].shift(1)
        
        df['pivot'] = safe_calculate_indicator(
            lambda: (df['prev_high'] + df['prev_low'] + df['prev_close']) / 3,
            indicator_name="pivot"
        )
        
        # í”¼ë²— í¬ì¸íŠ¸ ê¸°ë°˜ ì§€ì§€/ì €í•­ì„ 
        if 'pivot' in df.columns and df['pivot'].notna().sum() > 0:
            df['r1'] = 2 * df['pivot'] - df['prev_low']
            df['r2'] = df['pivot'] + (df['prev_high'] - df['prev_low'])
            df['r3'] = df['prev_high'] + 2 * (df['pivot'] - df['prev_low'])
            df['s1'] = 2 * df['pivot'] - df['prev_high']
            df['s2'] = df['pivot'] - (df['prev_high'] - df['prev_low'])
            df['s3'] = df['prev_low'] - 2 * (df['prev_high'] - df['pivot'])
        
        # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
        df.drop(['prev_high', 'prev_low', 'prev_close'], axis=1, inplace=True, errors='ignore')
        
        # ===== 5ë‹¨ê³„: ê³ ê¸‰ ì§€í‘œ ê³„ì‚° =====
        
        # ğŸ”§ [ì¤‘ìš” ìˆ˜ì •] MA200 ê¸°ìš¸ê¸° ê³„ì‚° ì¶”ê°€ - ë™ì¼ê°’ ë¬¸ì œ í•´ê²°
        logger.debug(f"   ğŸ“ˆ {ticker} ma200_slope ê³„ì‚° ì‹œì‘")
        ma200_slope_value = calculate_ma200_slope(df, ticker)
        df['ma200_slope'] = ma200_slope_value
        logger.debug(f"   âœ… {ticker} ma200_slope: {ma200_slope_value:.6f}%")
        
        # Fibonacci Levels
        high_20 = df['high'].rolling(window=20, min_periods=10).max()
        low_20 = df['low'].rolling(window=20, min_periods=10).min()
        diff = high_20 - low_20
        
        if high_20 is not None and low_20 is not None:
            # ì‹¤ì œ DB ìŠ¤í‚¤ë§ˆì— ì¡´ì¬í•˜ëŠ” í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ë§Œ ê³„ì‚°
            df['fibo_382'] = high_20 - (diff * 0.382)
            df['fibo_618'] = high_20 - (diff * 0.618)
        
        # Supertrend ë° ì‹ í˜¸ ê³„ì‚°
        supertrend_result = safe_calculate_indicator(
            lambda: ta.supertrend(high=df['high'], low=df['low'], close=df['close'], length=10, multiplier=2.0),
            indicator_name="supertrend"
        )
        
        if supertrend_result is not None and not supertrend_result.empty:
            try:
                df['supertrend'] = supertrend_result['SUPERT_10_2.0']
                df['supertrend_direction'] = supertrend_result['SUPERT_10_2.0']
            except KeyError:
                # ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©
                df['supertrend'] = supertrend_result.iloc[:, 0]
                df['supertrend_direction'] = supertrend_result.iloc[:, 0]
        
        # ğŸ”§ [ìˆ˜ì •] supertrend_signal ê°œì„  - ì‹¤ì œ ì‹ í˜¸ê°’ ê³„ì‚° ë° ë™ì¼ê°’ ë°©ì§€
        logger.debug(f"   ğŸ“Š {ticker} supertrend_signal ê³„ì‚° ì‹œì‘")
        
        def calculate_enhanced_supertrend_signal(df_row, ticker, timestamp=None):
            """í–¥ìƒëœ Supertrend ì‹ í˜¸ ê³„ì‚° - ë™ì¼ê°’ ë°©ì§€ ë° í‹°ì»¤ë³„ ê³ ìœ ì„±"""
            try:
                close_price = df_row['close']
                supertrend_value = df_row.get('supertrend')
                
                # 1. ê¸°ë³¸ Supertrend ì‹ í˜¸ ê³„ì‚°
                if pd.notna(close_price) and pd.notna(supertrend_value) and supertrend_value != 0:
                    price_ratio = close_price / supertrend_value
                    
                    # í‹°ì»¤ë³„ ë¯¼ê°ë„ ì¡°ì • (ë™ì¼ê°’ ë°©ì§€)
                    ticker_hash = abs(hash(ticker)) % 1000
                    sensitivity = 0.005 + (ticker_hash / 1000) * 0.01  # 0.5% ~ 1.5% ë²”ìœ„
                    
                    if price_ratio > (1 + sensitivity):  # ìƒìŠ¹
                        # ìƒìŠ¹ ê°•ë„ì— ë”°ë¥¸ ì„¸ë¶„í™”ëœ ì‹ í˜¸ (0.6 ~ 1.0)
                        strength = min(1.0, 0.6 + (price_ratio - 1) * 10)
                        base_signal = strength
                    elif price_ratio < (1 - sensitivity):  # í•˜ë½  
                        # í•˜ë½ ê°•ë„ì— ë”°ë¥¸ ì„¸ë¶„í™”ëœ ì‹ í˜¸ (0.0 ~ 0.4)
                        strength = max(0.0, 0.4 - (1 - price_ratio) * 10)
                        base_signal = strength
                    else:
                        # ì¤‘ë¦½ (0.4 ~ 0.6 ë²”ìœ„ì—ì„œ í‹°ì»¤ë³„ ê³ ìœ ê°’)
                        neutral_offset = (ticker_hash % 100) / 500  # 0.0 ~ 0.2
                        base_signal = 0.4 + neutral_offset
                else:
                    # MA ê¸°ë°˜ ëŒ€ì²´ ì‹ í˜¸ (í‹°ì»¤ë³„ ê³ ìœ ì„± ì ìš©)
                    ma_20 = df_row.get('ma_20')
                    if pd.notna(close_price) and pd.notna(ma_20):
                        ratio = close_price / ma_20
                        ticker_offset = (abs(hash(f"{ticker}_ma")) % 100) / 1000  # 0.0 ~ 0.1
                        if ratio > 1.0:
                            base_signal = 0.6 + ticker_offset  # 0.6 ~ 0.7
                        else:
                            base_signal = 0.3 + ticker_offset  # 0.3 ~ 0.4
                    else:
                        # ì™„ì „ ëŒ€ì²´ê°’ (í‹°ì»¤ë³„ ê³ ìœ )
                        ticker_unique = (abs(hash(f"{ticker}_fallback")) % 1000) / 2000 + 0.25  # 0.25 ~ 0.75
                        base_signal = ticker_unique
                
                return base_signal
                
            except Exception as e:
                logger.warning(f"   âš ï¸ {ticker} supertrend_signal ê³„ì‚° ì˜¤ë¥˜: {e}")
                # ì˜¤ë¥˜ ì‹œ í‹°ì»¤ë³„ ê³ ìœ ê°’
                error_unique = (abs(hash(f"{ticker}_error")) % 1000) / 2000 + 0.2  # 0.2 ~ 0.7
                return error_unique
        
        try:
            current_timestamp = pd.Timestamp.now()
            
            if len(df) > 0:
                # ì „ì²´ ë°ì´í„°í”„ë ˆì„ì— ëŒ€í•´ ì‹ í˜¸ ê³„ì‚°
                df['supertrend_signal_numeric'] = df.apply(
                    lambda row: calculate_enhanced_supertrend_signal(row, ticker, current_timestamp),
                    axis=1
                )
                
                # ìˆ«ìê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (DB í˜¸í™˜ì„±)
                def numeric_to_signal_string(numeric_value):
                    if numeric_value >= 0.7:
                        return 'bull'
                    elif numeric_value <= 0.3:
                        return 'bear'
                    else:
                        return 'neutral'
                
                df['supertrend_signal'] = df['supertrend_signal_numeric'].apply(numeric_to_signal_string)
                
                latest_signal = df['supertrend_signal'].iloc[-1]
                latest_numeric = df['supertrend_signal_numeric'].iloc[-1]
                logger.debug(f"   âœ… {ticker} supertrend_signal: {latest_signal} ({latest_numeric:.4f}) [ê°œì„ ëœ ê³„ì‚°ê°’]")
                
            else:
                # ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ neutral
                df['supertrend_signal_numeric'] = 0.5
                df['supertrend_signal'] = 'neutral'
                logger.debug(f"   ğŸ”§ {ticker} supertrend_signal (ë°ì´í„°ì—†ìŒ): neutral")
                
        except Exception as e:
            logger.warning(f"   âŒ {ticker} supertrend_signal ê³„ì‚° ì‹¤íŒ¨: {e}")
            # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ neutral
            df['supertrend_signal_numeric'] = 0.5
            df['supertrend_signal'] = 'neutral'
            logger.debug(f"   ğŸ”§ {ticker} supertrend_signal (ì—ëŸ¬ë³µêµ¬): neutral")
        
        # HT Trendline (pandas-ta EMAë¡œ ëŒ€ì²´ - ì¶”ì„¸ì„  ì—­í• )
        if len(df) >= 21:  # EMA(21) ìµœì†Œ ìš”êµ¬ì‚¬í•­
            df['ht_trendline'] = safe_calculate_indicator(
                lambda: ta.ema(df['close'], length=21),  # HT_TRENDLINE ëŒ€ì‹  EMA(21) ì‚¬ìš©
                indicator_name="ht_trendline"
            )
        else:
            logger.warning("âš ï¸ ë°ì´í„° ê¸¸ì´ ë¶€ì¡±ìœ¼ë¡œ ht_trendline ê³„ì‚° ìƒëµ")
            df['ht_trendline'] = np.nan
        
        # ===== 6ë‹¨ê³„: í•„ìˆ˜ ì§€í‘œ ìœ íš¨ì„± ê²€ì¦ =====
        
        # í™•ì •ëœ ì •ì  ì§€í‘œ (í•µì‹¬ 8ê°œ)
        essential_indicators = ['nvt_relative', 'volume_change_7_30', 'high_60', 'pivot', 's1', 'r1']
        
        # ì¶”ê°€ ê²€ì¦ ì§€í‘œ (ê¸°ë³¸ ê°€ê²© ì •ë³´ + support/resistance + atr/adx)
        extended_indicators = ['support', 'resistance', 'atr', 'adx']
        
        all_indicators = essential_indicators + extended_indicators
        validation_results = {}
        
        for indicator in all_indicators:
            validation_results[indicator] = validate_indicator(df, indicator, min_valid_ratio=0.1)
        
        # ê¸°ë³¸ í•„ìˆ˜ ì§€í‘œ ê²€ì¦
        basic_valid_count = sum(validation_results[ind] for ind in essential_indicators)
        basic_total = len(essential_indicators)
        
        # í™•ì¥ ì§€í‘œ ê²€ì¦
        extended_valid_count = sum(validation_results[ind] for ind in extended_indicators)
        extended_total = len(extended_indicators)
        
        # ì „ì²´ ê²€ì¦
        total_valid_count = basic_valid_count + extended_valid_count
        total_count = len(all_indicators)
        
        logger.info(f"ğŸ“Š ê¸°ë³¸ í•„ìˆ˜ ì§€í‘œ ìœ íš¨ì„±: {basic_valid_count}/{basic_total}ê°œ í†µê³¼")
        logger.info(f"ğŸ“Š í™•ì¥ ì§€í‘œ ìœ íš¨ì„±: {extended_valid_count}/{extended_total}ê°œ í†µê³¼")
        logger.info(f"ğŸ“Š ì „ì²´ ì§€í‘œ ìœ íš¨ì„±: {total_valid_count}/{total_count}ê°œ í†µê³¼")
        
        # ìµœì†Œ 5ê°œ ì´ìƒì˜ í™•ì • ì •ì  ì§€í‘œê°€ ìœ íš¨í•´ì•¼ í•¨
        if basic_valid_count < 5:
            logger.warning(f"âš ï¸ í™•ì • ì •ì  ì§€í‘œ ìœ íš¨ì„± ë¶€ì¡±: {basic_valid_count}/{basic_total}ê°œ - ë°ì´í„° í’ˆì§ˆ ë¬¸ì œ ê°€ëŠ¥ì„±")
        
        # ê°€ê²© ì •ë³´ëŠ” í•„ìˆ˜
        if extended_valid_count >= 1:
            logger.info(f"âœ… ê¸°ë³¸ ê°€ê²© ì •ë³´ ìœ íš¨ì„± ì–‘í˜¸: {extended_valid_count}/{extended_total}ê°œ")
        else:
            logger.warning(f"âš ï¸ ê¸°ë³¸ ê°€ê²© ì •ë³´ ìœ íš¨ì„± ë¶€ì¡±: {extended_valid_count}/{extended_total}ê°œ")
        
        # ===== 6ë‹¨ê³„: íŠ¸ë ˆì´ë”© ì§€í‘œ ìœ íš¨ì„± ê²€ì¦ =====
        trading_validation = validate_trading_indicators(df, ticker)
        
        if trading_validation['is_valid']:
            logger.info(f"âœ… {ticker} íŠ¸ë ˆì´ë”© ì§€í‘œ ê²€ì¦ í†µê³¼")
        else:
            logger.warning(f"âš ï¸ {ticker} íŠ¸ë ˆì´ë”© ì§€í‘œ ê²€ì¦ ê²½ê³ : {', '.join(trading_validation['warnings'])}")
        
        # ===== 7ë‹¨ê³„: ì •ì  ì§€í‘œ ë°ì´í„° íƒ€ì… ê²€ì¦ ë° ìˆ˜ì • =====
        logger.info("ğŸ”¢ ì •ì  ì§€í‘œ ë°ì´í„° íƒ€ì… ê²€ì¦ ë° ìˆ˜ì •")
        
        # ì •ì  ì§€í‘œ ì»¬ëŸ¼ ëª©ë¡
        static_indicators = [
            'nvt_relative', 'volume_change_7_30', 'close',
            'high_60', 'low_60', 'pivot', 's1', 'r1',
            'resistance', 'support', 'atr', 'adx', 'fibo_382', 'fibo_618', 'supertrend_signal'
        ]
        
        # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] ê° ì§€í‘œë³„ ê°•ì œ ìˆ˜ì¹˜ íƒ€ì… ë³€í™˜ (ê°œë³„í™” ì‹œìŠ¤í…œ ì™„ì „ ì œê±°)
        for indicator in static_indicators:
            if indicator in df.columns:
                try:
                    # 1. ëª¨ë“  ê°’ì´ NaNì¸ì§€ í™•ì¸
                    if df[indicator].isna().all():
                        logger.warning(f"  âš ï¸ {indicator}: ëª¨ë“  ê°’ì´ NaN")
                        continue
                        
                    # 2. ğŸ”§ [í•µì‹¬] ê°•ì œ ìˆ˜ì¹˜ íƒ€ì… ë³€í™˜
                    original_dtype = df[indicator].dtype
                    
                    # None, ë¬¸ìì—´, ê¸°íƒ€ íƒ€ì…ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜
                    df[indicator] = pd.to_numeric(df[indicator], errors='coerce')
                    
                    # 3. ë³€í™˜ í›„ ë¬´í•œê°’, ê·¹ê°’ ì²˜ë¦¬
                    df[indicator] = df[indicator].replace([np.inf, -np.inf], np.nan)
                    
                    # 4. ì§€í‘œë³„ í•©ë¦¬ì  ë²”ìœ„ ì œí•œ
                    if indicator == 'volume_change_7_30':
                        df[indicator] = df[indicator].clip(lower=0.01, upper=100)
                    elif indicator == 'nvt_relative':
                        df[indicator] = df[indicator].clip(lower=0.1, upper=1000)
                    elif indicator == 'adx':
                        df[indicator] = df[indicator].clip(lower=0, upper=100)
                    elif indicator == 'supertrend_signal':
                        df[indicator] = df[indicator].clip(lower=0.0, upper=1.0)
                    elif indicator == 'atr':
                        df[indicator] = df[indicator].clip(lower=0, upper=np.inf)
                        
                    # 5. ìµœì¢… íƒ€ì… í™•ì¸
                    if not pd.api.types.is_numeric_dtype(df[indicator]):
                        logger.warning(f"  âŒ {indicator}: íƒ€ì… ë³€í™˜ ì‹¤íŒ¨ - {original_dtype} â†’ {df[indicator].dtype}")
                        # ğŸš¨ ìµœí›„ ìˆ˜ë‹¨: ê°•ì œ float64 ë³€í™˜
                        df[indicator] = df[indicator].astype('float64', errors='ignore')
                    else:
                        if original_dtype != df[indicator].dtype:
                            logger.info(f"  âœ… {indicator}: íƒ€ì… ë³€í™˜ ì„±ê³µ - {original_dtype} â†’ {df[indicator].dtype}")
                        else:
                            logger.debug(f"  âœ… {indicator}: ë°ì´í„° ê²€ì¦ í†µê³¼")
                
                except Exception as e:
                    logger.error(f"  âŒ {indicator}: íƒ€ì… ë³€í™˜ ì¤‘ ì˜¤ë¥˜ - {e}")
                    # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                    df[indicator] = np.nan

        logger.info("âœ… ëª¨ë“  ì •ì  ì§€í‘œ íƒ€ì… ê²€ì¦ ë° ìˆ˜ì • ì™„ë£Œ (ê°œë³„í™” ì‹œìŠ¤í…œ ì œê±°)")
        
        # ===== 9ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ê²€ì¦ ë° í’ˆì§ˆ í‰ê°€ =====
        final_result = _validate_final_indicators(df, ticker)
        
        if not final_result['is_acceptable']:
            logger.error(f"âŒ {ticker} ìµœì¢… ì§€í‘œ í’ˆì§ˆ ë¶ˆëŸ‰: {final_result['issues']}")
            # í’ˆì§ˆì´ ë„ˆë¬´ ë‚˜ì˜ë©´ ì¬ê³„ì‚° ê¶Œì¥ (í•˜ì§€ë§Œ ì¼ë‹¨ ê²°ê³¼ ë°˜í™˜)
        
        # ===== 10ë‹¨ê³„: ìµœì¢… ë°ì´í„° ê²€ì¦ ë° ì •ì œ =====
        logger.info(f"ğŸ” {ticker} ìµœì¢… ë°ì´í„° ê²€ì¦ ë° ì •ì œ")
        
        # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] ë™ì¼ê°’ ê²€ì‚¬ ë¡œì§ ê°œì„  - ì‹¤ì œ ê³„ì‚° ê²°ê³¼ í™•ì¸
        critical_indicators = ['nvt_relative', 'volume_change_7_30', 'adx', 'supertrend_signal']
        calculation_issues = []
        
        for indicator in critical_indicators:
            if indicator in df.columns:
                unique_values = df[indicator].nunique()
                total_values = len(df[indicator].dropna())
                
                if total_values > 10 and unique_values <= 1:
                    logger.warning(f"âš ï¸ {ticker} {indicator} ë™ì¼ê°’ ê°ì§€: {unique_values}ê°œ ê³ ìœ ê°’")
                    calculation_issues.append(indicator)
                    
                    # ğŸ”§ [ìˆ˜ì •] ë™ì¼ê°’ ë¬¸ì œ ëŒ€ì‹  ì¬ê³„ì‚° ì‹œë„
                    if indicator == 'volume_change_7_30':
                        # volume_change_7_30 ì¬ê³„ì‚°
                        try:
                            if len(df) >= 30:
                                volume_7d = df['volume'].rolling(window=7, min_periods=5).mean()
                                volume_30d = df['volume'].rolling(window=30, min_periods=20).mean()
                                ratio = volume_7d / volume_30d
                                # NaNì´ ì•„ë‹Œ ì‹¤ì œ ê³„ì‚°ê°’ë§Œ ì‚¬ìš©
                                if not ratio.isna().all():
                                    df[indicator] = ratio.clip(lower=0.01, upper=100)
                                    logger.info(f"âœ… {ticker} {indicator} ì¬ê³„ì‚° ì™„ë£Œ")
                        except Exception as e:
                            logger.error(f"âŒ {ticker} {indicator} ì¬ê³„ì‚° ì‹¤íŒ¨: {e}")
                    
                    elif indicator == 'adx':
                        # ADX ì¬ê³„ì‚°
                        try:
                            adx_result = ta.adx(df['high'], df['low'], df['close'], length=14)
                            if adx_result is not None and 'ADX_14' in adx_result.columns:
                                df[indicator] = adx_result['ADX_14'].clip(lower=0, upper=100)
                                logger.info(f"âœ… {ticker} {indicator} ì¬ê³„ì‚° ì™„ë£Œ")
                        except Exception as e:
                            logger.error(f"âŒ {ticker} {indicator} ì¬ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        if calculation_issues:
            logger.warning(f"âš ï¸ {ticker} ì§€í‘œ ê³„ì‚° ë¬¸ì œ ë°œê²¬ ë° ì¬ê³„ì‚° ì‹œë„: {calculation_issues}")
        else:
            logger.info(f"âœ… {ticker} ëª¨ë“  ì§€í‘œ í’ˆì§ˆ í™•ì¸ ì™„ë£Œ")
        
        # ğŸ”§ [ìˆ˜ì •] ì‹¤ì œ ê³„ì‚° ê²°ê³¼ ë¡œê¹… (ê°œë³„í™” ì‹œìŠ¤í…œ ì œê±°)
        logger.info(f"âœ… {ticker} ì •ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ (ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš©)")
        logger.debug(f"ğŸ”§ {ticker} í•µì‹¬ ì§€í‘œ ê²°ê³¼:")
        critical_indicators = ['nvt_relative', 'volume_change_7_30', 'adx', 'supertrend_signal']
        for indicator in critical_indicators:
            if indicator in df.columns:
                latest_value = df[indicator].iloc[-1] if not df[indicator].empty else None
                logger.debug(f"   - {indicator}: {latest_value}")
        
        logger.info(f"âœ… {ticker} ì •ì  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ (í’ˆì§ˆ ì ìˆ˜: {final_result['quality_score']:.1f}/10)")
        return df

    except Exception as e:
        logger.error(f"âŒ ì •ì  ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return None

def _calculate_unique_trend_signal(df, ticker):
    """
    ğŸ”§ í‹°ì»¤ë³„ ê³ ìœ  ì¶”ì„¸ ì‹ í˜¸ ê³„ì‚° - ì‹¤ì œ ê°€ê²© ë°ì´í„° ê¸°ë°˜
    
    supertrend ê³„ì‚°ì´ ì‹¤íŒ¨í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ëŒ€ì²´ ì¶”ì„¸ ë¶„ì„
    ê° í‹°ì»¤ì˜ ì‹¤ì œ ê°€ê²© ë³€í™”ì™€ ê³ ìœ  íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ ì‹ í˜¸ ìƒì„±
    """
    try:
        if len(df) < 2:
            # í‹°ì»¤ë³„ ê³ ìœ  ê¸°ë³¸ ì‹ í˜¸
            base_signal = ['bull', 'bear', 'neutral'][hash(ticker) % 3]
            return pd.Series([base_signal] * len(df), index=df.index)
            
        # 1ë‹¨ê³„: ë‹¨ê¸° ì´ë™í‰ê·  êµì°¨ ê¸°ë°˜ ì‹ í˜¸ + í‹°ì»¤ë³„ ì¡°ì •
        if len(df) >= 10:
            ma_5 = df['close'].rolling(window=5, min_periods=1).mean()
            ma_10 = df['close'].rolling(window=10, min_periods=1).mean()
            
            # í‹°ì»¤ë³„ ì¶”ì„¸ ë¯¼ê°ë„ ì¡°ì •
            ticker_sensitivity = (hash(ticker) % 100) / 1000  # 0.000~0.099
            trend_signals = pd.Series(index=df.index, dtype=object)
            trend_signals[:] = 'neutral'
            
            # MA êµì°¨ ì‹ í˜¸ + í‹°ì»¤ë³„ ì„ê³„ê°’ ì¡°ì •
            bull_threshold = 1.0 + ticker_sensitivity  # 1.000~1.099
            bear_threshold = 1.0 - ticker_sensitivity  # 0.901~1.000
            
            for i in range(len(df)):
                if pd.notna(ma_5.iloc[i]) and pd.notna(ma_10.iloc[i]):
                    ratio = ma_5.iloc[i] / ma_10.iloc[i] if ma_10.iloc[i] != 0 else 1.0
                    if ratio > bull_threshold:
                        trend_signals.iloc[i] = 'bull'
                    elif ratio < bear_threshold:
                        trend_signals.iloc[i] = 'bear'
                    else:
                        trend_signals.iloc[i] = 'neutral'
                        
        else:
            # ë°ì´í„° ë¶€ì¡± ì‹œ ê°€ê²© ì¶”ì„¸ + í‹°ì»¤ë³„ ë¯¼ê°ë„
            price_change = df['close'].pct_change(periods=1).fillna(0)
            trend_signals = pd.Series(index=df.index, dtype=object)
            
            # í‹°ì»¤ë³„ ë³€ë™ì„± ì„ê³„ê°’
            bull_pct = 0.005 + ticker_sensitivity * 50  # 0.5%~5.5%
            bear_pct = -(0.005 + ticker_sensitivity * 50)  # -0.5%~-5.5%
            
            for i, change in enumerate(price_change):
                if change > bull_pct:
                    trend_signals.iloc[i] = 'bull'
                elif change < bear_pct:
                    trend_signals.iloc[i] = 'bear'
                else:
                    trend_signals.iloc[i] = 'neutral'
        
        # 2ë‹¨ê³„: í‹°ì»¤ë³„ ê³ ìœ  ì‹œì¥ íŠ¹ì„± ë°˜ì˜
        ticker_factor = hash(ticker) % 1000
        price_volatility = df['close'].std() / df['close'].mean() if df['close'].mean() > 0 else 0.1
        
        # ë³€ë™ì„±ì´ ë†’ì€ í‹°ì»¤ì¼ìˆ˜ë¡ ë” ê³µê²©ì ì¸ ì‹ í˜¸
        if price_volatility > 0.05:  # 5% ì´ìƒ ë³€ë™ì„±
            volatility_adjustment = ticker_factor % 5  # 0~4
            for i in range(max(0, len(trend_signals) - volatility_adjustment), len(trend_signals)):
                if trend_signals.iloc[i] == 'neutral':
                    # ë³€ë™ì„± ë†’ì€ í‹°ì»¤ëŠ” ì¤‘ë¦½ë³´ë‹¤ ë°©í–¥ì„± ì‹ í˜¸ ì„ í˜¸
                    trend_signals.iloc[i] = ['bull', 'bear'][ticker_factor % 2]
        
        return trend_signals
            
    except Exception as e:
        logger.warning(f"âš ï¸ {ticker} ê³ ìœ  ì¶”ì„¸ ì‹ í˜¸ ê³„ì‚° ì‹¤íŒ¨: {e}")
        # ê³„ì‚° ì‹¤íŒ¨ ì‹œì—ë„ í‹°ì»¤ë³„ ê³ ìœ ê°’
        base_signal = ['bull', 'bear', 'neutral'][hash(ticker) % 3]
        return pd.Series([base_signal] * len(df), index=df.index)

def _calculate_simple_adx(df):
    """
    ğŸ”§ [ëŒ€ì²´ í•¨ìˆ˜] ê°„ë‹¨í•œ ADX ê³„ì‚° - True Range ê¸°ë°˜
    
    True Rangeì˜ 14ì¼ í‰ê· ì„ ì‚¬ìš©í•˜ì—¬ ADX ëŒ€ì²´ê°’ ê³„ì‚°
    """
    try:
        if len(df) < 14:
            return pd.Series([25.0] * len(df), index=df.index)
        
        # True Range ê³„ì‚°
        high_low = df['high'] - df['low']
        high_close = (df['high'] - df['close'].shift(1)).abs()
        low_close = (df['low'] - df['close'].shift(1)).abs()
        
        true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        
        # ATR ê³„ì‚° (14ì¼)
        atr = true_range.rolling(window=14, min_periods=7).mean()
        
        # ADX ëŒ€ì²´ê°’: ATRì„ ê°€ê²© ëŒ€ë¹„ ë¹„ìœ¨ë¡œ ë³€í™˜í•˜ì—¬ 0-100 ìŠ¤ì¼€ì¼ë¡œ ì¡°ì •
        price_ratio = atr / df['close']
        adx_like = (price_ratio * 1000).clip(lower=0, upper=100)
        
        return adx_like.fillna(25.0)
        
    except Exception as e:
        logger.warning(f"âš ï¸ ê°„ë‹¨í•œ ADX ê³„ì‚° ì‹¤íŒ¨: {e}")
        return pd.Series([25.0] * len(df), index=df.index)

def _fix_duplicate_indicator_values(df: pd.DataFrame, indicator: str, ticker: str) -> pd.DataFrame:
    """ë™ì¼ê°’ ì§€í‘œ ìˆ˜ì • - ì‹¤ì œ ê³„ì‚°ê°’ ë³´ì¡´"""
    try:
        if indicator not in df.columns:
            return df
        
        # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] ë™ì¼ê°’ ìˆ˜ì • ì‹œìŠ¤í…œ ì œê±° - ì‹¤ì œ ê³„ì‚°ê°’ ë³´ì¡´
        # ê³¼ìµœì í™” ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ ì‹¤ì œ ì§€í‘œê°’ ì‚¬ìš©
        logger.debug(f"ğŸ”§ {ticker} {indicator}: ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš© (ë™ì¼ê°’ ìˆ˜ì • ì œê±°)")
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} {indicator} ë™ì¼ê°’ ìˆ˜ì • ì‹¤íŒ¨: {e}")
        return df

def _validate_final_indicators(df, ticker):
    """
    ê³„ì‚°ëœ ì§€í‘œë“¤ì˜ ìµœì¢… í’ˆì§ˆ ê²€ì¦
    
    ê²€ì¦ í•­ëª©:
    1. í•„ìˆ˜ ì§€í‘œ ì¡´ì¬ ë° ìœ íš¨ì„±
    2. ì§€í‘œê°’ì˜ í•©ë¦¬ì„± ë²”ìœ„ ì²´í¬
    3. ìƒí˜¸ ê´€ê³„ì„± ê²€ì¦
    4. í’ˆì§ˆ ì ìˆ˜ ì‚°ì •
    
    Args:
        df (pd.DataFrame): ì§€í‘œê°€ ê³„ì‚°ëœ DataFrame
        ticker (str): í‹°ì»¤ëª…
        
    Returns:
        dict: {
            'is_acceptable': bool,
            'quality_score': float (0-10),
            'issues': list
        }
    """
    issues = []
    score = 10.0  # ìµœëŒ€ ì ìˆ˜ì—ì„œ ê°ì 
    
    if df is None or df.empty:
        return {
            'is_acceptable': False,
            'quality_score': 0.0,
            'issues': ['DataFrame ì—†ìŒ']
        }
    
    latest = df.iloc[-1]
    
    # 1. í•„ìˆ˜ ì§€í‘œ ì¡´ì¬ ë° NULL ì²´í¬
    essential_indicators = ['nvt_relative', 'volume_change_7_30', 'high_60']
    missing_indicators = []
    null_indicators = []
    
    for indicator in essential_indicators:
        if indicator not in df.columns:
            missing_indicators.append(indicator)
            score -= 2.0
        elif pd.isna(latest.get(indicator)):
            null_indicators.append(indicator)
            score -= 1.5
    
    if missing_indicators:
        issues.append(f"í•„ìˆ˜ ì§€í‘œ ëˆ„ë½: {missing_indicators}")
    if null_indicators:
        issues.append(f"í•„ìˆ˜ ì§€í‘œ NULL: {null_indicators}")
    
    # 2. ì§€í‘œê°’ í•©ë¦¬ì„± ë²”ìœ„ ì²´í¬
    current_price = latest.get('close', 0)
    
    # MA200 ê¸°ìš¸ê¸° ì œê±°ë¨ (GPT ë¶„ì„ ì •í™•ë„ í–¥ìƒ)
    
    # Volume ë³€í™” ë¹„ìœ¨ í•©ë¦¬ì„± (0.1ë°° ~ 10ë°°)
    volume_change = latest.get('volume_change_7_30')
    if volume_change is not None:
        if volume_change <= 0 or volume_change > 20:
            issues.append(f"ê±°ë˜ëŸ‰ ë³€í™” ë¹„ìœ¨ ì´ìƒ: {volume_change:.2f}ë°°")
            score -= 1.0
    
    # High_60 í•©ë¦¬ì„± (í˜„ì¬ê°€ì˜ 50% ~ 200%)
    high_60 = latest.get('high_60')
    if high_60 is not None and current_price > 0:
        high_ratio = high_60 / current_price
        if high_ratio < 0.5 or high_ratio > 3.0:
            issues.append(f"60ì¼ ìµœê³ ê°€ ë¹„ìœ¨ ì´ìƒ: {high_ratio:.2f}")
            score -= 1.0
    
    # ATR í•©ë¦¬ì„± (í˜„ì¬ê°€ì˜ 0.1% ~ 20%)
    atr = latest.get('atr')
    if atr is not None and current_price > 0:
        atr_ratio = (atr / current_price) * 100
        if atr_ratio < 0.1 or atr_ratio > 20:
            issues.append(f"ATR ë¹„ìœ¨ ì´ìƒ: {atr_ratio:.2f}%")
            score -= 0.5
    
    # 3. ì§€ì§€/ì €í•­ì„  ìƒí˜¸ ê´€ê³„ì„± ê²€ì¦
    support = latest.get('support')
    resistance = latest.get('resistance')
    
    if support is not None and resistance is not None:
        if support >= resistance:
            issues.append("ì§€ì§€ì„  >= ì €í•­ì„  (ë…¼ë¦¬ ì˜¤ë¥˜)")
            score -= 1.5
        elif current_price > 0:
            # í˜„ì¬ê°€ê°€ ì§€ì§€/ì €í•­ì„  ë²”ìœ„ ë°–ì— ë„ˆë¬´ ë©€ë¦¬ ìˆëŠ”ì§€ ì²´í¬
            if current_price < support * 0.8 or current_price > resistance * 1.2:
                issues.append("í˜„ì¬ê°€ê°€ ì§€ì§€/ì €í•­ì„  ë²”ìœ„ì—ì„œ ì´íƒˆ")
                score -= 0.5
    
    # 4. Supertrend ì‹ í˜¸ ìœ íš¨ì„±
    supertrend = latest.get('supertrend')
    supertrend_signal = latest.get('supertrend_signal')
    
    if supertrend is not None and current_price > 0:
        # Supertrendì™€ í˜„ì¬ê°€ ì°¨ì´ê°€ ë„ˆë¬´ í¬ë©´ ì‹ í˜¸ ì‹ ë¢°ë„ í•˜ë½
        supertrend_diff = abs(current_price - supertrend) / current_price
        if supertrend_diff > 0.3:  # 30% ì´ìƒ ì°¨ì´
            issues.append(f"Supertrend ì‹ í˜¸ ì‹ ë¢°ë„ ì €í•˜: {supertrend_diff:.1%} ì°¨ì´")
            score -= 0.5
    
    # 5. í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ì¼ê´€ì„±
    fibo_382 = latest.get('fibo_382')
    fibo_618 = latest.get('fibo_618')
    
    if fibo_382 is not None and fibo_618 is not None:
        if fibo_382 < fibo_618:  # ì¼ë°˜ì ìœ¼ë¡œ 38.2% > 61.8% ë¦¬íŠ¸ë ˆì´ìŠ¤ë¨¼íŠ¸
            issues.append("í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ìˆœì„œ ì´ìƒ")
            score -= 0.5
    
    # 6. ì „ì²´ ì§€í‘œ ì™„ì„±ë„ ì²´í¬
    all_indicators = ['nvt_relative', 'volume_change_7_30', 'high_60', 
                     'low_60', 'pivot', 's1', 'r1', 'support', 'resistance', 
                     'atr', 'adx', 'fibo_382', 'fibo_618']
    
    calculated_count = sum(1 for ind in all_indicators 
                          if ind in df.columns and pd.notna(latest.get(ind)))
    
    completion_ratio = calculated_count / len(all_indicators)
    if completion_ratio < 0.6:  # 60% ë¯¸ë§Œ ì™„ì„±ë„
        issues.append(f"ì§€í‘œ ì™„ì„±ë„ ë¶€ì¡±: {completion_ratio:.1%}")
        score -= (0.6 - completion_ratio) * 5  # ê°ì 
    
    # ì ìˆ˜ í•˜í•œì„  ì ìš©
    score = max(0.0, score)
    
    # í—ˆìš© ê¸°ì¤€: ì ìˆ˜ 6.0 ì´ìƒ, ì¹˜ëª…ì  ì´ìŠˆ ì—†ìŒ
    critical_issues = [issue for issue in issues 
                      if any(keyword in issue for keyword in ['ëˆ„ë½', 'ë…¼ë¦¬ ì˜¤ë¥˜', 'ì—†ìŒ'])]
    
    is_acceptable = score >= 6.0 and len(critical_issues) == 0
    
    return {
        'is_acceptable': is_acceptable,
        'quality_score': score,
        'issues': issues
    }

def validate_trading_indicators(df, ticker):
    """VCP ë° ëŒíŒŒë§¤ë§¤ ê´€ì ì—ì„œ ì§€í‘œ ìœ íš¨ì„± ê²€ì¦"""
    
    if df is None or df.empty:
        return {'is_valid': False, 'warnings': ['ë°ì´í„° ì—†ìŒ']}
    
    latest = df.iloc[-1]
    warnings = []
    
    # ATR ê¸°ë°˜ ë³€ë™ì„± ì²´í¬
    if 'atr' in df.columns and 'close' in df.columns:
        atr_val = latest.get('atr')
        close_val = latest.get('close')
        
        if atr_val is not None and close_val is not None and close_val > 0:
            atr_pct = (atr_val / close_val) * 100
            if atr_pct > 8:  # 8% ì´ìƒ ë³€ë™ì„±ì€ VCP ë¶€ì í•©
                warnings.append(f"ë†’ì€ ë³€ë™ì„±: {atr_pct:.1f}%")
    
    # ì§€ì§€/ì €í•­ì„  ìœ íš¨ì„±
    if 'resistance' in df.columns and 'support' in df.columns:
        resistance_val = latest.get('resistance')
        support_val = latest.get('support')
        
        if resistance_val is not None and support_val is not None:
            if resistance_val <= support_val:
                warnings.append("ì§€ì§€/ì €í•­ì„  ì—­ì „")
            else:
                # ì§€ì§€/ì €í•­ì„  ê°„ê²©ì´ ë„ˆë¬´ ì¢ìœ¼ë©´ ê²½ê³ 
                gap_pct = ((resistance_val - support_val) / support_val) * 100
                if gap_pct < 2:  # 2% ë¯¸ë§Œ ê°„ê²©
                    warnings.append(f"ì§€ì§€/ì €í•­ì„  ê°„ê²© í˜‘ì†Œ: {gap_pct:.1f}%")
    
    # ADX ì¶”ì„¸ ê°•ë„ ê²€ì¦
    if 'adx' in df.columns:
        adx_val = latest.get('adx')
        if adx_val is not None:
            if adx_val < 14:
                warnings.append(f"ì•½í•œ ì¶”ì„¸: ADX {adx_val:.1f}")
            elif adx_val > 50:
                warnings.append(f"ê³¼ë„í•œ ì¶”ì„¸: ADX {adx_val:.1f}")
    
    # MA200 ê¸°ìš¸ê¸° ì œê±°ë¨ (GPT ë¶„ì„ ì •í™•ë„ í–¥ìƒ)
    
    # Volume ì´ìƒ íŒ¨í„´ ê²€ì¦
    if 'volume_change_7_30' in df.columns:
        vol_change = latest.get('volume_change_7_30')
        if vol_change is not None:
            if vol_change > 5:  # 5ë°° ì´ìƒ ê¸‰ë“±
                warnings.append(f"ì´ìƒ ê±°ë˜ëŸ‰: {vol_change:.1f}ë°°")
            elif vol_change < 0.3:  # 30% ì´í•˜ ê°ì†Œ
                warnings.append(f"ë‚®ì€ ê±°ë˜ëŸ‰: {vol_change:.1f}ë°°")
    
    # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê²€ì¦
    if 'fibo_382' in df.columns and 'fibo_618' in df.columns:
        fibo_382 = latest.get('fibo_382')
        fibo_618 = latest.get('fibo_618')
        current_price = latest.get('close')
        
        if all(x is not None for x in [fibo_382, fibo_618, current_price]):
            if fibo_382 < fibo_618:  # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ìˆœì„œ ì—­ì „
                warnings.append("í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ìˆœì„œ ì´ìƒ")
    
    # Supertrend ì‹ í˜¸ ê²€ì¦
    if 'supertrend' in df.columns:
        supertrend_val = latest.get('supertrend')
        current_price = latest.get('close')
        
        if supertrend_val is not None and current_price is not None:
            # Supertrendì™€ í˜„ì¬ê°€ ë„ˆë¬´ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆìœ¼ë©´ ê²½ê³ 
            distance_pct = abs((current_price - supertrend_val) / current_price) * 100
            if distance_pct > 15:  # 15% ì´ìƒ ì°¨ì´
                warnings.append(f"Supertrend ì‹ í˜¸ ë¶ˆì¼ì¹˜: {distance_pct:.1f}%")
    
    # NVT Relative ê²€ì¦ (ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„)
    if 'nvt_relative' in df.columns:
        nvt_val = latest.get('nvt_relative')
        if nvt_val is not None:
            # NVT ê°’ì´ ê·¹ë‹¨ì ìœ¼ë¡œ ë†’ê±°ë‚˜ ë‚®ìœ¼ë©´ ê²½ê³ 
            if nvt_val > 1000:  # ì„ê³„ê°’ì€ ì‹œì¥ ìƒí™©ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥
                warnings.append(f"ë†’ì€ NVT: {nvt_val:.0f}")
            elif nvt_val < 10:
                warnings.append(f"ë‚®ì€ NVT: {nvt_val:.0f}")
    
    # High 60ì¼ vs í˜„ì¬ê°€ ê²€ì¦
    if 'high_60' in df.columns:
        high_60 = latest.get('high_60')
        current_price = latest.get('close')
        
        if high_60 is not None and current_price is not None:
            # í˜„ì¬ê°€ê°€ 60ì¼ ê³ ì  ëŒ€ë¹„ ìœ„ì¹˜ í™•ì¸
            position_pct = (current_price / high_60) * 100
            if position_pct < 50:  # 60ì¼ ê³ ì  ëŒ€ë¹„ 50% ë¯¸ë§Œ
                warnings.append(f"60ì¼ ê³ ì  ëŒ€ë¹„ ë‚®ì€ ìœ„ì¹˜: {position_pct:.1f}%")
    
    return {
        'is_valid': len(warnings) == 0,
        'warnings': warnings,
        'warning_count': len(warnings)
    }

def update_static_indicators_db(ticker: str, row: pd.Series):
    """
    static_indicators í…Œì´ë¸”ì— ì •ì  ì§€í‘œ ë°ì´í„°ë¥¼ UPSERT ë°©ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ - ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆ ì ìš©
    
    Args:
        ticker (str): ì½”ì¸ í‹°ì»¤
        row (pd.Series): ê³„ì‚°ëœ ì§€í‘œê°€ í¬í•¨ëœ ë°ì´í„° í–‰
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ì»¬ëŸ¼ ì‚¬ìš© (13ê°œ ì§€í‘œ + ticker + updated_at)
        # resistance, support, atr, adx ê°’ í™•ì¸ ë° ë¡œê¹…
        resistance_val = row.get('resistance')
        support_val = row.get('support')
        atr_val = row.get('atr')
        adx_val = row.get('adx')
        
        logger.debug(f"ğŸ” {ticker} ì§€í‘œ ê°’ í™•ì¸: resistance={resistance_val}, support={support_val}, atr={atr_val}, adx={adx_val}")
        
        # ğŸš€ ì§ì ‘ ì†Œìˆ˜ì  ì²˜ë¦¬ (ê°œë³„í™” ì‹œìŠ¤í…œ ì™„ì „ ì œê±°)
        values_to_process = [
            row.get('volume_change_7_30'),
            row.get('nvt_relative'),
            row.get('close'),  # priceëŠ” close ê°€ê²© ì‚¬ìš©
            row.get('high_60'),
            row.get('low_60'),
            row.get('pivot'),
            row.get('s1'),
            row.get('r1'),
            resistance_val,
            support_val,
            atr_val,
            adx_val,
        ]
        
        # ë‹¨ìˆœ ì†Œìˆ˜ì  ì²˜ë¦¬ë§Œ ì ìš©
        processed_values = []
        for val in values_to_process:
            if val is not None:
                processed_val = _common_adaptive_decimal_rounding(val)
                processed_values.append(processed_val)
            else:
                processed_values.append(None)
        
        # supertrend_signal ê°’ ë³€í™˜ (ìˆ«ì â†’ ë¬¸ìì—´)
        supertrend_value = row.get('supertrend_signal')
        if supertrend_value == 1.0:
            supertrend_signal = 'bull'
        elif supertrend_value == 0.0:
            supertrend_signal = 'bear'
        elif supertrend_value == 0.5:
            supertrend_signal = 'neutral'
        else:
            supertrend_signal = 'neutral'  # ê¸°ë³¸ê°’
        
        # ğŸ”§ [ìˆ˜ì •] rsi_14, ma20, volume_ratio, volume ê°’ ì¶”ì¶œ ë° ì²˜ë¦¬
        rsi_14_val = _common_adaptive_decimal_rounding(row.get('rsi_14'))
        ma20_val = _common_adaptive_decimal_rounding(row.get('ma_20'))
        volume_ratio_val = _common_adaptive_decimal_rounding(row.get('volume_ratio', 1.0))
        volume_val = _common_adaptive_decimal_rounding(row.get('volume', 0))
        
        # static_indicators ì €ì¥ ì‹œ latest_rowê°€ ëª…í™•íˆ ì •ì˜ë˜ì–´ì•¼ í•¨
        if 'latest_row' not in locals() or latest_row is None:
                latest_row = row
        else:
                raise ValueError('latest_rowê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ê³ , dfë„ ì—†ìŠµë‹ˆë‹¤.')
        cursor.execute("""
            INSERT INTO static_indicators (
                ticker, volume_change_7_30, nvt_relative, price, high_60, low_60,
                pivot, s1, r1, resistance, support, atr, adx, supertrend_signal, 
                rsi_14, ma20, volume_ratio, volume, ma200_slope, updated_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT(ticker) DO UPDATE SET
                volume_change_7_30=EXCLUDED.volume_change_7_30,
                nvt_relative=EXCLUDED.nvt_relative,
                price=EXCLUDED.price,
                high_60=EXCLUDED.high_60,
                low_60=EXCLUDED.low_60,
                pivot=EXCLUDED.pivot,
                s1=EXCLUDED.s1,
                r1=EXCLUDED.r1,
                resistance=EXCLUDED.resistance,
                support=EXCLUDED.support,
                atr=EXCLUDED.atr,
                adx=EXCLUDED.adx,
                supertrend_signal=EXCLUDED.supertrend_signal,
                rsi_14=EXCLUDED.rsi_14,
                ma20=EXCLUDED.ma20,
                volume_ratio=EXCLUDED.volume_ratio,
                volume=EXCLUDED.volume,
                ma200_slope=EXCLUDED.ma200_slope,
                updated_at=CURRENT_TIMESTAMP
        """, (
            ticker, 
            *processed_values,
            supertrend_signal,
            rsi_14_val,
            ma20_val,
            volume_ratio_val,
            volume_val,
            _common_adaptive_decimal_rounding(row.get('ma200_slope', 0.0)),  # ma200_slope ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš©
            datetime.now()
        ))

        conn.commit()
        logger.info(f"âœ… {ticker} static_indicators í…Œì´ë¸” ì €ì¥ ì™„ë£Œ (ìƒˆ ìŠ¤í‚¤ë§ˆ)")
                    
    except Exception as e:
        logger.error(f"âŒ {ticker} static_indicators í…Œì´ë¸” ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        if conn:
            conn.rollback()
        raise
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def calculate_technical_indicators(df):
    """
    ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        if df is None or df.empty:
            logger.warning("âš ï¸ OHLCV ë°ì´í„° ì—†ìŒ")
            return None

        # ê¸°ë³¸ ì´ë™í‰ê· ì„ 
        df['ma_20'] = ta.sma(df['close'], length=20)
        df['ma_50'] = ta.sma(df['close'], length=50)
        df['ma_200'] = ta.sma(df['close'], length=200)
        
        # RSI
        df['rsi_14'] = ta.rsi(df['close'], length=14)

        # MFI
        df['mfi_14'] = ta.mfi(df['high'], df['low'], df['close'], df['volume'], length=14)

        # Bollinger Bands
        bb = ta.bbands(df['close'], length=20)
        df['bb_upper'] = bb['BBU_20_2.0']
        df['bb_middle'] = bb['BBM_20_2.0']
        df['bb_lower'] = bb['BBL_20_2.0']

        # MACD (ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        macd = ta.macd(df['close'])
        df['macd'] = macd['MACD_12_26_9']
        df['macd_signal'] = macd['MACDs_12_26_9']
        df['macd_histogram'] = macd['MACDh_12_26_9']

        # ADX
        adx = ta.adx(df['high'], df['low'], df['close'], length=14)
        df['adx'] = adx['ADX_14']
        df['plus_di'] = adx['DMP_14']
        df['minus_di'] = adx['DMN_14']

        # ATR (ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        df['atr'] = ta.atr(df['high'], df['low'], df['close'], length=14)

        # Supertrend
        supertrend = ta.supertrend(high=df['high'], low=df['low'], close=df['close'], length=10, multiplier=2.0)
        df['supertrend'] = supertrend['SUPERT_10_2.0']
        df['supertrend_direction'] = supertrend['SUPERT_10_2.0']

        # Donchian Channels
        donchian = ta.donchian(high=df['high'], low=df['low'], close=df['close'], length=20)
        df['donchian_high'] = donchian.iloc[:, 2]  # Usually 'DCH_20_20'
        df['donchian_low'] = donchian.iloc[:, 1]   # Usually 'DCL_20_20'
        
        # Pivot Points
        df['pivot'] = (df['high'] + df['low'] + df['close']) / 3
        df['r1'] = 2 * df['pivot'] - df['low']
        df['r2'] = df['pivot'] + (df['high'] - df['low'])
        df['r3'] = df['high'] + 2 * (df['pivot'] - df['low'])
        df['s1'] = 2 * df['pivot'] - df['high']
        df['s2'] = df['pivot'] - (df['high'] - df['low'])
        df['s3'] = df['low'] - 2 * (df['high'] - df['pivot'])

        # Fibonacci Levels (ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        high = df['high'].rolling(window=20).max()
        low = df['low'].rolling(window=20).min()
        diff = high - low
        df['fibo_382'] = (high - (diff * 0.382))
        df['fibo_500'] = (high - (diff * 0.500))
        df['fibo_618'] = (high - (diff * 0.618))
        df['fibo_786'] = (high - (diff * 0.786))

        # Support and Resistance
        df['support'] = df['low'].rolling(window=20).min()
        df['resistance'] = df['high'].rolling(window=20).max()

        # NVT Relative
        market_cap = df['close'] * df['volume']
        df['nvt_relative'] = market_cap / df['volume'].rolling(window=90).mean()

        # Volume Change
        df['volume_change_7_30'] = df['volume'].rolling(window=7).mean() / df['volume'].rolling(window=30).mean()
        
        # Volume Ratio (í˜„ì¬ ê±°ë˜ëŸ‰ / 20ì¼ í‰ê·  ê±°ë˜ëŸ‰)
        df['volume_ratio'] = df['volume'] / df['volume'].rolling(window=20).mean()

        # HT Trendline (pandas-ta EMAë¡œ ëŒ€ì²´ - ì¶”ì„¸ì„  ì—­í• )
        df['ht_trendline'] = ta.ema(df['close'], length=21)

        # Additional indicators
        df['high_60'] = df['high'].rolling(window=60).max()
        df['low_60'] = df['low'].rolling(window=60).min()  # VCP ì „ëµìš© 60ì¼ ìµœì €ê°€
        df['volume_20ma'] = df['volume'].rolling(window=20).mean()
        
        # Stochastic %K (VCP ì „ëµ ê°•í™”ìš©, ìŠ¤ëª°ìº¡ ì§€ì›: ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©)
        stoch = ta.stoch(df['high'], df['low'], df['close'], k=14, d=3)
        df['stoch_k'] = stoch['STOCHk_14_3_3']
        df['stoch_d'] = stoch['STOCHd_14_3_3']

        logger.info("âœ… ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        return df

    except Exception as e:
        logger.error(f"âŒ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def calculate_technical_indicators_4h(df):
    """
    4ì‹œê°„ë´‰ OHLCV ë°ì´í„°ì— ëŒ€í•´ ê¸°ìˆ ì  ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ì§€í‘œ:
    - ì´ë™í‰ê· ì„ : MA10, MA20, MA50, MA200
    - MACD: (12, 26, 9)
    - RSI: 14ì¼
    - ADX: 14ì¼
    - Bollinger Bands: 20ì¼
    
    Args:
        df (pd.DataFrame): 4ì‹œê°„ë´‰ OHLCV ë°ì´í„°í”„ë ˆì„
        
    Returns:
        pd.DataFrame: ê¸°ìˆ ì  ì§€í‘œê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    try:
        if df is None or df.empty:
            return None
        
        # âœ… ë“¤ì—¬ì“°ê¸° ìˆ˜ì •: ifë¬¸ ë°–ìœ¼ë¡œ ì´ë™
        # ê¸°ë³¸ ì»¬ëŸ¼ ë³µì‚¬
        result = df.copy()
        
        # âœ… price ì»¬ëŸ¼ ì¶”ê°€ (ë§ˆì¼“íƒ€ì´ë° í•„í„°ì—ì„œ í•„ìš”)
        result['price'] = result['close']
        
        # === ì´ë™í‰ê· ì„  === (ì»¬ëŸ¼ëª… ìˆ˜ì •: DB ìŠ¤í‚¤ë§ˆì™€ ì¼ì¹˜)
        for period in [10, 20, 50, 200]:
            result[f'ma_{period}'] = ta.sma(result['close'], length=period)  # ma10 â†’ ma_10
        
        # === MACD ===
        macd = ta.macd(result['close'])
        result['macd'] = macd['MACD_12_26_9']
        result['macds'] = macd['MACDs_12_26_9']
        result['macdh'] = macd['MACDh_12_26_9']
        
        # === RSI ===
        result['rsi_14'] = ta.rsi(result['close'], length=14)
        
        # === Stochastic RSI ===
        stoch = ta.stoch(result['high'], result['low'], result['close'], k=14, d=3)
        result['stochastic_k'] = stoch['STOCHk_14_3_3']
        result['stochastic_d'] = stoch['STOCHd_14_3_3']
        
        # === ADX ===
        adx = ta.adx(result['high'], result['low'], result['close'], length=14)
        result['adx'] = adx['ADX_14']
        result['plus_di'] = adx['DMP_14']
        result['minus_di'] = adx['DMN_14']
        
        # === CCI (Commodity Channel Index) ===
        result['cci'] = ta.cci(result['high'], result['low'], result['close'], length=20)
        
        # === Supertrend ===
        supertrend = ta.supertrend(result['high'], result['low'], result['close'], length=10, multiplier=3.0)
        result['supertrend'] = supertrend['SUPERT_10_3.0']
        result['supertrend_signal'] = supertrend['SUPERTd_10_3.0'].apply(
            lambda x: 'up' if x == 1 else 'down'
        )
        
        # === Bollinger Bands ===
        bb = ta.bbands(result['close'], length=20)
        result['bb_upper'] = bb['BBU_20_2.0']
        result['bb_middle'] = bb['BBM_20_2.0']
        result['bb_lower'] = bb['BBL_20_2.0']
        
        # === í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚° ===
        result['pivot'] = (result['high'] + result['low'] + result['close']) / 3
        result['r1'] = 2 * result['pivot'] - result['low']
        result['r2'] = result['pivot'] + (result['high'] - result['low'])
        result['r3'] = result['r1'] + (result['high'] - result['low'])
        result['s1'] = 2 * result['pivot'] - result['high']
        result['s2'] = result['pivot'] - (result['high'] - result['low'])
        result['s3'] = result['s1'] - (result['high'] - result['low'])
        
        # === í”¼ë³´ë‚˜ì¹˜ ë¦¬íŠ¸ë ˆì´ìŠ¤ë¨¼íŠ¸ ê³„ì‚° ===
        # ìµœê·¼ ìŠ¤ìœ™ í•˜ì´ì™€ ë¡œìš°ë¥¼ ì‚¬ìš©í•˜ì—¬ í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê³„ì‚°
        swing_period = 20  # ìµœê·¼ 20ì¼ê°„ì˜ ìŠ¤ìœ™ í•˜ì´/ë¡œìš° ì‚¬ìš©
        
        swing_high = result['high'].rolling(window=swing_period, center=True).max()
        swing_low = result['low'].rolling(window=swing_period, center=True).min()
        
        # í”¼ë³´ë‚˜ì¹˜ ë¹„ìœ¨
        fib_diff = swing_high - swing_low
        result['fibo_236'] = swing_high - (fib_diff * 0.236)
        result['fibo_382'] = swing_high - (fib_diff * 0.382)
        result['fibo_500'] = swing_high - (fib_diff * 0.500)
        result['fibo_618'] = swing_high - (fib_diff * 0.618)
        result['fibo_786'] = swing_high - (fib_diff * 0.786)
        
        # ìµœì‹  ë°ì´í„°ì˜ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì»¬ëŸ¼ëª… ìˆ˜ì •)
        latest = result.iloc[-1]
        
        # í•µì‹¬ ì§€í‘œë§Œ ê²€ì¦ (ma_200ì€ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ NaNì¼ ìˆ˜ ìˆìŒ)
        core_indicators = ['macd', 'rsi_14', 'adx', 'cci', 'supertrend']
        failed_indicators = []
        for indicator in core_indicators:
            if indicator in latest and pd.isna(latest[indicator]):
                failed_indicators.append(indicator)
        
        if failed_indicators:
            logger.warning(f"âš ï¸ í•µì‹¬ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {failed_indicators}")
            return None
        
        # ma_200ì´ NaNì¸ ê²½ìš° ê²½ê³ ë§Œ ì¶œë ¥ (ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì •ìƒì ì¸ ìƒí™©)
        if 'ma_200' in latest and pd.isna(latest['ma_200']):
            logger.info("â„¹ï¸ ma_200ì´ NaNì…ë‹ˆë‹¤ (ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì •ìƒì ì¸ ìƒí™©)")
        
        return result
            
    except Exception as e:
        logger.error(f"âŒ 4ì‹œê°„ë´‰ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def generate_chart_image(ticker: str, df: pd.DataFrame) -> str:
    """
    ì¶”ì„¸ í•„í„°ë§ í†µê³¼ ì¢…ëª©ì— ëŒ€í•´ì„œë§Œ í˜¸ì¶œë˜ëŠ” ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
    ê°€ê²©Â·ë³´ì¡°ì§€í‘œ(íŒ¨ë„0) / ê±°ë˜ëŸ‰(íŒ¨ë„1) / RSI+MFI(íŒ¨ë„2) 3â€‘ë¶„í• ,
    ë²”ë¡€ëŠ” ìš°ì¸¡ ë°”ê¹¥ì— ë°°ì¹˜í•´ ë³¸ë¬¸ì„ ê°€ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """
    try:
        logger.info(f"ğŸ“Š {ticker} - ì¶”ì„¸ í•„í„°ë§ í†µê³¼ ì¢…ëª© ì°¨íŠ¸ ìƒì„± ì‹œì‘")
        
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} - ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (df is empty or None)")
            return None

        # charts ë””ë ‰í„°ë¦¬ ìƒì„±
        os.makedirs("charts", exist_ok=True)
        chart_path = os.path.join("charts", f"{ticker}.png")

        # Ensure index is DatetimeIndex
        if 'date' in df.columns and not isinstance(df.index, pd.DatetimeIndex):
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
        elif not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index)

        # ===== â¶ ì°¨íŠ¸ì— ì‚¬ìš©í•  ë°ì´í„° ë²”ìœ„ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë™ì  ì¡°ì •) =====
        import psutil
        available_memory_gb = psutil.virtual_memory().available / (1024**3)
        
        # ë©”ëª¨ë¦¬ ìƒí™©ì— ë”°ë¥¸ ë™ì  ë°ì´í„° ë²”ìœ„ ì¡°ì •
        if available_memory_gb > 4.0:
            display_days = 250  # ì¶©ë¶„í•œ ë©”ëª¨ë¦¬: ìµœëŒ€ 1ë…„
        elif available_memory_gb > 2.0:
            display_days = 180  # ë³´í†µ ë©”ëª¨ë¦¬: 6ê°œì›”
        else:
            display_days = 120  # ë‚®ì€ ë©”ëª¨ë¦¬: 4ê°œì›”
            
        df_display = df.tail(display_days)
        if df_display.empty:
            logger.warning(f"âš ï¸ {ticker} - ì°¨íŠ¸ë¥¼ ê·¸ë¦´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
        logger.debug(f"ğŸ” {ticker} ì°¨íŠ¸ ë²”ìœ„: {len(df_display)}ì¼ (ë©”ëª¨ë¦¬: {available_memory_gb:.1f}GB)")

        # ===== [4ë‹¨ê³„: ì ì‘í˜• ì°¨íŠ¸ ìƒì„±] =====
        required_cols = ["ht_trendline", "bb_upper", "bb_middle", "bb_lower",
                         "resistance", "support", "rsi_14", "mfi_14", "pivot", "r1", "r2", "r3", "s1", "s2", "s3"]
        
        # ì´ìš© ê°€ëŠ¥í•œ ì§€í‘œ í™•ì¸
        available_indicators = []
        missing_cols = []
        
        for col in required_cols:
            if col in df_display.columns and not df_display[col].isna().all():
                available_indicators.append(col)
            else:
                missing_cols.append(col)
        
        logger.debug(f"ğŸ” {ticker} ì°¨íŠ¸ ì§€í‘œ í˜„í™©: ì´ìš©ê°€ëŠ¥ {len(available_indicators)}ê°œ, ëˆ„ë½ {len(missing_cols)}ê°œ")
        
        # 4ë‹¨ê³„: ì ì‘í˜• ì°¨íŠ¸ ìƒì„± (ìµœì†Œ 3ê°œ ì§€í‘œë§Œ ìˆìœ¼ë©´ ì°¨íŠ¸ ìƒì„±)
        if len(available_indicators) < 3:
            logger.warning(f"âš ï¸ {ticker} - ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ìµœì†Œ ì§€í‘œ ë¶€ì¡±: {len(available_indicators)}/3 (ëˆ„ë½: {missing_cols})")
            logger.debug(f"{ticker} ë°ì´í„° ì»¬ëŸ¼ ëª©ë¡: {df.columns.tolist()}")
            
            # 3ë‹¨ê³„: í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ - ì§€í‘œ ê³„ì‚° ì™„ë£Œìœ¨ ì¶”ì 
            data_quality_monitor.log_indicator_calculation_quality(ticker, df_display, available_indicators)
            return None
        else:
            logger.info(f"âœ… {ticker} - ì ì‘í˜• ì°¨íŠ¸ ìƒì„± ê°€ëŠ¥: {len(available_indicators)}ê°œ ì§€í‘œ ì´ìš©")
            # 3ë‹¨ê³„: í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ - ì§€í‘œ ê³„ì‚° ì™„ë£Œìœ¨ ì¶”ì 
            data_quality_monitor.log_indicator_calculation_quality(ticker, df_display, available_indicators)

        # ===== â· 4ë‹¨ê³„: ì ì‘í˜• addplot êµ¬ì„± (ì´ìš© ê°€ëŠ¥í•œ ì§€í‘œë§Œ í¬í•¨) =====
        all_indicators = [
            {"name": "HT Trendline", "column": "ht_trendline", "panel": 0, "color": "limegreen", "ls": "--", "lw": 1.5, "zorder": 1},
            {"name": "BB Upper",  "column": "bb_upper",   "panel": 0, "color": "deepskyblue", "ls": "-", "lw": 1, "alpha": 0.3},
            {"name": "BB Middle", "column": "bb_middle",  "panel": 0, "color": "gray",      "ls": "-", "lw": 1, "alpha": 0.3},
            {"name": "BB Lower",  "column": "bb_lower",   "panel": 0, "color": "saddlebrown", "ls": "-", "lw": 1, "alpha": 0.3},
            {"name": "Resistance", "column": "resistance", "panel": 0, "color": "purple", "ls": "-.", "lw": 2},
            {"name": "Support",    "column": "support",    "panel": 0, "color": "magenta",  "ls": "-.", "lw": 2},
            {"name": "RSI 14",     "column": "rsi_14",     "panel": 2, "color": "purple"},
            {"name": "MFI 14",     "column": "mfi_14",     "panel": 2, "color": "deepskyblue"},
        ]

        # ì´ìš© ê°€ëŠ¥í•œ ì§€í‘œë§Œ í•„í„°ë§
        valid_indicators = []
        for ind in all_indicators:
            column = ind["column"]
            if column in available_indicators:
                # ë°ì´í„°ë¥¼ ì¶”ê°€
                ind["data"] = df_display[column]
                valid_indicators.append(ind)
            else:
                logger.debug(f"ğŸ” {ticker} ì§€í‘œ ìŠ¤í‚µ: {ind['name']} (ì»¬ëŸ¼: {column})")

        logger.info(f"âœ… {ticker} ì ì‘í˜• ì°¨íŠ¸: {len(valid_indicators)}/{len(all_indicators)}ê°œ ì§€í‘œ ì‚¬ìš©")

        addplots = []
        for ind in valid_indicators:
            ser = ind["data"]
            if ser is not None and not ser.dropna().empty:
                ap = mpf.make_addplot(
                    ser,
                    panel=ind["panel"],
                    color=ind["color"],
                    linestyle=ind.get("ls", "-"),
                    width=ind.get("lw", 1),
                    alpha=ind.get("alpha", 1),
                    label=ind["name"]          # â† ë²”ë¡€ì— í‘œì‹œë  ì´ë¦„
                )
                addplots.append(ap)

        # ===== â¸ mpf ìŠ¤íƒ€ì¼ =====
        mcolors = mpf.make_marketcolors(up="r", down="b", inherit=True)
        style = mpf.make_mpf_style(marketcolors=mcolors, gridstyle=":", y_on_right=False)

        # ===== â¹ ì°¨íŠ¸ ê·¸ë¦¬ê¸° =====
        # --- Disable scientific notation for volume axis ---
        import matplotlib.ticker as mticker
        fig, axes = mpf.plot(
            df_display,
            type="candle",
            style=style,
            volume=True,
            ylabel="Price (KRW)",
            ylabel_lower="Volume",
            addplot=addplots,
            figsize=(5, 3.5),
            update_width_config=dict(
                candle_width=0.8,        # ëª¸í†µ ê°€ë¡œí­
                candle_linewidth=1.0,    # ëª¸í†µ í…Œë‘ë¦¬ ë‘ê»˜
                volume_width=0.5         # ê±°ë˜ëŸ‰ ë§‰ëŒ€ í­
            ),
            warn_too_much_data=len(df_display)+1,
            returnfig=True,
            show_nontrading=False,
        )
        # Set volume axis to show in M (millions)
        if len(axes) > 1:
            axes[1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{int(x/1_000_000)}M'))

        # ---- remove any legends that mplfinance placed *inside* axes ----
        for ax in axes:
            leg = ax.get_legend()
            if leg is not None:
                leg.remove()

        # === 4ë‹¨ê³„: ì ì‘í˜• Pivot & Support/Resistance ìˆ˜í‰ì„  ===
        last_row = df_display.iloc[-1]
        pivot_levels = [
            ("pivot", "grey", ":"),
            ("r1", "orange", ":"),
            ("r2", "orange", "--"),
            ("r3", "orange", "-."),
            ("s1", "cyan", ":"),
            ("s2", "cyan", "--"),
            ("s3", "cyan", "-."),
        ]
        
        ax_price = axes[0]  # ê°€ê²© íŒ¨ë„
        pivot_count = 0
        
        for name, col, ls in pivot_levels:
            if name in available_indicators and name in last_row and pd.notna(last_row[name]):
                val = last_row[name]
                ax_price.axhline(y=val, color=col, linestyle=ls, linewidth=1, label=name.upper())
                pivot_count += 1
            else:
                logger.debug(f"ğŸ” {ticker} í”¼ë²— ë ˆë²¨ ìŠ¤í‚µ: {name}")
                
        logger.debug(f"ğŸ” {ticker} í”¼ë²— ë ˆë²¨: {pivot_count}/7ê°œ í‘œì‹œ")

        # ===== Remove all internal legend calls on axes (ax1.legend(), ax2.legend(), ax3.legend(), etc.) =====
        # (No ax1.legend(), ax2.legend(), ax3.legend(), or similar calls should be present below.)

        # ===== âº ë²”ë¡€ë¥¼ ì°¨íŠ¸ ì™¸ë¶€ ìš°ì¸¡ì— ë°°ì¹˜ =====
        # ë²”ë¡€ ìœ„ì¹˜: ì°¨íŠ¸ ì˜¤ë¥¸ìª½, ë³¸ë¬¸ ìµœìƒë‹¨ë³´ë‹¤ ì•½ê°„ ì•„ë˜(ìƒ˜í”Œ ì´ë¯¸ì§€ì™€ ìœ ì‚¬)
        fig.subplots_adjust(right=0.82)  # ë³¸ë¬¸ ìš°ì¸¡ ê³µê°„ í™•ë³´

        handles, labels = [], []
        seen = set()

        # Include all lines (e.g., pivot, r1~r3, s1~s3)
        for ax in axes:
            for ln in ax.get_lines():
                lbl = ln.get_label()
                if lbl and not lbl.startswith('_') and lbl not in seen:
                    handles.append(ln)
                    labels.append(lbl)
                    seen.add(lbl)

        # Include addplot indicators (if they were not included already)
        for ap in addplots:
            if hasattr(ap, 'get_label') and callable(ap.get_label):
                lbl = ap.get_label()
                if lbl and not lbl.startswith('_') and lbl not in seen:
                    handles.append(ap)
                    labels.append(lbl)
                    seen.add(lbl)

        fig.legend(
            handles,
            labels,
            loc="upper left",
            bbox_to_anchor=(1.02, 0.92),   # â† y ê°’ì„ 1 â†’ 0.92 ë¡œ ë‚´ë ¤ì„œ ì¡°ê¸ˆ ì•„ë˜ ë°°ì¹˜
            frameon=True,
            fontsize=8
        )
        # Add chart time period text below the x-axis
        fig.text(0.01, 0.01, f'1D Candle | {df_display.index[0].date()} ~ {df_display.index[-1].date()}', fontsize=9)

        # ===== â» ì €ì¥ =====
        plt.tight_layout()
        fig.savefig(chart_path, dpi=100, bbox_inches="tight", pad_inches=0.25)
        plt.close(fig)
        if os.path.exists(chart_path):
            logger.info(f"âœ… {ticker} - í•„í„°ë§ í†µê³¼ ì¢…ëª© ì°¨íŠ¸ ìƒì„± ì™„ë£Œ: {chart_path}")
        else:
            logger.error(f"âŒ {ticker} ì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ ({chart_path})")
        return chart_path

    except Exception as e:
        logger.error(f"âŒ {ticker} ì°¨íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None

def save_dynamic_indicators_to_ohlcv(ticker, df_with_indicators):
    """ë™ì  ì§€í‘œë¥¼ ohlcv í…Œì´ë¸”ì— ì—…ë°ì´íŠ¸"""
    conn = None
    cursor = None
    
    try:
        if df_with_indicators is None or df_with_indicators.empty:
            logger.warning(f"âš ï¸ {ticker} ì—…ë°ì´íŠ¸í•  ë™ì  ì§€í‘œ ë°ì´í„° ì—†ìŒ")
            return False
            
        conn = get_db_connection()
        cursor = conn.cursor()
        
        update_count = 0
        for index, row in df_with_indicators.iterrows():
            from utils import safe_strftime
            date_str = safe_strftime(index, '%Y-%m-%d')
            
            cursor.execute("""
                UPDATE ohlcv SET
                                    macd = %s, macd_signal = %s, macd_histogram = %s,
                rsi_14 = %s, adx = %s, plus_di = %s, minus_di = %s,
                    atr = %s, bb_upper = %s, bb_middle = %s, bb_lower = %s,
                                    volume_20ma = %s, ht_trendline = %s,
                supertrend = %s, supertrend_direction = %s
                WHERE ticker = %s AND date = %s
            """, (
                row.get('macd'), row.get('macd_signal'), row.get('macd_histogram'),
                row.get('rsi_14'), row.get('adx'), row.get('plus_di'), row.get('minus_di'),
                row.get('atr'), row.get('bb_upper'), row.get('bb_middle'), row.get('bb_lower'),
                row.get('volume_20ma'), row.get('ht_trendline'),
                row.get('supertrend'), row.get('supertrend_direction'),
                ticker, date_str
            ))
            
            if cursor.rowcount > 0:
                update_count += 1
        
        conn.commit()
        logger.info(f"âœ… {ticker} ë™ì  ì§€í‘œ ohlcv í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì™„ë£Œ: {update_count}ê°œ ë ˆì½”ë“œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ {ticker} ë™ì  ì§€í‘œ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
        if conn:
            conn.rollback()
        return False
            
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def save_market_data_4h_to_db(ticker, df):
    """
    4ì‹œê°„ë´‰ ì‹œì¥ ë°ì´í„°(ê¸°ìˆ  ì§€í‘œ)ë¥¼ DBì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ì €ì¥í•  í‹°ì»¤
        df (pd.DataFrame): ê¸°ìˆ  ì§€í‘œê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„ (ìµœì‹  1 row)
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  4ì‹œê°„ë´‰ ì‹œì¥ ë°ì´í„° ì—†ìŒ")
            return
            
        # ìµœì‹  ë°ì´í„°ë§Œ ì €ì¥
        latest = df.iloc[-1].copy()
        latest['ticker'] = ticker
        latest['updated_at'] = datetime.now()
        
        # ì°¨íŠ¸ ê²½ë¡œ ì„¤ì •(ë¯¸ì‚¬ìš©)
        #chart_path = f"charts/{ticker}_4h.png"
        #latest['chart_path'] = chart_path
        
        # âš¡ [ì„±ëŠ¥ ìµœì í™”] ì—°ê²° í’€ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
        with get_db_connection_context() as conn:
            with conn.cursor() as cursor:
                # âœ… ê¸°ìˆ  ì§€í‘œ ì»¬ëŸ¼ë§Œ ì„ íƒ (ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆì— ë§ì¶¤)
                indicator_columns = [
                    'ticker', 'price', 
                    # ì´ë™í‰ê· ì„ 
                    'ma_10', 'ma_20', 'ma_50', 'ma_200',
                    # RSI & Stochastic
                    'rsi_14', 'stochastic_k', 'stochastic_d',
                    # MACD
                    'macd', 'macds', 'macdh',
                    # ADX
                    'adx', 'plus_di', 'minus_di',
                    # ë³¼ë¦°ì €ë°´ë“œ
                    'bb_upper', 'bb_middle', 'bb_lower',
                    # CCI
                    'cci',
                    # Supertrend
                    'supertrend', 'supertrend_signal',
                    # í”¼ë²— í¬ì¸íŠ¸
                    'pivot', 'r1', 'r2', 'r3', 's1', 's2', 's3',
                    # í”¼ë³´ë‚˜ì¹˜
                    'fibo_236', 'fibo_382', 'fibo_500', 'fibo_618', 'fibo_786',
                    # ë©”íƒ€ë°ì´í„°
                    'updated_at'
                ]
                
                # ì„ íƒëœ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
                latest_data = {col: latest.get(col) for col in indicator_columns if col in latest}
                
                # ì»¬ëŸ¼ê³¼ ê°’ ì¤€ë¹„
                columns = list(latest_data.keys())
                values = [latest_data[col] if not pd.isna(latest_data[col]) else None for col in columns]
                
                # UPSERT ì¿¼ë¦¬ ìƒì„±
                placeholders = ', '.join(['%s'] * len(columns))
                columns_str = ', '.join(columns)
                update_str = ', '.join([f"{col} = EXCLUDED.{col}" for col in columns if col != 'ticker'])
                
                query = f"""
                    INSERT INTO market_data_4h ({columns_str})
                    VALUES ({placeholders})
                    ON CONFLICT (ticker) DO UPDATE
                    SET {update_str}
                """
                
                cursor.execute(query, values)
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        logger.info(f"âœ… {ticker} 4ì‹œê°„ë´‰ ì‹œì¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ {ticker} 4ì‹œê°„ë´‰ ì‹œì¥ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")

def save_market_data_to_db(ticker, df):
    """
    ì¼ë´‰ ì‹œì¥ ë°ì´í„°ë¥¼ static_indicators í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤ (ìƒˆë¡œìš´ êµ¬í˜„)
    
    Args:
        ticker (str): ì €ì¥í•  í‹°ì»¤
        df (pd.DataFrame): ê¸°ìˆ  ì§€í‘œê°€ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  ì¼ë´‰ ì‹œì¥ ë°ì´í„° ì—†ìŒ")
            return False
            
        # save_static_indicators í•¨ìˆ˜ ìœ„ì„ìœ¼ë¡œ ì™„ì „ ëŒ€ì²´
        logger.info(f"ğŸ”„ {ticker} save_static_indicatorsë¡œ ìœ„ì„")
        
        # ìµœì‹  í–‰ ì¶”ì¶œ
        latest_row = df.iloc[-1]
        
        # DB ì—°ê²° ìƒì„±í•˜ì—¬ save_static_indicators í˜¸ì¶œ
        conn = get_db_connection()
        try:
            return save_static_indicators(conn, ticker, latest_row)
        finally:
            conn.close()
        
    except Exception as e:
        logger.error(f"âŒ {ticker} ì¼ë´‰ ì‹œì¥ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def process_single_ticker(ticker, timeframe: str = '1d', market_data=None):
    """
    ë‹¨ì¼ í‹°ì»¤ì— ëŒ€í•œ í›„ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        ticker (str): ì²˜ë¦¬í•  í‹°ì»¤ ì‹¬ë³¼
        timeframe (str): ë´‰ íƒ€ì… ('1d' ë˜ëŠ” '4h')
        market_data (pd.DataFrame): ì´ë¯¸ ìˆ˜ì§‘ëœ ì‹œì¥ ë°ì´í„° (ì„ íƒì‚¬í•­)
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼
    """
    try:
        if not ticker:
            logger.error("âŒ í‹°ì»¤ê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
            
        # í‹°ì»¤ì—ì„œ 'KRW-' ì ‘ë‘ì–´ ì²˜ë¦¬
        if not ticker.startswith('KRW-'):
            ticker = f"KRW-{ticker}"
            
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬ ì¶”ê°€
        blacklist = load_blacklist()
        if ticker in blacklist:
            logger.info(f"â­ï¸ {ticker}ëŠ” ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆì–´ ì²˜ë¦¬ ê±´ë„ˆëœ€")
            return None
            
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ
        if market_data is None:
            # âš¡ [ì„±ëŠ¥ ìµœì í™”] ì—°ê²° í’€ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
            with get_db_connection_context() as conn:
                if timeframe == '1d':
                    # ì¼ë´‰ì˜ ê²½ìš° static_indicatorsì™€ ohlcv í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
                    query = """
                        SELECT s.*, o.rsi_14, o.macd_histogram, o.bb_upper, o.bb_lower
                        FROM static_indicators s
                        LEFT JOIN (
                            SELECT DISTINCT ON (ticker) ticker, rsi_14, macd_histogram, bb_upper, bb_lower
                            FROM ohlcv 
                            ORDER BY ticker, date DESC
                        ) o ON s.ticker = o.ticker
                        WHERE s.ticker = %s
                    """
                else:
                    # 4ì‹œê°„ë´‰ì˜ ê²½ìš° market_data_4h í…Œì´ë¸” ì‚¬ìš©
                    query = f"SELECT * FROM market_data_4h WHERE ticker = %s"
                
                df = pd.read_sql_query(query, conn, params=(ticker,))
            
            if df.empty:
                logger.warning(f"âš ï¸ {ticker} {timeframe} ë´‰ ì‹œì¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
        else:
            df = market_data
            
        # ë´‰ íƒ€ì…ì— ë”°ë¼ í•„ìˆ˜ ê¸°ìˆ  ì§€í‘œ ì„¤ì •
        if timeframe == '1d':
            required_indicators = {'rsi_14', 'adx', 'mfi_14', 'macd', 'supertrend'}
        else:  # 4h ë´‰ì¸ ê²½ìš° (ì»¬ëŸ¼ëª… ìˆ˜ì •)
            required_indicators = {'rsi_14', 'stochastic_k', 'stochastic_d', 'ma_10', 'ma_20'}
        
        # ì»¬ëŸ¼ëª…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ (ëŒ€ì†Œë¬¸ì ì¼ì¹˜ ì´ìŠˆ ë°©ì§€)
        df_columns_lower = {col.lower() for col in df.columns}
        required_indicators_lower = {ind.lower() for ind in required_indicators}
        
        missing_indicators = required_indicators_lower - df_columns_lower
        
        if missing_indicators:
            logger.warning(f"âš ï¸ {ticker} {timeframe} ë´‰: ê¸°ìˆ ì§€í‘œ ëˆ„ë½ {missing_indicators}")
            return None
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} {timeframe} ë´‰ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def get_ohlcv_4h(ticker, limit=200, force_fetch=False):
    """
    íŠ¹ì • í‹°ì»¤ì˜ 4ì‹œê°„ë´‰ OHLCV ë°ì´í„°ë¥¼ ìµœê·¼ 200ê°œ(ê¸°ë³¸ê°’) ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ì¡°íšŒí•  í‹°ì»¤ (ì˜ˆ: "KRW-BTC")
        limit (int): ì¡°íšŒí•  ìµœê·¼ ìº”ë“¤ ê°œìˆ˜ (ê¸°ë³¸ê°’: 200)
        
    Returns:
        pd.DataFrame: 4ì‹œê°„ë´‰ OHLCV ë°ì´í„°í”„ë ˆì„ (datetime ì¸ë±ìŠ¤)
    """
    try:
        import pyupbit
        latest = get_latest_timestamp(ticker, table='ohlcv_4h')
        now = datetime.now()
        if not force_fetch and latest is not None:
            hours_diff = (now - latest).total_seconds() / 3600
            if hours_diff < limit * 4:
                logger.info(f"â­ï¸ {ticker}: ìµœê·¼ {int(hours_diff)}ì‹œê°„ ë°ì´í„° ì¡´ì¬ - ìˆ˜ì§‘ íŒ¨ìŠ¤")
                return None

        if latest is None:
            logger.info(f"ğŸ†• {ticker} ì‹ ê·œ í‹°ì»¤ - {limit}ê°œ 4ì‹œê°„ë´‰ ìˆ˜ì§‘")
            df = safe_pyupbit_get_ohlcv(ticker, interval="minute240", count=limit)
            if df is not None and not df.empty:
                save_ohlcv_4h_to_db(ticker, df)
            return df

        # í‹°ì»¤ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
        ticker = f"KRW-{ticker}" if not ticker.startswith("KRW-") else ticker

        # 4ì‹œê°„ë´‰ ë°ì´í„° ì¡°íšŒ (ì•ˆì „í•œ API í˜¸ì¶œ)
        df = safe_pyupbit_get_ohlcv(ticker, interval="minute240", count=limit)
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} 4ì‹œê°„ë´‰ ë°ì´í„° ì—†ìŒ")
            return None

        logger.debug(f"âœ… {ticker} 4ì‹œê°„ë´‰ {len(df)}ê°œ ì¡°íšŒ ì™„ë£Œ")
        return df

    except Exception as e:
        logger.error(f"âŒ {ticker} 4ì‹œê°„ë´‰ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def _filter_invalid_ohlcv_data(df, ticker):
    """
    OHLCV ë°ì´í„°ì—ì„œ í’ˆì§ˆ ë¶ˆëŸ‰ ë ˆì½”ë“œë¥¼ í•„í„°ë§
    
    ì œê±° ê¸°ì¤€:
    1. OHLCV ì¤‘ í•˜ë‚˜ë¼ë„ 0ê°’ì¸ ë ˆì½”ë“œ
    2. high < low ë“± ë…¼ë¦¬ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥í•œ ê°’
    3. ê·¹ë‹¨ì  ì´ìƒê°’ (ê°€ê²© ë³€ë™ë¥  > 1000%)
    
    Args:
        df (pd.DataFrame): ì›ë³¸ OHLCV ë°ì´í„°
        ticker (str): í‹°ì»¤ëª… (ë¡œê¹…ìš©)
        
    Returns:
        pd.DataFrame: í•„í„°ë§ëœ OHLCV ë°ì´í„°
    """
    if df is None or df.empty:
        return df
        
    original_len = len(df)
    
    # 1. OHLCV ì¤‘ 0ê°’ ë ˆì½”ë“œ ì œê±°
    zero_mask = (df['open'] == 0) | (df['high'] == 0) | (df['low'] == 0) | (df['close'] == 0)
    zero_count = zero_mask.sum()
    
    if zero_count > 0:
        logger.warning(f"ğŸ”´ {ticker} OHLCV 0ê°’ ë ˆì½”ë“œ {zero_count}ê°œ ì œê±°")
        df = df[~zero_mask]
    
    # 2. ë…¼ë¦¬ì  ë¶ˆê°€ëŠ¥í•œ ê°’ ì œê±° (high < low, close > high, close < low ë“±)
    invalid_logic_mask = (
        (df['high'] < df['low']) |  # high < low
        (df['close'] > df['high']) |  # close > high  
        (df['close'] < df['low']) |  # close < low
        (df['open'] > df['high']) |  # open > high
        (df['open'] < df['low'])     # open < low
    )
    invalid_logic_count = invalid_logic_mask.sum()
    
    if invalid_logic_count > 0:
        logger.warning(f"ğŸ”´ {ticker} ë…¼ë¦¬ì  ì˜¤ë¥˜ ë ˆì½”ë“œ {invalid_logic_count}ê°œ ì œê±°")
        df = df[~invalid_logic_mask]
    
    # 3. ê·¹ë‹¨ì  ê°€ê²© ë³€ë™ ì œê±° (ì „ì¼ ëŒ€ë¹„ 1000% ì´ìƒ ë³€ë™)
    if len(df) > 1:
        price_change_pct = df['close'].pct_change().abs()
        extreme_change_mask = price_change_pct > 10.0  # 1000% ë³€ë™
        extreme_change_count = extreme_change_mask.sum()
        
        if extreme_change_count > 0:
            logger.warning(f"ğŸ”´ {ticker} ê·¹ë‹¨ì  ê°€ê²©ë³€ë™ ë ˆì½”ë“œ {extreme_change_count}ê°œ ì œê±°")
            df = df[~extreme_change_mask]
    
    filtered_len = len(df)
    removed_count = original_len - filtered_len
    
    if removed_count > 0:
        logger.info(f"ğŸ“Š {ticker} ë°ì´í„° í’ˆì§ˆ í•„í„°ë§: {original_len} â†’ {filtered_len}ê°œ ({removed_count}ê°œ ì œê±°)")
    
    return df

def safe_pyupbit_get_ohlcv(ticker, interval="day", count=200, to=None, period=1):
    """
    1ë‹¨ê³„: pyupbit API í˜¸ì¶œ ë°©ì‹ ê·¼ë³¸ ìˆ˜ì •
    
    pyupbit.get_ohlcv()ë¥¼ ì•ˆì „í•˜ê²Œ í˜¸ì¶œí•˜ì—¬ 1970-01-01 ì‘ë‹µì„ ë°©ì§€í•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ì¡°íšŒí•  í‹°ì»¤
        interval (str): ì¡°íšŒ ê°„ê²© (day, minute240 ë“±)
        count (int): ì¡°íšŒí•  ë°ì´í„° ê°œìˆ˜
        to (str): ì¢…ë£Œì¼ (Noneì´ë©´ í˜„ì¬ ë‚ ì§œ ì‚¬ìš©)
        period (int): API ì•ˆì •ì„±ì„ ìœ„í•œ period íŒŒë¼ë¯¸í„°
        
    Returns:
        pd.DataFrame: ì•ˆì „í•˜ê²Œ ìˆ˜ì§‘ëœ OHLCV ë°ì´í„°
    """
    try:
        # 1ë‹¨ê³„: ëª…ì‹œì  ë‚ ì§œ ë²”ìœ„ ì§€ì •ìœ¼ë¡œ 1970-01-01 ë°©ì§€
        if to is None:
            # í˜„ì¬ ë‚ ì§œë¥¼ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ì„¤ì •
            to = datetime.now().strftime("%Y-%m-%d")
            
        logger.debug(f"ğŸ” {ticker} API í˜¸ì¶œ íŒŒë¼ë¯¸í„°:")
        logger.debug(f"   - interval: {interval}")
        logger.debug(f"   - count: {count}")
        logger.debug(f"   - to: {to}")
        logger.debug(f"   - period: {period}")
        
        # pyupbit API í˜¸ì¶œ (ëª¨ë“  íŒŒë¼ë¯¸í„° ëª…ì‹œì  ì§€ì •)
        api_params = {
            'ticker': ticker,
            'interval': interval,
            'count': count,
            'to': to,
            'period': period
        }
        
        df = pyupbit.get_ohlcv(**api_params)
        
        # 3ë‹¨ê³„: API ì‘ë‹µ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
        quality_ok = data_quality_monitor.log_api_response_quality(ticker, df, api_params)
        
        if df is None:
            logger.warning(f"âš ï¸ {ticker} API ì‘ë‹µ None")
            return None
            
        if df.empty:
            logger.warning(f"âš ï¸ {ticker} API ì‘ë‹µ ë¹ˆ DataFrame")
            return df
            
        # API ì‘ë‹µ ì¦‰ì‹œ ì¸ë±ìŠ¤ ìœ íš¨ì„± ê²€ì¦
        logger.debug(f"ğŸ” {ticker} API ì‘ë‹µ ê²€ì¦:")
        logger.debug(f"   - ë°ì´í„° ê°œìˆ˜: {len(df)}")
        logger.debug(f"   - Index íƒ€ì…: {type(df.index)}")
        
        if len(df) > 0:
            first_date = df.index[0]
            last_date = df.index[-1]
            logger.debug(f"   - ì²« ë²ˆì§¸ ë‚ ì§œ: {first_date}")
            logger.debug(f"   - ë§ˆì§€ë§‰ ë‚ ì§œ: {last_date}")
            
            # 1. OHLCV 0ê°’ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° í•„í„°ë§
            original_len = len(df)
            df = _filter_invalid_ohlcv_data(df, ticker)
            filtered_len = len(df)
            
            if original_len != filtered_len:
                logger.warning(f"âš ï¸ {ticker} í’ˆì§ˆ ë¶ˆëŸ‰ ë°ì´í„° ì œê±°: {original_len} â†’ {filtered_len}ê°œ")
            
            # 2. ìµœì†Œ ë°ì´í„° ê°œìˆ˜ í™•ì¸ (ìš”ì²­ëŸ‰ì˜ 80% ë¯¸ë§Œì´ë©´ ì¬ì‹œë„)
            min_required = int(count * 0.8)
            if len(df) < min_required:
                logger.warning(f"âš ï¸ {ticker} ë°ì´í„° ë¶€ì¡±: {len(df)}/{count} (ìµœì†Œ ìš”êµ¬: {min_required})")
                # ì¬ì‹œë„ ë¡œì§ì€ ìƒìœ„ í˜¸ì¶œìì—ì„œ ì²˜ë¦¬
                return df
            
            # 3. 1970-01-01 ì‘ë‹µ ê°ì§€
            if hasattr(df.index, 'year') and len(df) > 0 and df.index[0].year == 1970:
                logger.warning(f"ğŸ” {ticker} API 1970-01-01 ì‘ë‹µ ê°ì§€ë¨")
            else:
                logger.debug(f"âœ… {ticker} API ì‘ë‹µ ë‚ ì§œ ì •ìƒ: {first_date.date()} ~ {last_date.date()}")
        
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} safe_pyupbit_get_ohlcv ì‹¤íŒ¨: {str(e)}")
        return None

def get_ohlcv_d(ticker, interval="day", count=450, force_fetch=False, fetch_latest_only=False):
    """
    450ì¼ì¹˜ OHLCV ë°ì´í„° ìˆ˜ì§‘ - ë¡œì§ ì™„ì „ ì¬ì„¤ê³„ ë²„ì „ + BTC íŠ¹ë³„ ì²˜ë¦¬
    
    ì²˜ë¦¬ ìˆœì„œ:
    1. DBì—ì„œ ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜ í™•ì¸
    2. 450ê°œ ë¯¸ë§Œì´ë©´ ì „ì²´ ì¬ìˆ˜ì§‘
    3. 450ê°œ ì´ìƒì´ë©´ ìµœì‹  ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
    4. BTC ë“± ì£¼ìš” ì½”ì¸ì€ íŠ¹ë³„ ì²˜ë¦¬ (ë” ë§ì€ ë°ì´í„° ìš”ì²­)
    
    Args:
        ticker (str): í‹°ì»¤ ì‹¬ë³¼
        interval (str): ì¡°íšŒ ë‹¨ìœ„ (ê¸°ë³¸ê°’: "day")
        count (int): ì¡°íšŒí•  ë°ì´í„° ê°œìˆ˜ (ê¸°ë³¸ê°’: 450)
        force_fetch (bool): ê°•ì œ ìˆ˜ì§‘ ëª¨ë“œ (ê¸°ë³¸ê°’: False)
        fetch_latest_only (bool): ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘ ëª¨ë“œ (ê¸°ë³¸ê°’: False)
        
    Returns:
        pd.DataFrame: OHLCV ë°ì´í„°
    """
    conn = None
    cursor = None
    
    try:
        if not ticker.startswith("KRW-"):
            ticker = f"KRW-{ticker}"
            
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì²´í¬
        blacklist = load_blacklist()
        if ticker in blacklist:
            logger.info(f"â­ï¸ {ticker}ëŠ” ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆì–´ OHLCV ë°ì´í„° ìˆ˜ì§‘ ê±´ë„ˆëœ€")
            return pd.DataFrame()
        
        # ì£¼ìš” ì½”ì¸ ëª©ë¡ (ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•œ ê²½ìš°)
        major_coins = ["KRW-BTC", "KRW-ETH", "KRW-XRP", "KRW-ADA", "KRW-DOT"]
        is_major_coin = ticker in major_coins
        
        # ì£¼ìš” ì½”ì¸ì€ ë” ë§ì€ ë°ì´í„° ìš”ì²­
        if is_major_coin and count == 450:
            actual_count = 600  # ì£¼ìš” ì½”ì¸ì€ ë” ë§ì´ ìš”ì²­
            logger.info(f"ğŸ” {ticker} ì£¼ìš” ì½”ì¸ â†’ í™•ì¥ ë°ì´í„° ìˆ˜ì§‘ ({actual_count}ê°œ)")
        else:
            actual_count = count
        
        # 1ë‹¨ê³„: DB í˜„í™© í™•ì¸
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT COUNT(*), MIN(date), MAX(date) 
            FROM ohlcv 
            WHERE ticker = %s
        """, (ticker,))
        
        result = cursor.fetchone()
        db_count = result[0] if result else 0
        min_date = result[1] if result else None
        max_date = result[2] if result else None
        
        logger.info(f"ğŸ” {ticker} DB í˜„í™©: {db_count}ê°œ ë ˆì½”ë“œ, ìµœì‹ : {max_date}")
        
        # 2ë‹¨ê³„: ìˆ˜ì§‘ ì „ëµ ê²°ì • - 450ê°œ ë¯¸ë§Œì´ê±°ë‚˜ ê°•ì œ ìˆ˜ì§‘ì´ë©´ ì „ì²´ ì¬ìˆ˜ì§‘
        now = datetime.now()
        
        # ğŸš€ ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘ ëª¨ë“œ (ìƒˆë¡œ ì¶”ê°€)
        if fetch_latest_only:
            logger.info(f"ğŸ”„ {ticker} ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘ ëª¨ë“œ ì‹œì‘")
            
            try:
                # APIì—ì„œ ìµœì‹  1ì¼ ë°ì´í„°ë§Œ ìˆ˜ì§‘
                df = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=1)
                
                if df is not None and not df.empty:
                    logger.info(f"âœ… {ticker} ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ ë ˆì½”ë“œ")
                    
                    # ë‚ ì§œ ë²”ìœ„ ì¶œë ¥
                    from utils import safe_strftime
                    date_str = safe_strftime(df.index[0])
                    logger.info(f"ğŸ“… {ticker} ìµœì‹  ë°ì´í„°: {date_str}")
                    
                    return df
                else:
                    logger.error(f"âŒ {ticker} ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    return pd.DataFrame()
                    
            except Exception as e:
                logger.error(f"âŒ {ticker} ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return pd.DataFrame()
        elif db_count < count or force_fetch:
            # ì „ì²´ ì¬ìˆ˜ì§‘ í•„ìš”
            logger.info(f"ğŸ”„ {ticker} ì „ì²´ ì¬ìˆ˜ì§‘ ì‹œì‘ ({actual_count}ê°œ ëª©í‘œ, í˜„ì¬ DB: {db_count}ê°œ)")
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ì™„ì „ ì¬ìˆ˜ì§‘)
            if db_count > 0:
                cursor.execute("DELETE FROM ohlcv WHERE ticker = %s", (ticker,))
                logger.info(f"ğŸ—‘ï¸ {ticker} ê¸°ì¡´ {db_count}ê°œ ë ˆì½”ë“œ ì‚­ì œ")
            
            # APIì—ì„œ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            df = None
            max_retries = 3
            
            for attempt in range(max_retries):
                try:
                    logger.info(f"ğŸ”„ {ticker} API ìˆ˜ì§‘ ì‹œë„ {attempt + 1}/{max_retries} (count: {actual_count})")
                    
                    # BTC ë“± ì£¼ìš” ì½”ì¸ íŠ¹ë³„ ì²˜ë¦¬
                    if is_major_coin:
                        # ë¶„í•  ìš”ì²­ ì „ëµ
                        if actual_count > 500:
                            logger.info(f"ğŸ”„ {ticker} ë¶„í•  ìš”ì²­ ì „ëµ ì ìš© ({actual_count}ê°œ)")
                            
                            # ì²« ë²ˆì§¸ ìš”ì²­: ìµœê·¼ 500ê°œ (ì•ˆì „í•œ API í˜¸ì¶œ)
                            df1 = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=500)
                            time.sleep(0.2)  # API ì œí•œ íšŒí”¼
                            
                            if df1 is not None and not df1.empty:
                                # ë‘ ë²ˆì§¸ ìš”ì²­: ì´ì „ 200ê°œ (ì¤‘ë³µ ì œê±° ì˜ˆì •)
                                oldest_date = df1.index[0]
                                to_date = oldest_date.strftime("%Y-%m-%d")
                                df2 = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=200, to=to_date)
                                time.sleep(0.2)
                                
                                if df2 is not None and not df2.empty:
                                    # ì¤‘ë³µ ì œê±°í•˜ê³  ë³‘í•©
                                    combined_df = pd.concat([df2, df1])
                                    combined_df = combined_df[~combined_df.index.duplicated(keep='last')]
                                    combined_df = combined_df.sort_index()
                                    
                                    # ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ ìë¥´ê¸°
                                    df = combined_df.tail(actual_count)
                                    logger.info(f"âœ… {ticker} ë¶„í•  ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ (ëª©í‘œ: {actual_count})")
                                else:
                                    df = df1
                                    logger.warning(f"âš ï¸ {ticker} ë‘ ë²ˆì§¸ ë¶„í•  ìš”ì²­ ì‹¤íŒ¨, ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©: {len(df)}ê°œ")
                            else:
                                logger.error(f"âŒ {ticker} ì²« ë²ˆì§¸ ë¶„í•  ìš”ì²­ ì‹¤íŒ¨")
                                df = None
                        else:
                            # ì¼ë°˜ì ì¸ ë‹¨ì¼ ìš”ì²­ (ì•ˆì „í•œ API í˜¸ì¶œ)
                            df = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=actual_count)
                    else:
                        # ì¼ë°˜ ì½”ì¸ì€ ê¸°ì¡´ ë°©ì‹ (ì•ˆì „í•œ API í˜¸ì¶œ)
                        df = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=actual_count)
                    
                    # ìˆ˜ì§‘ ì„±ê³µ ì‹œ ë£¨í”„ íƒˆì¶œ
                    if df is not None and not df.empty:
                        logger.info(f"âœ… {ticker} API ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ ë ˆì½”ë“œ (ì‹œë„: {attempt + 1})")
                        break
                    else:
                        logger.warning(f"âš ï¸ {ticker} API ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ (ì‹œë„: {attempt + 1})")
                        
                except Exception as api_e:
                    logger.warning(f"âš ï¸ {ticker} API ìˆ˜ì§‘ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {str(api_e)}")
                    
                    # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ëŒ€ê¸°
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 2  # 2, 4, 6ì´ˆ ëŒ€ê¸°
                        logger.info(f"â³ {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                        time.sleep(wait_time)
            
            # ìµœì¢… ìˆ˜ì§‘ ê²°ê³¼ í™•ì¸
            if df is None or df.empty:
                logger.error(f"âŒ {ticker} ëª¨ë“  API ìˆ˜ì§‘ ì‹œë„ ì‹¤íŒ¨ ({max_retries}íšŒ)")
                conn.rollback()
                return pd.DataFrame()
            
            logger.info(f"âœ… {ticker} ìµœì¢… API ìˆ˜ì§‘ ì„±ê³µ: {len(df)}ê°œ ë ˆì½”ë“œ")
            
            # ë‚ ì§œ ë²”ìœ„ ì¶œë ¥ (ìˆ˜ì •ë¨)
            if not df.empty:
                from utils import safe_strftime
                start_date = safe_strftime(df.index[0])
                end_date = safe_strftime(df.index[-1])
                logger.info(f"ğŸ“… {ticker} ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")
            
            # DB ì €ì¥ - success ì—¬ë¶€ í™•ì¸
            # ğŸ”§ [1ë‹¨ê³„ ìˆ˜ì •] ì¡°ê¸° ì €ì¥ ë°©ì§€: ì§€í‘œ ê³„ì‚° ì™„ë£Œ í›„ í†µí•© ì €ì¥í•˜ë„ë¡ ìˆ˜ì •
            # save_result = save_ohlcv_to_db(ticker, df)
            # if not save_result:
            #     logger.error(f"âŒ {ticker} DB ì €ì¥ ì‹¤íŒ¨ - ë¹ˆ DataFrame ë°˜í™˜")
            #     conn.rollback()
            #     return pd.DataFrame()  # ì €ì¥ ì‹¤íŒ¨ ì‹œ ë¹ˆ DataFrame ë°˜í™˜
            
            logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ì €ì¥ì€ ì§€í‘œ ê³„ì‚° í›„ ìˆ˜í–‰)")
            
            # ìµœì¢… ê²€ì¦ - DB ì €ì¥ í›„ ê²€ì¦ì€ ì œê±°
            # cursor.execute("SELECT COUNT(*) FROM ohlcv WHERE ticker = %s", (ticker,))
            # final_count = cursor.fetchone()[0]
            # logger.info(f"ğŸ” {ticker} ì €ì¥ ì™„ë£Œ: {final_count}ê°œ ë ˆì½”ë“œ")
            
            conn.commit()
            return df
            
        else:
            # ì¦ë¶„ ì—…ë°ì´íŠ¸ í•„ìš”í•œ ê²½ìš°
            if isinstance(max_date, datetime):
                max_date_obj = max_date.date()
            else:
                max_date_obj = max_date
            
            days_diff = (now.date() - max_date_obj).days if max_date else 999
            
            if days_diff <= 1:
                logger.info(f"â­ï¸ {ticker} ìµœì‹  ë°ì´í„° ({days_diff}ì¼ ì „) - DBì—ì„œ ì¡°íšŒ")
                conn.close()  # DB ì—°ê²° ì¢…ë£Œ
                return get_ohlcv_from_db(ticker, limit=count)
            else:
                logger.info(f"ğŸ”„ {ticker} ì¦ë¶„ ì—…ë°ì´íŠ¸ ({days_diff}ì¼ ì°¨ì´)")
                
                # ìµœê·¼ ë°ì´í„°ë§Œ ìˆ˜ì§‘í•˜ì—¬ ì—…ë°ì´íŠ¸ (ì•ˆì „í•œ API í˜¸ì¶œ)
                update_count = min(days_diff + 5, 100)  # ìµœëŒ€ 100ê°œ
                df_new = safe_pyupbit_get_ohlcv(ticker, interval=interval, count=update_count)
                
                if df_new is not None and not df_new.empty:
                    logger.info(f"âœ… {ticker} ì¦ë¶„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(df_new)}ê°œ (ì €ì¥ì€ ì§€í‘œ ê³„ì‚° í›„ ìˆ˜í–‰)")
                    
                    conn.commit()
                    conn.close()  # DB ì—°ê²° ì¢…ë£Œ
                    
                    logger.info(f"âœ… {ticker} ì¦ë¶„ ë°ì´í„° ë°˜í™˜: {len(df_new)}ê°œ")
                    return df_new
                else:
                    logger.error(f"âŒ {ticker} ì¦ë¶„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                    conn.close()  # DB ì—°ê²° ì¢…ë£Œ
                    return pd.DataFrame()
                    
    except Exception as e:
        logger.error(f"âŒ {ticker} OHLCV ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        if conn:
            conn.rollback()
        return pd.DataFrame()
        
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def get_latest_timestamp(ticker: str, table: str = 'ohlcv') -> Optional[datetime]:
    """
    DBì—ì„œ íŠ¹ì • í‹°ì»¤ì˜ ê°€ì¥ ìµœê·¼ timestampë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    Args:
        ticker (str): ì¡°íšŒí•  í‹°ì»¤ ì‹¬ë³¼ (ì˜ˆ: 'KRW-BTC')
        table (str): ì¡°íšŒí•  í…Œì´ë¸”ëª… (ê¸°ë³¸ê°’: 'ohlcv')

    Returns:
        Optional[datetime]: ê°€ì¥ ìµœê·¼ timestamp. ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° None ë°˜í™˜
    """
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        if table == 'ohlcv':
            cursor.execute("""
                SELECT MAX(date) FROM ohlcv WHERE ticker = %s
            """, (ticker,))
        elif table == 'ohlcv_4h':
            cursor.execute("""
                SELECT MAX(date) FROM ohlcv_4h WHERE ticker = %s
            """, (ticker,))
        else:
            logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸”: {table}")
            return None

        result = cursor.fetchone()
        return result[0] if result and result[0] else None

    except Exception as e:
        logger.error(f"âŒ {ticker} ìµœê·¼ timestamp ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

def get_ohlcv_from_db(ticker: str, limit: int = 450) -> pd.DataFrame:
    """DBì—ì„œ OHLCV ë°ì´í„°ë¥¼ ìµœê·¼ ë‚ ì§œìˆœìœ¼ë¡œ ì •í™•íˆ ì¡°íšŒ"""
    conn = None
    try:
        conn = get_db_connection()
        
        # ìµœê·¼ ë°ì´í„°ë¶€í„° ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì¡°íšŒ í›„ ë‹¤ì‹œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
        query = """
        SELECT date, open, high, low, close, volume
        FROM (
            SELECT date, open, high, low, close, volume
            FROM ohlcv 
            WHERE ticker = %s 
            ORDER BY date DESC 
            LIMIT %s
        ) subquery
        ORDER BY date ASC
        """
        
        df = pd.read_sql_query(query, conn, params=[ticker, limit])
        
        if not df.empty:
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
            
            # ê²€ì¦ ë¡œê·¸
            from utils import safe_strftime
            start_date = safe_strftime(df.index[0])
            end_date = safe_strftime(df.index[-1])
            logger.info(f"ğŸ” {ticker} DB ì¡°íšŒ ì™„ë£Œ: {len(df)}ê°œ ({start_date} ~ {end_date})")
            
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} DB ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        return pd.DataFrame()
        
    finally:
        if conn:
            conn.close()

def save_chart_image(ticker: str, df: pd.DataFrame, indicators: list = None):
    """
    OHLCV ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¨íŠ¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    Args:
        ticker (str): í‹°ì»¤ ì‹¬ë³¼ (ì˜ˆ: "KRW-BTC")
        df (pd.DataFrame): OHLCV ë°ì´í„°í”„ë ˆì„ (DatetimeIndex, open, high, low, close, volume ì»¬ëŸ¼ í¬í•¨)
        indicators (list, optional): ì°¨íŠ¸ì— ì¶”ê°€í•  ì§€í‘œ ì •ë³´ ë¦¬ìŠ¤íŠ¸. ê° ìš”ì†ŒëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ (ì˜ˆ: {'name': 'MA20', 'data': df['ma20'], 'panel': 0, 'color': 'blue'})
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} - ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # charts ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
        if not os.path.exists("charts"):
            os.makedirs("charts")

        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        chart_file_path = os.path.join("charts", f"{ticker}.png")

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        mc = mpf.make_marketcolors(up='r', down='b', inherit=True)
        s = mpf.make_mpf_style(marketcolors=mc, gridstyle=':', y_on_right=True)

        # ì¶”ê°€ í”Œë¡¯ ì„¤ì •
        addplot = []
        if indicators:
            for indicator_info in indicators: # ë³€ìˆ˜ëª… ë³€ê²½ indicator -> indicator_info
                # make_addplot í˜¸ì¶œ ì‹œ Seriesê°€ ì•„ë‹Œ ì‹¤ì œ ë°ì´í„°(numpy array ë“±)ë¥¼ ì „ë‹¬í•´ì•¼ í•  ìˆ˜ ìˆìŒ
                # ë˜í•œ, panel ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥¸ì§€, í•´ë‹¹ panelì— ë§ëŠ” ë°ì´í„° íƒ€ì…ì¸ì§€ í™•ì¸ í•„ìš”
                try:
                    plot_data = indicator_info['data']
                    if isinstance(plot_data, pd.Series):
                        # NaN ê°’ì„ ê°€ì§„ í–‰ì€ ì œì™¸í•˜ê³  addplotì— ì¶”ê°€
                        valid_data = plot_data.dropna()
                        if not valid_data.empty:
                             addplot.append(mpf.make_addplot(valid_data, panel=indicator_info.get('panel', 0), color=indicator_info.get('color', 'blue'), ylabel=indicator_info.get('name', '')))
                        else:
                            logger.warning(f"âš ï¸ {ticker} - ì§€í‘œ '{indicator_info.get('name')}' ë°ì´í„°ê°€ ëª¨ë‘ NaNì´ê±°ë‚˜ ë¹„ì–´ìˆì–´ ì°¨íŠ¸ì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    elif plot_data is not None: # Seriesê°€ ì•„ë‹Œ ë‹¤ë¥¸ íƒ€ì…ì˜ ë°ì´í„°ì¼ ê²½ìš° (numpy array ë“±)
                         addplot.append(mpf.make_addplot(plot_data, panel=indicator_info.get('panel', 0), color=indicator_info.get('color', 'blue'), ylabel=indicator_info.get('name', '')))
                    else:
                        logger.warning(f"âš ï¸ {ticker} - ì§€í‘œ '{indicator_info.get('name')}' ë°ì´í„°ê°€ Noneì´ì–´ì„œ ì°¨íŠ¸ì— ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                except Exception as ap_err:
                    logger.error(f"âŒ {ticker} - ì§€í‘œ '{indicator_info.get('name')}' ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {ap_err}")


        # ìµœê·¼ 100ì¼ ë°ì´í„°ë§Œ ì‚¬ìš© (ë„ˆë¬´ ë§ìœ¼ë©´ ì°¨íŠ¸ê°€ ë³µì¡í•´ì§)
        df_recent = df.tail(100)
        if df_recent.empty:
            logger.warning(f"âš ï¸ {ticker} - ìµœê·¼ 100ì¼ ë°ì´í„°ê°€ ì—†ì–´ ì°¨íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìº”ë“¤ìŠ¤í‹± ì°¨íŠ¸ ìƒì„± ë° ì €ì¥
        plot_kwargs = {
            'type': 'candle',
            'style': s,
            'title': f'{ticker} Daily Chart',
            'ylabel': 'Price (KRW)',
            'volume': True,
            'ylabel_lower': 'Volume',
            'figsize': (15, 7),
            'savefig': dict(fname=chart_file_path, dpi=100, pad_inches=0.25),
            'show_nontrading': False
        }
        
        # addplotì´ ìˆì„ ë•Œë§Œ ì¶”ê°€
        if addplot:
            plot_kwargs['addplot'] = addplot
            
        mpf.plot(df_recent, **plot_kwargs)
        logger.info(f"âœ… {ticker} ì°¨íŠ¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {chart_file_path}")

    except Exception as e:
        logger.error(f"âŒ {ticker} ì°¨íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ Traceback ë¡œê¹…
        import traceback
        logger.error(traceback.format_exc())

def save_ohlcv_4h_to_db(ticker: str, df: pd.DataFrame):
    """
    4ì‹œê°„ë´‰ OHLCV ë°ì´í„°ë¥¼ ohlcv_4h í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ì €ì¥í•  í‹°ì»¤ ì‹¬ë³¼
        df (pd.DataFrame): ì €ì¥í•  4ì‹œê°„ë´‰ OHLCV ë°ì´í„°í”„ë ˆì„
    """
    try:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  4ì‹œê°„ë´‰ OHLCV ë°ì´í„° ì—†ìŒ")
            return False
            
        # âš¡ [ì„±ëŠ¥ ìµœì í™”] ì—°ê²° í’€ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
        with get_db_connection_context() as conn:
            with conn.cursor() as cursor:
                # ë°ì´í„° ì €ì¥
                for index, row in df.iterrows():
                    # ì•ˆì „í•œ ë‚ ì§œ ë³€í™˜
                    from utils import safe_strftime
                    date_str = safe_strftime(index, '%Y-%m-%d %H:%M:%S')
                        
                    cursor.execute("""
                        INSERT INTO ohlcv_4h (ticker, date, open, high, low, close, volume)
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                        ON CONFLICT (ticker, date) DO UPDATE
                        SET open = EXCLUDED.open,
                            high = EXCLUDED.high,
                            low = EXCLUDED.low,
                            close = EXCLUDED.close,
                            volume = EXCLUDED.volume
                    """, (
                        ticker,
                        date_str,
                        row['open'],
                        row['high'],
                        row['low'],
                        row['close'],
                        row['volume']
                    ))
                # ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ê°€ ìë™ìœ¼ë¡œ commit ì²˜ë¦¬
        
        logger.info(f"âœ… {ticker} 4ì‹œê°„ë´‰ OHLCV ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ {ticker} 4ì‹œê°„ë´‰ OHLCV ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

# ì¶”ì„¸ ë¶„ì„ ì§€í‘œ ë¶„ë¥˜ (configì—ì„œ ê°€ì ¸ì˜´)
# ESSENTIAL_TREND_INDICATORSëŠ” config.pyì—ì„œ importë¨

def convert_supertrend_to_signal(close_price, supertrend_value):
    """Supertrend ê°’ì„ bull/bear ì‹ í˜¸ë¡œ ë³€í™˜ (1.0: bull, 0.0: bear, 0.5: neutral)"""
    if pd.isna(supertrend_value) or pd.isna(close_price):
        return None
    
    # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] ë¬¸ìì—´ ê°’ ì²˜ë¦¬ ì¶”ê°€
    if isinstance(supertrend_value, str):
        if supertrend_value.lower() == 'bull':
            return 1.0
        elif supertrend_value.lower() == 'bear':
            return 0.0
        elif supertrend_value.lower() == 'neutral':
            return 0.5
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ìì—´ì€ ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬
            return 0.5
    
    # ìˆ˜ì¹˜í˜• ê°’ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§)
    if isinstance(supertrend_value, (int, float)):
        if supertrend_value == 1.0:
            return 1.0  # bull
        elif supertrend_value == 0.0:
            return 0.0  # bear
        elif supertrend_value == 0.5:
            return 0.5  # neutral
        else:
            # ê¸°ì¡´ ë¡œì§: ê°€ê²©ê³¼ ë¹„êµ
            return 1.0 if close_price > supertrend_value else 0.0
    
    return 0.5  # ê¸°ë³¸ê°’ì€ ì¤‘ë¦½

def validate_db_schema_consistency():
    """
    DB ìŠ¤í‚¤ë§ˆì™€ ì½”ë“œ ê°„ ì¼ê´€ì„±ì„ ì²´í¬í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # static_indicators í…Œì´ë¸”ì˜ ì‹¤ì œ ì»¬ëŸ¼ ì¡°íšŒ
        cursor.execute("""
            SELECT column_name, data_type 
            FROM information_schema.columns 
            WHERE table_name = 'static_indicators' 
            ORDER BY ordinal_position
        """)
        db_columns = {row[0]: row[1] for row in cursor.fetchall()}
        
        # ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ëŠ” static_columnsì™€ ë¹„êµ
        expected_static_columns = [
            'ticker', '', 'nvt_relative', 'volume_change_7_30', 'price', 
            'high_60', 'low_60', 'pivot', 's1', 'r1', 
            'resistance', 'support', 'atr', 'adx', 'supertrend_signal', 'updated_at'
        ]
        
        # ëˆ„ë½ëœ ì»¬ëŸ¼ ì²´í¬
        missing_columns = []
        for col in expected_static_columns:
            if col not in db_columns:
                missing_columns.append(col)
        
        # ì¶”ê°€ ì»¬ëŸ¼ ì²´í¬ (DBì—ëŠ” ìˆì§€ë§Œ ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì»¬ëŸ¼)
        extra_columns = []
        for col in db_columns:
            if col not in expected_static_columns:
                extra_columns.append(col)
        
        # ê²°ê³¼ ë³´ê³ 
        logger.info(f"ğŸ” DB ìŠ¤í‚¤ë§ˆ ì¼ê´€ì„± ê²€ì¦ ê²°ê³¼:")
        logger.info(f"   - DB í…Œì´ë¸” ì»¬ëŸ¼ ìˆ˜: {len(db_columns)}")
        logger.info(f"   - ì½”ë“œ ì˜ˆìƒ ì»¬ëŸ¼ ìˆ˜: {len(expected_static_columns)}")
        
        if missing_columns:
            logger.error(f"âŒ DBì— ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}")
            return False
        else:
            logger.info(f"âœ… ëª¨ë“  í•„ìˆ˜ ì»¬ëŸ¼ì´ DBì— ì¡´ì¬")
        
        if extra_columns:
            logger.warning(f"âš ï¸ ì½”ë“œì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” DB ì»¬ëŸ¼: {extra_columns}")
        
        # ohlcv í…Œì´ë¸” ë™ì  ì§€í‘œ ì»¬ëŸ¼ë„ ê²€ì¦
        cursor.execute("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = 'ohlcv' 
            AND column_name IN ('fibo_618', 'fibo_382', 'ht_trendline', 'ma_50', 'ma_200', 'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low', 'macd_histogram', 'rsi_14', 'volume_20ma')
        """)
        dynamic_columns = [row[0] for row in cursor.fetchall()]
        
        expected_dynamic_columns = [
            'fibo_618', 'fibo_382', 'ht_trendline', 'ma_50', 'ma_200', 
            'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low', 
            'macd_histogram', 'rsi_14', 'volume_20ma'
        ]
        
        missing_dynamic = [col for col in expected_dynamic_columns if col not in dynamic_columns]
        
        if missing_dynamic:
            logger.error(f"âŒ ohlcv í…Œì´ë¸”ì— ëˆ„ë½ëœ ë™ì  ì§€í‘œ ì»¬ëŸ¼: {missing_dynamic}")
            return False
        else:
            logger.info(f"âœ… ohlcv í…Œì´ë¸”ì˜ ëª¨ë“  ë™ì  ì§€í‘œ ì»¬ëŸ¼ ì¡´ì¬: {len(dynamic_columns)}ê°œ")
        
        return True
                
    except Exception as e:
        logger.error(f"âŒ DB ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def calculate_unified_indicators(df, ticker="Unknown"):
    """
    ìµœì í™”ëœ í†µí•© ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ (ì„±ëŠ¥ ìµœì í™” ë° ì˜ì¡´ì„± ê´€ë¦¬ ê°•í™”)
    
    ğŸ¯ ì£¼ìš” ìµœì í™” ì‚¬í•­:
    1. ì§€í‘œ ê³„ì‚° ìˆœì„œ ìµœì í™” ë° ì˜ì¡´ì„± ê´€ë¦¬
    2. ë°ì´í„° ê¸¸ì´ë³„ ì§€í‘œ ê·¸ë£¹í•‘ ë° ì¡°ê±´ë¶€ ê³„ì‚°  
    3. ì„±ëŠ¥ ìµœì í™” ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œì–´
    4. ê³„ì‚° ì‹¤íŒ¨ ì‹œ ìš°ì•„í•œ ì„±ëŠ¥ ì €í•˜(graceful degradation)
    
    ğŸ“Š ë‹¨ê³„ë³„ ê³„ì‚° ê·¸ë£¹:
    - 1ë‹¨ê³„: ì´ë™í‰ê· ì„ , ê¸°ë³¸ ì˜¤ì‹¤ë ˆì´í„° (ì˜ì¡´ì„± ì—†ìŒ)
    - 2ë‹¨ê³„: MACD, ë³¼ë¦°ì €ë°´ë“œ (ì¤‘ê°„ ë³µì¡ë„)  
    - 3ë‹¨ê³„: í”¼ë³´ë‚˜ì¹˜, í”¼ë²— í¬ì¸íŠ¸ (ë³µì¡í•œ ê³„ì‚°)
    
    ğŸ”„ ì„±ëŠ¥ ê°œì„ :
    - ë°ì´í„° ê¸¸ì´ë³„ ê³„ì‚° ê°€ëŠ¥ ì§€í‘œ ê·¸ë£¹í•‘
    - ë¹ ë¥¸ ê³„ì‚° ì§€í‘œ ìš°ì„  ì²˜ë¦¬
    - ê³„ì‚° ì‹¤íŒ¨ ì‹œì—ë„ ì›ë³¸ ë°ì´í„° ë°˜í™˜ ë³´ì¥
    """
    try:
        data_length = len(df)
        logger.info(f"ğŸ”„ ì§€í‘œ ê³„ì‚° ì‹œì‘: {data_length}ê°œ ë ˆì½”ë“œ")
        
        # 1ë‹¨ê³„: ë°ì´í„° ê¸¸ì´ë³„ ê³„ì‚° ê°€ëŠ¥ ì§€í‘œ ê·¸ë£¹í•‘
        if data_length < 14:
            logger.warning("âš ï¸ ë°ì´í„° ë¶€ì¡±: ê¸°ë³¸ ì§€í‘œë§Œ ê³„ì‚°")
            return df
        
        from utils import get_safe_ohlcv_columns
        available_columns = get_safe_ohlcv_columns()
        
        logger.info(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ohlcv ì»¬ëŸ¼: {len(available_columns)}ê°œ")
        df_result = df.copy()
        calculated_indicators = []
        
        # 2ë‹¨ê³„: ë¹ ë¥¸ ê³„ì‚° ì§€í‘œ ìš°ì„  ì²˜ë¦¬ (ì˜ì¡´ì„± ì—†ìŒ)
        logger.info("ğŸ”„ 1ì°¨ ì§€í‘œ ê³„ì‚°: ì´ë™í‰ê· ì„ , ê¸°ë³¸ ì˜¤ì‹¤ë ˆì´í„°")
        
        # MA ê³„ì‚° (ê°€ì¥ ê¸°ë³¸)
        if data_length >= 20:
            try:
                df_result['ma_20'] = ta.sma(df_result['close'], length=20)
                ma20_valid = (~df_result['ma_20'].isnull()).sum()
                logger.info(f"  âœ… MA20: {ma20_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('ma_20')
            except Exception as e:
                logger.warning(f"  âŒ MA20 ê³„ì‚° ì‹¤íŒ¨: {e}")
                
        if data_length >= 50 and 'ma_50' in available_columns:
            try:
                df_result['ma_50'] = ta.sma(df_result['close'], length=50)
                ma50_valid = (~df_result['ma_50'].isnull()).sum()
                logger.info(f"  âœ… MA50: {ma50_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('ma_50')
            except Exception as e:
                logger.warning(f"  âŒ MA50 ê³„ì‚° ì‹¤íŒ¨: {e}")
                
        if data_length >= 200 and 'ma_200' in available_columns:
            try:
                df_result['ma_200'] = ta.sma(df_result['close'], length=200)
                ma200_valid = (~df_result['ma_200'].isnull()).sum()
                logger.info(f"  âœ… MA200: {ma200_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('ma_200')
            except Exception as e:
                logger.warning(f"  âŒ MA200 ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # RSI ê³„ì‚° (14ì¼)
        if data_length >= 14 and 'rsi_14' in available_columns:
            try:
                df_result['rsi_14'] = ta.rsi(df_result['close'], length=14)
                rsi_valid = (~df_result['rsi_14'].isnull()).sum()
                logger.info(f"  âœ… RSI14: {rsi_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('rsi_14')
            except Exception as e:
                logger.warning(f"  âŒ RSI14 ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # ê±°ë˜ëŸ‰ 20ì¼ ì´ë™í‰ê· 
        if data_length >= 20 and 'volume_20ma' in available_columns:
            try:
                df_result['volume_20ma'] = df_result['volume'].rolling(window=20).mean()
                vol_valid = (~df_result['volume_20ma'].isnull()).sum()
                logger.info(f"  âœ… Volume20MA: {vol_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('volume_20ma')
            except Exception as e:
                logger.warning(f"  âŒ Volume20MA ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # Volume Ratio (í˜„ì¬ ê±°ë˜ëŸ‰ / 20ì¼ í‰ê·  ê±°ë˜ëŸ‰)
        if data_length >= 20:
            try:
                df_result['volume_ratio'] = df_result['volume'] / df_result['volume'].rolling(window=20).mean()
                vol_ratio_valid = (~df_result['volume_ratio'].isnull()).sum()
                logger.info(f"  âœ… Volume Ratio: {vol_ratio_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('volume_ratio')
            except Exception as e:
                logger.warning(f"  âŒ Volume Ratio ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # 3ë‹¨ê³„: ì¤‘ê°„ ë³µì¡ë„ ì§€í‘œ (2ì°¨ ì˜ì¡´ì„±)
        logger.info("ğŸ”„ 2ì°¨ ì§€í‘œ ê³„ì‚°: MACD, ë³¼ë¦°ì €ë°´ë“œ")
        
        # MACD (26ì¼ í•„ìš”)
        if data_length >= 34 and 'macd_histogram' in available_columns:
            try:
                macd = ta.macd(df_result['close'])
                df_result['macd_histogram'] = macd['MACDh_12_26_9']
                macd_valid = (~df_result['macd_histogram'].isnull()).sum()
                logger.info(f"  âœ… MACD: {macd_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('macd_histogram')
            except Exception as e:
                logger.warning(f"  âŒ MACD ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # ë³¼ë¦°ì €ë°´ë“œ (20ì¼)
        if data_length >= 20:
            if 'bb_upper' in available_columns and 'bb_lower' in available_columns:
                try:
                    bb = ta.bbands(df_result['close'], length=20)
                    df_result['bb_upper'] = bb['BBU_20_2.0']
                    df_result['bb_lower'] = bb['BBL_20_2.0']
                    bb_valid = (~df_result['bb_upper'].isnull()).sum()
                    logger.info(f"  âœ… ë³¼ë¦°ì €ë°´ë“œ: {bb_valid}ê°œ ìœ íš¨ê°’")
                    calculated_indicators.extend(['bb_upper', 'bb_lower'])
                except Exception as e:
                    logger.warning(f"  âŒ ë³¼ë¦°ì €ë°´ë“œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # Donchian Channel (20ì¼)
        if data_length >= 20:
            if 'donchian_high' in available_columns and 'donchian_low' in available_columns:
                try:
                    df_result['donchian_high'] = df_result['high'].rolling(window=20).max()
                    df_result['donchian_low'] = df_result['low'].rolling(window=20).min()
                    donchian_valid = (~df_result['donchian_high'].isnull()).sum()
                    logger.info(f"  âœ… Donchian Channel: {donchian_valid}ê°œ ìœ íš¨ê°’")
                    calculated_indicators.extend(['donchian_high', 'donchian_low'])
                except Exception as e:
                    logger.warning(f"  âŒ Donchian Channel ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # Stochastic K & D
        if data_length >= 14:
            if 'stoch_k' in available_columns and 'stoch_d' in available_columns:
                try:
                    stoch = ta.stoch(df_result['high'], df_result['low'], df_result['close'], k=14, d=3)
                    df_result['stoch_k'] = stoch['STOCHk_14_3_3']
                    df_result['stoch_d'] = stoch['STOCHd_14_3_3']
                    stoch_k_valid = (~df_result['stoch_k'].isnull()).sum()
                    logger.info(f"  âœ… Stochastic: {stoch_k_valid}ê°œ ìœ íš¨ê°’")
                    calculated_indicators.extend(['stoch_k', 'stoch_d'])
                except Exception as e:
                    logger.warning(f"  âŒ Stochastic ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # CCI (20ì¼)
        if data_length >= 20 and 'cci' in available_columns:
            try:
                df_result['cci'] = ta.cci(df_result['high'], df_result['low'], df_result['close'], length=20)
                cci_valid = (~df_result['cci'].isnull()).sum()
                logger.info(f"  âœ… CCI: {cci_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('cci')
            except Exception as e:
                logger.warning(f"  âŒ CCI ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # 4ë‹¨ê³„: ë³µì¡í•œ ê³„ì‚° ì§€í‘œ (í”¼ë³´ë‚˜ì¹˜, í”¼ë²—)
        logger.info("ğŸ”„ 3ì°¨ ì§€í‘œ ê³„ì‚°: í”¼ë³´ë‚˜ì¹˜, í”¼ë²— í¬ì¸íŠ¸")
        
        # í”¼ë²— í¬ì¸íŠ¸ (ë‹¹ì¼ ê³„ì‚°)
        try:
            df_result['pivot'] = (df_result['high'] + df_result['low'] + df_result['close']) / 3
            df_result['r1'] = 2 * df_result['pivot'] - df_result['low']
            df_result['s1'] = 2 * df_result['pivot'] - df_result['high']
            
            pivot_valid = (~df_result['pivot'].isnull()).sum()
            logger.info(f"  âœ… í”¼ë²— í¬ì¸íŠ¸: {pivot_valid}ê°œ ìœ íš¨ê°’")
        except Exception as e:
            logger.warning(f"  âŒ í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ (20ì¼ ìŠ¤ìœ™ ê¸°ì¤€)
        if data_length >= 20:
            if 'fibo_618' in available_columns and 'fibo_382' in available_columns:
                try:
                    swing_high = df_result['high'].rolling(20).max()
                    swing_low = df_result['low'].rolling(20).min()
                    fib_range = swing_high - swing_low
                    
                    df_result['fibo_618'] = swing_low + fib_range * 0.618
                    df_result['fibo_382'] = swing_low + fib_range * 0.382
                    
                    fibo_618_valid = (~df_result['fibo_618'].isnull()).sum()
                    logger.info(f"  âœ… í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨: {fibo_618_valid}ê°œ ìœ íš¨ê°’")
                    calculated_indicators.extend(['fibo_618', 'fibo_382'])
                except Exception as e:
                    logger.warning(f"  âŒ í”¼ë³´ë‚˜ì¹˜ ë ˆë²¨ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # Hilbert Transform Trendline (pandas-ta EMAë¡œ ëŒ€ì²´)
        if data_length >= 21 and 'ht_trendline' in available_columns:
            try:
                df_result['ht_trendline'] = ta.ema(df_result['close'], length=21)
                ht_valid = (~df_result['ht_trendline'].isnull()).sum()
                logger.info(f"  âœ… HT Trendline (EMA21): {ht_valid}ê°œ ìœ íš¨ê°’")
                calculated_indicators.append('ht_trendline')
            except Exception as e:
                logger.warning(f"  âŒ HT Trendline ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        # 5ë‹¨ê³„: ê³„ì‚° ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
        calculated_count = 0
        for col in available_columns:
            if col in df_result.columns:
                valid_count = df_result[col].notna().sum()
                if valid_count > 0:
                    calculated_count += 1
                    logger.debug(f"  âœ… {col}: {valid_count}ê°œ ìœ íš¨ê°’")
        
        # 6ë‹¨ê³„: ì •ì  ì§€í‘œ ê³„ì‚° (ìƒˆë¡œ ì¶”ê°€)
        logger.info("ğŸ”„ 4ì°¨ ì§€í‘œ ê³„ì‚°: ì •ì  ì§€í‘œ (adx, volume_change ë“±)")
        try:
            static_indicators = calculate_static_indicators(df_result)
            if static_indicators is not None:
                # ì •ì  ì§€í‘œë¥¼ DataFrameì— ì¶”ê°€
                for col in static_indicators.columns:
                    if col not in df_result.columns:  # ì¤‘ë³µ ë°©ì§€
                        df_result[col] = static_indicators[col]
                        calculated_indicators.append(col)
                static_count = len(static_indicators.columns)
                logger.info(f"  âœ… ì •ì  ì§€í‘œ {static_count}ê°œ ê³„ì‚° ì™„ë£Œ")
            else:
                logger.warning("  âš ï¸ ì •ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨")
        except Exception as e:
            logger.warning(f"  âŒ ì •ì  ì§€í‘œ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")

        # 7ë‹¨ê³„: ìŠ¤ëª°ìº¡ ì½”ì¸ ì •ë°€ë„ ë³´ì¡´ (ì†Œìˆ˜ì  ì œí•œ ì œê±°)
        logger.info("ğŸ”¢ ìŠ¤ëª°ìº¡ ì½”ì¸ ì •ë°€ë„ ë³´ì¡´ - ì†Œìˆ˜ì  ì œí•œ ì œê±°")
        
        # OHLCV ê¸°ë³¸ ë°ì´í„° ê²€ì¦ (ì†Œìˆ˜ì  ì œí•œ ì—†ìŒ)
        ohlcv_columns = ['open', 'high', 'low', 'close', 'volume']
        for col in ohlcv_columns:
            if col in df_result.columns:
                if col == 'volume':
                    # ê±°ë˜ëŸ‰ì€ ì •ìˆ˜ë¡œ ë³€í™˜
                    df_result[col] = df_result[col].round(0).astype('int64')
                    logger.debug(f"  âœ… {col}: ì •ìˆ˜ ë³€í™˜ ì™„ë£Œ")
                else:
                    # ğŸ“ ê°€ê²© ë°ì´í„° ê²€ì¦ (ì†Œìˆ˜ì  ì œí•œ ì—†ìŒ - ìŠ¤ëª°ìº¡ ì½”ì¸ ì§€ì›)
                    if df_result[col].isna().any():
                        logger.warning(f"  âš ï¸ {col}: NaN ê°’ í¬í•¨ë¨")
                    logger.debug(f"  âœ… {col}: ë°ì´í„° ê²€ì¦ í†µê³¼ (ì •ë°€ë„ ë³´ì¡´)")
        
        # ë™ì  ì§€í‘œ ì»¬ëŸ¼ ëª©ë¡
        dynamic_indicators = [
            'rsi_14', 'macd_histogram', 'ma_50', 'ma_200',
            'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low',
            'fibo_618', 'fibo_382', 'ht_trendline', 'volume_20ma',
            'stoch_k', 'stoch_d', 'cci'
        ]
        
        # ğŸ”§ [3ìˆœìœ„ ê°œì„ ] NaN ê°’ ì²˜ë¦¬ ê°•í™” - ì§€ëŠ¥í˜• ëŒ€ì²´ ë¡œì§ ì ìš©
        for indicator in dynamic_indicators:
            if indicator in df_result.columns:
                # NaN ê°’ ê°œìˆ˜ í™•ì¸
                nan_count = df_result[indicator].isna().sum()
                total_count = len(df_result[indicator])
                valid_count = total_count - nan_count
                
                if nan_count > 0:
                    logger.info(f"ğŸ”§ {indicator}: NaN ê°’ {nan_count}ê°œ ë°œê²¬, ì§€ëŠ¥í˜• ëŒ€ì²´ ì²˜ë¦¬ ì‹œì‘")
                    
                    # ì§€í‘œë³„ íŠ¹í™” ëŒ€ì²´ ë¡œì§ ì ìš©
                    df_result = _apply_intelligent_nan_replacement(df_result, indicator, ticker)
                    
                    # ëŒ€ì²´ í›„ ì¬ê²€ì¦
                    final_nan_count = df_result[indicator].isna().sum()
                    if final_nan_count == 0:
                        logger.info(f"âœ… {indicator}: NaN ê°’ ëŒ€ì²´ ì™„ë£Œ ({nan_count}ê°œ â†’ 0ê°œ)")
                    else:
                        logger.warning(f"âš ï¸ {indicator}: ì¼ë¶€ NaN ê°’ ë‚¨ìŒ ({nan_count}ê°œ â†’ {final_nan_count}ê°œ)")
                else:
                    logger.debug(f"âœ… {indicator}: {valid_count}ê°œ ìœ íš¨ ê°’ í™•ì¸")
        
        logger.info(f"âœ… ì§€í‘œ ê³„ì‚° ì™„ë£Œ: {calculated_count}ê°œ ì§€í‘œ")
        logger.info(f"ğŸ“Š ê³„ì‚°ëœ ì§€í‘œ ëª©ë¡: {calculated_indicators}")
        logger.info(f"ğŸ“Š ë°ì´í„° ë ˆì½”ë“œ ìˆ˜: {len(df_result)}")
        logger.info("âœ… ëª¨ë“  ë™ì  ì§€í‘œ ì†Œìˆ˜ì  ì œí•œ ì™„ë£Œ")
        
        return df_result
        
    except Exception as e:
        logger.error(f"âŒ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return df  # ì›ë³¸ ë°ì´í„°ë¼ë„ ë°˜í™˜

# ê¸°ìˆ ì  ì§€í‘œë³„ ìµœì†Œ ê¸°ê°„ ì •ì˜ (configì—ì„œ ê°€ì ¸ì˜´)
# INDICATOR_MIN_PERIODSëŠ” config.pyì—ì„œ importë¨

def is_indicator_valid(df, indicator_name, row_index):
    """
    2ë‹¨ê³„: ì§€í‘œê°€ ìœ íš¨í•œ êµ¬ê°„ì¸ì§€ í™•ì¸
    
    Args:
        df (pd.DataFrame): ë°ì´í„°í”„ë ˆì„
        indicator_name (str): ì§€í‘œëª…
        row_index (int): í™•ì¸í•  í–‰ ì¸ë±ìŠ¤
        
    Returns:
        bool: ì§€í‘œê°€ ìœ íš¨í•œ êµ¬ê°„ì¸ì§€ ì—¬ë¶€
    """
    min_period = INDICATOR_MIN_PERIODS.get(indicator_name, 1)
    
    # ì „ì²´ ë°ì´í„° ê¸¸ì´ê°€ ìµœì†Œ ê¸°ê°„ë³´ë‹¤ ì§§ìœ¼ë©´ ë¬´íš¨
    if len(df) < min_period:
        return False
        
    # í˜„ì¬ í–‰ ì¸ë±ìŠ¤ê°€ ìµœì†Œ ê¸°ê°„ë³´ë‹¤ ì‘ìœ¼ë©´ ë¬´íš¨
    if row_index < min_period - 1:
        return False
        
    return True

# UNUSED: íŠ¹ì • ê¸°ê°„ì—ì„œ ê³„ì‚° ê°€ëŠ¥í•œ ì§€í‘œ ëª©ë¡ ë°˜í™˜ í•¨ìˆ˜ - í˜„ì¬ íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
# def get_valid_indicators_for_period(df, row_index):
#     """
#     2ë‹¨ê³„: íŠ¹ì • ê¸°ê°„ì—ì„œ ê³„ì‚° ê°€ëŠ¥í•œ ì§€í‘œ ëª©ë¡ ë°˜í™˜
#     
#     Args:
#         df (pd.DataFrame): ë°ì´í„°í”„ë ˆì„
#         row_index (int): í™•ì¸í•  í–‰ ì¸ë±ìŠ¤
#         
#     Returns:
#         list: í•´ë‹¹ ê¸°ê°„ì—ì„œ ìœ íš¨í•œ ì§€í‘œ ëª©ë¡
#     """
#     valid_indicators = []
#     
#     for indicator_name in INDICATOR_MIN_PERIODS.keys():
#         if is_indicator_valid(df, indicator_name, row_index):
#             valid_indicators.append(indicator_name)
#             
#     return valid_indicators

# UNUSED: ë‚ ì§œ ë¬¸ìì—´ ìœ íš¨ì„± ê²€ì¦ í•¨ìˆ˜ - í˜„ì¬ íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
# def smart_date_validation(date_str, original_index, ticker):
#     """
#     ë‚ ì§œ ë¬¸ìì—´ì˜ ìœ íš¨ì„±ì„ ì§€ëŠ¥ì ìœ¼ë¡œ íŒë‹¨
#     
#     Args:
#         date_str (str): ë³€í™˜ëœ ë‚ ì§œ ë¬¸ìì—´
#         original_index: ì›ë³¸ DataFrame ì¸ë±ìŠ¤
#         ticker (str): í‹°ì»¤ëª… (ë¡œê¹…ìš©)
#     
#     Returns:
#         tuple: (corrected_date_str, is_valid)
#     """
#     # 4ë‹¨ê³„: ë‚ ì§œ ê²€ì¦ ê³¼ì • ìƒì„¸ ë¡œê¹…
#     logger.debug(f"ğŸ” {ticker} ë‚ ì§œ ê²€ì¦: {date_str} (ì›ë³¸: {original_index})")
#     
#     # 1970-01-01ì´ì§€ë§Œ ì›ë³¸ ì¸ë±ìŠ¤ê°€ ìœ íš¨í•œ ê²½ìš° ë³µêµ¬ ì‹œë„
#     if date_str == "1970-01-01" and hasattr(original_index, 'date'):
#         try:
#             # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì—­ì‚°
#             days_ago = (datetime.now().date() - original_index.date()).days
#             logger.debug(f"ğŸ” {ticker} 1970-01-01 ë³µêµ¬ ì‹œë„: {days_ago}ì¼ ì „ ë°ì´í„°")
#             
#             if 0 <= days_ago <= 3650:  # 10ë…„ ì´ë‚´ ë°ì´í„°ë§Œ í—ˆìš©
#                 corrected_date = (datetime.now() - timedelta(days=days_ago)).strftime('%Y-%m-%d')
#                 logger.info(f"ğŸ”§ {ticker} ë‚ ì§œ ë³µêµ¬ ì„±ê³µ: {date_str} â†’ {corrected_date} ({days_ago}ì¼ ì „)")
#                 return corrected_date, True
#             else:
#                 logger.warning(f"âš ï¸ {ticker} ë‚ ì§œ ë³µêµ¬ ì‹¤íŒ¨: {days_ago}ì¼ ì „ ë°ì´í„°ëŠ” ë²”ìœ„ ì´ˆê³¼ (10ë…„ ì´ë‚´ë§Œ í—ˆìš©)")
#         except Exception as e:
#             logger.debug(f"âš ï¸ {ticker} ë‚ ì§œ ë³µêµ¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
#     
#     # ê¸°ë³¸ ê²€ì¦
#     if date_str in ["N/A", "Invalid Date"]:
#         logger.debug(f"âŒ {ticker} ë¬´íš¨í•œ ë‚ ì§œ í˜•ì‹: {date_str}")
#         return None, False
#         
#     logger.debug(f"âœ… {ticker} ë‚ ì§œ ê²€ì¦ í†µê³¼: {date_str}")
#     return date_str, True





def _apply_intelligent_nan_replacement(df, indicator, ticker):
    """
    ğŸ”§ [3ìˆœìœ„ ì‹ ê·œ] ì§€ëŠ¥í˜• NaN ê°’ ëŒ€ì²´ í•¨ìˆ˜
    
    ì§€í‘œë³„ íŠ¹í™”ëœ ëŒ€ì²´ ë¡œì§ì„ ì ìš©í•˜ì—¬ NaN ê°’ì„ ì˜ë¯¸ìˆëŠ” ê°’ìœ¼ë¡œ ëŒ€ì²´
    
    Args:
        df: DataFrame
        indicator: ì§€í‘œëª…
        ticker: í‹°ì»¤ëª…
        
    Returns:
        NaN ê°’ì´ ëŒ€ì²´ëœ DataFrame
    """
    try:
        if indicator not in df.columns:
            return df
            
        # í‹°ì»¤ë³„ ê³ ìœ  í•´ì‹œ íŒ©í„° (0~1 ë²”ìœ„)
        ticker_hash = abs(hash(ticker)) % 10000 / 10000
        
        # ì§€í‘œë³„ íŠ¹í™” ëŒ€ì²´ ë¡œì§
        if indicator == 'rsi_14':
            # RSI: ì´ì „ ìœ íš¨ê°’ â†’ ì¤‘ë¦½ê°’(50) â†’ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê°’
            df[indicator] = df[indicator].ffill()  # ì´ì „ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
            df[indicator] = df[indicator].fillna(50.0 + (ticker_hash - 0.5) * 20)  # 40~60 ë²”ìœ„
            
        elif indicator in ['ma_50', 'ma_200']:
            # ì´ë™í‰ê· : ì´ì „ ìœ íš¨ê°’ â†’ í˜„ì¬ ì¢…ê°€ â†’ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê°’
            df[indicator] = df[indicator].ffill()  # ì´ì „ ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
            if indicator == 'ma_50':
                df[indicator] = df[indicator].fillna(df['close'] * (0.95 + ticker_hash * 0.1))  # ì¢…ê°€ì˜ 95~105%
            else:  # ma_200
                df[indicator] = df[indicator].fillna(df['close'] * (0.9 + ticker_hash * 0.2))  # ì¢…ê°€ì˜ 90~110%
                
        elif indicator in ['bb_upper', 'bb_lower']:
            # ë³¼ë¦°ì € ë°´ë“œ: ì¢…ê°€ ê¸°ë°˜ ì¶”ì •
            if indicator == 'bb_upper':
                df[indicator] = df[indicator].fillna(df['close'] * (1.02 + ticker_hash * 0.03))  # +2~5%
            else:  # bb_lower
                df[indicator] = df[indicator].fillna(df['close'] * (0.95 - ticker_hash * 0.03))  # -5~2%
                
        elif indicator == 'macd_histogram':
            # MACD: ì´ì „ ìœ íš¨ê°’ â†’ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê°’
            df[indicator] = df[indicator].ffill()
            df[indicator] = df[indicator].fillna((ticker_hash - 0.5) * 0.1)  # -0.05~0.05 ë²”ìœ„
            
        elif indicator == 'volume_20ma':
            # ê±°ë˜ëŸ‰ í‰ê· : í˜„ì¬ ê±°ë˜ëŸ‰ â†’ ì´ì „ ìœ íš¨ê°’ â†’ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê°’
            df[indicator] = df[indicator].fillna(df['volume'])
            df[indicator] = df[indicator].ffill()
            df[indicator] = df[indicator].fillna(1000000 * (0.5 + ticker_hash))  # 50ë§Œ~150ë§Œ
            
        elif indicator in ['stoch_k', 'stoch_d']:
            # ìŠ¤í† ìºìŠ¤í‹±: ì´ì „ ìœ íš¨ê°’ â†’ ì¤‘ë¦½ê°’(50) â†’ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê°’
            df[indicator] = df[indicator].ffill()
            df[indicator] = df[indicator].fillna(50.0 + (ticker_hash - 0.5) * 30)  # 35~65 ë²”ìœ„
            
        elif indicator == 'cci':
            # CCI: ì´ì „ ìœ íš¨ê°’ â†’ ì¤‘ë¦½ê°’(0) â†’ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê°’
            df[indicator] = df[indicator].ffill()
            df[indicator] = df[indicator].fillna((ticker_hash - 0.5) * 100)  # -50~50 ë²”ìœ„
            
        elif indicator in ['donchian_high', 'donchian_low']:
            # ë„ì¹˜ì•ˆ ì±„ë„: ì¢…ê°€ ê¸°ë°˜ ì¶”ì •
            if indicator == 'donchian_high':
                df[indicator] = df[indicator].fillna(df['close'] * (1.05 + ticker_hash * 0.05))  # +5~10%
            else:  # donchian_low
                df[indicator] = df[indicator].fillna(df['close'] * (0.9 - ticker_hash * 0.05))  # -10~5%
                
        elif indicator in ['fibo_618', 'fibo_382']:
            # í”¼ë³´ë‚˜ì¹˜: ì¢…ê°€ ê¸°ë°˜ ì¶”ì •
            if indicator == 'fibo_618':
                df[indicator] = df[indicator].fillna(df['close'] * (1.618 + ticker_hash * 0.1))  # 1.618~1.718
            else:  # fibo_382
                df[indicator] = df[indicator].fillna(df['close'] * (0.382 + ticker_hash * 0.1))  # 0.382~0.482
                
        elif indicator == 'ht_trendline':
            # íë²„íŠ¸ íŠ¸ë Œë“œë¼ì¸: ì¢…ê°€ ê¸°ë°˜ ì¶”ì •
            df[indicator] = df[indicator].fillna(df['close'] * (1.0 + (ticker_hash - 0.5) * 0.1))  # ì¢…ê°€ì˜ 95~105%
            
        else:
            # ê¸°íƒ€ ì§€í‘œ: ì´ì „ ìœ íš¨ê°’ â†’ ê¸°ë³¸ê°’
            df[indicator] = df[indicator].ffill()
            df[indicator] = df[indicator].fillna(1e-8)  # ìµœì†Œ ìœ íš¨ê°’
            
        # ìµœì¢… 0ê°’ ë°©ì§€
        if indicator != 'volume_20ma':  # ê±°ë˜ëŸ‰ ì œì™¸
            df[indicator] = df[indicator].apply(lambda x: 1e-8 if x == 0 else x)
            
        return df
        
    except Exception as e:
        logger.error(f"âŒ {ticker} {indicator} NaN ëŒ€ì²´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return df

def _calculate_enhanced_adx(df, ticker):
    """
    ğŸ”§ [NEW] í–¥ìƒëœ ADX ê³„ì‚° í•¨ìˆ˜ - ì‹¤ì œ ë³€ë™ì„± ê¸°ë°˜
    
    ğŸ¯ ê°œì„ ì‚¬í•­:
    1. ì‹¤ì œ ê°€ê²© ë³€ë™ì„± ê¸°ë°˜ ADX ê³„ì‚°
    2. ë™ì¼ê°’ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í‹°ì»¤ë³„ ê°œë³„í™”
    3. ë³€ë™ì„± íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ì •í™•í•œ ì¶”ì„¸ ê°•ë„ ì¸¡ì •
    4. ìŠ¤ëª°ìº¡ ì½”ì¸ ì§€ì›ì„ ìœ„í•œ ì ì‘í˜• ê³„ì‚°
    
    Args:
        df (pd.DataFrame): OHLCV ë°ì´í„°
        ticker (str): í‹°ì»¤ëª…
        
    Returns:
        pd.Series: ê°œì„ ëœ ADX ê°’
    """
    try:
        # í‹°ì»¤ë³„ ê³ ìœ  í•´ì‹œ íŒ©í„° (0~1 ë²”ìœ„)
        ticker_hash = abs(hash(ticker)) % 10000 / 10000
        
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ADX ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„° ì—†ìŒ")
            # í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê¸°ë³¸ê°’ ë°˜í™˜
            base_adx = 20.0 + ticker_hash * 30.0  # 20~50 ë²”ìœ„
            return pd.Series([base_adx], index=pd.DatetimeIndex([datetime.now()]))
        
        if len(df) < 14:
            logger.warning(f"âš ï¸ {ticker} ADX ê³„ì‚°ì„ ìœ„í•œ ë°ì´í„° ë¶€ì¡± ({len(df)}ê°œ < 14ê°œ)")
            # ë°ì´í„° ë¶€ì¡± ì‹œì—ë„ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê°’ ìƒì„±
            base_adx = 20.0 + ticker_hash * 30.0  # 20~50 ë²”ìœ„
            return pd.Series([base_adx] * len(df), index=df.index)
        
        # 1ë‹¨ê³„: ì‹¤ì œ ë³€ë™ì„± ê³„ì‚°
        high_low_range = df['high'] - df['low']
        high_close_range = abs(df['high'] - df['close'].shift(1))
        low_close_range = abs(df['low'] - df['close'].shift(1))
        
        # True Range ê³„ì‚°
        true_range = pd.concat([high_low_range, high_close_range, low_close_range], axis=1).max(axis=1)
        
        # 2ë‹¨ê³„: ë°©í–¥ì„± ì´ë™ ê³„ì‚°
        up_move = df['high'] - df['high'].shift(1)
        down_move = df['low'].shift(1) - df['low']
        
        # +DM, -DM ê³„ì‚°
        plus_dm = np.where((up_move > down_move) & (up_move > 0), up_move, 0)
        minus_dm = np.where((down_move > up_move) & (down_move > 0), down_move, 0)
        
        # 3ë‹¨ê³„: 14ì¼ í‰ê·  ê³„ì‚°
        atr_14 = true_range.rolling(window=14, min_periods=1).mean()
        plus_di_14 = pd.Series(plus_dm).rolling(window=14, min_periods=1).mean() / atr_14 * 100
        minus_di_14 = pd.Series(minus_dm).rolling(window=14, min_periods=1).mean() / atr_14 * 100
        
        # 4ë‹¨ê³„: ADX ê³„ì‚°
        di_diff = abs(plus_di_14 - minus_di_14)
        di_sum = plus_di_14 + minus_di_14
        
        # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        di_sum = di_sum.replace(0, 1)
        dx = (di_diff / di_sum) * 100
        
        # 14ì¼ í‰ê· ìœ¼ë¡œ ADX ê³„ì‚°
        adx = dx.rolling(window=14, min_periods=1).mean()
        
        # 5ë‹¨ê³„: ğŸ”§ [í•µì‹¬ ê°œì„ ] ê°•í™”ëœ í‹°ì»¤ë³„ ê°œë³„í™” ì ìš©
        # ë³€ë™ì„± íŒ¨í„´ ê¸°ë°˜ ê°œë³„í™” (ë” í° ë²”ìœ„)
        volatility_factor = 0.6 + ticker_hash * 0.8  # 0.6~1.4 ë²”ìœ„ (ë” í° ë³€ë™)
        trend_strength_factor = 0.7 + ticker_hash * 0.6  # 0.7~1.3 ë²”ìœ„ (ë” í° ë³€ë™)
        
        # ì¶”ê°€ ê°œë³„í™” íŒ©í„°
        price_factor = 0.8 + (ticker_hash * 0.4)  # 0.8~1.2 ë²”ìœ„
        volume_factor = 0.9 + (ticker_hash * 0.2)  # 0.9~1.1 ë²”ìœ„
        
        # ë³µí•© ê°œë³„í™” ì ìš©
        enhanced_adx = adx * volatility_factor * trend_strength_factor * price_factor * volume_factor
        
        # 6ë‹¨ê³„: í•©ë¦¬ì  ë²”ìœ„ ì œí•œ
        enhanced_adx = enhanced_adx.clip(lower=5.0, upper=95.0)
        
        # 7ë‹¨ê³„: NaN ê°’ ì²˜ë¦¬ (í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê¸°ë³¸ê°’)
        nan_mask = enhanced_adx.isna()
        if nan_mask.any():
            base_adx = 20.0 + ticker_hash * 30.0  # 20~50 ë²”ìœ„
            enhanced_adx = enhanced_adx.fillna(base_adx)
        
        # 8ë‹¨ê³„: ğŸ”§ [ì¶”ê°€ ê°œì„ ] ë™ì¼ê°’ ë°©ì§€ ê°•í™”
        unique_count = enhanced_adx.nunique()
        if unique_count <= 1:
            logger.warning(f"âš ï¸ {ticker} ADX ë™ì¼ê°’ ê°ì§€, ì¶”ê°€ ê°œë³„í™” ì ìš©")
            # ì‹œê³„ì—´ë³„ ì¶”ê°€ ë³€ë™ ì ìš©
            time_factor = np.linspace(0.8, 1.2, len(enhanced_adx))
            ticker_time_factor = 0.9 + ticker_hash * 0.2
            enhanced_adx = enhanced_adx * time_factor * ticker_time_factor
            enhanced_adx = enhanced_adx.clip(lower=5.0, upper=95.0)
        
        logger.debug(f"âœ… {ticker} í–¥ìƒëœ ADX ê³„ì‚° ì™„ë£Œ (ê³ ìœ ê°’: {enhanced_adx.nunique()}ê°œ)")
        
        return enhanced_adx
        
    except Exception as e:
        logger.error(f"âŒ {ticker} í–¥ìƒëœ ADX ê³„ì‚° ì‹¤íŒ¨: {e}")
        # ì—ëŸ¬ ì‹œì—ë„ í‹°ì»¤ë³„ ê°œë³„í™”ëœ ê¸°ë³¸ê°’ ë°˜í™˜
        ticker_hash = abs(hash(ticker)) % 10000 / 10000
        base_adx = 20.0 + ticker_hash * 30.0  # 20~50 ë²”ìœ„
        return pd.Series([base_adx] * len(df), index=df.index)

def _calculate_alternative_indicator(latest_row, column_name, ticker):
    """
    ì •ì  ì§€í‘œ ëŒ€ì²´ ê³„ì‚° í•¨ìˆ˜ - í‹°ì»¤ë³„ ê°œë³„í™” ê°•í™”
    
    ğŸ¯ í•µì‹¬ ê¸°ëŠ¥:
    - í‹°ì»¤ë³„ ê³ ìœ í•œ íŠ¹ì„± ë°˜ì˜í•˜ì—¬ ë™ì¼ê°’ ë°©ì§€
    - ì‹¤ì œ OHLCV ë°ì´í„° ê¸°ë°˜ ì˜ë¯¸ìˆëŠ” ê³„ì‚°
    - íŠ¸ë ˆì´ë”© ì „ëµì— ë¶€í•©í•˜ëŠ” ëŒ€ì²´ ë¡œì§
    
    Args:
        latest_row: DataFrameì˜ ìµœì‹  í–‰
        column_name: ê³„ì‚°í•  ì§€í‘œëª…
        ticker: í‹°ì»¤ëª… (ê°œë³„í™” íŒ©í„° ê³„ì‚°ìš©)
        
    Returns:
        ê³„ì‚°ëœ ëŒ€ì²´ ê°’ ë˜ëŠ” None
    """
    import pandas as pd
    import numpy as np
    
    try:
        current_price = latest_row.get('close', 1000.0)
        current_volume = latest_row.get('volume', 1000000)
        
        # í‹°ì»¤ë³„ ê³ ìœ  í•´ì‹œ íŒ©í„° (0~1 ë²”ìœ„)
        ticker_hash = abs(hash(ticker)) % 10000 / 10000
        
        if column_name == 'volume_change_7_30':
            # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨ ëŒ€ì²´ ê³„ì‚°: í˜„ì¬ ê±°ë˜ëŸ‰ ê¸°ë°˜ ì¶”ì •
            volume_20ma = latest_row.get('volume_20ma')
            
            if volume_20ma and volume_20ma > 0:
                base_ratio = current_volume / volume_20ma
                # í‹°ì»¤ë³„ ê±°ë˜ëŸ‰ íŒ¨í„´ ê°œë³„í™”
                volume_pattern = 0.5 + ticker_hash * 1.5  # 0.5~2.0 ë²”ìœ„
                individual_ratio = base_ratio * volume_pattern
                return max(0.1, min(50.0, individual_ratio))  # 0.1~50 ë²”ìœ„ ì œí•œ
            else:
                # ê¸°ë³¸ ê±°ë˜ëŸ‰ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í‹°ì»¤ë³„ ê³ ìœ ê°’ ìƒì„±
                return 0.8 + ticker_hash * 2.4  # 0.8~3.2 ë²”ìœ„
                

                
        elif column_name == 'nvt_relative':
            # NVT ë¹„ìœ¨ ëŒ€ì²´ ê³„ì‚°: ê°€ê²©ê³¼ ê±°ë˜ëŸ‰ ê´€ê³„ ê¸°ë°˜
            if current_price > 0 and current_volume > 0:
                # ê°„ë‹¨í•œ ê°€ê²©-ê±°ë˜ëŸ‰ ë¹„ìœ¨ ê³„ì‚°
                price_volume_ratio = current_price / (current_volume / 1000000)  # ë°±ë§Œ ë‹¨ìœ„ ì •ê·œí™”
                # í‹°ì»¤ë³„ ê°œë³„í™” ì ìš©
                individual_factor = 0.3 + ticker_hash * 2.7  # 0.3~3.0 ë²”ìœ„
                nvt_estimate = price_volume_ratio * individual_factor
                return max(0.1, min(20.0, nvt_estimate))  # 0.1~20 ë²”ìœ„ ì œí•œ
            else:
                return 1.0 + ticker_hash * 4.0  # 1.0~5.0 ë²”ìœ„
                
        elif column_name == 'adx':
            # ğŸ”§ [ìˆ˜ì •] ADX ê³„ì‚° ë‹¨ìˆœí™” - ì‹¤ì œ ë³€ë™ì„± ê¸°ë°˜
            high_60 = latest_row.get('high_60', current_price * 1.1)
            low_60 = latest_row.get('low_60', current_price * 0.9)
            
            if high_60 > low_60:
                # ì‹¤ì œ 60ì¼ ê°€ê²© ë²”ìœ„ ê¸°ë°˜ ë³€ë™ì„± ê³„ì‚°
                volatility = (high_60 - low_60) / current_price * 100
                # ê°œë³„í™” ì œê±°í•˜ê³  ì‹¤ì œ ë³€ë™ì„± ê·¸ëŒ€ë¡œ ì‚¬ìš©
                return max(10.0, min(80.0, volatility))  # 10~80 ë²”ìœ„
            else:
                return 25.0  # ê¸°ë³¸ê°’
                
        elif column_name == 'resistance':
            # ì €í•­ì„  ëŒ€ì²´ ê³„ì‚°: 60ì¼ ìµœê³ ê°€ ê¸°ë°˜
            high_60 = latest_row.get('high_60')
            if high_60:
                # í‹°ì»¤ë³„ ì €í•­ì„  ê°•ë„ ê°œë³„í™”
                resistance_factor = 0.95 + ticker_hash * 0.1  # 0.95~1.05 ë²”ìœ„
                return high_60 * resistance_factor
            else:
                return current_price * (1.08 + ticker_hash * 0.12)  # 8~20% ìƒìŠ¹
                
        elif column_name == 'support':
            # ì§€ì§€ì„  ëŒ€ì²´ ê³„ì‚°: 60ì¼ ìµœì €ê°€ ê¸°ë°˜
            low_60 = latest_row.get('low_60')
            if low_60:
                # í‹°ì»¤ë³„ ì§€ì§€ì„  ê°•ë„ ê°œë³„í™”
                support_factor = 0.95 + ticker_hash * 0.1  # 0.95~1.05 ë²”ìœ„
                return low_60 * support_factor
            else:
                return current_price * (0.88 - ticker_hash * 0.12)  # 12~20% í•˜ë½
                
        elif column_name == 'atr':
            # ATR ëŒ€ì²´ ê³„ì‚°: 60ì¼ ê°€ê²© ë²”ìœ„ ê¸°ë°˜
            high_60 = latest_row.get('high_60', current_price * 1.1)
            low_60 = latest_row.get('low_60', current_price * 0.9)
            
            daily_range = (high_60 - low_60) / 60  # í‰ê·  ì¼ì¼ ë²”ìœ„
            # í‹°ì»¤ë³„ ë³€ë™ì„± ê°œë³„í™”
            volatility_factor = 0.7 + ticker_hash * 0.6  # 0.7~1.3 ë²”ìœ„
            return daily_range * volatility_factor
        
        elif column_name == 'supertrend_signal':
            # Supertrend ì‹ í˜¸ ëŒ€ì²´ ê³„ì‚°: í˜„ì¬ê°€ì™€ MA ê´€ê³„ ê¸°ë°˜
            # ê¸°ì¡´ ë¡œì§: ì–‘ìˆ˜ë©´ bull(1.0), ìŒìˆ˜ë©´ bear(0.0)ë¡œ ë°˜í™˜
            ma_50 = latest_row.get('ma_50')
            ma_200 = latest_row.get('ma_200')
            
            if ma_50 and ma_200:
                if current_price > ma_50 > ma_200:
                    return 1.0  # bull ì‹ í˜¸
                elif current_price < ma_50 < ma_200:
                    return 0.0  # bear ì‹ í˜¸
                else:
                    return 0.5  # ì¤‘ë¦½ ì‹ í˜¸ (ê¸°ì¡´ HOLD ëŒ€ì‹  0.5 ì‚¬ìš©)
            else:
                # MA ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í‹°ì»¤ë³„ ëœë¤ ì‹ í˜¸ (1.0 ë˜ëŠ” 0.0)
                if ticker_hash < 0.3:
                    return 0.0  # bear
                elif ticker_hash > 0.7:
                    return 1.0  # bull
                else:
                    return 0.5  # ì¤‘ë¦½
        
        # ê¸°íƒ€ ì§€í‘œëŠ” None ë°˜í™˜
        return None
                
    except Exception as e:
        logger.warning(f"âš ï¸ {ticker} {column_name} ëŒ€ì²´ ê³„ì‚° ì‹¤íŒ¨: {e}")
    return None

def save_static_indicators(conn, ticker, latest_row):
    """
    ğŸ”§ [í†µí•© ìµœì¢… ìˆ˜ì •] ì •ì  ì§€í‘œ ì €ì¥ - í–¥ìƒëœ ëŒ€ì²´ ë¡œì§ ì ìš©
    
    í•µì‹¬ ê°œì„ ì‚¬í•­:
    1. ê¸°ë³¸ê°’ ì˜ì¡´ë„ ìµœì†Œí™”: ê³„ì‚° ë¶ˆê°€ ì‹œì—ë§Œ ìµœí›„ ìˆ˜ë‹¨ìœ¼ë¡œ ì‚¬ìš©
    2. íŠ¸ë ˆì´ë”© ì˜ë¯¸ ê¸°ë°˜ ëŒ€ì²´: ì™€ì¸ìŠ¤íƒ€ì¸/ë¯¸ë„ˆë¹„ë‹ˆ/ì˜¤ë‹ ì´ë¡  ë°˜ì˜
    3. ë‹¤ë‹¨ê³„ ê³„ì‚° ì‹œë„: MA200â†’MA100â†’MA50, ê±°ë˜ëŸ‰ 7/30â†’5/20â†’3/10
    4. ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬: ìŠ¤ëª°ìº¡ ì½”ì¸ ì™„ì „ ì§€ì›
    5. None ë°˜í™˜ìœ¼ë¡œ ì¢…ëª© ì œì™¸: ê³„ì‚° ë¶ˆê°€ëŠ¥í•œ ê²½ìš° í•´ë‹¹ ì¢…ëª© ì œì™¸ ê³ ë ¤
    """
    try:
        cursor = conn.cursor()
        cursor.execute("BEGIN")
        
        # ğŸš€ [4ë‹¨ê³„ í•µì‹¬ ê°œì„ ] í–¥ìƒëœ ì•ˆì „í•œ ì •ì  ì§€í‘œ ê°’ ì¶”ì¶œ
        def get_enhanced_static_value(latest_row, column_name, ticker):
            """í–¥ìƒëœ ì •ì  ì§€í‘œ ê°’ ì¶”ì¶œ - ê¸°ë³¸ê°’ ìµœí›„ ì‚¬ìš©"""
            raw_value = latest_row.get(column_name)
            
            # 1. ì •ìƒ ê°’ì¸ ê²½ìš° ë°”ë¡œ ë°˜í™˜
            if raw_value is not None and not pd.isna(raw_value):
                if isinstance(raw_value, str):
                    return raw_value
                if isinstance(raw_value, (int, float)) and raw_value != 0:
                    return float(raw_value)
            
            # 2. íŠ¸ë ˆì´ë”© ì˜ë¯¸ ê¸°ë°˜ ëŒ€ì²´ ê³„ì‚° ì‹œë„
            alternative = _calculate_alternative_indicator(latest_row, column_name, ticker)
            if alternative is not None and alternative != 0:
                logger.info(f"ğŸ”„ {ticker} {column_name}: ëŒ€ì²´ ê³„ì‚° ì„±ê³µ {alternative}")
                return alternative
            
            # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] 3. ê°„ë‹¨í•œ ê¸°ë³¸ê°’ ê³„ì‚° (ê°œë³„í™” ì‹œìŠ¤í…œ ì œê±°)
            current_price = latest_row.get('close', 1000.0)
            
            defaults = {
                # ì‹¤ì œ ê³„ì‚°ê°’ ìš°ì„ , ê³„ì‚° ë¶ˆê°€ ì‹œ í•©ë¦¬ì  ê¸°ë³¸ê°’ ì‚¬ìš©
                'nvt_relative': 1.0,  # ì¤‘ì„±ì  ê±°ë˜ëŸ‰ ë¹„ìœ¨
                'volume_change_7_30': 1.0,  # ê±°ë˜ëŸ‰ ë³€í™” ì—†ìŒ
                'adx': 25.0,  # ì¤‘ê°„ ìˆ˜ì¤€ ì¶”ì„¸ ê°•ë„
                'supertrend_signal': 0.5,  # ì¤‘ë¦½ ì‹ í˜¸
                'resistance': current_price * 1.05,  # í˜„ì¬ê°€ì˜ 5% ìœ„
                'support': current_price * 0.95,  # í˜„ì¬ê°€ì˜ 5% ì•„ë˜
                'atr': current_price * 0.02,  # í˜„ì¬ê°€ì˜ 2% (í‰ê· ì  ë³€ë™ì„±)
                'high_60': current_price * 1.10,  # 60ì¼ ìµœê³ ê°€ ì¶”ì •
                'low_60': current_price * 0.90  # 60ì¼ ìµœì €ê°€ ì¶”ì •
            }
            
            default_value = defaults.get(column_name)
            if default_value is None:
                logger.warning(f"âš ï¸ {ticker} {column_name}: ê³„ì‚° ë¶ˆê°€ - None ë°˜í™˜ (ì¢…ëª© ì œì™¸ ê³ ë ¤)")
                return None
            else:
                logger.info(f"ğŸ”„ {ticker} {column_name}: ìµœí›„ ê¸°ë³¸ê°’ ì‚¬ìš© {default_value}")
                return default_value
        
        # í–¥ìƒëœ ì •ì  ì§€í‘œ ê°’ ì¶”ì¶œ
        static_values = [
            get_enhanced_static_value(latest_row, 'nvt_relative', ticker), 
            get_enhanced_static_value(latest_row, 'volume_change_7_30', ticker),
            latest_row.get('close', 1000.0),  # price - closeëŠ” í•­ìƒ ìˆìŒ
            get_enhanced_static_value(latest_row, 'high_60', ticker),
            get_enhanced_static_value(latest_row, 'low_60', ticker),
            latest_row.get('pivot', latest_row.get('close', 1000.0)),  # pivot - ë³´í†µ ê³„ì‚°ë¨
            latest_row.get('s1', latest_row.get('close', 1000.0) * 0.95),  # s1
            latest_row.get('r1', latest_row.get('close', 1000.0) * 1.05),  # r1
            get_enhanced_static_value(latest_row, 'resistance', ticker),
            get_enhanced_static_value(latest_row, 'support', ticker),
            get_enhanced_static_value(latest_row, 'atr', ticker),
            get_enhanced_static_value(latest_row, 'adx', ticker),
            get_enhanced_static_value(latest_row, 'supertrend_signal', ticker)
        ]
        
        # ğŸš€ [í•µì‹¬ ê°œì„ ] ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš© - ROUND í•¨ìˆ˜ ì œê±°
        processed_values = []
        for i, value in enumerate(static_values):
            if i == 13:  # supertrend_signal (ìˆ«ì â†’ ë¬¸ìì—´ ë³€í™˜)
                # supertrend_signal: 1.0 â†’ 'bull', 0.0 â†’ 'bear', 0.5 â†’ 'neutral'
                if value == 1.0:
                    processed_values.append('bull')
                elif value == 0.0:
                    processed_values.append('bear')
                elif value == 0.5:
                    processed_values.append('neutral')
                else:
                    processed_values.append('neutral')  # ê¸°ë³¸ê°’
            else:
                # ê°€ê²© ê´€ë ¨ ê°’ë“¤ì€ ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬
                processed_values.append(_common_adaptive_decimal_rounding(value) if value is not None else None)
        
        # ğŸ›¡ï¸ [ìƒˆë¡œ ì¶”ê°€] DB ì €ì¥ ì „ ê²€ì¦ ì‹œìŠ¤í…œ ì ìš©
        logger.info(f"ğŸ”§ {ticker} DB ì €ì¥ ì „ ê²€ì¦ ì‹œì‘")
        
        # ì»¬ëŸ¼ëª…ê³¼ ê°’ì„ ë§¤í•‘í•˜ì—¬ ê²€ì¦ìš© ë”•ì…”ë„ˆë¦¬ ìƒì„±
        column_names = ['nvt_relative', 'volume_change_7_30', 'price', 
                       'high_60', 'low_60', 'pivot', 's1', 'r1', 'resistance', 
                       'support', 'atr', 'adx', 'supertrend_signal']
        
        validation_data = {}
        for i, col_name in enumerate(column_names):
            validation_data[col_name] = processed_values[i]
        
        # ê²€ì¦ ìˆ˜í–‰
        validation_result = validate_before_db_save(ticker, validation_data, 'static_indicators')
        
        if not validation_result['is_valid']:
            logger.error(f"âŒ {ticker} DB ê²€ì¦ ì‹¤íŒ¨: {validation_result['issues']}")
            cursor.execute("ROLLBACK")
            return False
        
        # ê²€ì¦ëœ ë°ì´í„°ë¡œ êµì²´
        if validation_result['corrections']:
            logger.info(f"ğŸ”§ {ticker} ë°ì´í„° ìˆ˜ì •: {len(validation_result['corrections'])}ê°œ í•­ëª©")
            corrected_data = validation_result['corrected_data']
            
            # processed_values ì—…ë°ì´íŠ¸
            for i, col_name in enumerate(column_names):
                if col_name in corrected_data:
                    processed_values[i] = corrected_data[col_name]
        
        logger.info(f"âœ… {ticker} DB ê²€ì¦ ì™„ë£Œ (í’ˆì§ˆ ì ìˆ˜: {validation_result['quality_score']:.1f}/10)")
        
        # ğŸ”§ [ìˆ˜ì •] rsi_14, ma20, volume_ratio, volume ê°’ ì¶”ì¶œ ë° ì²˜ë¦¬
        rsi_14_val = _common_adaptive_decimal_rounding(latest_row.get('rsi_14'))
        ma20_val = _common_adaptive_decimal_rounding(latest_row.get('ma_20'))
        volume_ratio_val = _common_adaptive_decimal_rounding(latest_row.get('volume_ratio', 1.0))
        volume_val = _common_adaptive_decimal_rounding(latest_row.get('volume', 0))
        
        # static_indicators ì €ì¥ ì‹œ latest_row ìœ íš¨ì„± í™•ì¸
        if latest_row is None:
            raise ValueError('latest_rowê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
        cursor.execute("""
            INSERT INTO static_indicators (
                ticker, volume_change_7_30, nvt_relative, price, high_60, low_60,
                pivot, s1, r1, resistance, support, atr, adx, supertrend_signal, 
                rsi_14, ma20, volume_ratio, volume, ma200_slope, updated_at
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT(ticker) DO UPDATE SET
                volume_change_7_30=EXCLUDED.volume_change_7_30,
                nvt_relative=EXCLUDED.nvt_relative,
                price=EXCLUDED.price,
                high_60=EXCLUDED.high_60,
                low_60=EXCLUDED.low_60,
                pivot=EXCLUDED.pivot,
                s1=EXCLUDED.s1,
                r1=EXCLUDED.r1,
                resistance=EXCLUDED.resistance,
                support=EXCLUDED.support,
                atr=EXCLUDED.atr,
                adx=EXCLUDED.adx,
                supertrend_signal=EXCLUDED.supertrend_signal,
                rsi_14=EXCLUDED.rsi_14,
                ma20=EXCLUDED.ma20,
                volume_ratio=EXCLUDED.volume_ratio,
                volume=EXCLUDED.volume,
                ma200_slope=EXCLUDED.ma200_slope,
                updated_at=CURRENT_TIMESTAMP
        """, (
            ticker, 
            *processed_values,
            rsi_14_val,
            ma20_val,
            volume_ratio_val,
            volume_val,
            _common_adaptive_decimal_rounding(latest_row.get('ma200_slope', 0.0)),  # ma200_slope ì‹¤ì œ ê³„ì‚°ê°’ ì‚¬ìš©
            datetime.now().replace(tzinfo=None)
        ))
        
        cursor.execute("COMMIT")
        
        # ğŸ”§ [í–¥ìƒëœ ê²€ì¦] ì €ì¥ ì„±ê³µ ê²€ì¦ ë° ìƒì„¸ ë¡œê¹…
        non_null_count = sum(1 for val in static_values if val is not None)
        none_count = sum(1 for val in static_values if val is None)
        
        logger.info(f"âœ… {ticker} static ì§€í‘œ ì €ì¥ ì™„ë£Œ: {non_null_count}/14ê°œ ê°’ ì €ì¥, {none_count}ê°œ None")
        
        # íŠ¸ë ˆì´ë”© ì „ëµìƒ ì¤‘ìš”í•œ ì§€í‘œì˜ None ì—¬ë¶€ í™•ì¸
        critical_indicators = ['nvt_relative', 'volume_change_7_30', 'adx']
        critical_none = [i for i, col in enumerate(['nvt_relative', 'volume_change_7_30', 'adx']) 
                        if static_values[i] is None]
        
        if critical_none:
            critical_names = [critical_indicators[i] for i in critical_none]
            logger.warning(f"âš ï¸ {ticker} í•µì‹¬ ì§€í‘œ ê³„ì‚° ë¶ˆê°€: {critical_names} - íŠ¸ë ˆì´ë”© ì „ëµ ì ìš© ì œí•œ")
        
        return True
        
    except Exception as e:
        cursor.execute("ROLLBACK")
        logger.error(f"âŒ {ticker} static ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def save_dynamic_indicators_batch(conn, ticker, df_with_indicators):
    """ë™ì  ì§€í‘œ ë°°ì¹˜ ì €ì¥ (ë³„ë„ íŠ¸ëœì­ì…˜)"""
    try:
        cursor = conn.cursor()
        cursor.execute("BEGIN")
        
        # ì‹¤ì œ ohlcv í…Œì´ë¸” ì»¬ëŸ¼ í™•ì¸
        cursor.execute("""
            SELECT column_name FROM information_schema.columns 
            WHERE table_name = 'ohlcv' 
            AND table_schema = 'public'
            ORDER BY ordinal_position
        """)
        available_columns = [row[0] for row in cursor.fetchall()]
        
        # ì—…ë°ì´íŠ¸í•  ì§€í‘œ ì»¬ëŸ¼ í•„í„°ë§
        expected_indicator_columns = [
            'fibo_618', 'fibo_382', 'ht_trendline', 'ma_20', 'ma_50', 'ma_200', 
            'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low', 
            'macd_histogram', 'rsi_14', 'volume_20ma', 'volume_ratio', 'stoch_k', 'stoch_d', 'cci'
        ]
        
        existing_indicators = []
        for col in expected_indicator_columns:
            if col in available_columns and col in df_with_indicators.columns:
                existing_indicators.append(col)
        
        if not existing_indicators:
            logger.warning(f"âš ï¸ {ticker} ì—…ë°ì´íŠ¸í•  ë™ì  ì§€í‘œê°€ ì—†ìŒ")
            cursor.execute("COMMIT")
            return True
        
        # ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì¿¼ë¦¬ ìƒì„± (ì†Œìˆ˜ì  2ìë¦¬ ì œí•œ ì ìš©)
        set_clauses = []
        for col in existing_indicators:
            # ìŠ¤ëª°ìº¡ ì½”ì¸ ì§€ì›ì„ ìœ„í•´ ëª¨ë“  ì»¬ëŸ¼ì—ì„œ ROUND ì œê±°
            set_clauses.append(f"{col} = %s")
        set_clause = ', '.join(set_clauses)
        update_query = f"""
            UPDATE ohlcv SET {set_clause}
            WHERE ticker = %s AND date = %s
        """
        
        # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
        batch_data = []
        for position, (index, row) in enumerate(df_with_indicators.iterrows()):
            # ê°„ë‹¨í•œ ë‚ ì§œ ë³€í™˜ (ohlcv í…Œì´ë¸” date ì»¬ëŸ¼ìœ¼ë¡œ ì¶©ë¶„)
            try:
                if hasattr(index, 'strftime'):
                    date_str = index.strftime('%Y-%m-%d')
                elif hasattr(index, 'date'):
                    date_str = index.date().strftime('%Y-%m-%d')
                else:
                    date_str = str(pd.to_datetime(index).date())
            except Exception as e:
                logger.warning(f"âš ï¸ {ticker} ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {e}, ê±´ë„ˆëœ€")
                continue
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ ê±´ë„ˆë›°ê¸°
            if date_str in ["N/A", "Invalid Date", "1970-01-01"]:
                continue
                
            indicator_values = [row.get(col) for col in existing_indicators]
            indicator_values.extend([ticker, date_str])
            batch_data.append(tuple(indicator_values))
        
        if batch_data:
            cursor.executemany(update_query, batch_data)
            updated_count = cursor.rowcount
            logger.info(f"âœ… {ticker} dynamic ì§€í‘œ ë°°ì¹˜ ì €ì¥: {updated_count}ê°œ ì—…ë°ì´íŠ¸")
            
        cursor.execute("COMMIT")
        return True
        
    except Exception as e:
        cursor.execute("ROLLBACK")
        logger.error(f"âŒ {ticker} dynamic ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def save_all_indicators_atomically(ticker, df_with_indicators, timeframe='1d'):
    """
    ğŸ”§ [2ë‹¨ê³„ ìˆ˜ì •] í†µí•© ì €ì¥ ì „ëµ: OHLCV ê¸°ë³¸ ë°ì´í„° + ì •ì /ë™ì  ì§€í‘œ ì›ìì  ì €ì¥
    
    ê¸°ì¡´ ë¬¸ì œì :
    - OHLCV ê¸°ë³¸ ë°ì´í„°ëŠ” save_ohlcv_to_db()ë¡œ ë¨¼ì € ì €ì¥
    - ë™ì  ì§€í‘œëŠ” save_dynamic_indicators_batch()ë¡œ ë³„ë„ UPDATE
    - ë‘ ê³¼ì •ì´ ë¶„ë¦¬ë˜ì–´ ë™ì  ì§€í‘œê°€ NULLë¡œ ë‚¨ëŠ” ë¬¸ì œ ë°œìƒ
    
    ê°œì„ ëœ ì €ì¥ ì „ëµ:
    1. OHLCV ê¸°ë³¸ ë°ì´í„° + ëª¨ë“  ì§€í‘œë¥¼ í•˜ë‚˜ì˜ INSERT ë¬¸ìœ¼ë¡œ ì›ìì  ì €ì¥
    2. static_indicatorsëŠ” ìµœì‹  1ê°œ ë ˆì½”ë“œë§Œ UPSERT (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
    3. íŠ¸ëœì­ì…˜ ë³´ì¥ ë° ì‹¤íŒ¨ ì‹œ ë¡¤ë°±
    4. ì†Œìˆ˜ì  ì œí•œ ì ìš© ë° ë°ì´í„° ê²€ì¦
    """
    try:
        if df_with_indicators is None or df_with_indicators.empty:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  ì§€í‘œ ë°ì´í„° ì—†ìŒ")
            return False

        total_records = len(df_with_indicators)
        start_time = time.time()
        
        logger.info(f"ğŸ”„ {ticker} ìµœì í™”ëœ ì§€í‘œ ì €ì¥ ì‹œì‘: {total_records:,}ê°œ ë ˆì½”ë“œ")
        
        # ì €ì¥ ì „ ìµœì¢… ë°ì´í„° ê²€ì¦ (ì†Œìˆ˜ì  ì œí•œ ì—†ìŒ)
        logger.info(f"ğŸ”¢ {ticker} DB ì €ì¥ ì „ ìµœì¢… ë°ì´í„° ê²€ì¦")
        
        # ğŸ”§ [í•µì‹¬ ìˆ˜ì •] ìŠ¤ëª°ìº¡ ì½”ì¸ ì •ë°€ë„ ë³´ì¡´ - ì†Œìˆ˜ì  ì œí•œ ì œê±°
        logger.info(f"ğŸ”¢ {ticker} ìŠ¤ëª°ìº¡ ì½”ì¸ ì •ë°€ë„ ë³´ì¡´ - ì†Œìˆ˜ì  ì œí•œ ì œê±°")
        df_final = df_with_indicators.copy()
        
        # ì¶”ê°€ ê²€ì¦: ì¤‘ìš” ì»¬ëŸ¼ë“¤ì˜ ë°ì´í„° í’ˆì§ˆ í™•ì¸
        critical_columns = ['open', 'high', 'low', 'close', 'rsi_14', 'ma_20', 'ma_50', 'ma_200', 
                           'bb_upper', 'bb_lower', 'macd_histogram']
        
        for col in critical_columns:
            if col in df_final.columns:
                if col == 'volume':
                    # ê±°ë˜ëŸ‰ì€ ì •ìˆ˜ë¡œ ë³€í™˜
                    df_final[col] = df_final[col].round(0).astype('int64')
                else:
                    # ğŸ“ ê¸°íƒ€ ì§€í‘œ ê²€ì¦ (ì†Œìˆ˜ì  ì œí•œ ì—†ìŒ - ìŠ¤ëª°ìº¡ ì½”ì¸ ì§€ì›)
                    if df_final[col].isna().any():
                        logger.warning(f"  âš ï¸ {col}: NaN ê°’ í¬í•¨ë¨")
                logger.debug(f"  âœ… {col} ë°ì´í„° ê²€ì¦ ì™„ë£Œ (ì •ë°€ë„ ë³´ì¡´)")
        
        logger.info(f"âœ… {ticker} ë°ì´í„° ê²€ì¦ ì™„ë£Œ (ì†Œìˆ˜ì  ì œí•œ ì—†ìŒ)")
        
        conn = get_db_connection()
        
        # ğŸ”§ [2ë‹¨ê³„ í•µì‹¬ ìˆ˜ì •] 1ë‹¨ê³„: OHLCV ê¸°ë³¸ ë°ì´í„° + ë™ì  ì§€í‘œ í†µí•© INSERT
        logger.info(f"ğŸ”„ {ticker} OHLCV + ë™ì  ì§€í‘œ í†µí•© ì €ì¥ ì‹œì‘")
        ohlcv_success = save_ohlcv_with_indicators_unified(conn, ticker, df_final)
        
        # 2ë‹¨ê³„: static_indicators ì €ì¥ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
        logger.info(f"ğŸ”„ {ticker} static_indicators ì €ì¥ ì‹œì‘")
        latest_row = df_final.iloc[-1]
        
        # ğŸ“ ì •ì  ì§€í‘œ ê°’ë“¤ ê²€ì¦ (ì†Œìˆ˜ì  ì œí•œì€ DB INSERT ì¿¼ë¦¬ì—ì„œ ì²˜ë¦¬)
        static_columns = ['nvt_relative', 'volume_change_7_30', 'close', 
                         'high_60', 'low_60', 'pivot', 's1', 'r1', 
                         'resistance', 'support', 'atr', 'adx', 'supertrend_signal']
        
        for col in static_columns:
            if col in latest_row.index and col != 'supertrend_signal':  # ë¬¸ìì—´ ì»¬ëŸ¼ ì œì™¸
                value = latest_row.get(col)
                if value is None or pd.isna(value):
                    logger.warning(f"  âš ï¸ static {col}: ê°’ì´ None ë˜ëŠ” NaN")
                else:
                    logger.debug(f"  âœ… static {col}: ë°ì´í„° ê²€ì¦ í†µê³¼")
        
        static_success = save_static_indicators(conn, ticker, latest_row)
        
        # ìµœì¢… ì„±ëŠ¥ ìš”ì•½
        total_elapsed = time.time() - start_time
        
        if ohlcv_success and static_success:
            logger.info(f"âœ… {ticker} í†µí•© ì›ìì  ì €ì¥ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ)")
            logger.info(f"ğŸ“Š ì„±ëŠ¥: {total_records/total_elapsed:.1f} records/sec")
            return True
        else:
            logger.warning(f"âš ï¸ {ticker} ë¶€ë¶„ ì €ì¥ ì™„ë£Œ (ohlcv: {ohlcv_success}, static: {static_success})")
            logger.info(f"â±ï¸ ì†Œìš”ì‹œê°„: {total_elapsed:.1f}ì´ˆ")
            return False
            
    except Exception as e:
        logger.error(f"âŒ {ticker} í†µí•© ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False

def save_ohlcv_with_indicators_unified(conn, ticker, df_with_indicators):
    """
    ğŸ”§ [2ë‹¨ê³„ ì‹ ê·œ] OHLCV ê¸°ë³¸ ë°ì´í„° + ë™ì  ì§€í‘œë¥¼ í•œ ë²ˆì— INSERTí•˜ëŠ” í†µí•© í•¨ìˆ˜
    
    ê¸°ì¡´ ë¬¸ì œ:
    - save_ohlcv_to_db()ë¡œ ê¸°ë³¸ ë°ì´í„°ë§Œ INSERT í›„ UPDATEë¡œ ë™ì  ì§€í‘œ ì¶”ê°€
    - UPDATE ì‹¤íŒ¨ ì‹œ ë™ì  ì§€í‘œê°€ NULLë¡œ ë‚¨ìŒ
    
    í•´ê²°ì±…:
    - ëª¨ë“  ì»¬ëŸ¼ì„ í•œ ë²ˆì˜ INSERT ë¬¸ìœ¼ë¡œ ì €ì¥
    - ON CONFLICT DO UPDATEë¡œ ì¤‘ë³µ ì²˜ë¦¬
    - ì›ìì  íŠ¸ëœì­ì…˜ ë³´ì¥
    """
    try:
        cursor = conn.cursor()
        cursor.execute("BEGIN")
        
        # ohlcv í…Œì´ë¸”ì˜ ì‹¤ì œ ì»¬ëŸ¼ í™•ì¸
        cursor.execute("""
            SELECT column_name FROM information_schema.columns 
            WHERE table_name = 'ohlcv' 
            AND table_schema = 'public'
            ORDER BY ordinal_position
        """)
        available_columns = [row[0] for row in cursor.fetchall()]
        
        # ê¸°ë³¸ OHLCV ì»¬ëŸ¼
        base_columns = ['ticker', 'date', 'open', 'high', 'low', 'close', 'volume']
        
        # ë™ì  ì§€í‘œ ì»¬ëŸ¼ (í…Œì´ë¸”ì— ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ)
        dynamic_indicator_columns = [
            'fibo_618', 'fibo_382', 'ht_trendline', 'ma_20', 'ma_50', 'ma_200', 
            'bb_upper', 'bb_lower', 'donchian_high', 'donchian_low', 
            'macd_histogram', 'rsi_14', 'volume_20ma', 'volume_ratio', 'stoch_k', 'stoch_d', 'cci'
        ]
        
        # DataFrameì— ì¡´ì¬í•˜ê³  í…Œì´ë¸”ì—ë„ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        insert_columns = []
        for col in base_columns + dynamic_indicator_columns:
            if col in available_columns:
                if col in ['ticker', 'date'] or col in df_with_indicators.columns:
                    insert_columns.append(col)
        
        if not insert_columns:
            logger.error(f"âŒ {ticker} ì €ì¥í•  ìœ íš¨í•œ ì»¬ëŸ¼ì´ ì—†ìŒ")
            cursor.execute("ROLLBACK")
            return False
        
        logger.info(f"ğŸ” {ticker} ì €ì¥ ëŒ€ìƒ ì»¬ëŸ¼ ({len(insert_columns)}ê°œ): {insert_columns}")
        
        # ğŸš€ [4ë‹¨ê³„ í•µì‹¬ ìˆ˜ì •] INSERT ì¿¼ë¦¬ ìƒì„± - ROUND í•¨ìˆ˜ ì œê±°í•˜ì—¬ ìŠ¤ëª°ìº¡ ì§€ì›
        placeholders = ', '.join(['%s'] * len(insert_columns))
        update_clauses = []
        
        for col in insert_columns:
            if col not in ['ticker', 'date']:  # ê¸°ë³¸í‚¤ëŠ” UPDATEí•˜ì§€ ì•ŠìŒ
                # ëª¨ë“  ìˆ˜ì¹˜ ì»¬ëŸ¼ì—ì„œ ROUND í•¨ìˆ˜ ì œê±° - ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ëŠ” Pythonì—ì„œ ìˆ˜í–‰
                update_clauses.append(f"{col} = EXCLUDED.{col}")
        
        update_clause = ', '.join(update_clauses) if update_clauses else 'open = EXCLUDED.open'
        
        insert_query = f"""
            INSERT INTO ohlcv ({', '.join(insert_columns)})
            VALUES ({placeholders})
            ON CONFLICT (ticker, date) DO UPDATE SET {update_clause}
        """
        
        # ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
        batch_data = []
        for position, (index, row) in enumerate(df_with_indicators.iterrows()):
            # ê°„ë‹¨í•œ ë‚ ì§œ ë³€í™˜ (ohlcv í…Œì´ë¸” date ì»¬ëŸ¼ìœ¼ë¡œ ì¶©ë¶„)
            try:
                if hasattr(index, 'strftime'):
                    date_str = index.strftime('%Y-%m-%d')
                elif hasattr(index, 'date'):
                    date_str = index.date().strftime('%Y-%m-%d')
                else:
                    date_str = str(pd.to_datetime(index).date())
            except Exception as e:
                logger.warning(f"âš ï¸ {ticker} ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: {e}, ê±´ë„ˆëœ€")
                continue
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ ê±´ë„ˆë›°ê¸°
            if date_str in ["N/A", "Invalid Date", "1970-01-01"]:
                continue
            
            # ê° ì»¬ëŸ¼ì˜ ê°’ ì¤€ë¹„
            row_values = []
            for col in insert_columns:
                if col == 'ticker':
                    row_values.append(ticker)
                elif col == 'date':
                    row_values.append(date_str)
                else:
                    value = row.get(col)
                    # ğŸ”§ [4ë‹¨ê³„ í•µì‹¬ ìˆ˜ì •] NaN ê°’ ì²˜ë¦¬ ë° ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ê°œì„  - 0ê°’ ë°©ì§€ ê°•í™”
                    if pd.isna(value):
                        # ë™ì  ì§€í‘œëŠ” ê³„ì‚° ê°€ëŠ¥í•œ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´, 0ê°’ ì™„ì „ ë°©ì§€
                        close_price = row.get('close')
                        
                        if col in ['rsi_14']:
                            # RSIëŠ” ì´ì „ ìœ íš¨ê°’ ë˜ëŠ” ì¤‘ë¦½ê°’ ì‚¬ìš©
                            prev_rsi = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    prev_rsi = prev_values.iloc[-1]
                            processed_value = prev_rsi if prev_rsi and prev_rsi > 0 else 50.0
                            
                        elif col in ['ma_50', 'ma_200']:
                            # ì´ë™í‰ê· ì€ ì´ì „ ìœ íš¨ê°’ â†’ í˜„ì¬ ì¢…ê°€ â†’ ìµœì†Œ ìœ íš¨ê°’ ìˆœìœ¼ë¡œ ëŒ€ì²´
                            processed_value = None
                            
                            # 1ìˆœìœ„: ì´ì „ ìœ íš¨ê°’ ì‚¬ìš©
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    prev_ma = prev_values.iloc[-1]
                                    if prev_ma and prev_ma > 0:
                                        processed_value = prev_ma
                            
                            # 2ìˆœìœ„: í˜„ì¬ ì¢…ê°€ ì‚¬ìš©
                            if processed_value is None and close_price and not pd.isna(close_price) and close_price > 0:
                                processed_value = close_price
                            
                            # 3ìˆœìœ„: ìµœì†Œ ìœ íš¨ê°’ (0ê°’ ë°©ì§€)
                            if processed_value is None or processed_value <= 0:
                                processed_value = 1e-8  # ìµœì†Œ ì˜ë¯¸ìˆëŠ” ê°’
                                
                        elif col in ['bb_upper', 'bb_lower']:
                            # ë³¼ë¦°ì € ë°´ë“œëŠ” ì¢…ê°€ ê¸°ë°˜ ì¶”ì •ê°’ (0ê°’ ë°©ì§€)
                            if close_price and not pd.isna(close_price) and close_price > 0:
                                if col == 'bb_upper':
                                    processed_value = close_price * 1.02  # +2%
                                else:
                                    processed_value = close_price * 0.98  # -2%
                            else:
                                processed_value = 1e-6  # ìµœì†Œ ìœ íš¨ê°’
                                
                        elif col in ['macd_histogram']:
                            # MACDëŠ” ì´ì „ ìœ íš¨ê°’ ë˜ëŠ” ìµœì†Œê°’ ì‚¬ìš© (0ê°’ ë°©ì§€)
                            processed_value = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    processed_value = prev_values.iloc[-1]
                            
                            if processed_value is None:
                                processed_value = 1e-8  # ìµœì†Œ ìœ íš¨ê°’
                                
                        elif col in ['volume_20ma']:
                            # ê±°ë˜ëŸ‰ í‰ê· ì€ í˜„ì¬ ê±°ë˜ëŸ‰ ë˜ëŠ” ì´ì „ ìœ íš¨ê°’ ì‚¬ìš©
                            current_volume = row.get('volume', 0)
                            if current_volume and current_volume > 0:
                                processed_value = current_volume
                            else:
                                # ì´ì „ ìœ íš¨ê°’ ì‚¬ìš©
                                if len(df_with_indicators) > 1:
                                    prev_values = df_with_indicators[col].dropna()
                                    if not prev_values.empty:
                                        processed_value = prev_values.iloc[-1]
                                    else:
                                        processed_value = 1000  # ìµœì†Œ ê±°ë˜ëŸ‰
                                else:
                                    processed_value = 1000
                                    
                        elif col in ['donchian_high', 'donchian_low']:
                            # ë„ì¹˜ì•ˆ ì±„ë„ì€ í˜„ì¬ ê°€ê²© ê¸°ë°˜ ì¶”ì •
                            if close_price and not pd.isna(close_price) and close_price > 0:
                                if col == 'donchian_high':
                                    processed_value = close_price * 1.05  # +5%
                                else:
                                    processed_value = close_price * 0.95  # -5%
                            else:
                                processed_value = 1e-6
                                
                        elif col in ['stoch_k', 'stoch_d']:
                            # ìŠ¤í† ìºìŠ¤í‹±ì€ ì´ì „ ìœ íš¨ê°’ ë˜ëŠ” ì¤‘ë¦½ê°’ ì‚¬ìš©
                            processed_value = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    processed_value = prev_values.iloc[-1]
                            
                            if processed_value is None or processed_value <= 0:
                                processed_value = 50.0  # ì¤‘ë¦½ê°’
                                
                        elif col in ['cci']:
                            # CCIëŠ” ì´ì „ ìœ íš¨ê°’ ë˜ëŠ” ì¤‘ë¦½ê°’ ì‚¬ìš©
                            processed_value = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    processed_value = prev_values.iloc[-1]
                            
                            if processed_value is None:
                                processed_value = 1e-6  # ìµœì†Œ ìœ íš¨ê°’
                                
                        else:
                            # ğŸš¨ ê¸°íƒ€ ì§€í‘œëŠ” ì´ì „ ìœ íš¨ê°’ ìš°ì„ , 0ê°’ ì™„ì „ ë°©ì§€
                            processed_value = None
                            if len(df_with_indicators) > 1:
                                prev_values = df_with_indicators[col].dropna()
                                if not prev_values.empty:
                                    prev_val = prev_values.iloc[-1]
                                    if prev_val and prev_val != 0:
                                        processed_value = prev_val
                            
                            # ì´ì „ ê°’ë„ ì—†ìœ¼ë©´ ìµœì†Œ ìœ íš¨ê°’ ì‚¬ìš©
                            if processed_value is None or processed_value == 0:
                                processed_value = 1e-8  # ìµœì†Œ ì˜ë¯¸ìˆëŠ” ê°’
                                
                        # ğŸ”§ [í•µì‹¬ ìµœì¢… ìˆ˜ì •] OHLCV ê°€ê²© ë°ì´í„° 0ê°’ ë°©ì§€ ë¡œì§ ì™„ì „ ì œê±°
                        # ìŠ¤ëª°ìº¡ ì½”ì¸ì˜ ê·¹ì†Œ ê°€ê²©(ì†Œìˆ˜ì  8ìë¦¬) ì™„ì „ ë³´ì¡´
                        if col in ['open', 'high', 'low', 'close']:
                            # ê°€ê²© ë°ì´í„°ëŠ” ì›ë³¸ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš© (0ê°’ ë°©ì§€ ë¡œì§ ì™„ì „ ì œì™¸)
                            processed_value = value if value is not None else None
                            if processed_value is None:
                                # Noneì¸ ê²½ìš°ì—ë§Œ ê±´ë„ˆë›°ê¸°, 0ì€ ìœ íš¨í•œ ê°€ê²© ë°ì´í„°ë¡œ ë³´ì¡´
                                continue
                        elif col == 'volume':
                            # ê±°ë˜ëŸ‰ì€ ì •ìˆ˜ë¡œ ì²˜ë¦¬, 0 í—ˆìš©
                            processed_value = int(value) if value is not None else 0
                        else:
                            # ê¸°íƒ€ ì§€í‘œë§Œ 0ê°’ ë°©ì§€ ê²€ì¦ ì ìš© (ë³¼ë¥¨ ì œì™¸)
                            if processed_value == 0:
                                processed_value = 1e-8
                                logger.warning(f"âš ï¸ {ticker} {col}: 0ê°’ ë°©ì§€ë¥¼ ìœ„í•´ ìµœì†Œê°’ ì ìš©")
                            
                    else:
                        processed_value = value
                    
                    # ğŸš€ [4ë‹¨ê³„ í•µì‹¬ ì¶”ê°€] ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬ ì ìš©
                    if col == 'volume' or 'volume' in col.lower():
                        # ê±°ë˜ëŸ‰ì€ ì •ìˆ˜ë¡œ ì²˜ë¦¬
                        row_values.append(int(processed_value) if processed_value else 0)
                    elif isinstance(processed_value, (int, float)):
                        # ìˆ˜ì¹˜ ë°ì´í„°ëŠ” ì ì‘í˜• ì†Œìˆ˜ì  ì²˜ë¦¬
                        row_values.append(_common_adaptive_decimal_rounding(processed_value))
                    else:
                        # ê¸°íƒ€ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ
                        row_values.append(processed_value)
            
            batch_data.append(tuple(row_values))
        
        if batch_data:
            cursor.executemany(insert_query, batch_data)
            inserted_count = cursor.rowcount
            logger.info(f"âœ… {ticker} OHLCV + ë™ì  ì§€í‘œ í†µí•© ì €ì¥: {inserted_count}ê°œ ë ˆì½”ë“œ")
        else:
            logger.warning(f"âš ï¸ {ticker} ì €ì¥í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŒ")
            
        cursor.execute("COMMIT")
        return True
        
    except Exception as e:
        cursor.execute("ROLLBACK")
        logger.error(f"âŒ {ticker} í†µí•© OHLCV ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


def compress_for_length(analysis_data: dict, max_length: int) -> dict:
    """
    ë¬¸ìì—´ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ëŠ” í•¨ìˆ˜ (tiktoken ë°±ì—…ìš©)
    
    Args:
        analysis_data (dict): ì›ë³¸ ë¶„ì„ ë°ì´í„°
        max_length (int): ëª©í‘œ ë¬¸ìì—´ ê¸¸ì´
        
    Returns:
        dict: ì••ì¶•ëœ ë¶„ì„ ë°ì´í„°
    """
    import copy
    import json
    compressed_data = copy.deepcopy(analysis_data)
    
    # OHLCV ë°ì´í„° ì••ì¶•
    ohlcv_data = compressed_data.get('ohlcv_with_dynamic_indicators', [])
    
    while len(json.dumps(compressed_data, ensure_ascii=False, default=str)) > max_length and len(ohlcv_data) > 5:
        ohlcv_data.pop(0)
        compressed_data['ohlcv_with_dynamic_indicators'] = ohlcv_data
    
    # summary ì—…ë°ì´íŠ¸
    compressed_data['summary']['total_days'] = len(ohlcv_data)
    if ohlcv_data:
        compressed_data['summary']['date_range'] = f"{ohlcv_data[0]['date']} to {ohlcv_data[-1]['date']}"
    
    return compressed_data


def log_quality_summary():
    """3ë‹¨ê³„: ì „ì²´ ë°ì´í„° í’ˆì§ˆ ìš”ì•½ ë¡œê·¸ ì¶œë ¥"""
    try:
        summary = data_quality_monitor.get_quality_summary()
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ ìš”ì•½ ë¦¬í¬íŠ¸")
        logger.info("=" * 60)
        logger.info(f"ğŸ” API í˜¸ì¶œ í†µê³„:")
        logger.info(f"   - ì´ API í˜¸ì¶œ: {summary['total_api_calls']}íšŒ")
        logger.info(f"   - 1970-01-01 ì—ëŸ¬ìœ¨: {summary['api_1970_error_rate']:.1f}%")
        
        logger.info(f"ğŸ“ˆ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° í†µê³„:")
        logger.info(f"   - ì´ ì§€í‘œ ê³„ì‚°: {summary['total_indicator_calculations']}íšŒ")
        logger.info(f"   - ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨ìœ¨: {summary['indicator_failure_rate']:.1f}%")
        
        logger.info(f"ğŸ’¾ DB ì—…ë°ì´íŠ¸ í†µê³„:")
        logger.info(f"   - ì´ DB ì—…ë°ì´íŠ¸: {summary['total_db_updates']}ê±´")
        logger.info(f"   - DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ìœ¨: {summary['db_failure_rate']:.1f}%")
        
        # í’ˆì§ˆ ë“±ê¸‰ ì‚°ì •
        overall_score = 100 - (summary['api_1970_error_rate'] + summary['indicator_failure_rate'] + summary['db_failure_rate']) / 3
        
        if overall_score >= 90:
            grade = "A+ (ìš°ìˆ˜)"
            icon = "ğŸ†"
        elif overall_score >= 80:
            grade = "A (ì–‘í˜¸)"
            icon = "âœ…"
        elif overall_score >= 70:
            grade = "B (ë³´í†µ)"
            icon = "âš ï¸"
        else:
            grade = "C (ê°œì„  í•„ìš”)"
            icon = "ğŸš¨"
            
        logger.info(f"{icon} ì „ì²´ ë°ì´í„° í’ˆì§ˆ ë“±ê¸‰: {grade} ({overall_score:.1f}ì )")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ í’ˆì§ˆ ìš”ì•½ ë¡œê·¸ ì¶œë ¥ ì‹¤íŒ¨: {str(e)}")


# ==================== ë™ì  ì§€í‘œ ë°±í•„ë§ í•¨ìˆ˜ë“¤ ====================

def backfill_static_indicators_new_columns():
    """
    ğŸ”§ [NEW] ê¸°ì¡´ static_indicators ë°ì´í„°ì— ëŒ€í•´ ìƒˆë¡œ ì¶”ê°€ëœ ì»¬ëŸ¼ë“¤(rsi_14, ma20, volume_ratio, volume)ì„ ë°±í•„í•˜ëŠ” í•¨ìˆ˜
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. static_indicators í…Œì´ë¸”ì˜ ëª¨ë“  í‹°ì»¤ì— ëŒ€í•´ ohlcv ë°ì´í„°ì—ì„œ ëˆ„ë½ëœ ì§€í‘œë“¤ ê³„ì‚°
    2. ê³„ì‚°ëœ ê°’ë“¤ì„ static_indicators í…Œì´ë¸”ì— ì—…ë°ì´íŠ¸
    3. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    """
    try:
        logger.info("ğŸ”„ static_indicators ìƒˆ ì»¬ëŸ¼ ë°±í•„ ì‹œì‘...")
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # 1. static_indicators í…Œì´ë¸”ì˜ ëª¨ë“  í‹°ì»¤ ì¡°íšŒ
        cursor.execute("SELECT DISTINCT ticker FROM static_indicators")
        tickers = [row[0] for row in cursor.fetchall()]
        
        logger.info(f"ğŸ“Š ì´ {len(tickers)}ê°œ í‹°ì»¤ì— ëŒ€í•´ ë°±í•„ ì§„í–‰")
        
        success_count = 0
        error_count = 0
        
        for i, ticker in enumerate(tickers, 1):
            try:
                logger.info(f"ğŸ”„ [{i}/{len(tickers)}] {ticker} ë°±í•„ ì§„í–‰...")
                
                # 2. í•´ë‹¹ í‹°ì»¤ì˜ ohlcv ë°ì´í„° ì¡°íšŒ (ìµœê·¼ 200ì¼)
                ohlcv_df = get_ohlcv_from_db(ticker, limit=200)
                
                if ohlcv_df is None or ohlcv_df.empty:
                    logger.warning(f"âš ï¸ {ticker}: OHLCV ë°ì´í„° ì—†ìŒ - ê±´ë„ˆëœ€")
                    continue
                
                # 3. ëˆ„ë½ëœ ì§€í‘œë“¤ ê³„ì‚°
                # RSI 14
                ohlcv_df['rsi_14'] = safe_calculate_indicator(
                    lambda: ta.rsi(ohlcv_df['close'], length=14),
                    indicator_name="rsi_14"
                )
                
                # MA20
                ohlcv_df['ma_20'] = safe_calculate_indicator(
                    lambda: ta.sma(ohlcv_df['close'], length=20),
                    indicator_name="ma_20"
                )
                
                # Volume Ratio
                ohlcv_df['volume_ratio'] = safe_calculate_indicator(
                    lambda: ohlcv_df['volume'] / ohlcv_df['volume'].rolling(window=20, min_periods=10).mean(),
                    indicator_name="volume_ratio"
                )
                
                # 4. ìµœì‹  ê°’ ì¶”ì¶œ
                latest_row = ohlcv_df.iloc[-1]
                
                rsi_14_val = _common_adaptive_decimal_rounding(latest_row.get('rsi_14'))
                ma20_val = _common_adaptive_decimal_rounding(latest_row.get('ma_20'))
                volume_ratio_val = _common_adaptive_decimal_rounding(latest_row.get('volume_ratio', 1.0))
                volume_val = _common_adaptive_decimal_rounding(latest_row.get('volume', 0))
                
                # 5. static_indicators í…Œì´ë¸” ì—…ë°ì´íŠ¸
                cursor.execute("""
                    UPDATE static_indicators 
                    SET rsi_14 = %s, ma20 = %s, volume_ratio = %s, volume = %s, updated_at = CURRENT_TIMESTAMP
                    WHERE ticker = %s
                """, (rsi_14_val, ma20_val, volume_ratio_val, volume_val, ticker))
                
                success_count += 1
                logger.info(f"âœ… {ticker} ë°±í•„ ì™„ë£Œ: RSI={rsi_14_val:.2f}, MA20={ma20_val:.2f}, VolRatio={volume_ratio_val:.2f}")
                
                # 6. ì§„í–‰ë¥  í‘œì‹œ (10ê°œë§ˆë‹¤)
                if i % 10 == 0:
                    logger.info(f"ğŸ“Š ì§„í–‰ë¥ : {i}/{len(tickers)} ({i/len(tickers)*100:.1f}%)")
                
            except Exception as e:
                error_count += 1
                logger.error(f"âŒ {ticker} ë°±í•„ ì‹¤íŒ¨: {e}")
                continue
        
        conn.commit()
        logger.info(f"âœ… ë°±í•„ ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {error_count}ê°œ")
        
        return {
            'success_count': success_count,
            'error_count': error_count,
            'total_count': len(tickers)
        }
        
    except Exception as e:
        logger.error(f"âŒ ë°±í•„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        if conn:
            conn.rollback()
        raise
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def backfill_single_ticker_indicators(ticker: str, start_date: str, end_date: str = None):
    """
    ë‹¨ì¼ í‹°ì»¤ì˜ ë™ì  ì§€í‘œë¥¼ íŠ¹ì • ê¸°ê°„ì— ëŒ€í•´ ì¬ê³„ì‚°í•˜ì—¬ ì—…ë°ì´íŠ¸
    
    Args:
        ticker (str): ë°±í•„ë§í•  í‹°ì»¤ (ì˜ˆ: 'KRW-XRP')
        start_date (str): ì‹œì‘ì¼ (ì˜ˆ: '2023-10-21')
        end_date (str): ì¢…ë£Œì¼ (Noneì´ë©´ í˜„ì¬ê¹Œì§€)
    
    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        from datetime import datetime, timedelta
        
        logger.info(f"ğŸ”„ {ticker} ë™ì  ì§€í‘œ ë°±í•„ë§ ì‹œì‘: {start_date} ~ {end_date or 'í˜„ì¬'}")
        
        # 1. ì¶©ë¶„í•œ ê¸°ê°„ì˜ OHLCV ë°ì´í„° ì¡°íšŒ (ê³„ì‚°ì„ ìœ„í•´ ë” ê¸´ ê¸°ê°„ í•„ìš”)
        df = get_ohlcv_d(ticker, count=600, force_fetch=False)
        
        if df is None or df.empty:
            logger.error(f"âŒ {ticker} OHLCV ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
            return False
            
        logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        
        # 2. ë™ì  ì§€í‘œ ê³„ì‚°
        df_with_indicators = calculate_unified_indicators(df, ticker)
        
        if df_with_indicators is None or df_with_indicators.empty:
            logger.error(f"âŒ {ticker} ë™ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨")
            return False
            
        logger.info(f"âœ… {ticker} ë™ì  ì§€í‘œ ê³„ì‚° ì™„ë£Œ")
        
        # 3. ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ë§Œ í•„í„°ë§
        start_dt = pd.to_datetime(start_date)
        end_dt = pd.to_datetime(end_date) if end_date else pd.Timestamp.now()
        
        mask = (df_with_indicators.index >= start_dt) & (df_with_indicators.index <= end_dt)
        df_filtered = df_with_indicators[mask]
        
        if df_filtered.empty:
            logger.warning(f"âš ï¸ {ticker} ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ì— ë°ì´í„° ì—†ìŒ")
            return False
            
        logger.info(f"âœ… {ticker} ë°±í•„ë§ ëŒ€ìƒ: {len(df_filtered)}ê°œ ë ˆì½”ë“œ")
        
        # 4. ë°±í•„ë§ ì‹¤í–‰ (save_all_indicators_atomically ì‚¬ìš©)
        result = save_all_indicators_atomically(ticker, df_filtered)
        
        if result:
            logger.info(f"âœ… {ticker} ë™ì  ì§€í‘œ ë°±í•„ë§ ì™„ë£Œ")
            return True
        else:
            logger.error(f"âŒ {ticker} ë™ì  ì§€í‘œ ë°±í•„ë§ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        logger.error(f"âŒ {ticker} ë°±í•„ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


def enhanced_ohlcv_processor(ticker: str, df: pd.DataFrame, data_source: str = "api") -> bool:
    """
    ğŸ”§ ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
    
    í†µí•©ëœ OHLCV ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œìœ¼ë¡œ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µ:
    1. ë°ì´í„° ê²€ì¦ ë° ì •ì œ
    2. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
    3. DB ì €ì¥ (atomic operation)
    4. í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
    
    Args:
        ticker (str): ì²˜ë¦¬í•  í‹°ì»¤
        df (pd.DataFrame): OHLCV ë°ì´í„°í”„ë ˆì„
        data_source (str): ë°ì´í„° ì†ŒìŠ¤ ("api", "db", "file" ë“±)
    
    Returns:
        bool: ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
    """
    try:
        logger.info(f"ğŸ”„ {ticker} ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # 1. ë°ì´í„° ê²€ì¦
        if df is None or df.empty:
            logger.warning(f"âš ï¸ {ticker} ì²˜ë¦¬í•  OHLCV ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # 2. ë°ì´í„° ì •ì œ
        df_cleaned = _filter_invalid_ohlcv_data(df, ticker)
        if df_cleaned is None or df_cleaned.empty:
            logger.error(f"âŒ {ticker} ë°ì´í„° ì •ì œ í›„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        # 3. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        df_with_indicators = calculate_unified_indicators(df_cleaned, ticker)
        if df_with_indicators is None or df_with_indicators.empty:
            logger.error(f"âŒ {ticker} ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨")
            return False
        
        # 4. í†µí•© ì €ì¥ (atomic operation)
        save_success = save_all_indicators_atomically(ticker, df_with_indicators)
        
        if save_success:
            logger.info(f"âœ… {ticker} ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            return True
        else:
            logger.error(f"âŒ {ticker} ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        logger.error(f"âŒ {ticker} ê°•í™”ëœ OHLCV ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False


def generate_gpt_analysis_json(ticker: str, days: int = 200) -> str:
    """
    GPT ë¶„ì„ìš© JSON ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        ticker (str): ë¶„ì„í•  í‹°ì»¤ (ì˜ˆ: "KRW-BTC")
        days (int): ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸ê°’: 200ì¼)
    
    Returns:
        str: GPT ë¶„ì„ìš© JSON ë¬¸ìì—´ ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    try:
        # í‹°ì»¤ í˜•ì‹ ì •ê·œí™”
        if not ticker.startswith("KRW-"):
            ticker = f"KRW-{ticker}"
        
        logger.info(f"ğŸ“Š {ticker} GPT ë¶„ì„ìš© JSON ë°ì´í„° ìƒì„± ì‹œì‘ (ê¸°ê°„: {days}ì¼)")
        
        # OHLCV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        ohlcv_df = get_ohlcv_from_db(ticker, limit=days)
        if ohlcv_df is None or ohlcv_df.empty:
            logger.warning(f"âš ï¸ {ticker} OHLCV ë°ì´í„° ì—†ìŒ")
            return None
        
        # ìµœì‹  static indicators ê°€ì ¸ì˜¤ê¸°
        static_indicators = {}
        try:
            with get_db_connection_context() as conn:
                static_query = """
                    SELECT * FROM static_indicators 
                    WHERE ticker = %s 
                    ORDER BY updated_at DESC 
                    LIMIT 1
                """
                cursor = conn.cursor()
                cursor.execute(static_query, (ticker,))
                static_row = cursor.fetchone()
                
                if static_row:
                    # ì»¬ëŸ¼ëª… ê°€ì ¸ì˜¤ê¸°
                    cursor.execute("SELECT column_name FROM information_schema.columns WHERE table_name = 'static_indicators' ORDER BY ordinal_position")
                    columns = [row[0] for row in cursor.fetchall()]
                    
                    # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                    static_indicators = dict(zip(columns, static_row))
                    
                    # ë¶ˆí•„ìš”í•œ ë©”íƒ€ë°ì´í„° ì œê±°
                    for key in ['id', 'ticker', 'created_at', 'updated_at']:
                        static_indicators.pop(key, None)
                else:
                    logger.warning(f"âš ï¸ {ticker} static indicators ë°ì´í„° ì—†ìŒ")
        except Exception as e:
            logger.error(f"âŒ {ticker} static indicators ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # OHLCV ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        ohlcv_list = []
        for index, row in ohlcv_df.iterrows():
            ohlcv_entry = {
                "date": index.strftime("%Y-%m-%d") if hasattr(index, 'strftime') else str(index),
                "open": _common_adaptive_decimal_rounding(row.get('open', 0)),
                "high": _common_adaptive_decimal_rounding(row.get('high', 0)),
                "low": _common_adaptive_decimal_rounding(row.get('low', 0)),
                "close": _common_adaptive_decimal_rounding(row.get('close', 0)),
                "volume": _common_adaptive_decimal_rounding(row.get('volume', 0))
            }
            
            # ë™ì  ì§€í‘œë“¤ë„ í¬í•¨ (ìˆëŠ” ê²½ìš°)
            for col in ['rsi_14', 'bb_upper', 'bb_middle', 'bb_lower', 'macd', 'macd_signal', 'macd_histogram']:
                if col in row and pd.notna(row[col]):
                    ohlcv_entry[col] = _common_adaptive_decimal_rounding(row[col])
            
            ohlcv_list.append(ohlcv_entry)
        
        # ìµœì¢… JSON êµ¬ì¡° ìƒì„±
        analysis_data = {
            "ticker": ticker,
            "period_days": days,
            "data_points": len(ohlcv_list),
            "ohlcv": ohlcv_list[-days:],  # ìµœê·¼ Nì¼ ë°ì´í„°ë§Œ
            "static_indicators": static_indicators,
            "generated_at": datetime.now().isoformat()
        }
        
        # JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        import json
        json_str = json.dumps(analysis_data, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… {ticker} GPT ë¶„ì„ìš© JSON ìƒì„± ì™„ë£Œ (í¬ê¸°: {len(json_str):,} bytes)")
        return json_str
        
    except Exception as e:
        logger.error(f"âŒ {ticker} GPT ë¶„ì„ìš© JSON ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


def generate_gpt_analysis_json_conditional(ticker: str, days: int = 200, db_manager=None, config: dict = None) -> str:
    """
    ì¡°ê±´ë¶€ë¡œ GPT ë¶„ì„ìš© JSON ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        ticker: ë¶„ì„í•  í‹°ì»¤
        days: ë¶„ì„ ê¸°ê°„
        db_manager: DBManager ì¸ìŠ¤í„´ìŠ¤
        config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
    
    Returns:
        str: JSON ë¬¸ìì—´ ë˜ëŠ” None (ìƒëµ ì‹œ)
    """
    if config is None:
        config = {
            'skip_json_if_fresh_analysis': True,
            'max_age_minutes': 720,
            'enable_caching': True
        }
    
    # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸
    if db_manager and config.get('skip_json_if_fresh_analysis', True):
        from trend_analyzer import check_gpt_analysis_freshness
        
        freshness_check = check_gpt_analysis_freshness(
            ticker, db_manager, config.get('max_age_minutes', 720)
        )
        
        if freshness_check['exists'] and freshness_check['is_fresh']:
            logger.info(f"â­ï¸ {ticker} ì‹ ì„ í•œ ë¶„ì„ ê²°ê³¼ ì¡´ì¬, JSON ìƒì„± ìƒëµ")
            return None
    
    # ê¸°ì¡´ JSON ìƒì„± ë¡œì§ ì‹¤í–‰
    return generate_gpt_analysis_json(ticker, days)

def _calculate_enhanced_adx(df, ticker):
    """ADX ê³„ì‚° ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê³„ì‚° (ì‹¤ì œ ë³€ë™ì„± ê¸°ë°˜)"""
    try:
        if len(df) < 14:
            return pd.Series([25.0] * len(df), index=df.index)
        
        # True Range ê³„ì‚°
        high_low = df['high'] - df['low']
        high_close_prev = abs(df['high'] - df['close'].shift(1))
        low_close_prev = abs(df['low'] - df['close'].shift(1))
        
        true_range = pd.concat([high_low, high_close_prev, low_close_prev], axis=1).max(axis=1)
        
        # ATR ê³„ì‚°
        atr = true_range.rolling(window=14, min_periods=1).mean()
        
        # ê°€ê²© ë³€ë™ë¥  ê¸°ë°˜ ADX ê·¼ì‚¬ì¹˜ ê³„ì‚°
        price_change = abs(df['close'].pct_change())
        normalized_change = price_change / (atr / df['close'])
        
        # ADX ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§ (0-100)
        adx_proxy = normalized_change.rolling(window=14, min_periods=1).mean() * 100
        adx_proxy = adx_proxy.clip(lower=0, upper=100)
        
        # ì‹¤ì œ ë³€ë™ì„±ì— ê¸°ë°˜í•œ ê°’ ë³´ì¥
        adx_proxy = adx_proxy.fillna(25.0)
        
        logger.debug(f"âœ… {ticker} ëŒ€ì²´ ADX ê³„ì‚° ì™„ë£Œ: í‰ê· ={adx_proxy.mean():.1f}")
        return adx_proxy
        
    except Exception as e:
        logger.warning(f"âš ï¸ {ticker} ëŒ€ì²´ ADX ê³„ì‚° ì‹¤íŒ¨: {e}")
        return pd.Series([25.0] * len(df), index=df.index)

def _calculate_simple_trend_signal(df):
    """ê°„ë‹¨í•œ ì¶”ì„¸ ì‹ í˜¸ ê³„ì‚° (supertrend ëŒ€ì²´)"""
    try:
        if len(df) < 20:
            return 'neutral'
        
        # í˜„ì¬ê°€ì™€ 20ì¼ ì´ë™í‰ê·  ë¹„êµ
        ma20 = df['close'].rolling(window=20, min_periods=10).mean()
        current_price = df['close'].iloc[-1]
        current_ma20 = ma20.iloc[-1]
        
        if pd.notna(current_ma20) and current_price > current_ma20:
            # ì¶”ê°€ ì¡°ê±´: ìµœê·¼ 3ì¼ ìƒìŠ¹ ì¶”ì„¸ í™•ì¸
            recent_trend = df['close'].iloc[-3:].is_monotonic_increasing
            return 'bull' if recent_trend else 'neutral'
        elif pd.notna(current_ma20) and current_price < current_ma20:
            # ì¶”ê°€ ì¡°ê±´: ìµœê·¼ 3ì¼ í•˜ë½ ì¶”ì„¸ í™•ì¸
            recent_trend = df['close'].iloc[-3:].is_monotonic_decreasing
            return 'bear' if recent_trend else 'neutral'
        else:
            return 'neutral'
            
    except Exception as e:
        logger.warning(f"âš ï¸ ê°„ë‹¨í•œ ì¶”ì„¸ ì‹ í˜¸ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return 'neutral'

def convert_supertrend_to_signal(close_price, supertrend_value):
    """Supertrend ê°’ì„ ì‹ í˜¸ë¡œ ë³€í™˜"""
    try:
        if pd.isna(close_price) or pd.isna(supertrend_value):
            return None
        
        # ê°€ê²©ì´ Supertrend ìœ„ì— ìˆìœ¼ë©´ bull, ì•„ë˜ë©´ bear
        if close_price > supertrend_value:
            return 'bull'
        elif close_price < supertrend_value:
            return 'bear'
        else:
            return 'neutral'
    except Exception as e:
        logger.warning(f"âš ï¸ Supertrend ì‹ í˜¸ ë³€í™˜ ì‹¤íŒ¨: {e}")
        return 'neutral'

