#!/usr/bin/env python3
"""
AWS Lambda í•¨ìˆ˜: Makenaide í‹°ì»¤ ìŠ¤ìºë„ˆ (AsyncPG ìµœì í™” ë²„ì „)
ê¸°ëŠ¥: Upbit REST API ì§ì ‘ í˜¸ì¶œ â†’ ì‹ ê·œ í‹°ì»¤ ê°ì§€ â†’ DB ì—…ë°ì´íŠ¸ â†’ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ â†’ ê±°ë˜ëŸ‰ í•„í„°ë§ â†’ SQS ì „ì†¡

ìµœê³  ìµœì í™” ë‚´ìš©:
- asyncpg ì‚¬ìš© (psycopg2 ëŒ€ì‹ ) - 0 ì˜ì¡´ì„±, 3ë°° ë¹ ë¥¸ ì„±ëŠ¥
- pyupbit ì˜ì¡´ì„± ì œê±° (ì§ì ‘ HTTP ìš”ì²­ìœ¼ë¡œ ëŒ€ì²´)
- pandas, numpy, pytz ë“± ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°
- ì™„ì „í•œ ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
- ìµœì†Œí•œì˜ dependenciesë§Œ ì‚¬ìš© (asyncpg, aiohttp)
"""

import json
import boto3
import logging
import os
import asyncio
import aiohttp
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
sqs = boto3.client('sqs')

# Upbit API ì—”ë“œí¬ì¸íŠ¸
UPBIT_API_BASE = "https://api.upbit.com/v1"
UPBIT_MARKET_ALL_URL = f"{UPBIT_API_BASE}/market/all"

async def get_db_connection():
    """PostgreSQL DB ì—°ê²° - asyncpg ì‚¬ìš© (ê²½ëŸ‰í™”ëœ ë¹„ë™ê¸° ë°©ì‹)"""
    try:
        # asyncpg ë™ì  import
        import asyncpg
    except ImportError as e:
        logger.error(f"asyncpg import ì‹¤íŒ¨: {e}")
        raise Exception("asyncpgê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    try:
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
        pg_host = os.environ.get('PG_HOST', 'makenaide.cni2ka4ugf7f.ap-northeast-2.rds.amazonaws.com')
        pg_port = int(os.environ.get('PG_PORT', '5432'))
        pg_database = os.environ.get('PG_DATABASE', 'makenaide')
        pg_user = os.environ.get('PG_USER', 'bruce')
        pg_password = os.environ.get('PG_PASSWORD')
        
        if not pg_password:
            raise Exception("PG_PASSWORD í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        logger.info(f"DB ì—°ê²° ì‹œë„: {pg_host}:{pg_port}/{pg_database}")
        
        # asyncpgë¡œ ë¹„ë™ê¸° ì—°ê²° ìƒì„±
        connection = await asyncpg.connect(
            host=pg_host,
            port=pg_port,
            database=pg_database,
            user=pg_user,
            password=pg_password,
            command_timeout=10
        )
        return connection
        
    except Exception as e:
        logger.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        raise

async def get_upbit_krw_tickers() -> List[str]:
    """
    ë¹„ë™ê¸° HTTP ìš”ì²­ìœ¼ë¡œ Upbit KRW ë§ˆì¼“ í‹°ì»¤ ëª©ë¡ ì¡°íšŒ
    aiohttp ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
    """
    try:
        logger.info("ğŸ“¡ Upbit REST APIë¡œ ë§ˆì¼“ ì •ë³´ ì¡°íšŒ ì¤‘... (ë¹„ë™ê¸°)")
        
        async with aiohttp.ClientSession() as session:
            async with session.get(UPBIT_MARKET_ALL_URL, timeout=aiohttp.ClientTimeout(total=10)) as response:
                response.raise_for_status()
                markets_data = await response.json()
        
        # KRW ë§ˆì¼“ë§Œ í•„í„°ë§
        krw_tickers = [
            market['market'] for market in markets_data 
            if market['market'].startswith('KRW-')
        ]
        
        logger.info(f"âœ… Upbit REST APIì—ì„œ {len(krw_tickers)}ê°œ KRW í‹°ì»¤ ì¡°íšŒ ì™„ë£Œ (ë¹„ë™ê¸°)")
        return krw_tickers
        
    except aiohttp.ClientError as e:
        logger.error(f"âŒ Upbit API ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise Exception(f"Upbit API í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
    except (ValueError, KeyError) as e:
        logger.error(f"âŒ Upbit API ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        raise Exception(f"Upbit API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {str(e)}")

async def load_blacklist_from_db(connection) -> Dict[str, Any]:
    """DBì—ì„œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ (ë¹„ë™ê¸°)"""
    try:
        rows = await connection.fetch("SELECT ticker, reason FROM blacklist WHERE is_active = true")
        
        blacklist = {}
        for row in rows:
            blacklist[row['ticker']] = row['reason']
            
        logger.info(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ: {len(blacklist)}ê°œ (ë¹„ë™ê¸°)")
        return blacklist
        
    except Exception as e:
        logger.error(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

async def update_tickers():
    """
    ìµœê³  ìµœì í™”ëœ ë¹„ë™ê¸° í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    - asyncpgë¡œ ì„±ëŠ¥ ìµœì í™”
    - ì™„ì „í•œ ë¹„ë™ê¸° ì²˜ë¦¬
    """
    connection = None
    try:
        logger.info("ğŸ”„ í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘ (AsyncPG ìµœì í™” ë²„ì „)")
        
        # DB ì—°ê²°
        connection = await get_db_connection()
        
        # ë³‘ë ¬ ì²˜ë¦¬: ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œì™€ í‹°ì»¤ ì¡°íšŒ ë™ì‹œ ì‹¤í–‰
        blacklist_task = load_blacklist_from_db(connection)
        tickers_task = get_upbit_krw_tickers()
        
        blacklist, current_tickers = await asyncio.gather(blacklist_task, tickers_task)
        
        if not current_tickers:
            logger.error("âŒ Upbit API í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨")
            return False, "Upbit API í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨"

        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” í‹°ì»¤ ì œì™¸
        filtered_tickers = [ticker for ticker in current_tickers if ticker not in blacklist]
        if len(filtered_tickers) != len(current_tickers):
            blacklisted = set(current_tickers) - set(filtered_tickers)
            logger.info(f"â›”ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì œì™¸ í‹°ì»¤: {sorted(blacklisted)}")

        # ê¸°ì¡´ í‹°ì»¤ ì¡°íšŒ (ë¹„ë™ê¸°)
        existing_rows = await connection.fetch("SELECT ticker, updated_at FROM tickers")
        existing_ticker_times = {row['ticker']: row['updated_at'] for row in existing_rows}

        logger.info(f"ğŸ“Š DBì— ê¸°ì¡´ í‹°ì»¤ {len(existing_ticker_times)}ê°œ ì¡´ì¬")

        # íŠ¸ëœì­ì…˜ ì‹œì‘
        async with connection.transaction():
            # ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‹°ì»¤ DBì—ì„œ ì‚­ì œ
            blacklisted_tickers = set(existing_ticker_times.keys()) & set(blacklist.keys())
            if blacklisted_tickers:
                await connection.executemany(
                    "DELETE FROM tickers WHERE ticker = $1",
                    [(ticker,) for ticker in blacklisted_tickers]
                )
                logger.info(f"ğŸ—‘ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‹°ì»¤ DBì—ì„œ ì‚­ì œ: {sorted(blacklisted_tickers)}")

            # ì‹ ê·œ í‹°ì»¤ ì¶”ê°€ (ë°°ì¹˜ ì²˜ë¦¬)
            new_tickers = set(filtered_tickers) - set(existing_ticker_times.keys())
            if new_tickers:
                await connection.executemany(
                    "INSERT INTO tickers (ticker, created_at) VALUES ($1, CURRENT_TIMESTAMP)",
                    [(ticker,) for ticker in new_tickers]
                )
                logger.info(f"ğŸ‰ ì‹ ê·œ í‹°ì»¤ ê°ì§€ ë° ì¶”ê°€ë¨: {sorted(new_tickers)}")

            # ê¸°ì¡´ í‹°ì»¤ ì—…ë°ì´íŠ¸ (24ì‹œê°„ ì´ìƒ ì§€ë‚œ ê²½ìš°) - ë°°ì¹˜ ì²˜ë¦¬
            update_threshold = datetime.now() - timedelta(hours=24)
            tickers_to_update = []
            
            for ticker in filtered_tickers:
                if ticker in existing_ticker_times:
                    last_update = existing_ticker_times[ticker]
                    if last_update < update_threshold:
                        tickers_to_update.append((ticker,))
            
            if tickers_to_update:
                await connection.executemany(
                    "UPDATE tickers SET updated_at = CURRENT_TIMESTAMP WHERE ticker = $1",
                    tickers_to_update
                )
                
            updated_count = len(tickers_to_update)

        logger.info(f"âœ… í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ - ì‹ ê·œ: {len(new_tickers)}ê°œ, ì—…ë°ì´íŠ¸: {updated_count}ê°œ")
        
        return True, {
            'total_api_tickers': len(current_tickers),
            'filtered_tickers': len(filtered_tickers),
            'new_tickers': len(new_tickers),
            'updated_tickers': updated_count,
            'blacklisted_removed': len(blacklisted_tickers)
        }

    except Exception as e:
        logger.error(f"âŒ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False, str(e)
    
    finally:
        if connection:
            await connection.close()

async def get_active_tickers() -> List[str]:
    """í™œì„± í‹°ì»¤ ëª©ë¡ ì¡°íšŒ (ë¹„ë™ê¸°)"""
    connection = None
    try:
        connection = await get_db_connection()
        
        # ë¹„ë™ê¸° ì¿¼ë¦¬ ì‹¤í–‰
        rows = await connection.fetch("""
            SELECT ticker 
            FROM tickers 
            WHERE is_active = true
            ORDER BY ticker
        """)
        
        tickers = [row['ticker'] for row in rows]
        
        logger.info(f"í™œì„± í‹°ì»¤ ì¡°íšŒ ì™„ë£Œ: {len(tickers)}ê°œ (ë¹„ë™ê¸°)")
        return tickers
        
    except Exception as e:
        logger.error(f"í™œì„± í‹°ì»¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        # í´ë°±: ëª¨ë“  í‹°ì»¤ ì¡°íšŒ
        try:
            if connection:
                rows = await connection.fetch("SELECT DISTINCT ticker FROM tickers ORDER BY ticker")
                tickers = [row['ticker'] for row in rows]
                logger.info(f"í´ë°±ìœ¼ë¡œ ì „ì²´ í‹°ì»¤ ì¡°íšŒ: {len(tickers)}ê°œ")
                return tickers
        except:
            pass
        return []
        
    finally:
        if connection:
            await connection.close()

async def filter_by_volume(tickers: List[str]) -> List[str]:
    """ê±°ë˜ëŸ‰ ê¸°ë°˜ í•„í„°ë§ (ë¹„ë™ê¸° ë°°ì¹˜ ìµœì í™”)"""
    connection = None
    try:
        connection = await get_db_connection()
        
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì„±ëŠ¥ ìµœì í™”ëœ ì¿¼ë¦¬
        query = """
            SELECT ticker, AVG(volume * close) as avg_trading_value
            FROM ohlcv 
            WHERE ticker = ANY($1::text[])
            AND date >= CURRENT_DATE - INTERVAL '7 days'
            GROUP BY ticker
            HAVING AVG(volume * close) >= 100000000
        """
        
        rows = await connection.fetch(query, tickers)
        filtered_tickers = [row['ticker'] for row in rows]
        
        logger.info(f"ê±°ë˜ëŸ‰ í•„í„°ë§ ì™„ë£Œ: {len(filtered_tickers)}ê°œ (ì „ì²´: {len(tickers)}ê°œ, ë¹„ë™ê¸°)")
        return filtered_tickers
        
    except Exception as e:
        logger.error(f"ê±°ë˜ëŸ‰ í•„í„°ë§ ì‹¤íŒ¨: {e}")
        return tickers  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
        
    finally:
        if connection:
            await connection.close()

def send_to_sqs(tickers: List[str], queue_url: str):
    """SQSì— í‹°ì»¤ ëª©ë¡ ì „ì†¡ (ë°°ì¹˜ ìµœì í™”)"""
    try:
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì „ì†¡ (10ê°œì”©)
        batch_size = 10
        
        for i in range(0, len(tickers), batch_size):
            batch = tickers[i:i + batch_size]
            
            entries = []
            for j, ticker in enumerate(batch):
                entries.append({
                    'Id': str(i + j),
                    'MessageBody': json.dumps({
                        'ticker': ticker,
                        'timestamp': datetime.now().isoformat(),
                        'source': 'ticker_scanner_asyncpg'
                    })
                })
            
            response = sqs.send_message_batch(
                QueueUrl=queue_url,
                Entries=entries
            )
            
            logger.info(f"SQS ì „ì†¡ ì™„ë£Œ: {len(entries)}ê°œ (ë°°ì¹˜ {i//batch_size + 1})")
            
        logger.info(f"ì „ì²´ SQS ì „ì†¡ ì™„ë£Œ: {len(tickers)}ê°œ í‹°ì»¤")
        
    except Exception as e:
        logger.error(f"SQS ì „ì†¡ ì‹¤íŒ¨: {e}")
        raise

async def async_main():
    """ë¹„ë™ê¸° ë©”ì¸ ë¡œì§"""
    try:
        logger.info("ğŸš€ Makenaide AsyncPG ìµœì í™” í‹°ì»¤ ìŠ¤ìºë„ˆ ì‹œì‘")
        start_time = datetime.now()
        
        # 1. í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ (ìµœê³  ìµœì í™”ëœ ë¹„ë™ê¸° ì²˜ë¦¬)
        update_success, update_result = await update_tickers()
        if not update_success:
            logger.error(f"âŒ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_result}")
            return {
                'statusCode': 500,
                'body': json.dumps({
                    'error': f'í‹°ì»¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_result}',
                    'timestamp': datetime.now().isoformat(),
                    'version': 'asyncpg_optimized'
                })
            }
        
        # 2. ë³‘ë ¬ ì²˜ë¦¬: í™œì„± í‹°ì»¤ ì¡°íšŒì™€ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ë™ì‹œ ì‹¤í–‰
        tickers_task = get_active_tickers()
        
        tickers = await tickers_task
        
        if not tickers:
            logger.warning("í™œì„± í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'message': 'í™œì„± í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤',
                    'update_result': update_result,
                    'processed_count': 0,
                    'version': 'asyncpg_optimized'
                })
            }
        
        # 3. ê±°ë˜ëŸ‰ í•„í„°ë§ (ë¹„ë™ê¸° ìµœì í™”)
        volume_filtered = await filter_by_volume(tickers)
        
        # 4. SQS ì „ì†¡
        queue_url = os.environ.get('OHLCV_QUEUE_URL')
        if queue_url and volume_filtered:
            send_to_sqs(volume_filtered, queue_url)
        
        # 5. ê²°ê³¼ ë°˜í™˜
        execution_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'AsyncPG ìµœì í™” í‹°ì»¤ ìŠ¤ìºë‹ ì™„ë£Œ',
                'update_result': update_result,
                'total_db_tickers': len(tickers),
                'volume_filtered': len(volume_filtered),
                'execution_time': execution_time,
                'timestamp': datetime.now().isoformat(),
                'version': 'asyncpg_optimized',
                'optimizations': [
                    'pyupbit â†’ direct HTTP requests with aiohttp',
                    'psycopg2 â†’ asyncpg (3x faster, 0 dependencies)',
                    'removed pandas/numpy dependencies',
                    'full async processing',
                    'batch SQL operations',
                    'parallel task execution'
                ]
            })
        }
        
        logger.info(f"âœ… AsyncPG ìµœì í™” í‹°ì»¤ ìŠ¤ìºë‹ ì™„ë£Œ: {len(volume_filtered)}ê°œ í‹°ì»¤ ì²˜ë¦¬ ({execution_time:.2f}ì´ˆ)")
        return result
        
    except Exception as e:
        logger.error(f"âŒ AsyncPG ìµœì í™” í‹°ì»¤ ìŠ¤ìºë‹ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'version': 'asyncpg_optimized'
            })
        }

def lambda_handler(event, context):
    """Lambda ë©”ì¸ í•¸ë“¤ëŸ¬ - asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰"""
    # Lambdaì—ì„œ ë¹„ë™ê¸° ì½”ë“œ ì‹¤í–‰
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    try:
        return loop.run_until_complete(async_main())
    finally:
        loop.close() 