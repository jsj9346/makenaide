#!/usr/bin/env python3
"""
AWS Lambda í•¨ìˆ˜: Makenaide í‹°ì»¤ ìŠ¤ìºë„ˆ (ìµœì í™” ë²„ì „)
ê¸°ëŠ¥: Upbit REST API ì§ì ‘ í˜¸ì¶œ â†’ ì‹ ê·œ í‹°ì»¤ ê°ì§€ â†’ DB ì—…ë°ì´íŠ¸ â†’ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ â†’ ê±°ë˜ëŸ‰ í•„í„°ë§ â†’ SQS ì „ì†¡

ìµœì í™” ë‚´ìš©:
- pyupbit ì˜ì¡´ì„± ì œê±° (ì§ì ‘ HTTP ìš”ì²­ìœ¼ë¡œ ëŒ€ì²´)
- pandas, numpy, pytz ë“± ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°
- ìµœì†Œí•œì˜ dependenciesë§Œ ì‚¬ìš© (requests, psycopg2-binary, boto3)
"""

import json
import boto3
import logging
import os
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
sqs = boto3.client('sqs')

# Upbit API ì—”ë“œí¬ì¸íŠ¸
UPBIT_API_BASE = "https://api.upbit.com/v1"
UPBIT_MARKET_ALL_URL = f"{UPBIT_API_BASE}/market/all"

def get_db_connection():
    """PostgreSQL DB ì—°ê²° - psycopg2ë¥¼ ë™ì ìœ¼ë¡œ import"""
    try:
        # ë™ì  importë¡œ psycopg2 ê°€ì ¸ì˜¤ê¸°
        import psycopg2
        import psycopg2.extras
    except ImportError as e:
        logger.error(f"psycopg2 import ì‹¤íŒ¨: {e}")
        raise Exception("psycopg2ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    try:
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
        pg_host = os.environ.get('PG_HOST', 'makenaide.cni2ka4ugf7f.ap-northeast-2.rds.amazonaws.com')
        pg_port = int(os.environ.get('PG_PORT', '5432'))
        pg_database = os.environ.get('PG_DATABASE', 'makenaide')
        pg_user = os.environ.get('PG_USER', 'bruce')
        pg_password = os.environ.get('PG_PASSWORD')
        
        if not pg_password:
            raise Exception("PG_PASSWORD í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        logger.info(f"DB ì—°ê²° ì‹œë„: {pg_host}:{pg_port}/{pg_database}")
        
        conn = psycopg2.connect(
            host=pg_host,
            port=pg_port,
            database=pg_database,
            user=pg_user,
            password=pg_password,
            connect_timeout=10
        )
        return conn
    except Exception as e:
        logger.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        raise

def get_upbit_krw_tickers() -> List[str]:
    """
    Upbit REST APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ KRW ë§ˆì¼“ í‹°ì»¤ ëª©ë¡ ì¡°íšŒ
    pyupbit.get_tickers(fiat="KRW") ê¸°ëŠ¥ì„ ì§ì ‘ HTTP ìš”ì²­ìœ¼ë¡œ ëŒ€ì²´
    """
    try:
        logger.info("ğŸ“¡ Upbit REST APIë¡œ ë§ˆì¼“ ì •ë³´ ì¡°íšŒ ì¤‘...")
        
        # HTTP GET ìš”ì²­ (ì¸ì¦ ë¶ˆí•„ìš”)
        response = requests.get(UPBIT_MARKET_ALL_URL, timeout=10)
        response.raise_for_status()
        
        markets_data = response.json()
        
        # KRW ë§ˆì¼“ë§Œ í•„í„°ë§
        krw_tickers = [
            market['market'] for market in markets_data 
            if market['market'].startswith('KRW-')
        ]
        
        logger.info(f"âœ… Upbit REST APIì—ì„œ {len(krw_tickers)}ê°œ KRW í‹°ì»¤ ì¡°íšŒ ì™„ë£Œ")
        return krw_tickers
        
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ Upbit API ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise Exception(f"Upbit API í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
    except (ValueError, KeyError) as e:
        logger.error(f"âŒ Upbit API ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
        raise Exception(f"Upbit API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜: {str(e)}")

def load_blacklist_from_db() -> Dict[str, Any]:
    """DBì—ì„œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("SELECT ticker, reason FROM blacklist WHERE is_active = true")
        results = cursor.fetchall()
        
        blacklist = {}
        for ticker, reason in results:
            blacklist[ticker] = reason
            
        cursor.close()
        conn.close()
        
        logger.info(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ: {len(blacklist)}ê°œ")
        return blacklist
        
    except Exception as e:
        logger.error(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def update_tickers():
    """
    ìµœì í™”ëœ í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    - pyupbit ëŒ€ì‹  ì§ì ‘ HTTP ìš”ì²­ ì‚¬ìš©
    - ê²½ëŸ‰í™”ëœ ë¡œì§ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
    """
    try:
        logger.info("ğŸ”„ í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘ (ìµœì í™” ë²„ì „)")
        
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        blacklist = load_blacklist_from_db()
        if not blacklist:
            logger.warning("âš ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ë¹„ì–´ìˆìŒ")
            blacklist = {}

        # í˜„ì¬ ê±°ë˜ ê°€ëŠ¥í•œ í‹°ì»¤ ëª©ë¡ ì¡°íšŒ (ì§ì ‘ HTTP ìš”ì²­)
        current_tickers = get_upbit_krw_tickers()
        if not current_tickers:
            logger.error("âŒ Upbit API í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨")
            return False, "Upbit API í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨"

        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” í‹°ì»¤ ì œì™¸
        filtered_tickers = [ticker for ticker in current_tickers if ticker not in blacklist]
        if len(filtered_tickers) != len(current_tickers):
            blacklisted = set(current_tickers) - set(filtered_tickers)
            logger.info(f"â›”ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì œì™¸ í‹°ì»¤: {sorted(blacklisted)}")

        # DB ì—°ê²°
        conn = get_db_connection()
        cursor = conn.cursor()

        try:
            # ê¸°ì¡´ í‹°ì»¤ ì¡°íšŒ
            cursor.execute("SELECT ticker, updated_at FROM tickers")
            existing_rows = cursor.fetchall()
            existing_ticker_times = {row[0]: row[1] for row in existing_rows}

            logger.info(f"ğŸ“Š DBì— ê¸°ì¡´ í‹°ì»¤ {len(existing_ticker_times)}ê°œ ì¡´ì¬")

            # ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‹°ì»¤ DBì—ì„œ ì‚­ì œ
            blacklisted_tickers = set(existing_ticker_times.keys()) & set(blacklist.keys())
            if blacklisted_tickers:
                for ticker in blacklisted_tickers:
                    cursor.execute("DELETE FROM tickers WHERE ticker = %s", (ticker,))
                conn.commit()
                logger.info(f"ğŸ—‘ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‹°ì»¤ DBì—ì„œ ì‚­ì œ: {sorted(blacklisted_tickers)}")

            # ì‹ ê·œ í‹°ì»¤ ì¶”ê°€ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì œì™¸)
            new_tickers = set(filtered_tickers) - set(existing_ticker_times.keys())
            if new_tickers:
                for new_ticker in new_tickers:
                    cursor.execute(
                        "INSERT INTO tickers (ticker, created_at) VALUES (%s, CURRENT_TIMESTAMP)",
                        (new_ticker,)
                    )
                conn.commit()
                logger.info(f"ğŸ‰ ì‹ ê·œ í‹°ì»¤ ê°ì§€ ë° ì¶”ê°€ë¨: {sorted(new_tickers)}")

            # ê¸°ì¡´ í‹°ì»¤ ì—…ë°ì´íŠ¸ (24ì‹œê°„ ì´ìƒ ì§€ë‚œ ê²½ìš°)
            update_threshold = datetime.now() - timedelta(hours=24)
            updated_count = 0
            for ticker in filtered_tickers:
                if ticker in existing_ticker_times:
                    last_update = existing_ticker_times[ticker]
                    if last_update < update_threshold:
                        try:
                            cursor.execute("""
                                UPDATE tickers
                                SET updated_at = CURRENT_TIMESTAMP
                                WHERE ticker = %s
                            """, (ticker,))
                            updated_count += 1
                        except Exception as e:
                            logger.error(f"âŒ {ticker} ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
                            continue

            conn.commit()
            logger.info(f"âœ… í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ - ì‹ ê·œ: {len(new_tickers)}ê°œ, ì—…ë°ì´íŠ¸: {updated_count}ê°œ")
            
            return True, {
                'total_api_tickers': len(current_tickers),
                'filtered_tickers': len(filtered_tickers),
                'new_tickers': len(new_tickers),
                'updated_tickers': updated_count,
                'blacklisted_removed': len(blacklisted_tickers)
            }

        except Exception as e:
            conn.rollback()
            logger.error(f"âŒ DB ì‘ì—… ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise

        finally:
            cursor.close()
            conn.close()

    except Exception as e:
        logger.error(f"âŒ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False, str(e)

def get_active_tickers() -> List[str]:
    """í™œì„± í‹°ì»¤ ëª©ë¡ ì¡°íšŒ (DBì—ì„œ)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # tickers í…Œì´ë¸”ì—ì„œ is_activeê°€ trueì¸ í‹°ì»¤ë“¤ë§Œ ì¡°íšŒ
        cursor.execute("""
            SELECT ticker 
            FROM tickers 
            WHERE is_active = true
            ORDER BY ticker
        """)
        
        tickers = [row[0] for row in cursor.fetchall()]
        
        cursor.close()
        conn.close()
        
        logger.info(f"í™œì„± í‹°ì»¤ ì¡°íšŒ ì™„ë£Œ: {len(tickers)}ê°œ")
        return tickers
        
    except Exception as e:
        logger.error(f"í™œì„± í‹°ì»¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        # í´ë°±: ëª¨ë“  í‹°ì»¤ ì¡°íšŒ
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT DISTINCT ticker FROM tickers ORDER BY ticker")
            tickers = [row[0] for row in cursor.fetchall()]
            cursor.close()
            conn.close()
            logger.info(f"í´ë°±ìœ¼ë¡œ ì „ì²´ í‹°ì»¤ ì¡°íšŒ: {len(tickers)}ê°œ")
            return tickers
        except:
            return []

def filter_by_volume(tickers: List[str]) -> List[str]:
    """ê±°ë˜ëŸ‰ ê¸°ë°˜ í•„í„°ë§ (ê²½ëŸ‰í™” ë²„ì „)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        filtered_tickers = []
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
        batch_size = 10
        for i in range(0, len(tickers), batch_size):
            batch = tickers[i:i + batch_size]
            
            # IN ì ˆì„ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ì—¬ëŸ¬ í‹°ì»¤ ì¡°íšŒ
            placeholders = ','.join(['%s'] * len(batch))
            query = f"""
                SELECT ticker, AVG(volume * close) as avg_trading_value
                FROM ohlcv 
                WHERE ticker IN ({placeholders})
                AND date >= CURRENT_DATE - INTERVAL '7 days'
                GROUP BY ticker
                HAVING AVG(volume * close) >= 100000000
            """
            
            cursor.execute(query, batch)
            results = cursor.fetchall()
            
            for row in results:
                filtered_tickers.append(row[0])
        
        cursor.close()
        conn.close()
        
        logger.info(f"ê±°ë˜ëŸ‰ í•„í„°ë§ ì™„ë£Œ: {len(filtered_tickers)}ê°œ (ì „ì²´: {len(tickers)}ê°œ)")
        return filtered_tickers
        
    except Exception as e:
        logger.error(f"ê±°ë˜ëŸ‰ í•„í„°ë§ ì‹¤íŒ¨: {e}")
        return tickers  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜

def send_to_sqs(tickers: List[str], queue_url: str):
    """SQSì— í‹°ì»¤ ëª©ë¡ ì „ì†¡ (ë°°ì¹˜ ìµœì í™”)"""
    try:
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì „ì†¡ (10ê°œì”©)
        batch_size = 10
        
        for i in range(0, len(tickers), batch_size):
            batch = tickers[i:i + batch_size]
            
            entries = []
            for j, ticker in enumerate(batch):
                entries.append({
                    'Id': str(i + j),
                    'MessageBody': json.dumps({
                        'ticker': ticker,
                        'timestamp': datetime.now().isoformat(),
                        'source': 'ticker_scanner_optimized'
                    })
                })
            
            response = sqs.send_message_batch(
                QueueUrl=queue_url,
                Entries=entries
            )
            
            logger.info(f"SQS ì „ì†¡ ì™„ë£Œ: {len(entries)}ê°œ (ë°°ì¹˜ {i//batch_size + 1})")
            
        logger.info(f"ì „ì²´ SQS ì „ì†¡ ì™„ë£Œ: {len(tickers)}ê°œ í‹°ì»¤")
        
    except Exception as e:
        logger.error(f"SQS ì „ì†¡ ì‹¤íŒ¨: {e}")
        raise

def lambda_handler(event, context):
    """ìµœì í™”ëœ Lambda ë©”ì¸ í•¸ë“¤ëŸ¬ - ë””ë²„ê¹… ê°•í™” ë²„ì „"""
    try:
        logger.info("ğŸš€ Makenaide ìµœì í™” í‹°ì»¤ ìŠ¤ìºë„ˆ ì‹œì‘")
        start_time = datetime.now()
        
        # 0. ê°„ë‹¨í•œ DB ì—°ê²° í…ŒìŠ¤íŠ¸
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM tickers")
            existing_count = cursor.fetchone()[0]
            cursor.close()
            conn.close()
            logger.info(f"ğŸ”— DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ, ê¸°ì¡´ í‹°ì»¤ ìˆ˜: {existing_count}")
        except Exception as e:
            logger.error(f"âŒ DB ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return {
                'statusCode': 500,
                'body': json.dumps({
                    'error': f'DB ì—°ê²° ì‹¤íŒ¨: {str(e)}',
                    'timestamp': datetime.now().isoformat()
                })
            }
        
        # 1. í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ (ìµœì í™”ëœ HTTP ìš”ì²­ ì‚¬ìš©)
        logger.info("ğŸ“¡ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì‹œì‘...")
        update_success, update_result = update_tickers()
        
        if not update_success:
            logger.error(f"âŒ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_result}")
            return {
                'statusCode': 500,
                'body': json.dumps({
                    'error': f'í‹°ì»¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_result}',
                    'timestamp': datetime.now().isoformat(),
                    'version': 'optimized_debug'
                })
            }
        
        logger.info(f"âœ… í‹°ì»¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {update_result}")
        
        # 2. í™œì„± í‹°ì»¤ ì¡°íšŒ (DBì—ì„œ)
        logger.info("ğŸ” í™œì„± í‹°ì»¤ ì¡°íšŒ ì‹œì‘...")
        tickers = get_active_tickers()
        logger.info(f"ğŸ“Š í™œì„± í‹°ì»¤ ì¡°íšŒ ê²°ê³¼: {len(tickers)}ê°œ")
        
        if not tickers:
            logger.warning("âš ï¸ í™œì„± í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'message': 'DB ì—°ê²° ì„±ê³µ',
                    'ticker_count': 0,
                    'update_result': update_result,
                    'warning': 'í™œì„± í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤',
                    'timestamp': datetime.now().isoformat(),
                    'version': 'optimized_debug'
                })
            }
        
        # 3. ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ (ì¶”ê°€ í•„í„°ë§)
        logger.info("â›”ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ ì‹œì‘...")
        blacklist = load_blacklist_from_db()
        filtered_tickers = [t for t in tickers if t not in blacklist]
        
        logger.info(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ í•„í„°ë§: {len(tickers)} â†’ {len(filtered_tickers)}")
        
        # 4. ê±°ë˜ëŸ‰ í•„í„°ë§ (ìµœì í™”ëœ ë°°ì¹˜ ì²˜ë¦¬)
        logger.info("ğŸ“ˆ ê±°ë˜ëŸ‰ í•„í„°ë§ ì‹œì‘...")
        volume_filtered = filter_by_volume(filtered_tickers)
        logger.info(f"ê±°ë˜ëŸ‰ í•„í„°ë§ ì™„ë£Œ: {len(volume_filtered)}ê°œ")
        
        # 5. SQS ì „ì†¡ (ì„ íƒì‚¬í•­)
        queue_url = os.environ.get('OHLCV_QUEUE_URL')
        if queue_url and volume_filtered:
            logger.info(f"ğŸ“¤ SQS ì „ì†¡ ì‹œì‘: {len(volume_filtered)}ê°œ í‹°ì»¤")
            send_to_sqs(volume_filtered, queue_url)
            logger.info("âœ… SQS ì „ì†¡ ì™„ë£Œ")
        else:
            logger.info("ğŸ“¤ SQS ì „ì†¡ ê±´ë„ˆëœ€ (í URL ì—†ìŒ ë˜ëŠ” í•„í„°ë§ëœ í‹°ì»¤ ì—†ìŒ)")
        
        # 6. ê²°ê³¼ ë°˜í™˜
        execution_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'DB ì—°ê²° ì„±ê³µ',
                'ticker_count': len(volume_filtered),
                'update_result': update_result,
                'total_db_tickers': len(tickers),
                'blacklist_filtered': len(filtered_tickers),
                'volume_filtered': len(volume_filtered),
                'execution_time': execution_time,
                'timestamp': datetime.now().isoformat(),
                'version': 'optimized_debug'
            })
        }
        
        logger.info(f"âœ… ìµœì í™”ëœ í‹°ì»¤ ìŠ¤ìºë‹ ì™„ë£Œ: {len(volume_filtered)}ê°œ í‹°ì»¤ ì²˜ë¦¬ ({execution_time:.2f}ì´ˆ)")
        return result
        
    except Exception as e:
        logger.error(f"âŒ ìµœì í™”ëœ í‹°ì»¤ ìŠ¤ìºë‹ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e),
                'timestamp': datetime.now().isoformat(),
                'version': 'optimized_debug'
            })
        } 