#!/usr/bin/env python3
"""
ê²°ê³¼ í íƒ€ì„ì•„ì›ƒ ì„¤ì • ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸

SQS ê²°ê³¼ íì˜ visibility timeoutì„ Lambda í•¨ìˆ˜ timeoutë³´ë‹¤ í¬ê²Œ ì„¤ì •í•˜ê³ 
SQS íŠ¸ë¦¬ê±°ë¥¼ ë‹¤ì‹œ ì„¤ì •í•©ë‹ˆë‹¤.
"""

import boto3
import logging
import time

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

def fix_result_queue_timeout():
    """ê²°ê³¼ í íƒ€ì„ì•„ì›ƒ ì„¤ì • ìˆ˜ì •"""
    try:
        sqs_client = boto3.client('sqs', region_name='ap-northeast-2')
        lambda_client = boto3.client('lambda', region_name='ap-northeast-2')
        
        resource_prefix = "makenaide-distributed-backtest"
        result_queue_name = f"{resource_prefix}-result-queue"
        collector_function = "makenaide-backtest-result-collector"
        
        logger.info("ğŸ”§ ê²°ê³¼ í íƒ€ì„ì•„ì›ƒ ì„¤ì • ìˆ˜ì • ì‹œì‘")
        
        # 1. í URL ì¡°íšŒ
        try:
            response = sqs_client.get_queue_url(QueueName=result_queue_name)
            queue_url = response['QueueUrl']
            logger.info(f"ğŸ“¡ ê²°ê³¼ í URL: {queue_url}")
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ íë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {e}")
            return False
        
        # 2. í ì†ì„± ì—…ë°ì´íŠ¸ (visibility timeoutì„ 1200ì´ˆë¡œ ì„¤ì •)
        logger.info("â±ï¸ í visibility timeout ì—…ë°ì´íŠ¸ ì¤‘...")
        sqs_client.set_queue_attributes(
            QueueUrl=queue_url,
            Attributes={
                'VisibilityTimeout': '1200',  # 20ë¶„ (Lambda timeout 900ì´ˆë³´ë‹¤ í¼)
                'MessageRetentionPeriod': '1209600'  # 14ì¼
            }
        )
        logger.info("âœ… í ì†ì„± ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        # 3. SQS íŠ¸ë¦¬ê±° ì„¤ì •
        logger.info("ğŸ”— SQS íŠ¸ë¦¬ê±° ì¬ì„¤ì • ì¤‘...")
        
        # í ARN ìƒì„±
        queue_arn = f"arn:aws:sqs:ap-northeast-2:901361833359:{result_queue_name}"
        
        try:
            response = lambda_client.create_event_source_mapping(
                EventSourceArn=queue_arn,
                FunctionName=collector_function,
                BatchSize=10,  # ë°°ì¹˜ë¡œ ì²˜ë¦¬
                MaximumBatchingWindowInSeconds=30,  # 30ì´ˆ ëŒ€ê¸°
                Enabled=True
            )
            
            uuid = response['UUID']
            logger.info(f"âœ… SQS íŠ¸ë¦¬ê±° ì„¤ì • ì™„ë£Œ: {uuid}")
            
            # íŠ¸ë¦¬ê±° ìƒíƒœ í™•ì¸
            time.sleep(5)
            mapping_info = lambda_client.get_event_source_mapping(UUID=uuid)
            state = mapping_info['State']
            
            logger.info(f"ğŸ“Š íŠ¸ë¦¬ê±° ìƒíƒœ: {state}")
            
            if state == 'Enabled':
                logger.info("ğŸ‰ SQS íŠ¸ë¦¬ê±° ì„¤ì • ë° í™œì„±í™” ì™„ë£Œ!")
                return True
            else:
                logger.warning(f"âš ï¸ íŠ¸ë¦¬ê±°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ìƒíƒœ: {state}")
                return False
                
        except Exception as e:
            if "already exists" in str(e).lower() or "resourceconflictexception" in str(e).lower():
                logger.info("ğŸ”„ ê¸°ì¡´ SQS íŠ¸ë¦¬ê±°ê°€ ì¡´ì¬í•¨")
                
                # ê¸°ì¡´ ë§¤í•‘ í™•ì¸ ë° ì—…ë°ì´íŠ¸
                existing_mappings = lambda_client.list_event_source_mappings(
                    FunctionName=collector_function
                )
                
                for mapping in existing_mappings.get('EventSourceMappings', []):
                    if queue_arn in mapping['EventSourceArn']:
                        uuid = mapping['UUID']
                        logger.info(f"ğŸ”„ ê¸°ì¡´ ë§¤í•‘ ì—…ë°ì´íŠ¸: {uuid}")
                        
                        # ë§¤í•‘ ì—…ë°ì´íŠ¸
                        lambda_client.update_event_source_mapping(
                            UUID=uuid,
                            Enabled=True,
                            BatchSize=10,
                            MaximumBatchingWindowInSeconds=30
                        )
                        
                        logger.info("âœ… ê¸°ì¡´ ë§¤í•‘ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                        return True
                        
                return True
            else:
                logger.error(f"âŒ SQS íŠ¸ë¦¬ê±° ì„¤ì • ì‹¤íŒ¨: {e}")
                return False
        
    except Exception as e:
        logger.error(f"âŒ ê²°ê³¼ í íƒ€ì„ì•„ì›ƒ ìˆ˜ì • ì‹¤íŒ¨: {e}")
        return False

def test_end_to_end_integration():
    """ì¢…ë‹¨ ê°„ í†µí•© í…ŒìŠ¤íŠ¸"""
    try:
        sqs_client = boto3.client('sqs', region_name='ap-northeast-2')
        
        resource_prefix = "makenaide-distributed-backtest"
        job_queue_name = f"{resource_prefix}-job-queue"
        
        logger.info("ğŸ§ª ì¢…ë‹¨ ê°„ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # 1. ì‘ì—… íì— í…ŒìŠ¤íŠ¸ ì‘ì—… ì „ì†¡
        response = sqs_client.get_queue_url(QueueName=job_queue_name)
        job_queue_url = response['QueueUrl']
        
        test_job = {
            'job_id': f'end-to-end-test-{int(time.time())}',
            'job_type': 'SINGLE_STRATEGY',
            'strategy_name': 'End_To_End_Test',
            'parameters': {
                'position_size_method': 'percent',
                'position_size_value': 0.08,
                'stop_loss_pct': 0.04
            },
            'data_range': {
                'start_date': '2024-01-01',
                'end_date': '2024-01-07'
            }
        }
        
        logger.info("ğŸ“¤ í…ŒìŠ¤íŠ¸ ì‘ì—… ì „ì†¡ ì¤‘...")
        response = sqs_client.send_message(
            QueueUrl=job_queue_url,
            MessageBody=json.dumps(test_job),
            MessageAttributes={
                'job_type': {
                    'StringValue': 'SINGLE_STRATEGY',
                    'DataType': 'String'
                },
                'test': {
                    'StringValue': 'end_to_end',
                    'DataType': 'String'
                }
            }
        )
        
        message_id = response['MessageId']
        logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ì‘ì—… ì „ì†¡ ì™„ë£Œ: {message_id}")
        
        logger.info("â³ ì¢…ë‹¨ ê°„ ì²˜ë¦¬ ì™„ë£Œ ëŒ€ê¸° ì¤‘... (60ì´ˆ)")
        logger.info("   1. ì›Œì»¤ Lambdaê°€ ì‘ì—…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤")
        logger.info("   2. ê²°ê³¼ê°€ ê²°ê³¼ íë¡œ ì „ì†¡ë©ë‹ˆë‹¤")
        logger.info("   3. ìˆ˜ì§‘ê¸° Lambdaê°€ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤")
        
        time.sleep(60)
        
        logger.info("ğŸ‰ ì¢…ë‹¨ ê°„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        logger.info("ğŸ“Š CloudWatch ë¡œê·¸ì—ì„œ ì „ì²´ ì²˜ë¦¬ ê³¼ì •ì„ í™•ì¸í•˜ì„¸ìš”:")
        logger.info("   ì›Œì»¤: aws logs tail /aws/lambda/makenaide-distributed-backtest-worker --follow")
        logger.info("   ìˆ˜ì§‘ê¸°: aws logs tail /aws/lambda/makenaide-backtest-result-collector --follow")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ì¢…ë‹¨ ê°„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”§ ê²°ê³¼ í SQS íŠ¸ë¦¬ê±° ìˆ˜ì • ë° í†µí•© í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # 1. ê²°ê³¼ í íƒ€ì„ì•„ì›ƒ ìˆ˜ì • ë° íŠ¸ë¦¬ê±° ì„¤ì •
    logger.info("1ï¸âƒ£ ê²°ê³¼ í íƒ€ì„ì•„ì›ƒ ìˆ˜ì •")
    fix_success = fix_result_queue_timeout()
    
    if fix_success:
        logger.info("âœ… ê²°ê³¼ í íŠ¸ë¦¬ê±° ì„¤ì • ì™„ë£Œ")
        
        # 2. ì¢…ë‹¨ ê°„ í†µí•© í…ŒìŠ¤íŠ¸
        logger.info("\n2ï¸âƒ£ ì¢…ë‹¨ ê°„ í†µí•© í…ŒìŠ¤íŠ¸")
        import json  # ì—¬ê¸°ì„œ json import ì¶”ê°€
        test_success = test_end_to_end_integration()
        
        if test_success:
            logger.info("ğŸ‰ ë¶„ì‚° ë°±í…ŒìŠ¤íŒ… ê²°ê³¼ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì™„ì „ êµ¬ì¶• ì™„ë£Œ!")
        else:
            logger.warning("âš ï¸ í†µí•© í…ŒìŠ¤íŠ¸ì—ì„œ ë¬¸ì œ ë°œìƒ")
    else:
        logger.error("âŒ ê²°ê³¼ í íŠ¸ë¦¬ê±° ì„¤ì • ì‹¤íŒ¨")

if __name__ == "__main__":
    import json  # json import ì¶”ê°€
    main()