#!/usr/bin/env python3
"""
AWS CloudWatch ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

ğŸ¯ ëª©ì :
- Lambda í•¨ìˆ˜ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- EC2 ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§  
- RDS ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ì¶”ì 
- ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì•ŒëŒ ì„¤ì •

ğŸ”§ ì‚¬ìš©ë²•:
python aws_cloudwatch_monitor.py [--setup-alarms] [--collect-metrics]
"""

import boto3
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import os
from dotenv import load_dotenv

class CloudWatchMonitor:
    """AWS CloudWatch ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        load_dotenv('env.aws')
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
        # AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.cloudwatch = boto3.client('cloudwatch')
            self.ec2 = boto3.client('ec2')
            self.rds = boto3.client('rds')
            self.lambda_client = boto3.client('lambda')
            self.logs_client = boto3.client('logs')
            
            self.logger.info("âœ… AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
        
        # ì„¤ì •ê°’
        self.function_name = os.getenv('LAMBDA_FUNCTION_NAME', 'makenaide-controller')
        self.db_instance_id = 'makenaide'
        self.sns_topic_arn = os.getenv('SNS_TOPIC_ARN')  # ì„ íƒì 

    def setup_custom_alarms(self) -> bool:
        """ì»¤ìŠ¤í…€ CloudWatch ì•ŒëŒ ì„¤ì •"""
        self.logger.info("ğŸš¨ CloudWatch ì•ŒëŒ ì„¤ì • ì‹œì‘...")
        
        alarms = [
            # Lambda í•¨ìˆ˜ ì—ëŸ¬ìœ¨ ì•ŒëŒ
            {
                'AlarmName': 'makenaide-lambda-error-rate',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 2,
                'MetricName': 'Errors',
                'Namespace': 'AWS/Lambda',
                'Period': 300,
                'Statistic': 'Sum',
                'Threshold': 5.0,
                'ActionsEnabled': True,
                'AlarmDescription': 'Makenaide Lambda í•¨ìˆ˜ ì—ëŸ¬ ë°œìƒ',
                'Dimensions': [
                    {
                        'Name': 'FunctionName',
                        'Value': self.function_name
                    }
                ],
                'Unit': 'Count'
            },
            
            # Lambda í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì•ŒëŒ
            {
                'AlarmName': 'makenaide-lambda-duration',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 2,
                'MetricName': 'Duration',
                'Namespace': 'AWS/Lambda',
                'Period': 300,
                'Statistic': 'Average',
                'Threshold': 600000.0,  # 10ë¶„ (ë°€ë¦¬ì´ˆ)
                'ActionsEnabled': True,
                'AlarmDescription': 'Makenaide Lambda í•¨ìˆ˜ ì‹¤í–‰ì‹œê°„ ì´ˆê³¼',
                'Dimensions': [
                    {
                        'Name': 'FunctionName',
                        'Value': self.function_name
                    }
                ],
                'Unit': 'Milliseconds'
            },
            
            # RDS CPU ì‚¬ìš©ë¥  ì•ŒëŒ
            {
                'AlarmName': 'makenaide-rds-cpu-high',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 3,
                'MetricName': 'CPUUtilization',
                'Namespace': 'AWS/RDS',
                'Period': 300,
                'Statistic': 'Average',
                'Threshold': 80.0,
                'ActionsEnabled': True,
                'AlarmDescription': 'Makenaide RDS CPU ì‚¬ìš©ë¥  ë†’ìŒ',
                'Dimensions': [
                    {
                        'Name': 'DBInstanceIdentifier',
                        'Value': self.db_instance_id
                    }
                ],
                'Unit': 'Percent'
            },
            
            # RDS ì—°ê²° ìˆ˜ ì•ŒëŒ
            {
                'AlarmName': 'makenaide-rds-connections-high',
                'ComparisonOperator': 'GreaterThanThreshold',
                'EvaluationPeriods': 2,
                'MetricName': 'DatabaseConnections',
                'Namespace': 'AWS/RDS',
                'Period': 300,
                'Statistic': 'Average',
                'Threshold': 15.0,
                'ActionsEnabled': True,
                'AlarmDescription': 'Makenaide RDS ì—°ê²° ìˆ˜ ë†’ìŒ',
                'Dimensions': [
                    {
                        'Name': 'DBInstanceIdentifier',
                        'Value': self.db_instance_id
                    }
                ],
                'Unit': 'Count'
            }
        ]
        
        # SNS í† í”½ì´ ìˆìœ¼ë©´ ì•ŒëŒ ì•¡ì…˜ ì¶”ê°€
        if self.sns_topic_arn:
            for alarm in alarms:
                alarm['AlarmActions'] = [self.sns_topic_arn]
                alarm['OKActions'] = [self.sns_topic_arn]
        
        # ì•ŒëŒ ìƒì„±
        created_count = 0
        for alarm in alarms:
            try:
                self.cloudwatch.put_metric_alarm(**alarm)
                self.logger.info(f"âœ… ì•ŒëŒ ìƒì„±: {alarm['AlarmName']}")
                created_count += 1
            except Exception as e:
                self.logger.error(f"âŒ ì•ŒëŒ ìƒì„± ì‹¤íŒ¨ {alarm['AlarmName']}: {e}")
        
        self.logger.info(f"ğŸ¯ ì´ {created_count}ê°œ ì•ŒëŒ ì„¤ì • ì™„ë£Œ")
        return created_count > 0

    def collect_lambda_metrics(self, hours: int = 24) -> Dict[str, Any]:
        """Lambda í•¨ìˆ˜ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        self.logger.info(f"ğŸ“Š Lambda ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘ (ìµœê·¼ {hours}ì‹œê°„)")
        
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=hours)
        
        metrics = {}
        
        metric_queries = [
            ('Invocations', 'Sum', 'í˜¸ì¶œ íšŸìˆ˜'),
            ('Duration', 'Average', 'í‰ê·  ì‹¤í–‰ì‹œê°„'),
            ('Errors', 'Sum', 'ì—ëŸ¬ íšŸìˆ˜'),
            ('Throttles', 'Sum', 'ìŠ¤ë¡œí‹€ íšŸìˆ˜')
        ]
        
        for metric_name, statistic, description in metric_queries:
            try:
                response = self.cloudwatch.get_metric_statistics(
                    Namespace='AWS/Lambda',
                    MetricName=metric_name,
                    Dimensions=[
                        {
                            'Name': 'FunctionName',
                            'Value': self.function_name
                        }
                    ],
                    StartTime=start_time,
                    EndTime=end_time,
                    Period=3600,  # 1ì‹œê°„ ë‹¨ìœ„
                    Statistics=[statistic]
                )
                
                datapoints = response.get('Datapoints', [])
                if datapoints:
                    # ì‹œê°„ìˆœ ì •ë ¬
                    datapoints.sort(key=lambda x: x['Timestamp'])
                    latest_value = datapoints[-1][statistic]
                    total_value = sum(dp[statistic] for dp in datapoints)
                    
                    metrics[metric_name] = {
                        'description': description,
                        'latest_value': latest_value,
                        'total_value': total_value,
                        'datapoints_count': len(datapoints),
                        'unit': datapoints[-1].get('Unit', 'None')
                    }
                    
                    self.logger.info(f"âœ… {description}: ìµœê·¼ê°’={latest_value}, ì´í•©={total_value}")
                else:
                    self.logger.warning(f"âš ï¸ {description}: ë°ì´í„° ì—†ìŒ")
                    metrics[metric_name] = {'description': description, 'no_data': True}
                    
            except Exception as e:
                self.logger.error(f"âŒ {metric_name} ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                metrics[metric_name] = {'description': description, 'error': str(e)}
        
        return metrics

    def collect_rds_metrics(self, hours: int = 24) -> Dict[str, Any]:
        """RDS ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        self.logger.info(f"ğŸ“Š RDS ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œì‘ (ìµœê·¼ {hours}ì‹œê°„)")
        
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(hours=hours)
        
        metrics = {}
        
        metric_queries = [
            ('CPUUtilization', 'Average', 'CPU ì‚¬ìš©ë¥ ', 'Percent'),
            ('DatabaseConnections', 'Average', 'ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìˆ˜', 'Count'),
            ('FreeableMemory', 'Average', 'ì—¬ìœ  ë©”ëª¨ë¦¬', 'Bytes'),
            ('ReadLatency', 'Average', 'ì½ê¸° ì§€ì—°ì‹œê°„', 'Seconds'),
            ('WriteLatency', 'Average', 'ì“°ê¸° ì§€ì—°ì‹œê°„', 'Seconds')
        ]
        
        for metric_name, statistic, description, unit in metric_queries:
            try:
                response = self.cloudwatch.get_metric_statistics(
                    Namespace='AWS/RDS',
                    MetricName=metric_name,
                    Dimensions=[
                        {
                            'Name': 'DBInstanceIdentifier',
                            'Value': self.db_instance_id
                        }
                    ],
                    StartTime=start_time,
                    EndTime=end_time,
                    Period=3600,  # 1ì‹œê°„ ë‹¨ìœ„
                    Statistics=[statistic]
                )
                
                datapoints = response.get('Datapoints', [])
                if datapoints:
                    datapoints.sort(key=lambda x: x['Timestamp'])
                    latest_value = datapoints[-1][statistic]
                    avg_value = sum(dp[statistic] for dp in datapoints) / len(datapoints)
                    
                    metrics[metric_name] = {
                        'description': description,
                        'latest_value': latest_value,
                        'average_value': avg_value,
                        'datapoints_count': len(datapoints),
                        'unit': unit
                    }
                    
                    if unit == 'Bytes':
                        # ë©”ëª¨ë¦¬ëŠ” MB ë‹¨ìœ„ë¡œ í‘œì‹œ
                        latest_mb = latest_value / (1024 * 1024)
                        avg_mb = avg_value / (1024 * 1024)
                        self.logger.info(f"âœ… {description}: ìµœê·¼ê°’={latest_mb:.1f}MB, í‰ê· ={avg_mb:.1f}MB")
                    else:
                        self.logger.info(f"âœ… {description}: ìµœê·¼ê°’={latest_value:.2f}, í‰ê· ={avg_value:.2f}")
                else:
                    self.logger.warning(f"âš ï¸ {description}: ë°ì´í„° ì—†ìŒ")
                    metrics[metric_name] = {'description': description, 'no_data': True}
                    
            except Exception as e:
                self.logger.error(f"âŒ {metric_name} ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                metrics[metric_name] = {'description': description, 'error': str(e)}
        
        return metrics

    def send_custom_metric(self, metric_name: str, value: float, unit: str = 'Count', dimensions: Optional[List] = None) -> bool:
        """ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì „ì†¡"""
        try:
            metric_data = {
                'MetricName': metric_name,
                'Value': value,
                'Unit': unit,
                'Timestamp': datetime.utcnow()
            }
            
            if dimensions:
                metric_data['Dimensions'] = dimensions
            
            self.cloudwatch.put_metric_data(
                Namespace='Makenaide/Trading',
                MetricData=[metric_data]
            )
            
            self.logger.info(f"ğŸ“ˆ ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì „ì†¡: {metric_name}={value} {unit}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return False

    def get_recent_logs(self, log_group_name: str, hours: int = 1) -> List[Dict]:
        """ìµœê·¼ ë¡œê·¸ ì´ë²¤íŠ¸ ì¡°íšŒ"""
        self.logger.info(f"ğŸ“‹ ë¡œê·¸ ì¡°íšŒ: {log_group_name} (ìµœê·¼ {hours}ì‹œê°„)")
        
        try:
            end_time = int(datetime.utcnow().timestamp() * 1000)
            start_time = int((datetime.utcnow() - timedelta(hours=hours)).timestamp() * 1000)
            
            response = self.logs_client.filter_log_events(
                logGroupName=log_group_name,
                startTime=start_time,
                endTime=end_time,
                limit=100
            )
            
            events = response.get('events', [])
            self.logger.info(f"âœ… {len(events)}ê°œ ë¡œê·¸ ì´ë²¤íŠ¸ ì¡°íšŒ")
            
            return events
            
        except Exception as e:
            self.logger.error(f"âŒ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def generate_monitoring_report(self, hours: int = 24) -> Dict[str, Any]:
        """ì¢…í•© ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ ìƒì„±"""
        self.logger.info(f"ğŸ“Š ì¢…í•© ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ ìƒì„± (ìµœê·¼ {hours}ì‹œê°„)")
        
        report = {
            'timestamp': datetime.utcnow().isoformat(),
            'period_hours': hours,
            'lambda_metrics': self.collect_lambda_metrics(hours),
            'rds_metrics': self.collect_rds_metrics(hours),
            'health_status': 'unknown'
        }
        
        # í—¬ìŠ¤ ìƒíƒœ íŒì •
        try:
            lambda_errors = report['lambda_metrics'].get('Errors', {}).get('total_value', 0)
            rds_cpu = report['rds_metrics'].get('CPUUtilization', {}).get('latest_value', 0)
            
            if lambda_errors > 10 or rds_cpu > 90:
                report['health_status'] = 'critical'
            elif lambda_errors > 5 or rds_cpu > 80:
                report['health_status'] = 'warning'
            else:
                report['health_status'] = 'healthy'
        except:
            pass
        
        # ë³´ê³ ì„œ ì €ì¥
        report_file = f"aws_monitoring_report_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ“„ ëª¨ë‹ˆí„°ë§ ë³´ê³ ì„œ ì €ì¥: {report_file}")
        self.logger.info(f"ğŸ¯ ì‹œìŠ¤í…œ ìƒíƒœ: {report['health_status'].upper()}")
        
        return report

    def check_alarm_status(self) -> Dict[str, str]:
        """ì•ŒëŒ ìƒíƒœ í™•ì¸"""
        self.logger.info("ğŸš¨ ì•ŒëŒ ìƒíƒœ í™•ì¸...")
        
        try:
            alarm_names = [
                'makenaide-lambda-error-rate',
                'makenaide-lambda-duration', 
                'makenaide-rds-cpu-high',
                'makenaide-rds-connections-high'
            ]
            
            response = self.cloudwatch.describe_alarms(AlarmNames=alarm_names)
            alarms = response.get('MetricAlarms', [])
            
            alarm_status = {}
            for alarm in alarms:
                name = alarm['AlarmName']
                state = alarm['StateValue']
                alarm_status[name] = state
                
                if state == 'ALARM':
                    self.logger.warning(f"ğŸš¨ ì•ŒëŒ ë°œìƒ: {name}")
                elif state == 'OK':
                    self.logger.info(f"âœ… ì •ìƒ: {name}")
                else:
                    self.logger.info(f"â“ ìƒíƒœ ë¶ˆë¶„ëª…: {name} ({state})")
            
            return alarm_status
            
        except Exception as e:
            self.logger.error(f"âŒ ì•ŒëŒ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
            return {}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='AWS CloudWatch ëª¨ë‹ˆí„°ë§')
    parser.add_argument('--setup-alarms', action='store_true', help='ì•ŒëŒ ì„¤ì •')
    parser.add_argument('--collect-metrics', action='store_true', help='ë©”íŠ¸ë¦­ ìˆ˜ì§‘')
    parser.add_argument('--hours', type=int, default=24, help='ìˆ˜ì§‘ ê¸°ê°„ (ì‹œê°„)')
    parser.add_argument('--check-alarms', action='store_true', help='ì•ŒëŒ ìƒíƒœ í™•ì¸')
    
    args = parser.parse_args()
    
    monitor = CloudWatchMonitor()
    
    if args.setup_alarms:
        monitor.setup_custom_alarms()
    
    if args.collect_metrics:
        monitor.generate_monitoring_report(args.hours)
    
    if args.check_alarms:
        monitor.check_alarm_status()
    
    if not any([args.setup_alarms, args.collect_metrics, args.check_alarms]):
        # ê¸°ë³¸ ë™ì‘: ì¢…í•© ëª¨ë‹ˆí„°ë§
        monitor.generate_monitoring_report(args.hours)
        monitor.check_alarm_status()


if __name__ == '__main__':
    main() 