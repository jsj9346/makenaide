#!/usr/bin/env python3
"""
Lambda Data Collector - Phase 2 ÏïÑÌÇ§ÌÖçÏ≤ò Í∞úÏÑ†
Makenaide Î¥áÏùò Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î°úÏßÅÏùÑ ÎèÖÎ¶ΩÏ†ÅÏù∏ Lambda Ìï®ÏàòÎ°ú Î∂ÑÎ¶¨

Ï£ºÏöî Í∏∞Îä•:
1. OHLCV Îç∞Ïù¥ÌÑ∞ ÏàòÏßë (ÏùºÎ¥â/4ÏãúÍ∞ÑÎ¥â)
2. Í∏∞Ïà†Ï†Å ÏßÄÌëú Î∞∞Ïπò Ï°∞Ìöå
3. ÏãúÏû• Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨
4. DB Ï†ÄÏû• Î∞è Ï∫êÏã±

Author: Phase 2 Architecture Migration
Version: 1.0.0
"""

import json
import logging
import time
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import pandas as pd

# AWS Lambda ÌôòÍ≤Ω ÏÑ§Ï†ï
logger = logging.getLogger()
logger.setLevel(logging.INFO)

class DataCollectorConfig:
    """Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏÑ§Ï†ï ÌÅ¥ÎûòÏä§"""
    
    # Í∏∞Î≥∏ ÏàòÏßë ÏÑ§Ï†ï
    DEFAULT_OHLCV_DAYS = 450
    DEFAULT_4H_LIMIT = 200
    
    # Ï£ºÏöî ÏΩîÏù∏ ÌôïÏû• ÏàòÏßë
    MAJOR_COINS = ["KRW-BTC", "KRW-ETH", "KRW-XRP", "KRW-ADA", "KRW-DOT"]
    MAJOR_COIN_DAYS = 600
    
    # Î∞∞Ïπò Ï≤òÎ¶¨ ÏÑ§Ï†ï
    BATCH_SIZE = 10  # Ìïú Î≤àÏóê Ï≤òÎ¶¨Ìï† Ìã∞Ïª§ Ïàò
    
    # DB Ïó∞Í≤∞ ÏÑ§Ï†ï
    DB_CONFIG = {
        'host': os.environ.get('DB_HOST', 'makenaide.cni2ka4ugf7f.ap-northeast-2.rds.amazonaws.com'),
        'port': int(os.environ.get('DB_PORT', '5432')),
        'database': os.environ.get('DB_NAME', 'makenaide'),
        'user': os.environ.get('DB_USER', 'bruce'),
        'password': os.environ.get('DB_PASSWORD', '0asis314.')
    }

class DatabaseManager:
    """Lambda ÌôòÍ≤ΩÏö© Í≤ΩÎüâÌôîÎêú DB Îß§ÎãàÏ†Ä"""
    
    def __init__(self, config: dict):
        self.config = config
        self.connection = None
        
    def get_connection(self):
        """DB Ïó∞Í≤∞ ÌöçÎìù"""
        if self.connection is None:
            import psycopg2
            try:
                self.connection = psycopg2.connect(**self.config)
                logger.info("‚úÖ PostgreSQL Ïó∞Í≤∞ ÏÑ±Í≥µ")
            except Exception as e:
                logger.error(f"‚ùå DB Ïó∞Í≤∞ Ïã§Ìå®: {e}")
                raise
        return self.connection
    
    def execute_query(self, query: str, params: tuple = None, fetchone: bool = False):
        """ÏøºÎ¶¨ Ïã§Ìñâ"""
        conn = self.get_connection()
        cursor = conn.cursor()
        try:
            cursor.execute(query, params)
            if fetchone:
                return cursor.fetchone()
            else:
                return cursor.fetchall()
        except Exception as e:
            logger.error(f"‚ùå ÏøºÎ¶¨ Ïã§Ìñâ Ïã§Ìå®: {e}")
            conn.rollback()
            raise
        finally:
            cursor.close()
    
    def insert_ohlcv_batch(self, ticker: str, df: pd.DataFrame, table: str = 'ohlcv'):
        """OHLCV Îç∞Ïù¥ÌÑ∞ Î∞∞Ïπò ÏÇΩÏûÖ"""
        if df.empty:
            return
            
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú
            cursor.execute(f"DELETE FROM {table} WHERE ticker = %s", (ticker,))
            
            # ÏÉà Îç∞Ïù¥ÌÑ∞ ÏÇΩÏûÖ
            for date, row in df.iterrows():
                cursor.execute(f"""
                    INSERT INTO {table} (ticker, date, open, high, low, close, volume)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (ticker, date) DO UPDATE SET
                        open = EXCLUDED.open,
                        high = EXCLUDED.high,
                        low = EXCLUDED.low,
                        close = EXCLUDED.close,
                        volume = EXCLUDED.volume
                """, (ticker, date, row['open'], row['high'], row['low'], row['close'], row['volume']))
            
            conn.commit()
            logger.info(f"‚úÖ {ticker} {table} Îç∞Ïù¥ÌÑ∞ {len(df)}Í∞ú Ï†ÄÏû• ÏôÑÎ£å")
            
        except Exception as e:
            conn.rollback()
            logger.error(f"‚ùå {ticker} {table} Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Ïã§Ìå®: {e}")
            raise
        finally:
            cursor.close()
    
    def get_existing_data_count(self, ticker: str, table: str = 'ohlcv') -> int:
        """Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ Í∞úÏàò Ï°∞Ìöå"""
        try:
            result = self.execute_query(
                f"SELECT COUNT(*) FROM {table} WHERE ticker = %s",
                (ticker,),
                fetchone=True
            )
            return result[0] if result else 0
        except Exception as e:
            logger.error(f"‚ùå {ticker} Îç∞Ïù¥ÌÑ∞ Í∞úÏàò Ï°∞Ìöå Ïã§Ìå®: {e}")
            return 0
    
    def get_latest_timestamp(self, ticker: str, table: str = 'ohlcv') -> Optional[datetime]:
        """ÏµúÏã† ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Ï°∞Ìöå"""
        try:
            result = self.execute_query(
                f"SELECT MAX(date) FROM {table} WHERE ticker = %s",
                (ticker,),
                fetchone=True
            )
            return result[0] if result and result[0] else None
        except Exception as e:
            logger.error(f"‚ùå {ticker} ÏµúÏã† ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Ï°∞Ìöå Ïã§Ìå®: {e}")
            return None

class MarketDataCollector:
    """ÎßàÏºì Îç∞Ïù¥ÌÑ∞ ÏàòÏßëÍ∏∞"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db = db_manager
        self.config = DataCollectorConfig()
        
    def collect_ohlcv_daily(self, ticker: str, force_fetch: bool = False) -> Optional[pd.DataFrame]:
        """ÏùºÎ¥â OHLCV Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        try:
            logger.info(f"üìä {ticker} ÏùºÎ¥â Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏãúÏûë")
            
            # Ìã∞Ïª§ ÌòïÏãù Ï†ïÍ∑úÌôî
            if not ticker.startswith("KRW-"):
                ticker = f"KRW-{ticker}"
            
            # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏
            existing_count = self.db.get_existing_data_count(ticker)
            latest_date = self.db.get_latest_timestamp(ticker)
            
            # ÏàòÏßëÎüâ Í≤∞Ï†ï
            target_count = (self.config.MAJOR_COIN_DAYS 
                          if ticker in self.config.MAJOR_COINS 
                          else self.config.DEFAULT_OHLCV_DAYS)
            
            if not force_fetch and existing_count >= target_count:
                # Ï¶ùÎ∂Ñ ÏóÖÎç∞Ïù¥Ìä∏Îßå ÌïÑÏöîÌïúÏßÄ ÌôïÏù∏
                if latest_date:
                    days_diff = (datetime.now() - latest_date).days
                    if days_diff <= 1:
                        logger.info(f"‚è≠Ô∏è {ticker} ÏµúÏã† Îç∞Ïù¥ÌÑ∞ Ï°¥Ïû¨ - ÏàòÏßë Ìå®Ïä§")
                        return None
                    else:
                        logger.info(f"üîÑ {ticker} Ï¶ùÎ∂Ñ ÏóÖÎç∞Ïù¥Ìä∏ ({days_diff}Ïùº Ï∞®Ïù¥)")
                        return self._collect_incremental_data(ticker, latest_date)
            
            # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
            logger.info(f"üÜï {ticker} Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ({target_count}Í∞ú)")
            return self._collect_full_data(ticker, target_count)
            
        except Exception as e:
            logger.error(f"‚ùå {ticker} ÏùºÎ¥â Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ïã§Ìå®: {e}")
            return None
    
    def collect_ohlcv_4h(self, ticker: str, limit: int = None) -> Optional[pd.DataFrame]:
        """4ÏãúÍ∞ÑÎ¥â OHLCV Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        try:
            logger.info(f"üìä {ticker} 4ÏãúÍ∞ÑÎ¥â Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏãúÏûë")
            
            if not ticker.startswith("KRW-"):
                ticker = f"KRW-{ticker}"
            
            limit = limit or self.config.DEFAULT_4H_LIMIT
            
            # pyupbit API Ìò∏Ï∂ú
            df = self._safe_pyupbit_call(ticker, interval="minute240", count=limit)
            
            if df is not None and not df.empty:
                # DB Ï†ÄÏû•
                self.db.insert_ohlcv_batch(ticker, df, table='ohlcv_4h')
                logger.info(f"‚úÖ {ticker} 4ÏãúÍ∞ÑÎ¥â {len(df)}Í∞ú ÏàòÏßë ÏôÑÎ£å")
                return df
            else:
                logger.warning(f"‚ö†Ô∏è {ticker} 4ÏãúÍ∞ÑÎ¥â Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå {ticker} 4ÏãúÍ∞ÑÎ¥â Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ïã§Ìå®: {e}")
            return None
    
    def _collect_full_data(self, ticker: str, count: int) -> Optional[pd.DataFrame]:
        """Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        df = self._safe_pyupbit_call(ticker, interval="day", count=count)
        
        if df is not None and not df.empty:
            # Îç∞Ïù¥ÌÑ∞ ÌíàÏßà Í≤ÄÏ¶ù Î∞è Ï†ïÏ†ú
            df = self._validate_and_clean_data(df, ticker)
            
            # DB Ï†ÄÏû•
            self.db.insert_ohlcv_batch(ticker, df)
            
            logger.info(f"‚úÖ {ticker} Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ {len(df)}Í∞ú ÏàòÏßë ÏôÑÎ£å")
            return df
        
        return None
    
    def _collect_incremental_data(self, ticker: str, latest_date: datetime) -> Optional[pd.DataFrame]:
        """Ï¶ùÎ∂Ñ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        days_to_fetch = min((datetime.now() - latest_date).days + 5, 30)  # ÏµúÎåÄ 30Ïùº
        
        df = self._safe_pyupbit_call(ticker, interval="day", count=days_to_fetch)
        
        if df is not None and not df.empty:
            # Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞Î≥¥Îã§ ÏÉàÎ°úÏö¥ Í≤ÉÎßå ÌïÑÌÑ∞ÎßÅ
            df = df[df.index > latest_date]
            
            if not df.empty:
                df = self._validate_and_clean_data(df, ticker)
                
                # Ï¶ùÎ∂Ñ Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä
                conn = self.db.get_connection()
                cursor = conn.cursor()
                
                try:
                    for date, row in df.iterrows():
                        cursor.execute("""
                            INSERT INTO ohlcv (ticker, date, open, high, low, close, volume)
                            VALUES (%s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT (ticker, date) DO UPDATE SET
                                open = EXCLUDED.open,
                                high = EXCLUDED.high,
                                low = EXCLUDED.low,
                                close = EXCLUDED.close,
                                volume = EXCLUDED.volume
                        """, (ticker, date, row['open'], row['high'], row['low'], row['close'], row['volume']))
                    
                    conn.commit()
                    logger.info(f"‚úÖ {ticker} Ï¶ùÎ∂Ñ Îç∞Ïù¥ÌÑ∞ {len(df)}Í∞ú Ï†ÄÏû• ÏôÑÎ£å")
                    
                except Exception as e:
                    conn.rollback()
                    logger.error(f"‚ùå {ticker} Ï¶ùÎ∂Ñ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Ïã§Ìå®: {e}")
                    raise
                finally:
                    cursor.close()
                
                return df
        
        return None
    
    def _safe_pyupbit_call(self, ticker: str, interval: str, count: int) -> Optional[pd.DataFrame]:
        """ÏïàÏ†ÑÌïú pyupbit API Ìò∏Ï∂ú"""
        try:
            import pyupbit
            time.sleep(0.1)  # API Ï†úÌïú Ï§ÄÏàò
            
            df = pyupbit.get_ohlcv(ticker, interval=interval, count=count)
            
            if df is None or df.empty:
                logger.warning(f"‚ö†Ô∏è {ticker} API ÏùëÎãµ ÏóÜÏùå")
                return None
            
            return df
            
        except Exception as e:
            logger.error(f"‚ùå {ticker} pyupbit API Ìò∏Ï∂ú Ïã§Ìå®: {e}")
            return None
    
    def _validate_and_clean_data(self, df: pd.DataFrame, ticker: str) -> pd.DataFrame:
        """Îç∞Ïù¥ÌÑ∞ ÌíàÏßà Í≤ÄÏ¶ù Î∞è Ï†ïÏ†ú"""
        if df.empty:
            return df
        
        # 1. Null Í∞í Ï†úÍ±∞
        df = df.dropna()
        
        # 2. 0Í∞í Ï†úÍ±∞ (OHLCV Î™®Îëê 0Ïù∏ Ìñâ)
        mask = (df['open'] > 0) & (df['high'] > 0) & (df['low'] > 0) & (df['close'] > 0)
        df = df[mask]
        
        # 3. Í∞ÄÍ≤© ÎÖºÎ¶¨ÏÑ± Í≤ÄÏ¶ù (high >= low, high >= open,close, low <= open,close)
        valid_price_mask = (
            (df['high'] >= df['low']) &
            (df['high'] >= df['open']) &
            (df['high'] >= df['close']) &
            (df['low'] <= df['open']) &
            (df['low'] <= df['close'])
        )
        df = df[valid_price_mask]
        
        # 4. ÎÇ†Ïßú Ïù∏Îç±Ïä§ Í≤ÄÏ¶ù
        if hasattr(df.index, 'year'):
            # 1970ÎÖÑ Îç∞Ïù¥ÌÑ∞ Ï†úÍ±∞ (ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Ïò§Î•ò)
            df = df[df.index.year > 2000]
        
        # 5. Ï§ëÎ≥µ Ï†úÍ±∞
        df = df[~df.index.duplicated(keep='last')]
        
        # 6. Ï†ïÎ†¨
        df = df.sort_index()
        
        logger.info(f"üîß {ticker} Îç∞Ïù¥ÌÑ∞ Ï†ïÏ†ú ÏôÑÎ£å: {len(df)}Í∞ú Î†àÏΩîÎìú")
        return df

class TechnicalIndicatorBatchCollector:
    """Í∏∞Ïà†Ï†Å ÏßÄÌëú Î∞∞Ïπò ÏàòÏßëÍ∏∞"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db = db_manager
    
    def get_technical_data_batch(self, tickers: List[str]) -> Dict[str, Any]:
        """Ïó¨Îü¨ Ìã∞Ïª§Ïùò Í∏∞Ïà†Ï†Å ÏßÄÌëúÎ•º Î∞∞ÏπòÎ°ú Ï°∞Ìöå (Phase 1 ÏµúÏ†ÅÌôî Ï†ÅÏö©)"""
        start_time = time.time()
        logger.info(f"üìä Î∞∞Ïπò Í∏∞Ïà†Ï†Å ÏßÄÌëú Ï°∞Ìöå ÏãúÏûë: {len(tickers)}Í∞ú Ìã∞Ïª§")
        
        if not tickers:
            return {}
        
        results = {}
        
        try:
            conn = self.db.get_connection()
            cursor = conn.cursor()
            
            # Phase 1ÏóêÏÑú ÏµúÏ†ÅÌôîÎêú Îã®Ïùº JOIN ÏøºÎ¶¨ ÏÇ¨Ïö©
            for ticker in tickers:
                cursor.execute("""
                    SELECT 
                        s.price, s.atr, s.adx, s.volume_change_7_30, s.supertrend_signal,
                        o.close, o.rsi_14, o.ma_50, o.ma_200, o.bb_upper, o.bb_lower
                    FROM static_indicators s
                    LEFT JOIN (
                        SELECT ticker, close, rsi_14, ma_50, ma_200, bb_upper, bb_lower
                        FROM ohlcv 
                        WHERE ticker = %s 
                        ORDER BY date DESC 
                        LIMIT 1
                    ) o ON s.ticker = o.ticker
                    WHERE s.ticker = %s
                """, (ticker, ticker))
                
                result = cursor.fetchone()
                
                if result:
                    results[ticker] = {
                        'price': result[0],
                        'atr': result[1],
                        'adx': result[2],
                        'volume_change_7_30': result[3],
                        'supertrend_signal': result[4],
                        'close': result[5],
                        'rsi_14': result[6],
                        'ma_50': result[7],
                        'ma_200': result[8],
                        'bb_upper': result[9],
                        'bb_lower': result[10]
                    }
                else:
                    results[ticker] = None
            
            cursor.close()
            
            elapsed = time.time() - start_time
            success_count = len([r for r in results.values() if r is not None])
            
            logger.info(f"‚úÖ Î∞∞Ïπò Ï°∞Ìöå ÏôÑÎ£å: {success_count}/{len(tickers)}Í∞ú ÏÑ±Í≥µ ({elapsed:.3f}Ï¥à)")
            logger.info(f"üí∞ DB ÏøºÎ¶¨ ÏµúÏ†ÅÌôî: {len(tickers)*2-len(tickers)}Í∞ú ÏøºÎ¶¨ Ï†àÏïΩ")
            
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Î∞∞Ïπò Í∏∞Ïà†Ï†Å ÏßÄÌëú Ï°∞Ìöå Ïã§Ìå®: {e}")
            return {}

class LambdaDataCollector:
    """Lambda Îç∞Ïù¥ÌÑ∞ ÏàòÏßëÍ∏∞ Î©îÏù∏ ÌÅ¥ÎûòÏä§"""
    
    def __init__(self):
        self.db = DatabaseManager(DataCollectorConfig.DB_CONFIG)
        self.market_collector = MarketDataCollector(self.db)
        self.technical_collector = TechnicalIndicatorBatchCollector(self.db)
        
    def process_data_collection_request(self, event: dict) -> dict:
        """Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏöîÏ≤≠ Ï≤òÎ¶¨"""
        try:
            start_time = time.time()
            
            # ÏöîÏ≤≠ ÌååÎùºÎØ∏ÌÑ∞ ÌååÏã±
            collection_type = event.get('collection_type', 'ohlcv_daily')
            tickers = event.get('tickers', [])
            force_fetch = event.get('force_fetch', False)
            
            logger.info(f"üöÄ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏãúÏûë: {collection_type}, {len(tickers)}Í∞ú Ìã∞Ïª§")
            
            results = {}
            
            if collection_type == 'ohlcv_daily':
                results = self._collect_daily_data(tickers, force_fetch)
            elif collection_type == 'ohlcv_4h':
                results = self._collect_4h_data(tickers)
            elif collection_type == 'technical_batch':
                results = self._collect_technical_data(tickers)
            elif collection_type == 'mixed':
                # ÌòºÌï© ÏàòÏßë (ÏùºÎ¥â + Í∏∞Ïà†Ï†Å ÏßÄÌëú)
                daily_results = self._collect_daily_data(tickers, force_fetch)
                technical_results = self._collect_technical_data(tickers)
                results = {
                    'daily_data': daily_results,
                    'technical_data': technical_results
                }
            else:
                raise ValueError(f"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî ÏàòÏßë ÌÉÄÏûÖ: {collection_type}")
            
            elapsed = time.time() - start_time
            
            response = {
                'statusCode': 200,
                'body': {
                    'success': True,
                    'collection_type': collection_type,
                    'processed_tickers': len(tickers),
                    'execution_time': round(elapsed, 3),
                    'results': results,
                    'timestamp': datetime.now().isoformat()
                }
            }
            
            logger.info(f"‚úÖ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏôÑÎ£å: {elapsed:.3f}Ï¥à")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ï≤òÎ¶¨ Ïã§Ìå®: {e}")
            return {
                'statusCode': 500,
                'body': {
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
            }
    
    def _collect_daily_data(self, tickers: List[str], force_fetch: bool) -> dict:
        """ÏùºÎ¥â Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        results = {}
        
        for ticker in tickers:
            try:
                df = self.market_collector.collect_ohlcv_daily(ticker, force_fetch)
                results[ticker] = {
                    'success': df is not None,
                    'records': len(df) if df is not None else 0
                }
            except Exception as e:
                logger.error(f"‚ùå {ticker} ÏùºÎ¥â Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ïã§Ìå®: {e}")
                results[ticker] = {
                    'success': False,
                    'error': str(e)
                }
        
        return results
    
    def _collect_4h_data(self, tickers: List[str]) -> dict:
        """4ÏãúÍ∞ÑÎ¥â Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        results = {}
        
        for ticker in tickers:
            try:
                df = self.market_collector.collect_ohlcv_4h(ticker)
                results[ticker] = {
                    'success': df is not None,
                    'records': len(df) if df is not None else 0
                }
            except Exception as e:
                logger.error(f"‚ùå {ticker} 4ÏãúÍ∞ÑÎ¥â Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ïã§Ìå®: {e}")
                results[ticker] = {
                    'success': False,
                    'error': str(e)
                }
        
        return results
    
    def _collect_technical_data(self, tickers: List[str]) -> dict:
        """Í∏∞Ïà†Ï†Å ÏßÄÌëú Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"""
        try:
            return self.technical_collector.get_technical_data_batch(tickers)
        except Exception as e:
            logger.error(f"‚ùå Í∏∞Ïà†Ï†Å ÏßÄÌëú Î∞∞Ïπò ÏàòÏßë Ïã§Ìå®: {e}")
            return {}

def lambda_handler(event, context):
    """Lambda Ìï®Ïàò ÏßÑÏûÖÏ†ê"""
    try:
        logger.info(f"üì• Lambda Îç∞Ïù¥ÌÑ∞ ÏàòÏßë ÏöîÏ≤≠ ÏàòÏã†: {json.dumps(event, indent=2)}")
        
        # Îç∞Ïù¥ÌÑ∞ ÏàòÏßëÍ∏∞ Ï¥àÍ∏∞Ìôî
        collector = LambdaDataCollector()
        
        # ÏöîÏ≤≠ Ï≤òÎ¶¨
        result = collector.process_data_collection_request(event)
        
        logger.info(f"üì§ Lambda ÏùëÎãµ: {json.dumps(result, indent=2)}")
        return result
        
    except Exception as e:
        logger.error(f"‚ùå Lambda Ìï®Ïàò Ïã§Ìñâ Ïã§Ìå®: {e}")
        return {
            'statusCode': 500,
            'body': {
                'success': False,
                'error': f"Lambda Ìï®Ïàò Ïã§Ìñâ Ïã§Ìå®: {str(e)}",
                'timestamp': datetime.now().isoformat()
            }
        }

# Î°úÏª¨ ÌÖåÏä§Ìä∏Ïö©
if __name__ == "__main__":
    # ÌÖåÏä§Ìä∏ Ïù¥Î≤§Ìä∏
    test_event = {
        'collection_type': 'mixed',
        'tickers': ['KRW-BTC', 'KRW-ETH', 'KRW-ADA'],
        'force_fetch': False
    }
    
    result = lambda_handler(test_event, None)
    print(json.dumps(result, indent=2, ensure_ascii=False))