#!/usr/bin/env python3
"""
Lambda Data Collector - Phase 2 ì•„í‚¤í…ì²˜ ê°œì„ 
Makenaide ë´‡ì˜ ë°ì´í„° ìˆ˜ì§‘ ë¡œì§ì„ ë…ë¦½ì ì¸ Lambda í•¨ìˆ˜ë¡œ ë¶„ë¦¬

ì£¼ìš” ê¸°ëŠ¥:
1. OHLCV ë°ì´í„° ìˆ˜ì§‘ (ì¼ë´‰/4ì‹œê°„ë´‰)
2. ê¸°ìˆ ì  ì§€í‘œ ë°°ì¹˜ ì¡°íšŒ
3. ì‹œì¥ ë°ì´í„° ì „ì²˜ë¦¬
4. DB ì €ì¥ ë° ìºì‹±

Author: Phase 2 Architecture Migration
Version: 1.0.0
"""

import json
import logging
import time
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import pandas as pd

# AWS Lambda í™˜ê²½ ì„¤ì •
logger = logging.getLogger()
logger.setLevel(logging.INFO)

class DataCollectorConfig:
    """ë°ì´í„° ìˆ˜ì§‘ ì„¤ì • í´ë˜ìŠ¤"""
    
    # ê¸°ë³¸ ìˆ˜ì§‘ ì„¤ì •
    DEFAULT_OHLCV_DAYS = 450
    DEFAULT_4H_LIMIT = 200
    
    # ì£¼ìš” ì½”ì¸ í™•ì¥ ìˆ˜ì§‘
    MAJOR_COINS = ["KRW-BTC", "KRW-ETH", "KRW-XRP", "KRW-ADA", "KRW-DOT"]
    MAJOR_COIN_DAYS = 600
    
    # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
    BATCH_SIZE = 10  # í•œ ë²ˆì— ì²˜ë¦¬í•  í‹°ì»¤ ìˆ˜
    
    # DB ì—°ê²° ì„¤ì •
    DB_CONFIG = {
        'host': os.environ.get('DB_HOST', 'makenaide.cni2ka4ugf7f.ap-northeast-2.rds.amazonaws.com'),
        'port': int(os.environ.get('DB_PORT', '5432')),
        'database': os.environ.get('DB_NAME', 'makenaide'),
        'user': os.environ.get('DB_USER', 'bruce'),
        'password': os.environ.get('DB_PASSWORD', '0asis314.')
    }

class DatabaseManager:
    """Lambda í™˜ê²½ìš© ê²½ëŸ‰í™”ëœ DB ë§¤ë‹ˆì €"""
    
    def __init__(self, config: dict):
        self.config = config
        self.connection = None
        
    def get_connection(self):
        """DB ì—°ê²° íšë“"""
        if self.connection is None:
            import psycopg2
            try:
                self.connection = psycopg2.connect(**self.config)
                logger.info("âœ… PostgreSQL ì—°ê²° ì„±ê³µ")
            except Exception as e:
                logger.error(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
                raise
        return self.connection
    
    def execute_query(self, query: str, params: tuple = None, fetchone: bool = False):
        """ì¿¼ë¦¬ ì‹¤í–‰"""
        conn = self.get_connection()
        cursor = conn.cursor()
        try:
            cursor.execute(query, params)
            if fetchone:
                return cursor.fetchone()
            else:
                return cursor.fetchall()
        except Exception as e:
            logger.error(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            conn.rollback()
            raise
        finally:
            cursor.close()
    
    def insert_ohlcv_batch(self, ticker: str, df: pd.DataFrame, table: str = 'ohlcv'):
        """OHLCV ë°ì´í„° ë°°ì¹˜ ì‚½ì…"""
        if df.empty:
            return
            
        conn = self.get_connection()
        cursor = conn.cursor()
        
        try:
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
            cursor.execute(f"DELETE FROM {table} WHERE ticker = %s", (ticker,))
            
            # ìƒˆ ë°ì´í„° ì‚½ì…
            for date, row in df.iterrows():
                cursor.execute(f"""
                    INSERT INTO {table} (ticker, date, open, high, low, close, volume)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (ticker, date) DO UPDATE SET
                        open = EXCLUDED.open,
                        high = EXCLUDED.high,
                        low = EXCLUDED.low,
                        close = EXCLUDED.close,
                        volume = EXCLUDED.volume
                """, (ticker, date, row['open'], row['high'], row['low'], row['close'], row['volume']))
            
            conn.commit()
            logger.info(f"âœ… {ticker} {table} ë°ì´í„° {len(df)}ê°œ ì €ì¥ ì™„ë£Œ")
            
        except Exception as e:
            conn.rollback()
            logger.error(f"âŒ {ticker} {table} ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
        finally:
            cursor.close()
    
    def get_existing_data_count(self, ticker: str, table: str = 'ohlcv') -> int:
        """ê¸°ì¡´ ë°ì´í„° ê°œìˆ˜ ì¡°íšŒ"""
        try:
            result = self.execute_query(
                f"SELECT COUNT(*) FROM {table} WHERE ticker = %s",
                (ticker,),
                fetchone=True
            )
            return result[0] if result else 0
        except Exception as e:
            logger.error(f"âŒ {ticker} ë°ì´í„° ê°œìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def get_latest_timestamp(self, ticker: str, table: str = 'ohlcv') -> Optional[datetime]:
        """ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°íšŒ"""
        try:
            result = self.execute_query(
                f"SELECT MAX(date) FROM {table} WHERE ticker = %s",
                (ticker,),
                fetchone=True
            )
            return result[0] if result and result[0] else None
        except Exception as e:
            logger.error(f"âŒ {ticker} ìµœì‹  íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

class MarketDataCollector:
    """ë§ˆì¼“ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db = db_manager
        self.config = DataCollectorConfig()
        
    def collect_ohlcv_daily(self, ticker: str, force_fetch: bool = False) -> Optional[pd.DataFrame]:
        """ì¼ë´‰ OHLCV ë°ì´í„° ìˆ˜ì§‘"""
        try:
            logger.info(f"ğŸ“Š {ticker} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            
            # í‹°ì»¤ í˜•ì‹ ì •ê·œí™”
            if not ticker.startswith("KRW-"):
                ticker = f"KRW-{ticker}"
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            existing_count = self.db.get_existing_data_count(ticker)
            latest_date = self.db.get_latest_timestamp(ticker)
            
            # ìˆ˜ì§‘ëŸ‰ ê²°ì •
            target_count = (self.config.MAJOR_COIN_DAYS 
                          if ticker in self.config.MAJOR_COINS 
                          else self.config.DEFAULT_OHLCV_DAYS)
            
            if not force_fetch and existing_count >= target_count:
                # ì¦ë¶„ ì—…ë°ì´íŠ¸ë§Œ í•„ìš”í•œì§€ í™•ì¸
                if latest_date:
                    days_diff = (datetime.now() - latest_date).days
                    if days_diff <= 1:
                        logger.info(f"â­ï¸ {ticker} ìµœì‹  ë°ì´í„° ì¡´ì¬ - ìˆ˜ì§‘ íŒ¨ìŠ¤")
                        return None
                    else:
                        logger.info(f"ğŸ”„ {ticker} ì¦ë¶„ ì—…ë°ì´íŠ¸ ({days_diff}ì¼ ì°¨ì´)")
                        return self._collect_incremental_data(ticker, latest_date)
            
            # ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
            logger.info(f"ğŸ†• {ticker} ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ({target_count}ê°œ)")
            return self._collect_full_data(ticker, target_count)
            
        except Exception as e:
            logger.error(f"âŒ {ticker} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
    
    def collect_ohlcv_4h(self, ticker: str, limit: int = None) -> Optional[pd.DataFrame]:
        """4ì‹œê°„ë´‰ OHLCV ë°ì´í„° ìˆ˜ì§‘"""
        try:
            logger.info(f"ğŸ“Š {ticker} 4ì‹œê°„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            
            if not ticker.startswith("KRW-"):
                ticker = f"KRW-{ticker}"
            
            limit = limit or self.config.DEFAULT_4H_LIMIT
            
            # pyupbit API í˜¸ì¶œ
            df = self._safe_pyupbit_call(ticker, interval="minute240", count=limit)
            
            if df is not None and not df.empty:
                # DB ì €ì¥
                self.db.insert_ohlcv_batch(ticker, df, table='ohlcv_4h')
                logger.info(f"âœ… {ticker} 4ì‹œê°„ë´‰ {len(df)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                return df
            else:
                logger.warning(f"âš ï¸ {ticker} 4ì‹œê°„ë´‰ ë°ì´í„° ì—†ìŒ")
                return None
                
        except Exception as e:
            logger.error(f"âŒ {ticker} 4ì‹œê°„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
    
    def _collect_full_data(self, ticker: str, count: int) -> Optional[pd.DataFrame]:
        """ì „ì²´ ë°ì´í„° ìˆ˜ì§‘"""
        df = self._safe_pyupbit_call(ticker, interval="day", count=count)
        
        if df is not None and not df.empty:
            # ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ
            df = self._validate_and_clean_data(df, ticker)
            
            # DB ì €ì¥
            self.db.insert_ohlcv_batch(ticker, df)
            
            logger.info(f"âœ… {ticker} ì „ì²´ ë°ì´í„° {len(df)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            return df
        
        return None
    
    def _collect_incremental_data(self, ticker: str, latest_date: datetime) -> Optional[pd.DataFrame]:
        """ì¦ë¶„ ë°ì´í„° ìˆ˜ì§‘"""
        days_to_fetch = min((datetime.now() - latest_date).days + 5, 30)  # ìµœëŒ€ 30ì¼
        
        df = self._safe_pyupbit_call(ticker, interval="day", count=days_to_fetch)
        
        if df is not None and not df.empty:
            # ê¸°ì¡´ ë°ì´í„°ë³´ë‹¤ ìƒˆë¡œìš´ ê²ƒë§Œ í•„í„°ë§
            df = df[df.index > latest_date]
            
            if not df.empty:
                df = self._validate_and_clean_data(df, ticker)
                
                # ì¦ë¶„ ë°ì´í„° ì¶”ê°€
                conn = self.db.get_connection()
                cursor = conn.cursor()
                
                try:
                    for date, row in df.iterrows():
                        cursor.execute("""
                            INSERT INTO ohlcv (ticker, date, open, high, low, close, volume)
                            VALUES (%s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT (ticker, date) DO UPDATE SET
                                open = EXCLUDED.open,
                                high = EXCLUDED.high,
                                low = EXCLUDED.low,
                                close = EXCLUDED.close,
                                volume = EXCLUDED.volume
                        """, (ticker, date, row['open'], row['high'], row['low'], row['close'], row['volume']))
                    
                    conn.commit()
                    logger.info(f"âœ… {ticker} ì¦ë¶„ ë°ì´í„° {len(df)}ê°œ ì €ì¥ ì™„ë£Œ")
                    
                except Exception as e:
                    conn.rollback()
                    logger.error(f"âŒ {ticker} ì¦ë¶„ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
                    raise
                finally:
                    cursor.close()
                
                return df
        
        return None
    
    def _safe_pyupbit_call(self, ticker: str, interval: str, count: int) -> Optional[pd.DataFrame]:
        """ì•ˆì „í•œ pyupbit API í˜¸ì¶œ"""
        try:
            import pyupbit
            time.sleep(0.1)  # API ì œí•œ ì¤€ìˆ˜
            
            df = pyupbit.get_ohlcv(ticker, interval=interval, count=count)
            
            if df is None or df.empty:
                logger.warning(f"âš ï¸ {ticker} API ì‘ë‹µ ì—†ìŒ")
                return None
            
            return df
            
        except Exception as e:
            logger.error(f"âŒ {ticker} pyupbit API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _validate_and_clean_data(self, df: pd.DataFrame, ticker: str) -> pd.DataFrame:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ"""
        if df.empty:
            return df
        
        # 1. Null ê°’ ì œê±°
        df = df.dropna()
        
        # 2. 0ê°’ ì œê±° (OHLCV ëª¨ë‘ 0ì¸ í–‰)
        mask = (df['open'] > 0) & (df['high'] > 0) & (df['low'] > 0) & (df['close'] > 0)
        df = df[mask]
        
        # 3. ê°€ê²© ë…¼ë¦¬ì„± ê²€ì¦ (high >= low, high >= open,close, low <= open,close)
        valid_price_mask = (
            (df['high'] >= df['low']) &
            (df['high'] >= df['open']) &
            (df['high'] >= df['close']) &
            (df['low'] <= df['open']) &
            (df['low'] <= df['close'])
        )
        df = df[valid_price_mask]
        
        # 4. ë‚ ì§œ ì¸ë±ìŠ¤ ê²€ì¦
        if hasattr(df.index, 'year'):
            # 1970ë…„ ë°ì´í„° ì œê±° (íƒ€ì„ìŠ¤íƒ¬í”„ ì˜¤ë¥˜)
            df = df[df.index.year > 2000]
        
        # 5. ì¤‘ë³µ ì œê±°
        df = df[~df.index.duplicated(keep='last')]
        
        # 6. ì •ë ¬
        df = df.sort_index()
        
        logger.info(f"ğŸ”§ {ticker} ë°ì´í„° ì •ì œ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        return df

class TechnicalIndicatorBatchCollector:
    """ê¸°ìˆ ì  ì§€í‘œ ë°°ì¹˜ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, db_manager: DatabaseManager):
        self.db = db_manager
    
    def get_technical_data_batch(self, tickers: List[str]) -> Dict[str, Any]:
        """ì—¬ëŸ¬ í‹°ì»¤ì˜ ê¸°ìˆ ì  ì§€í‘œë¥¼ ë°°ì¹˜ë¡œ ì¡°íšŒ (Phase 1 ìµœì í™” ì ìš©)"""
        start_time = time.time()
        logger.info(f"ğŸ“Š ë°°ì¹˜ ê¸°ìˆ ì  ì§€í‘œ ì¡°íšŒ ì‹œì‘: {len(tickers)}ê°œ í‹°ì»¤")
        
        if not tickers:
            return {}
        
        results = {}
        
        try:
            conn = self.db.get_connection()
            cursor = conn.cursor()
            
            # Phase 1ì—ì„œ ìµœì í™”ëœ ë‹¨ì¼ JOIN ì¿¼ë¦¬ ì‚¬ìš©
            for ticker in tickers:
                cursor.execute("""
                    SELECT 
                        s.price, s.atr, s.adx, s.volume_change_7_30, s.supertrend_signal,
                        o.close, o.rsi_14, o.ma_50, o.ma_200, o.bb_upper, o.bb_lower
                    FROM static_indicators s
                    LEFT JOIN (
                        SELECT ticker, close, rsi_14, ma_50, ma_200, bb_upper, bb_lower
                        FROM ohlcv 
                        WHERE ticker = %s 
                        ORDER BY date DESC 
                        LIMIT 1
                    ) o ON s.ticker = o.ticker
                    WHERE s.ticker = %s
                """, (ticker, ticker))
                
                result = cursor.fetchone()
                
                if result:
                    results[ticker] = {
                        'price': result[0],
                        'atr': result[1],
                        'adx': result[2],
                        'volume_change_7_30': result[3],
                        'supertrend_signal': result[4],
                        'close': result[5],
                        'rsi_14': result[6],
                        'ma_50': result[7],
                        'ma_200': result[8],
                        'bb_upper': result[9],
                        'bb_lower': result[10]
                    }
                else:
                    results[ticker] = None
            
            cursor.close()
            
            elapsed = time.time() - start_time
            success_count = len([r for r in results.values() if r is not None])
            
            logger.info(f"âœ… ë°°ì¹˜ ì¡°íšŒ ì™„ë£Œ: {success_count}/{len(tickers)}ê°œ ì„±ê³µ ({elapsed:.3f}ì´ˆ)")
            logger.info(f"ğŸ’° DB ì¿¼ë¦¬ ìµœì í™”: {len(tickers)*2-len(tickers)}ê°œ ì¿¼ë¦¬ ì ˆì•½")
            
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ê¸°ìˆ ì  ì§€í‘œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

class LambdaDataCollector:
    """Lambda ë°ì´í„° ìˆ˜ì§‘ê¸° ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.db = DatabaseManager(DataCollectorConfig.DB_CONFIG)
        self.market_collector = MarketDataCollector(self.db)
        self.technical_collector = TechnicalIndicatorBatchCollector(self.db)
        
    def process_data_collection_request(self, event: dict) -> dict:
        """ë°ì´í„° ìˆ˜ì§‘ ìš”ì²­ ì²˜ë¦¬"""
        try:
            start_time = time.time()
            
            # ìš”ì²­ íŒŒë¼ë¯¸í„° íŒŒì‹±
            collection_type = event.get('collection_type', 'ohlcv_daily')
            tickers = event.get('tickers', [])
            force_fetch = event.get('force_fetch', False)
            
            logger.info(f"ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {collection_type}, {len(tickers)}ê°œ í‹°ì»¤")
            
            results = {}
            
            if collection_type == 'ohlcv_daily':
                results = self._collect_daily_data(tickers, force_fetch)
            elif collection_type == 'ohlcv_4h':
                results = self._collect_4h_data(tickers)
            elif collection_type == 'technical_batch':
                results = self._collect_technical_data(tickers)
            elif collection_type == 'mixed':
                # í˜¼í•© ìˆ˜ì§‘ (ì¼ë´‰ + ê¸°ìˆ ì  ì§€í‘œ)
                daily_results = self._collect_daily_data(tickers, force_fetch)
                technical_results = self._collect_technical_data(tickers)
                results = {
                    'daily_data': daily_results,
                    'technical_data': technical_results
                }
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìˆ˜ì§‘ íƒ€ì…: {collection_type}")
            
            elapsed = time.time() - start_time
            
            response = {
                'statusCode': 200,
                'body': {
                    'success': True,
                    'collection_type': collection_type,
                    'processed_tickers': len(tickers),
                    'execution_time': round(elapsed, 3),
                    'results': results,
                    'timestamp': datetime.now().isoformat()
                }
            }
            
            logger.info(f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {elapsed:.3f}ì´ˆ")
            return response
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'statusCode': 500,
                'body': {
                    'success': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
            }
    
    def _collect_daily_data(self, tickers: List[str], force_fetch: bool) -> dict:
        """ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘"""
        results = {}
        
        for ticker in tickers:
            try:
                df = self.market_collector.collect_ohlcv_daily(ticker, force_fetch)
                results[ticker] = {
                    'success': df is not None,
                    'records': len(df) if df is not None else 0
                }
            except Exception as e:
                logger.error(f"âŒ {ticker} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                results[ticker] = {
                    'success': False,
                    'error': str(e)
                }
        
        return results
    
    def _collect_4h_data(self, tickers: List[str]) -> dict:
        """4ì‹œê°„ë´‰ ë°ì´í„° ìˆ˜ì§‘"""
        results = {}
        
        for ticker in tickers:
            try:
                df = self.market_collector.collect_ohlcv_4h(ticker)
                results[ticker] = {
                    'success': df is not None,
                    'records': len(df) if df is not None else 0
                }
            except Exception as e:
                logger.error(f"âŒ {ticker} 4ì‹œê°„ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                results[ticker] = {
                    'success': False,
                    'error': str(e)
                }
        
        return results
    
    def _collect_technical_data(self, tickers: List[str]) -> dict:
        """ê¸°ìˆ ì  ì§€í‘œ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            return self.technical_collector.get_technical_data_batch(tickers)
        except Exception as e:
            logger.error(f"âŒ ê¸°ìˆ ì  ì§€í‘œ ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}

def lambda_handler(event, context):
    """Lambda í•¨ìˆ˜ ì§„ì…ì """
    try:
        logger.info(f"ğŸ“¥ Lambda ë°ì´í„° ìˆ˜ì§‘ ìš”ì²­ ìˆ˜ì‹ : {json.dumps(event, indent=2)}")
        
        # ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
        collector = LambdaDataCollector()
        
        # ìš”ì²­ ì²˜ë¦¬
        result = collector.process_data_collection_request(event)
        
        logger.info(f"ğŸ“¤ Lambda ì‘ë‹µ: {json.dumps(result, indent=2)}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Lambda í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return {
            'statusCode': 500,
            'body': {
                'success': False,
                'error': f"Lambda í•¨ìˆ˜ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}",
                'timestamp': datetime.now().isoformat()
            }
        }

# ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì´ë²¤íŠ¸
    test_event = {
        'collection_type': 'mixed',
        'tickers': ['KRW-BTC', 'KRW-ETH', 'KRW-ADA'],
        'force_fetch': False
    }
    
    result = lambda_handler(test_event, None)
    print(json.dumps(result, indent=2, ensure_ascii=False))