#!/usr/bin/env python3
"""
AWS Lambda í•¨ìˆ˜: Makenaide í‹°ì»¤ ìŠ¤ìºë„ˆ
ê¸°ëŠ¥: Upbit API í‹°ì»¤ ì¡°íšŒ â†’ ì‹ ê·œ í‹°ì»¤ ê°ì§€ â†’ DB ì—…ë°ì´íŠ¸ â†’ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ â†’ ê±°ë˜ëŸ‰ í•„í„°ë§ â†’ SQS ì „ì†¡
"""

import json
import boto3
import logging
import os
import pyupbit
from datetime import datetime, timedelta
from typing import List, Dict, Any

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
sqs = boto3.client('sqs')

def get_db_connection():
    """PostgreSQL DB ì—°ê²° - psycopg2ë¥¼ ë™ì ìœ¼ë¡œ import"""
    try:
        # ë™ì  importë¡œ psycopg2 ê°€ì ¸ì˜¤ê¸°
        import psycopg2
        import psycopg2.extras
    except ImportError as e:
        logger.error(f"psycopg2 import ì‹¤íŒ¨: {e}")
        raise Exception("psycopg2ê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
    
    try:
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
        pg_host = os.environ.get('PG_HOST', 'makenaide.cni2ka4ugf7f.ap-northeast-2.rds.amazonaws.com')
        pg_port = int(os.environ.get('PG_PORT', '5432'))
        pg_database = os.environ.get('PG_DATABASE', 'makenaide')
        pg_user = os.environ.get('PG_USER', 'bruce')
        pg_password = os.environ.get('PG_PASSWORD')
        
        if not pg_password:
            raise Exception("PG_PASSWORD í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        logger.info(f"DB ì—°ê²° ì‹œë„: {pg_host}:{pg_port}/{pg_database}")
        
        conn = psycopg2.connect(
            host=pg_host,
            port=pg_port,
            database=pg_database,
            user=pg_user,
            password=pg_password,
            connect_timeout=10
        )
        return conn
    except Exception as e:
        logger.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        raise

def load_blacklist_from_db() -> Dict[str, Any]:
    """DBì—ì„œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute("SELECT ticker, reason FROM blacklist WHERE is_active = true")
        results = cursor.fetchall()
        
        blacklist = {}
        for ticker, reason in results:
            blacklist[ticker] = reason
            
        cursor.close()
        conn.close()
        
        logger.info(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì™„ë£Œ: {len(blacklist)}ê°œ")
        return blacklist
        
    except Exception as e:
        logger.error(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}

def update_tickers():
    """
    Upbit APIë¥¼ í†µí•´ í‹°ì»¤ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    scanner.pyì˜ update_tickers í•¨ìˆ˜ë¥¼ Lambdaì— ë§ê²Œ í¬íŒ…
    """
    try:
        logger.info("ğŸ”„ í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        blacklist = load_blacklist_from_db()
        if not blacklist:
            logger.warning("âš ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ë¹„ì–´ìˆìŒ")
            blacklist = {}

        # í˜„ì¬ ê±°ë˜ ê°€ëŠ¥í•œ í‹°ì»¤ ëª©ë¡ ì¡°íšŒ (Upbit API)
        logger.info("ğŸ“¡ Upbit APIì—ì„œ í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì¤‘...")
        current_tickers = pyupbit.get_tickers(fiat="KRW")
        if not current_tickers:
            logger.error("âŒ Upbit API í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨")
            return False, "Upbit API í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨"

        logger.info(f"âœ… Upbit APIì—ì„œ {len(current_tickers)}ê°œ í‹°ì»¤ ì¡°íšŒ ì™„ë£Œ")

        # ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” í‹°ì»¤ ì œì™¸
        filtered_tickers = [ticker for ticker in current_tickers if ticker not in blacklist]
        if len(filtered_tickers) != len(current_tickers):
            blacklisted = set(current_tickers) - set(filtered_tickers)
            logger.info(f"â›”ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì œì™¸ í‹°ì»¤: {sorted(blacklisted)}")

        # DB ì—°ê²°
        conn = get_db_connection()
        cursor = conn.cursor()

        try:
            # ê¸°ì¡´ í‹°ì»¤ ì¡°íšŒ
            cursor.execute("SELECT ticker, updated_at FROM tickers")
            existing_rows = cursor.fetchall()
            existing_ticker_times = {row[0]: row[1] for row in existing_rows}

            logger.info(f"ğŸ“Š DBì— ê¸°ì¡´ í‹°ì»¤ {len(existing_ticker_times)}ê°œ ì¡´ì¬")

            # ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‹°ì»¤ DBì—ì„œ ì‚­ì œ
            blacklisted_tickers = set(existing_ticker_times.keys()) & set(blacklist.keys())
            if blacklisted_tickers:
                for ticker in blacklisted_tickers:
                    cursor.execute("DELETE FROM tickers WHERE ticker = %s", (ticker,))
                conn.commit()
                logger.info(f"ğŸ—‘ï¸ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‹°ì»¤ DBì—ì„œ ì‚­ì œ: {sorted(blacklisted_tickers)}")

            # ì‹ ê·œ í‹°ì»¤ ì¶”ê°€ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì œì™¸)
            new_tickers = set(filtered_tickers) - set(existing_ticker_times.keys())
            if new_tickers:
                for new_ticker in new_tickers:
                    cursor.execute(
                        "INSERT INTO tickers (ticker, created_at) VALUES (%s, CURRENT_TIMESTAMP)",
                        (new_ticker,)
                    )
                conn.commit()
                logger.info(f"ğŸ‰ ì‹ ê·œ í‹°ì»¤ ê°ì§€ ë° ì¶”ê°€ë¨: {sorted(new_tickers)}")

            # ê¸°ì¡´ í‹°ì»¤ ì—…ë°ì´íŠ¸ (24ì‹œê°„ ì´ìƒ ì§€ë‚œ ê²½ìš°)
            update_threshold = datetime.now() - timedelta(hours=24)
            updated_count = 0
            for ticker in filtered_tickers:
                if ticker in existing_ticker_times:
                    last_update = existing_ticker_times[ticker]
                    if last_update < update_threshold:
                        try:
                            cursor.execute("""
                                UPDATE tickers
                                SET updated_at = CURRENT_TIMESTAMP
                                WHERE ticker = %s
                            """, (ticker,))
                            updated_count += 1
                        except Exception as e:
                            logger.error(f"âŒ {ticker} ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
                            continue

            conn.commit()
            logger.info(f"âœ… í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ - ì‹ ê·œ: {len(new_tickers)}ê°œ, ì—…ë°ì´íŠ¸: {updated_count}ê°œ")
            
            return True, {
                'total_api_tickers': len(current_tickers),
                'filtered_tickers': len(filtered_tickers),
                'new_tickers': len(new_tickers),
                'updated_tickers': updated_count,
                'blacklisted_removed': len(blacklisted_tickers)
            }

        except Exception as e:
            conn.rollback()
            logger.error(f"âŒ DB ì‘ì—… ì¤‘ ì˜¤ë¥˜: {str(e)}")
            raise

        finally:
            cursor.close()
            conn.close()

    except Exception as e:
        logger.error(f"âŒ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return False, str(e)

def get_active_tickers() -> List[str]:
    """í™œì„± í‹°ì»¤ ëª©ë¡ ì¡°íšŒ (DBì—ì„œ)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # tickers í…Œì´ë¸”ì—ì„œ is_activeê°€ trueì¸ í‹°ì»¤ë“¤ë§Œ ì¡°íšŒ
        cursor.execute("""
            SELECT ticker 
            FROM tickers 
            WHERE is_active = true
            ORDER BY ticker
        """)
        
        tickers = [row[0] for row in cursor.fetchall()]
        
        cursor.close()
        conn.close()
        
        logger.info(f"í™œì„± í‹°ì»¤ ì¡°íšŒ ì™„ë£Œ: {len(tickers)}ê°œ")
        return tickers
        
    except Exception as e:
        logger.error(f"í™œì„± í‹°ì»¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        # í´ë°±: ëª¨ë“  í‹°ì»¤ ì¡°íšŒ
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT DISTINCT ticker FROM tickers ORDER BY ticker")
            tickers = [row[0] for row in cursor.fetchall()]
            cursor.close()
            conn.close()
            logger.info(f"í´ë°±ìœ¼ë¡œ ì „ì²´ í‹°ì»¤ ì¡°íšŒ: {len(tickers)}ê°œ")
            return tickers
        except:
            return []

def filter_by_volume(tickers: List[str]) -> List[str]:
    """ê±°ë˜ëŸ‰ ê¸°ë°˜ í•„í„°ë§"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        filtered_tickers = []
        
        for ticker in tickers:
            # ìµœê·¼ 7ì¼ í‰ê·  ê±°ë˜ëŸ‰ í™•ì¸
            cursor.execute("""
                SELECT AVG(volume * close) as avg_trading_value
                FROM ohlcv 
                WHERE ticker = %s 
                AND date >= CURRENT_DATE - INTERVAL '7 days'
            """, (ticker,))
            
            result = cursor.fetchone()
            if result and result[0]:
                avg_trading_value = float(result[0])
                
                # 1ì–µì› ì´ìƒ ê±°ë˜ëŒ€ê¸ˆ
                if avg_trading_value >= 100_000_000:
                    filtered_tickers.append(ticker)
        
        cursor.close()
        conn.close()
        
        logger.info(f"ê±°ë˜ëŸ‰ í•„í„°ë§ ì™„ë£Œ: {len(filtered_tickers)}ê°œ (ì „ì²´: {len(tickers)}ê°œ)")
        return filtered_tickers
        
    except Exception as e:
        logger.error(f"ê±°ë˜ëŸ‰ í•„í„°ë§ ì‹¤íŒ¨: {e}")
        return tickers  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜

def send_to_sqs(tickers: List[str], queue_url: str):
    """SQSì— í‹°ì»¤ ëª©ë¡ ì „ì†¡"""
    try:
        # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì „ì†¡ (10ê°œì”©)
        batch_size = 10
        
        for i in range(0, len(tickers), batch_size):
            batch = tickers[i:i + batch_size]
            
            entries = []
            for j, ticker in enumerate(batch):
                entries.append({
                    'Id': str(i + j),
                    'MessageBody': json.dumps({
                        'ticker': ticker,
                        'timestamp': datetime.now().isoformat(),
                        'source': 'ticker_scanner'
                    })
                })
            
            response = sqs.send_message_batch(
                QueueUrl=queue_url,
                Entries=entries
            )
            
            logger.info(f"SQS ì „ì†¡ ì™„ë£Œ: {len(entries)}ê°œ (ë°°ì¹˜ {i//batch_size + 1})")
            
        logger.info(f"ì „ì²´ SQS ì „ì†¡ ì™„ë£Œ: {len(tickers)}ê°œ í‹°ì»¤")
        
    except Exception as e:
        logger.error(f"SQS ì „ì†¡ ì‹¤íŒ¨: {e}")
        raise

def lambda_handler(event, context):
    """Lambda ë©”ì¸ í•¸ë“¤ëŸ¬"""
    try:
        logger.info("ğŸš€ Makenaide í†µí•© í‹°ì»¤ ìŠ¤ìºë„ˆ ì‹œì‘")
        start_time = datetime.now()
        
        # 1. í‹°ì»¤ ì •ë³´ ì—…ë°ì´íŠ¸ (Upbit API â†’ DB)
        update_success, update_result = update_tickers()
        if not update_success:
            logger.error(f"âŒ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_result}")
            return {
                'statusCode': 500,
                'body': json.dumps({
                    'error': f'í‹°ì»¤ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {update_result}',
                    'timestamp': datetime.now().isoformat()
                })
            }
        
        # 2. í™œì„± í‹°ì»¤ ì¡°íšŒ (DBì—ì„œ)
        tickers = get_active_tickers()
        if not tickers:
            logger.warning("í™œì„± í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'message': 'í™œì„± í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤',
                    'update_result': update_result,
                    'processed_count': 0
                })
            }
        
        # 3. ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„°ë§ (ì¶”ê°€ í•„í„°ë§)
        blacklist = load_blacklist_from_db()
        filtered_tickers = [t for t in tickers if t not in blacklist]
        
        logger.info(f"ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ í•„í„°ë§: {len(tickers)} â†’ {len(filtered_tickers)}")
        
        # 4. ê±°ë˜ëŸ‰ í•„í„°ë§
        volume_filtered = filter_by_volume(filtered_tickers)
        
        # 5. SQS ì „ì†¡
        queue_url = os.environ.get('OHLCV_QUEUE_URL')
        if queue_url and volume_filtered:
            send_to_sqs(volume_filtered, queue_url)
        
        # 6. ê²°ê³¼ ë°˜í™˜
        execution_time = (datetime.now() - start_time).total_seconds()
        
        result = {
            'statusCode': 200,
            'body': json.dumps({
                'message': 'í†µí•© í‹°ì»¤ ìŠ¤ìºë‹ ì™„ë£Œ',
                'update_result': update_result,
                'total_db_tickers': len(tickers),
                'blacklist_filtered': len(filtered_tickers),
                'volume_filtered': len(volume_filtered),
                'execution_time': execution_time,
                'timestamp': datetime.now().isoformat()
            })
        }
        
        logger.info(f"âœ… í†µí•© í‹°ì»¤ ìŠ¤ìºë‹ ì™„ë£Œ: {len(volume_filtered)}ê°œ í‹°ì»¤ ì²˜ë¦¬")
        return result
        
    except Exception as e:
        logger.error(f"âŒ í†µí•© í‹°ì»¤ ìŠ¤ìºë‹ ì‹¤íŒ¨: {e}")
        import traceback
        logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })
        } 