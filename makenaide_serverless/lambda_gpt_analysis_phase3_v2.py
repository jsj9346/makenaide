#!/usr/bin/env python3
"""
âš¡ Phase 3: GPT Analysis Lambda
- OpenAI GPT-4ë¥¼ í™œìš©í•œ ì „ë¬¸ê°€ê¸‰ ì°¨íŠ¸ ë° ë°ì´í„° ë¶„ì„
- JSON ë°ì´í„° + ì°¨íŠ¸ ì´ë¯¸ì§€ ë³µí•© ë¶„ì„
- Phase 2 ê²°ê³¼ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ìµœì¢… íˆ¬ì ì˜ê²¬ ì œê³µ
"""

import boto3
import json
import logging
import pandas as pd
import numpy as np
import pytz
import os
import base64
import io
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
import pyupbit
import openai
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.patches import Rectangle
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger()
logger.setLevel(logging.INFO)

class GPTAnalysisPhase3:
    """GPT-4ë¥¼ í™œìš©í•œ ì¢…í•© ì°¨íŠ¸ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.s3_client = boto3.client('s3')
        self.events_client = boto3.client('events')
        self.secrets_client = boto3.client('secretsmanager')
        self.s3_bucket = os.environ.get('S3_BUCKET', 'makenaide-serverless-data')
        self.kst = pytz.timezone('Asia/Seoul')
        
        # OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
        self.openai_api_key = self._get_secret('makenaide-openai-api-key')
        if self.openai_api_key:
            openai.api_key = self.openai_api_key
        
        # GPT ë¶„ì„ ì„¤ì •
        self.gpt_config = {
            'model': os.environ.get('OPENAI_MODEL', 'gpt-4'),
            'max_tokens': int(os.environ.get('GPT_MAX_TOKENS', '2000')),
            'temperature': float(os.environ.get('GPT_TEMPERATURE', '0.3')),
            'analysis_depth': os.environ.get('ANALYSIS_DEPTH', 'comprehensive')  # basic, detailed, comprehensive
        }

    def _get_secret(self, secret_name: str) -> Optional[str]:
        """AWS Secrets Managerì—ì„œ API í‚¤ ì¡°íšŒ"""
        try:
            response = self.secrets_client.get_secret_value(SecretId=secret_name)
            return response['SecretString']
        except Exception as e:
            logger.error(f"âŒ Secret ì¡°íšŒ ì‹¤íŒ¨ {secret_name}: {e}")
            return None

    def load_phase2_data(self) -> Optional[List[Dict[str, Any]]]:
        """Phase 2 ê²°ê³¼ ë°ì´í„° ë¡œë“œ"""
        try:
            logger.info("ğŸ“Š Phase 2 ê²°ê³¼ ë°ì´í„° ë¡œë“œ ì¤‘...")
            
            # ìµœì‹  Phase 2 ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
            response = self.s3_client.list_objects_v2(
                Bucket=self.s3_bucket,
                Prefix='phase2/comprehensive_filtered_candidates_'
            )
            
            if 'Contents' not in response or not response['Contents']:
                logger.warning("Phase 2 ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ê°€ì¥ ìµœì‹  íŒŒì¼ ì„ íƒ
            latest_file = max(response['Contents'], key=lambda x: x['LastModified'])
            
            response = self.s3_client.get_object(
                Bucket=self.s3_bucket,
                Key=latest_file['Key']
            )
            
            data = json.loads(response['Body'].read().decode('utf-8'))
            
            candidates = data.get('candidates', [])
            if not candidates:
                logger.warning("Phase 2ì—ì„œ í•„í„°ë§ëœ í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
                
            logger.info(f"âœ… Phase 2 ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(candidates)}ê°œ í›„ë³´")
            return candidates
            
        except Exception as e:
            logger.error(f"âŒ Phase 2 ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def get_ohlcv_data(self, ticker: str, period: int = 60) -> Optional[pd.DataFrame]:
        """ì—…ë¹„íŠ¸ì—ì„œ OHLCV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            logger.info(f"ğŸ“ˆ {ticker} OHLCV ë°ì´í„° ì¡°íšŒ ì¤‘... (ìµœê·¼ {period}ì¼)")
            
            # ì—…ë¹„íŠ¸ APIë¡œ ë°ì´í„° ì¡°íšŒ
            df = pyupbit.get_ohlcv(ticker, interval="day", count=period)
            
            if df is None or df.empty:
                logger.warning(f"{ticker} ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
                return None
            
            # ë°ì´í„° ì •ë¦¬
            df.index.name = 'date'
            df.reset_index(inplace=True)
            df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']
            
            logger.info(f"âœ… {ticker} ë°ì´í„° ì¡°íšŒ ì™„ë£Œ: {len(df)}ì¼")
            return df
            
        except Exception as e:
            logger.error(f"âŒ {ticker} OHLCV ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def create_comprehensive_chart(self, ticker: str, df: pd.DataFrame, candidate_data: Dict) -> Optional[str]:
        """ì¢…í•© ì°¨íŠ¸ ìƒì„± (ìº”ë“¤ìŠ¤í‹± + ê¸°ìˆ ì§€í‘œ)"""
        try:
            logger.info(f"ğŸ¨ {ticker} ì¢…í•© ì°¨íŠ¸ ìƒì„± ì¤‘...")
            
            # ì°¨íŠ¸ ì„¤ì •
            fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 12), height_ratios=[3, 1, 1])
            fig.suptitle(f'{ticker} ì¢…í•© ê¸°ìˆ  ë¶„ì„', fontsize=16, fontweight='bold')
            
            # ìƒ‰ìƒ ì„¤ì •
            up_color = '#FF6B6B'    # ìƒìŠ¹ - ë¹¨ê°„ìƒ‰
            down_color = '#4ECDC4'  # í•˜ë½ - ì²­ë¡ìƒ‰
            volume_color = '#95E1D3'
            
            # === 1. ë©”ì¸ ì°¨íŠ¸: ìº”ë“¤ìŠ¤í‹± + ì´ë™í‰ê· ì„  ===
            dates = df['date']
            opens = df['open']
            highs = df['high'] 
            lows = df['low']
            closes = df['close']
            volumes = df['volume']
            
            # ìº”ë“¤ìŠ¤í‹± ê·¸ë¦¬ê¸°
            for i in range(len(df)):
                date = i
                open_price = opens.iloc[i]
                high_price = highs.iloc[i]
                low_price = lows.iloc[i]
                close_price = closes.iloc[i]
                
                color = up_color if close_price >= open_price else down_color
                
                # ëª¸í†µ
                height = abs(close_price - open_price)
                bottom = min(open_price, close_price)
                ax1.add_patch(Rectangle((date-0.3, bottom), 0.6, height, 
                                      facecolor=color, edgecolor='black', alpha=0.8))
                
                # ê¼¬ë¦¬
                ax1.plot([date, date], [low_price, high_price], color='black', linewidth=1)
            
            # ì´ë™í‰ê· ì„ 
            ma5 = closes.rolling(5).mean()
            ma20 = closes.rolling(20).mean() 
            ma60 = closes.rolling(60).mean()
            
            ax1.plot(range(len(df)), ma5, label='MA5', color='#FF9F43', linewidth=2)
            ax1.plot(range(len(df)), ma20, label='MA20', color='#10AC84', linewidth=2)
            ax1.plot(range(len(df)), ma60, label='MA60', color='#5F27CD', linewidth=2)
            
            # í˜„ì¬ ê°€ê²©ê³¼ ê¸°ë³¸ ì •ë³´ í‘œì‹œ
            current_price = closes.iloc[-1]
            price_change = ((current_price - closes.iloc[-2]) / closes.iloc[-2]) * 100
            
            ax1.set_title(f'í˜„ì¬ê°€: {current_price:,.0f}ì› ({price_change:+.2f}%)', 
                         fontsize=12, pad=20)
            ax1.legend(loc='upper left')
            ax1.grid(True, alpha=0.3)
            ax1.set_ylabel('ê°€ê²© (ì›)', fontsize=10)
            
            # === 2. RSI ì°¨íŠ¸ ===
            # RSI ê³„ì‚°
            delta = closes.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            
            ax2.plot(range(len(df)), rsi, color='#6C5CE7', linewidth=2)
            ax2.axhline(y=70, color='red', linestyle='--', alpha=0.7, label='ê³¼ë§¤ìˆ˜ (70)')
            ax2.axhline(y=30, color='blue', linestyle='--', alpha=0.7, label='ê³¼ë§¤ë„ (30)')
            ax2.axhline(y=50, color='gray', linestyle='-', alpha=0.5)
            ax2.fill_between(range(len(df)), 30, 70, alpha=0.1, color='yellow')
            
            current_rsi = rsi.iloc[-1]
            ax2.set_title(f'RSI(14): {current_rsi:.1f}', fontsize=10)
            ax2.set_ylabel('RSI', fontsize=10)
            ax2.legend(loc='upper right', fontsize=8)
            ax2.grid(True, alpha=0.3)
            ax2.set_ylim(0, 100)
            
            # === 3. ê±°ë˜ëŸ‰ ì°¨íŠ¸ ===
            colors = [up_color if closes.iloc[i] >= opens.iloc[i] else down_color for i in range(len(df))]
            ax3.bar(range(len(df)), volumes, color=colors, alpha=0.6, width=0.8)
            
            volume_ma = volumes.rolling(20).mean()
            ax3.plot(range(len(df)), volume_ma, color='orange', linewidth=2, label='ê±°ë˜ëŸ‰ MA20')
            
            current_volume = volumes.iloc[-1]
            volume_ratio = current_volume / volume_ma.iloc[-1] if pd.notna(volume_ma.iloc[-1]) else 1
            
            ax3.set_title(f'ê±°ë˜ëŸ‰: {current_volume:,.0f} (í‰ê·  ëŒ€ë¹„ {volume_ratio:.1f}ë°°)', fontsize=10)
            ax3.set_ylabel('ê±°ë˜ëŸ‰', fontsize=10)
            ax3.legend(loc='upper right', fontsize=8)
            ax3.grid(True, alpha=0.3)
            ax3.set_xlabel('ì¼ì (ìµœê·¼ 60ì¼)', fontsize=10)
            
            # Xì¶• ë¼ë²¨ ì„¤ì • (ìµœê·¼ ë‚ ì§œë“¤ë§Œ)
            x_ticks = range(0, len(df), max(1, len(df)//6))
            x_labels = [dates.iloc[i].strftime('%m/%d') for i in x_ticks]
            for ax in [ax1, ax2, ax3]:
                ax.set_xticks(x_ticks)
                ax.set_xticklabels(x_labels, rotation=45)
            
            plt.tight_layout()
            
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            image_base64 = base64.b64encode(buffer.getvalue()).decode()
            
            plt.close()
            logger.info(f"âœ… {ticker} ì°¨íŠ¸ ìƒì„± ì™„ë£Œ")
            return image_base64
            
        except Exception as e:
            logger.error(f"âŒ {ticker} ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def prepare_analysis_data(self, ticker: str, candidate_data: Dict, df: pd.DataFrame) -> Dict[str, Any]:
        """GPT ë¶„ì„ìš© ë°ì´í„° ì¤€ë¹„"""
        try:
            # ìµœì‹  ë°ì´í„° ê³„ì‚°
            current_price = df['close'].iloc[-1]
            prev_price = df['close'].iloc[-2]
            price_change_1d = ((current_price - prev_price) / prev_price) * 100
            
            # ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
            ma5 = df['close'].rolling(5).mean().iloc[-1]
            ma20 = df['close'].rolling(20).mean().iloc[-1]
            ma60 = df['close'].rolling(60).mean().iloc[-1]
            
            # RSI
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = (100 - (100 / (1 + rs))).iloc[-1]
            
            # ê±°ë˜ëŸ‰ ë¶„ì„
            current_volume = df['volume'].iloc[-1]
            avg_volume_20 = df['volume'].rolling(20).mean().iloc[-1]
            volume_ratio = current_volume / avg_volume_20 if avg_volume_20 > 0 else 1
            
            # ê°€ê²© ìœ„ì¹˜ ë¶„ì„
            high_52w = df['high'].max()
            low_52w = df['low'].min()
            price_position = ((current_price - low_52w) / (high_52w - low_52w)) * 100
            
            analysis_data = {
                'ticker': ticker,
                'timestamp': datetime.now(self.kst).isoformat(),
                'market_condition': candidate_data.get('market_condition', 'NEUTRAL'),
                
                # ê°€ê²© ì •ë³´
                'price_data': {
                    'current_price': current_price,
                    'price_change_1d': price_change_1d,
                    'high_52w': high_52w,
                    'low_52w': low_52w,
                    'price_position_pct': price_position
                },
                
                # ê¸°ìˆ ì  ì§€í‘œ
                'technical_indicators': {
                    'ma5': ma5,
                    'ma20': ma20, 
                    'ma60': ma60,
                    'rsi_14': rsi,
                    'ma_arrangement': 'bullish' if current_price > ma5 > ma20 else 'bearish'
                },
                
                # ê±°ë˜ëŸ‰ ë¶„ì„
                'volume_analysis': {
                    'current_volume': current_volume,
                    'avg_volume_20': avg_volume_20,
                    'volume_ratio': volume_ratio,
                    'volume_trend': 'high' if volume_ratio > 1.5 else 'normal'
                },
                
                # Phase 2 í•„í„°ë§ ê²°ê³¼
                'phase2_analysis': {
                    'final_score': candidate_data.get('final_score', 0),
                    'filter_score': candidate_data.get('filter_score', 0),
                    'pattern_score': candidate_data.get('pattern_score', 0),
                    'pattern_analysis': candidate_data.get('pattern_analysis', {}),
                    'analysis_details': candidate_data.get('analysis_details', {})
                }
            }
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"âŒ {ticker} ë¶„ì„ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return {}

    def create_gpt_prompt(self, ticker: str, analysis_data: Dict, market_condition: str) -> str:
        """GPT ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        prompt = f"""
ë‹¹ì‹ ì€ ì•”í˜¸í™”í ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. {ticker}ì— ëŒ€í•œ ì¢…í•©ì ì¸ ê¸°ìˆ  ë¶„ì„ì„ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”.

## ğŸ“Š ê¸°ë³¸ ì •ë³´
- í‹°ì»¤: {ticker}
- í˜„ì¬ê°€: {analysis_data['price_data']['current_price']:,.0f}ì›
- 1ì¼ ë³€í™”ìœ¨: {analysis_data['price_data']['price_change_1d']:+.2f}%
- ì‹œì¥ ìƒí™©: {market_condition}
- 52ì£¼ ê°€ê²© ìœ„ì¹˜: {analysis_data['price_data']['price_position_pct']:.1f}%

## ğŸ“ˆ ê¸°ìˆ ì  ì§€í‘œ
- MA5: {analysis_data['technical_indicators']['ma5']:,.0f}ì›
- MA20: {analysis_data['technical_indicators']['ma20']:,.0f}ì›  
- MA60: {analysis_data['technical_indicators']['ma60']:,.0f}ì›
- RSI(14): {analysis_data['technical_indicators']['rsi_14']:.1f}
- ì´í‰ì„  ë°°ì—´: {analysis_data['technical_indicators']['ma_arrangement']}

## ğŸ“Š ê±°ë˜ëŸ‰ ë¶„ì„
- í˜„ì¬ ê±°ë˜ëŸ‰: {analysis_data['volume_analysis']['current_volume']:,.0f}
- í‰ê·  ê±°ë˜ëŸ‰ ëŒ€ë¹„: {analysis_data['volume_analysis']['volume_ratio']:.1f}ë°°
- ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ: {analysis_data['volume_analysis']['volume_trend']}

## ğŸ¯ Phase 2 í•„í„°ë§ ê²°ê³¼
- ìµœì¢… ì ìˆ˜: {analysis_data['phase2_analysis']['final_score']:.1f}ì 
- í•„í„° ì ìˆ˜: {analysis_data['phase2_analysis']['filter_score']:.1f}ì 
- íŒ¨í„´ ì ìˆ˜: {analysis_data['phase2_analysis']['pattern_score']:.1f}ì 
- ì™€ì¸ìŠ¤íƒ€ì¸ Stage2: {analysis_data['phase2_analysis']['pattern_analysis'].get('weinstein_stage2', False)}
- ë¯¸ë„ˆë¹„ë‹ˆ VCP: {analysis_data['phase2_analysis']['pattern_analysis'].get('minervini_vcp', False)}
- ì˜¤ë‹ ì»µí•¸ë“¤: {analysis_data['phase2_analysis']['pattern_analysis'].get('oneill_cup_handle', False)}

## ğŸ” ë¶„ì„ ìš”ì²­ì‚¬í•­

ë‹¤ìŒ ê´€ì ì—ì„œ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ ì£¼ì„¸ìš”:

### 1. ê¸°ìˆ ì  ë¶„ì„ (Technical Analysis)
- í˜„ì¬ ì¶”ì„¸ì™€ ëª¨ë©˜í…€ í‰ê°€
- ì£¼ìš” ì§€ì§€/ì €í•­ ìˆ˜ì¤€ í™•ì¸
- ì´ë™í‰ê· ì„  ë¶„ì„ ë° ëŒíŒŒ ê°€ëŠ¥ì„±
- RSI ê¸°ë°˜ ê³¼ë§¤ìˆ˜/ê³¼ë§¤ë„ ìƒíƒœ

### 2. íŒ¨í„´ ë¶„ì„ (Pattern Recognition)
- ì™€ì¸ìŠ¤íƒ€ì¸ 4ë‹¨ê³„ ì‚¬ì´í´ì—ì„œì˜ í˜„ì¬ ìœ„ì¹˜
- ë¯¸ë„ˆë¹„ë‹ˆ VCP íŒ¨í„´ ì¡´ì¬ ì—¬ë¶€ ë° ì™„ì„±ë„
- ì˜¤ë‹ì˜ ì»µì•¤í•¸ë“¤ ë˜ëŠ” ê¸°íƒ€ ëŒíŒŒ íŒ¨í„´

### 3. ì‹œì¥ ìƒí™©ë³„ ì „ëµ (Market Context)
- í˜„ì¬ {market_condition} ì‹œì¥ì—ì„œì˜ ì í•©ì„±
- í•˜ë½ì¥/ìƒìŠ¹ì¥ë³„ ë§ì¶¤ ì ‘ê·¼ë²•
- ë¦¬ìŠ¤í¬ ìš”ì¸ ë° ì£¼ì˜ì‚¬í•­

### 4. íˆ¬ì ì˜ê²¬ (Investment Opinion)
- ë§¤ìˆ˜/ê´€ë§/ë§¤ë„ ì¶”ì²œ (BUY/HOLD/SELL)
- ëª©í‘œê°€ ë° ì†ì ˆê°€ ì œì•ˆ
- í¬ì§€ì…˜ í¬ê¸° ê¶Œì¥ì‚¬í•­ (1-10 ì ìˆ˜)

### 5. ë¦¬ìŠ¤í¬ í‰ê°€ (Risk Assessment)
- íˆ¬ì ë¦¬ìŠ¤í¬ ìˆ˜ì¤€ (1-10)
- ì£¼ìš” ìœ„í—˜ ìš”ì¸
- ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸

## ğŸ“ ì‘ë‹µ í˜•ì‹
JSON í˜•íƒœë¡œ êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”:

```json
{{
    "ticker": "{ticker}",
    "analysis_timestamp": "{analysis_data.get('timestamp', '')}",
    "overall_rating": "BUY/HOLD/SELL",
    "confidence_score": 85,
    "technical_analysis": {{
        "trend_direction": "bullish/bearish/neutral",
        "momentum_strength": "strong/moderate/weak",
        "support_level": 50000,
        "resistance_level": 60000,
        "key_insights": ["ìƒìŠ¹ ëŒíŒŒ ì„ë°•", "ê±°ë˜ëŸ‰ ê¸‰ì¦ ì‹ í˜¸"]
    }},
    "pattern_analysis": {{
        "primary_pattern": "Stage 2 Breakout",
        "pattern_completion": 80,
        "breakout_probability": 75,
        "pattern_insights": ["VCP íŒ¨í„´ ì™„ì„±ë„ ë†’ìŒ"]
    }},
    "market_context": {{
        "market_suitability": "high/medium/low",
        "strategy_recommendation": "ì ê·¹ ë§¤ìˆ˜",
        "risk_factors": ["ì‹œì¥ ì „ë°˜ ë³€ë™ì„±"]
    }},
    "investment_opinion": {{
        "recommendation": "BUY",
        "target_price": 65000,
        "stop_loss": 45000,
        "position_size_score": 7,
        "holding_period": "2-4 weeks"
    }},
    "risk_assessment": {{
        "risk_level": 6,
        "major_risks": ["ì‹œì¥ ê¸‰ë½ ë¦¬ìŠ¤í¬"],
        "monitoring_points": ["ê±°ë˜ëŸ‰ ë³€í™”", "MA20 ì´íƒˆ ì—¬ë¶€"]
    }},
    "summary": "ì¢…í•©ì ì¸ íˆ¬ì ì˜ê²¬ ìš”ì•½ (2-3ë¬¸ì¥)"
}}
```

ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.
"""
        
        return prompt

    def analyze_with_gpt(self, ticker: str, analysis_data: Dict, chart_base64: Optional[str] = None) -> Optional[Dict]:
        """GPT-4ë¥¼ ì‚¬ìš©í•œ ì¢…í•© ë¶„ì„"""
        try:
            if not self.openai_api_key:
                logger.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return None
                
            logger.info(f"ğŸ¤– {ticker} GPT ë¶„ì„ ì‹œì‘...")
            
            market_condition = analysis_data.get('market_condition', 'NEUTRAL')
            prompt = self.create_gpt_prompt(ticker, analysis_data, market_condition)
            
            # GPT-4 API í˜¸ì¶œ
            messages = [
                {
                    "role": "system", 
                    "content": "ë‹¹ì‹ ì€ ì•”í˜¸í™”í ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì™€ì¸ìŠ¤íƒ€ì¸, ë¯¸ë„ˆë¹„ë‹ˆ, ì˜¤ë‹ì˜ ê¸°ìˆ ì  ë¶„ì„ ì´ë¡ ì— ì •í†µí•˜ë©°, JSON í˜•íƒœì˜ êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ]
            
            # ì°¨íŠ¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€ (í–¥í›„ vision API ì§€ì›ì‹œ)
            if chart_base64 and "gpt-4-vision" in self.gpt_config['model']:
                messages[1]["content"] = [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{chart_base64}"}}
                ]
            
            response = openai.ChatCompletion.create(
                model=self.gpt_config['model'],
                messages=messages,
                max_tokens=self.gpt_config['max_tokens'],
                temperature=self.gpt_config['temperature'],
                timeout=60
            )
            
            gpt_result = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                # JSON ë¶€ë¶„ ì¶”ì¶œ
                start_idx = gpt_result.find('{')
                end_idx = gpt_result.rfind('}') + 1
                if start_idx != -1 and end_idx != -1:
                    json_str = gpt_result[start_idx:end_idx]
                    analysis_result = json.loads(json_str)
                else:
                    # JSONì´ ì—†ëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”
                    analysis_result = {
                        "ticker": ticker,
                        "analysis_timestamp": analysis_data.get('timestamp', ''),
                        "overall_rating": "HOLD",
                        "confidence_score": 50,
                        "gpt_raw_response": gpt_result,
                        "summary": gpt_result[:200] + "..." if len(gpt_result) > 200 else gpt_result
                    }
            except json.JSONDecodeError:
                logger.warning(f"GPT ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸ ì €ì¥: {ticker}")
                analysis_result = {
                    "ticker": ticker,
                    "analysis_timestamp": analysis_data.get('timestamp', ''),
                    "overall_rating": "HOLD",
                    "confidence_score": 50,
                    "gpt_raw_response": gpt_result,
                    "summary": "GPT ë¶„ì„ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨)"
                }
            
            logger.info(f"âœ… {ticker} GPT ë¶„ì„ ì™„ë£Œ: {analysis_result.get('overall_rating', 'HOLD')}")
            return analysis_result
            
        except Exception as e:
            logger.error(f"âŒ {ticker} GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "ticker": ticker,
                "analysis_timestamp": analysis_data.get('timestamp', ''),
                "overall_rating": "HOLD",
                "confidence_score": 0,
                "error": str(e),
                "summary": f"GPT ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
            }

    def process_candidates(self, candidates: List[Dict]) -> List[Dict[str, Any]]:
        """í›„ë³´ë“¤ì— ëŒ€í•´ GPT ë¶„ì„ ì‹¤í–‰"""
        try:
            logger.info(f"ğŸ” GPT ë¶„ì„ ì‹œì‘: {len(candidates)}ê°œ í›„ë³´")
            analysis_results = []
            
            for idx, candidate in enumerate(candidates):
                ticker = candidate.get('ticker')
                if not ticker:
                    continue
                
                try:
                    logger.info(f"ğŸ“Š {ticker} ë¶„ì„ ì¤‘... ({idx+1}/{len(candidates)})")
                    
                    # 1. OHLCV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    df = self.get_ohlcv_data(ticker, period=60)
                    if df is None:
                        logger.warning(f"{ticker} ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨, ê±´ë„ˆë›°ê¸°")
                        continue
                    
                    # 2. ì°¨íŠ¸ ìƒì„±
                    chart_base64 = self.create_comprehensive_chart(ticker, df, candidate)
                    
                    # 3. ë¶„ì„ ë°ì´í„° ì¤€ë¹„
                    analysis_data = self.prepare_analysis_data(ticker, candidate, df)
                    if not analysis_data:
                        logger.warning(f"{ticker} ë¶„ì„ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨")
                        continue
                    
                    # 4. GPT ë¶„ì„ ì‹¤í–‰
                    gpt_analysis = self.analyze_with_gpt(ticker, analysis_data, chart_base64)
                    if not gpt_analysis:
                        logger.warning(f"{ticker} GPT ë¶„ì„ ì‹¤íŒ¨")
                        continue
                    
                    # 5. ê²°ê³¼ í†µí•©
                    final_result = {
                        'ticker': ticker,
                        'analysis_timestamp': datetime.now(self.kst).isoformat(),
                        'phase2_data': candidate,
                        'technical_data': analysis_data,
                        'gpt_analysis': gpt_analysis,
                        'chart_base64': chart_base64,
                        'processing_order': idx + 1
                    }
                    
                    analysis_results.append(final_result)
                    logger.info(f"âœ… {ticker} ë¶„ì„ ì™„ë£Œ: {gpt_analysis.get('overall_rating', 'HOLD')}")
                    
                    # API ì œí•œ ê³ ë ¤í•˜ì—¬ ëŒ€ê¸° (1ì´ˆ)
                    if idx < len(candidates) - 1:  # ë§ˆì§€ë§‰ì´ ì•„ë‹Œ ê²½ìš°
                        import time
                        time.sleep(1)
                
                except Exception as e:
                    logger.error(f"âŒ {ticker} ê°œë³„ ë¶„ì„ ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"ğŸ¯ GPT ë¶„ì„ ì™„ë£Œ: {len(analysis_results)}ê°œ ë¶„ì„ ê²°ê³¼")
            return analysis_results
            
        except Exception as e:
            logger.error(f"âŒ í›„ë³´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []

    def save_results_to_s3(self, results: List[Dict[str, Any]]) -> bool:
        """ë¶„ì„ ê²°ê³¼ë¥¼ S3ì— ì €ì¥"""
        try:
            timestamp = datetime.now(self.kst).strftime('%Y%m%d_%H%M%S')
            
            # ê²°ê³¼ ë°ì´í„° êµ¬ì„±
            output_data = {
                'phase': 'gpt_analysis',
                'status': 'success',
                'timestamp': timestamp,
                'analyzed_count': len(results),
                'gpt_config': self.gpt_config,
                'analysis_results': results,
                'summary': {
                    'total_analyzed': len(results),
                    'ratings': {
                        'BUY': len([r for r in results if r.get('gpt_analysis', {}).get('overall_rating') == 'BUY']),
                        'HOLD': len([r for r in results if r.get('gpt_analysis', {}).get('overall_rating') == 'HOLD']),
                        'SELL': len([r for r in results if r.get('gpt_analysis', {}).get('overall_rating') == 'SELL'])
                    },
                    'avg_confidence': np.mean([r.get('gpt_analysis', {}).get('confidence_score', 0) for r in results]) if results else 0
                }
            }
            
            # ë©”ì¸ ê²°ê³¼ íŒŒì¼
            main_key = f'phase3/gpt_analysis_results_{timestamp}.json'
            
            # ì°¨íŠ¸ ì´ë¯¸ì§€ë“¤ì€ ì œì™¸í•˜ê³  ì €ì¥ (ìš©ëŸ‰ ìµœì í™”)
            save_data = output_data.copy()
            for result in save_data['analysis_results']:
                if 'chart_base64' in result:
                    del result['chart_base64']  # ì°¨íŠ¸ëŠ” ë³„ë„ ì €ì¥
            
            self.s3_client.put_object(
                Bucket=self.s3_bucket,
                Key=main_key,
                Body=json.dumps(save_data, indent=2, ensure_ascii=False),
                ContentType='application/json'
            )
            
            # ì°¨íŠ¸ ì´ë¯¸ì§€ë“¤ ë³„ë„ ì €ì¥
            for result in results:
                if 'chart_base64' in result and result['chart_base64']:
                    chart_key = f'phase3/charts/{result["ticker"]}_chart_{timestamp}.png'
                    self.s3_client.put_object(
                        Bucket=self.s3_bucket,
                        Key=chart_key,
                        Body=base64.b64decode(result['chart_base64']),
                        ContentType='image/png'
                    )
            
            logger.info(f"âœ… Phase 3 ê²°ê³¼ S3 ì €ì¥ ì™„ë£Œ: s3://{self.s3_bucket}/{main_key}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ S3 ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    def trigger_next_phase(self) -> bool:
        """Phase 4 íŠ¸ë¦¬ê±°"""
        try:
            self.events_client.put_events(
                Entries=[
                    {
                        'Source': 'makenaide.phase3',
                        'DetailType': 'Phase 3 GPT Analysis Completed',
                        'Detail': json.dumps({
                            'status': 'completed',
                            'timestamp': datetime.now(self.kst).isoformat(),
                            'next_phase': 'phase4'
                        })
                    }
                ]
            )
            
            logger.info("âœ… Phase 4 íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸ ë°œì†¡ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Phase 4 íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
            return False

def lambda_handler(event, context):
    """Lambda í•¸ë“¤ëŸ¬"""
    try:
        logger.info("ğŸš€ Phase 3 GPT Analysis ì‹œì‘")
        logger.info(f"ğŸ“¥ ì…ë ¥ ì´ë²¤íŠ¸: {json.dumps(event, indent=2, ensure_ascii=False)}")
        
        gpt_analyzer = GPTAnalysisPhase3()
        
        # 1. Phase 2 ë°ì´í„° ë¡œë“œ
        phase2_candidates = gpt_analyzer.load_phase2_data()
        if not phase2_candidates:
            logger.error("âŒ Phase 2 í›„ë³´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {
                'statusCode': 400,
                'body': json.dumps({'error': 'Phase 2 ë°ì´í„° ì—†ìŒ'})
            }
        
        # 2. GPT ë¶„ì„ ì‹¤í–‰ (ìµœëŒ€ 5ê°œê¹Œì§€)
        top_candidates = phase2_candidates[:5]  # ìƒìœ„ 5ê°œë§Œ ë¶„ì„ (API ë¹„ìš© ìµœì í™”)
        analysis_results = gpt_analyzer.process_candidates(top_candidates)
        
        if not analysis_results:
            logger.warning("âš ï¸ GPT ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'status': 'completed',
                    'analyzed_count': 0,
                    'message': 'GPT ë¶„ì„ ê²°ê³¼ ì—†ìŒ'
                })
            }
        
        # 3. ê²°ê³¼ ì €ì¥
        save_success = gpt_analyzer.save_results_to_s3(analysis_results)
        
        if not save_success:
            logger.error("âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")
            return {
                'statusCode': 500,
                'body': json.dumps({'error': 'S3 ì €ì¥ ì‹¤íŒ¨'})
            }
        
        # 4. Phase 4 íŠ¸ë¦¬ê±° (ë§¤ìˆ˜ ì¶”ì²œì´ ìˆëŠ” ê²½ìš°ë§Œ)
        buy_recommendations = [r for r in analysis_results if r.get('gpt_analysis', {}).get('overall_rating') == 'BUY']
        
        if buy_recommendations:
            trigger_success = gpt_analyzer.trigger_next_phase()
            if not trigger_success:
                logger.warning("âš ï¸ Phase 4 íŠ¸ë¦¬ê±° ì‹¤íŒ¨")
        else:
            logger.info("ğŸ“­ ë§¤ìˆ˜ ì¶”ì²œ ì¢…ëª©ì´ ì—†ì–´ Phase 4 íŠ¸ë¦¬ê±° ìƒëµ")
        
        # 5. ìµœì¢… ê²°ê³¼ ë°˜í™˜
        result = {
            'statusCode': 200,
            'body': json.dumps({
                'status': 'success',
                'input_candidates': len(phase2_candidates),
                'analyzed_count': len(analysis_results),
                'buy_recommendations': len(buy_recommendations),
                'analysis_summary': {
                    'BUY': len([r for r in analysis_results if r.get('gpt_analysis', {}).get('overall_rating') == 'BUY']),
                    'HOLD': len([r for r in analysis_results if r.get('gpt_analysis', {}).get('overall_rating') == 'HOLD']),
                    'SELL': len([r for r in analysis_results if r.get('gpt_analysis', {}).get('overall_rating') == 'SELL'])
                },
                'top_recommendations': [
                    {
                        'ticker': r['ticker'],
                        'rating': r.get('gpt_analysis', {}).get('overall_rating', 'HOLD'),
                        'confidence': r.get('gpt_analysis', {}).get('confidence_score', 0)
                    } for r in analysis_results[:3]  # ìƒìœ„ 3ê°œ
                ],
                'next_phase_triggered': len(buy_recommendations) > 0
            }, ensure_ascii=False, indent=2)
        }
        
        logger.info(f"âœ… Phase 3 ì™„ë£Œ: {len(analysis_results)}ê°œ ë¶„ì„, {len(buy_recommendations)}ê°œ ë§¤ìˆ˜ ì¶”ì²œ")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Phase 3 ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'error': str(e),
                'status': 'failed'
            })
        }

if __name__ == "__main__":
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    test_event = {
        'source': 'makenaide.phase2',
        'detail-type': 'Phase 2 Comprehensive Filtering Completed'
    }
    
    result = lambda_handler(test_event, None)
    print(json.dumps(result, indent=2, ensure_ascii=False))