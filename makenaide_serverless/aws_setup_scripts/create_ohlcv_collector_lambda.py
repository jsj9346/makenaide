#!/usr/bin/env python3
"""
OHLCV ìˆ˜ì§‘ ì „ìš© Lambda í•¨ìˆ˜ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ğŸ¯ ëª©ì :
- ê°œë³„ í‹°ì»¤ë³„ OHLCV ë°ì´í„° ìˆ˜ì§‘ì„ ë³‘ë ¬ Lambdaë¡œ ì²˜ë¦¬
- SQS íŠ¸ë¦¬ê±° ë°©ì‹ìœ¼ë¡œ í™•ì¥ì„±ê³¼ ì•ˆì •ì„± í™•ë³´
- ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°ê¹Œì§€ í¬í•¨í•œ ì™„ì „í•œ ë°ì´í„° ì²˜ë¦¬

ğŸ’° ì˜ˆìƒ ë¹„ìš© ì ˆê°: ì•½ 40-50%
"""

import boto3
import json
import os

def create_ohlcv_collector_lambda():
    """OHLCV ìˆ˜ì§‘ Lambda í•¨ìˆ˜ ìƒì„±"""
    
    # AWS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    lambda_client = boto3.client('lambda', region_name='ap-northeast-2')
    sqs_client = boto3.client('sqs', region_name='ap-northeast-2')
    
    # Lambda í•¨ìˆ˜ ì½”ë“œ ìƒì„±
    lambda_code = '''
import json
import boto3
import psycopg2
import os
import logging
import time
from datetime import datetime, date
import pyupbit
import pandas as pd
import numpy as np

logger = logging.getLogger()
logger.setLevel(logging.INFO)

def safe_pyupbit_get_ohlcv(ticker, interval="day", count=450, max_retries=3):
    """ì•ˆì „í•œ pyupbit OHLCV ë°ì´í„° ì¡°íšŒ"""
    for attempt in range(max_retries):
        try:
            time.sleep(0.1 * attempt)  # ì¬ì‹œë„ ì‹œ ì§€ì—°
            df = pyupbit.get_ohlcv(ticker, interval=interval, count=count)
            if df is not None and not df.empty:
                return df
        except Exception as e:
            logger.warning(f"âš ï¸ {ticker} API ì¡°íšŒ ì‹œë„ {attempt+1}/{max_retries} ì‹¤íŒ¨: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
    return None

def calculate_basic_indicators(df):
    """ê¸°ë³¸ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
    try:
        # ì´ë™í‰ê· ì„ 
        df['ma_20'] = df['close'].rolling(window=20).mean()
        df['ma_50'] = df['close'].rolling(window=50).mean()
        df['ma_200'] = df['close'].rolling(window=200).mean()
        
        # RSI
        delta = df['close'].diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=14).mean()
        avg_loss = loss.rolling(window=14).mean()
        rs = avg_gain / avg_loss
        df['rsi_14'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['close'].ewm(span=12).mean()
        exp2 = df['close'].ewm(span=26).mean()
        df['macd'] = exp1 - exp2
        df['macd_signal'] = df['macd'].ewm(span=9).mean()
        df['macd_histogram'] = df['macd'] - df['macd_signal']
        
        # ë³¼ë¦°ì € ë°´ë“œ
        bb_period = 20
        bb_std = 2
        df['bb_middle'] = df['close'].rolling(window=bb_period).mean()
        bb_std_dev = df['close'].rolling(window=bb_period).std()
        df['bb_upper'] = df['bb_middle'] + (bb_std_dev * bb_std)
        df['bb_lower'] = df['bb_middle'] - (bb_std_dev * bb_std)
        
        # ê±°ë˜ëŸ‰ ì§€í‘œ
        df['volume_20ma'] = df['volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_20ma']
        
        return df
        
    except Exception as e:
        logger.error(f"âŒ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return df

def save_ohlcv_to_db(ticker, df, db_config):
    """OHLCV ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        
        # ë°ì´í„° ì¤€ë¹„
        records = []
        for index, row in df.iterrows():
            if pd.isna(row['close']) or row['close'] <= 0:
                continue
                
            record = (
                ticker,
                index.date() if hasattr(index, 'date') else index,
                float(row['open']) if not pd.isna(row['open']) else None,
                float(row['high']) if not pd.isna(row['high']) else None,
                float(row['low']) if not pd.isna(row['low']) else None,
                float(row['close']) if not pd.isna(row['close']) else None,
                float(row['volume']) if not pd.isna(row['volume']) else None,
                float(row.get('ma_20')) if not pd.isna(row.get('ma_20', np.nan)) else None,
                float(row.get('ma_50')) if not pd.isna(row.get('ma_50', np.nan)) else None,
                float(row.get('ma_200')) if not pd.isna(row.get('ma_200', np.nan)) else None,
                float(row.get('bb_upper')) if not pd.isna(row.get('bb_upper', np.nan)) else None,
                float(row.get('bb_lower')) if not pd.isna(row.get('bb_lower', np.nan)) else None,
                float(row.get('macd_histogram')) if not pd.isna(row.get('macd_histogram', np.nan)) else None,
                float(row.get('rsi_14')) if not pd.isna(row.get('rsi_14', np.nan)) else None,
                float(row.get('volume_20ma')) if not pd.isna(row.get('volume_20ma', np.nan)) else None,
                float(row.get('volume_ratio')) if not pd.isna(row.get('volume_ratio', np.nan)) else None
            )
            records.append(record)
        
        if records:
            # UPSERT ì¿¼ë¦¬ ì‹¤í–‰
            upsert_query = """
                INSERT INTO ohlcv (
                    ticker, date, open, high, low, close, volume,
                    ma_20, ma_50, ma_200, bb_upper, bb_lower, 
                    macd_histogram, rsi_14, volume_20ma, volume_ratio
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (ticker, date) 
                DO UPDATE SET 
                    open = EXCLUDED.open,
                    high = EXCLUDED.high,
                    low = EXCLUDED.low,
                    close = EXCLUDED.close,
                    volume = EXCLUDED.volume,
                    ma_20 = EXCLUDED.ma_20,
                    ma_50 = EXCLUDED.ma_50,
                    ma_200 = EXCLUDED.ma_200,
                    bb_upper = EXCLUDED.bb_upper,
                    bb_lower = EXCLUDED.bb_lower,
                    macd_histogram = EXCLUDED.macd_histogram,
                    rsi_14 = EXCLUDED.rsi_14,
                    volume_20ma = EXCLUDED.volume_20ma,
                    volume_ratio = EXCLUDED.volume_ratio
            """
            
            cursor.executemany(upsert_query, records)
            conn.commit()
            
            logger.info(f"âœ… {ticker} OHLCV ë°ì´í„° {len(records)}ê°œ ì €ì¥ ì™„ë£Œ")
            
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"âŒ {ticker} DB ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def lambda_handler(event, context):
    """
    OHLCV ìˆ˜ì§‘ Lambda í•¨ìˆ˜
    
    SQS ë©”ì‹œì§€ë¡œë¶€í„° í‹°ì»¤ ëª©ë¡ì„ ë°›ì•„ì„œ OHLCV ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ì²˜ë¦¬
    """
    try:
        logger.info("ğŸ“Š OHLCV ìˆ˜ì§‘ Lambda í•¨ìˆ˜ ì‹œì‘")
        
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ DB ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        db_config = {
            'host': os.environ['DB_HOST'],
            'port': os.environ['DB_PORT'],
            'database': os.environ['DB_NAME'],
            'user': os.environ['DB_USER'],
            'password': os.environ['DB_PASSWORD']
        }
        
        processed_tickers = []
        failed_tickers = []
        
        # SQS Records ì²˜ë¦¬
        if 'Records' in event:
            for record in event['Records']:
                try:
                    message_body = json.loads(record['body'])
                    tickers = message_body.get('tickers', [])
                    
                    logger.info(f"ğŸ“‹ ì²˜ë¦¬í•  í‹°ì»¤: {len(tickers)}ê°œ")
                    
                    for ticker in tickers:
                        try:
                            # 1. OHLCV ë°ì´í„° ìˆ˜ì§‘
                            df = safe_pyupbit_get_ohlcv(ticker, interval="day", count=450)
                            
                            if df is None or df.empty:
                                logger.warning(f"âš ï¸ {ticker} OHLCV ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                                failed_tickers.append(ticker)
                                continue
                            
                            # 2. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                            df_with_indicators = calculate_basic_indicators(df)
                            
                            # 3. DB ì €ì¥
                            save_success = save_ohlcv_to_db(ticker, df_with_indicators, db_config)
                            
                            if save_success:
                                processed_tickers.append(ticker)
                                logger.info(f"âœ… {ticker} ì²˜ë¦¬ ì™„ë£Œ")
                            else:
                                failed_tickers.append(ticker)
                                
                        except Exception as e:
                            logger.error(f"âŒ {ticker} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                            failed_tickers.append(ticker)
                            
                except Exception as e:
                    logger.error(f"âŒ SQS ë©”ì‹œì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        else:
            # ì§ì ‘ í˜¸ì¶œì˜ ê²½ìš°
            tickers = event.get('tickers', [])
            logger.info(f"ğŸ“‹ ì§ì ‘ í˜¸ì¶œ - ì²˜ë¦¬í•  í‹°ì»¤: {len(tickers)}ê°œ")
            
            for ticker in tickers:
                try:
                    df = safe_pyupbit_get_ohlcv(ticker, interval="day", count=450)
                    if df is not None and not df.empty:
                        df_with_indicators = calculate_basic_indicators(df)
                        if save_ohlcv_to_db(ticker, df_with_indicators, db_config):
                            processed_tickers.append(ticker)
                        else:
                            failed_tickers.append(ticker)
                    else:
                        failed_tickers.append(ticker)
                except Exception as e:
                    logger.error(f"âŒ {ticker} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    failed_tickers.append(ticker)
        
        # 4. í›„ì† ì²˜ë¦¬ íŠ¸ë¦¬ê±° (í•„í„°ë§ Lambda)
        if processed_tickers:
            try:
                sqs = boto3.client('sqs')
                filter_queue_url = os.environ.get('FILTER_QUEUE_URL')
                
                if filter_queue_url:
                    filter_message = {
                        'action': 'filter_tickers',
                        'tickers': processed_tickers,
                        'timestamp': datetime.utcnow().isoformat(),
                        'session_id': context.aws_request_id
                    }
                    
                    sqs.send_message(
                        QueueUrl=filter_queue_url,
                        MessageBody=json.dumps(filter_message)
                    )
                    
                    logger.info(f"ğŸ“¤ {len(processed_tickers)}ê°œ í‹°ì»¤ë¥¼ í•„í„°ë§ íë¡œ ì „ì†¡")
            except Exception as e:
                logger.warning(f"âš ï¸ í•„í„°ë§ í ì „ì†¡ ì‹¤íŒ¨: {e}")
        
        # 5. ì‘ë‹µ ë°˜í™˜
        response = {
            'statusCode': 200,
            'body': json.dumps({
                'status': 'success',
                'processed_tickers': len(processed_tickers),
                'failed_tickers': len(failed_tickers),
                'processed_list': processed_tickers,
                'failed_list': failed_tickers,
                'session_id': context.aws_request_id
            })
        }
        
        logger.info(f"âœ… OHLCV ìˆ˜ì§‘ ì™„ë£Œ: ì„±ê³µ {len(processed_tickers)}ê°œ, ì‹¤íŒ¨ {len(failed_tickers)}ê°œ")
        return response
        
    except Exception as e:
        logger.error(f"âŒ OHLCV ìˆ˜ì§‘ Lambda ì˜¤ë¥˜: {str(e)}")
        return {
            'statusCode': 500,
            'body': json.dumps({
                'status': 'error',
                'error_message': str(e),
                'session_id': context.aws_request_id
            })
        }
'''
    
    # Lambda íŒ¨í‚¤ì§€ ìƒì„±
    package_dir = 'ohlcv_collector_package'
    os.makedirs(package_dir, exist_ok=True)
    
    # lambda_function.py íŒŒì¼ ìƒì„±
    with open(f'{package_dir}/lambda_function.py', 'w', encoding='utf-8') as f:
        f.write(lambda_code)
    
    # requirements.txt ìƒì„±
    with open(f'{package_dir}/requirements.txt', 'w') as f:
        f.write("""psycopg2-binary==2.9.7
boto3==1.28.44
pyupbit==0.2.31
pandas==2.0.3
numpy==1.24.3
""")
    
    # ZIP íŒ¨í‚¤ì§€ ìƒì„±
    import zipfile
    import shutil
    
    zip_filename = 'ohlcv_collector_lambda.zip'
    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk(package_dir):
            for file in files:
                file_path = os.path.join(root, file)
                arcname = os.path.relpath(file_path, package_dir)
                zipf.write(file_path, arcname)
    
    # Lambda í•¨ìˆ˜ ìƒì„±/ì—…ë°ì´íŠ¸
    function_name = 'makenaide-ohlcv-collector'
    
    try:
        # ê¸°ì¡´ í•¨ìˆ˜ í™•ì¸
        lambda_client.get_function(FunctionName=function_name)
        
        # ê¸°ì¡´ í•¨ìˆ˜ ì—…ë°ì´íŠ¸
        with open(zip_filename, 'rb') as f:
            zip_content = f.read()
        
        response = lambda_client.update_function_code(
            FunctionName=function_name,
            ZipFile=zip_content
        )
        print(f"âœ… Lambda í•¨ìˆ˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {function_name}")
        
    except lambda_client.exceptions.ResourceNotFoundException:
        # ìƒˆ í•¨ìˆ˜ ìƒì„±
        with open(zip_filename, 'rb') as f:
            zip_content = f.read()
        
        response = lambda_client.create_function(
            FunctionName=function_name,
            Runtime='python3.9',
            Role=f'arn:aws:iam::{boto3.client("sts").get_caller_identity()["Account"]}:role/makenaide-lambda-role',
            Handler='lambda_function.lambda_handler',
            Code={'ZipFile': zip_content},
            Description='Makenaide OHLCV ìˆ˜ì§‘ ì „ìš© Lambda í•¨ìˆ˜',
            Timeout=900,  # 15ë¶„ (ìµœëŒ€)
            MemorySize=1024,  # 1GB
            Environment={
                'Variables': {
                    'DB_HOST': 'makenaide.cni2ka4ugf7f.ap-northeast-2.rds.amazonaws.com',
                    'DB_PORT': '5432',
                    'DB_NAME': 'makenaide',
                    'DB_USER': 'bruce',
                    'DB_PASSWORD': 'REPLACE_WITH_ACTUAL_PASSWORD',
                    'FILTER_QUEUE_URL': 'https://sqs.ap-northeast-2.amazonaws.com/ACCOUNT_ID/makenaide-filter'
                }
            }
        )
        print(f"âœ… Lambda í•¨ìˆ˜ ìƒì„± ì™„ë£Œ: {function_name}")
    
    # ì •ë¦¬
    shutil.rmtree(package_dir)
    os.remove(zip_filename)
    
    return response['FunctionArn']

def create_sqs_queues():
    """í•„ìš”í•œ SQS íë“¤ ìƒì„±"""
    sqs = boto3.client('sqs', region_name='ap-northeast-2')
    account_id = boto3.client('sts').get_caller_identity()['Account']
    
    queues = [
        {
            'name': 'makenaide-ohlcv-collection',
            'description': 'OHLCV ìˆ˜ì§‘ ì‘ì—… í'
        },
        {
            'name': 'makenaide-filter',
            'description': 'í‹°ì»¤ í•„í„°ë§ ì‘ì—… í'
        }
    ]
    
    created_queues = {}
    
    for queue in queues:
        try:
            response = sqs.create_queue(
                QueueName=queue['name'],
                Attributes={
                    'VisibilityTimeoutSeconds': '900',  # 15ë¶„
                    'MessageRetentionPeriod': '1209600',  # 14ì¼
                    'ReceiveMessageWaitTimeSeconds': '20'  # ë¡± í´ë§
                }
            )
            
            queue_url = response['QueueUrl']
            created_queues[queue['name']] = queue_url
            print(f"âœ… SQS í ìƒì„± ì™„ë£Œ: {queue['name']}")
            
        except sqs.exceptions.QueueNameExists:
            # ê¸°ì¡´ í URL ê°€ì ¸ì˜¤ê¸°
            response = sqs.get_queue_url(QueueName=queue['name'])
            queue_url = response['QueueUrl']
            created_queues[queue['name']] = queue_url
            print(f"âœ… ê¸°ì¡´ SQS í ì‚¬ìš©: {queue['name']}")
    
    return created_queues

if __name__ == '__main__':
    print("ğŸš€ OHLCV ìˆ˜ì§‘ Lambda í•¨ìˆ˜ ìƒì„± ì‹œì‘...")
    try:
        # 1. SQS í ìƒì„±
        print("ğŸ“¨ SQS í ìƒì„± ì¤‘...")
        queues = create_sqs_queues()
        
        # 2. Lambda í•¨ìˆ˜ ìƒì„±
        function_arn = create_ohlcv_collector_lambda()
        print(f"âœ… OHLCV ìˆ˜ì§‘ Lambda í•¨ìˆ˜ ìƒì„±/ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        print(f"ğŸ“‹ í•¨ìˆ˜ ARN: {function_arn}")
        
        print("\nğŸ“‹ ìƒì„±ëœ SQS í:")
        for name, url in queues.items():
            print(f"  - {name}: {url}")
        
        print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
        print("1. SQS íŠ¸ë¦¬ê±° ì„¤ì • (OHLCV ìˆ˜ì§‘ Lambda â† OHLCV í)")
        print("2. í•„í„°ë§ Lambda í•¨ìˆ˜ ìƒì„±")
        print("3. í™˜ê²½ë³€ìˆ˜ ì‹¤ì œ ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}") 