#!/usr/bin/env python3
"""
í•˜ì´ë¸Œë¦¬ë“œ í•„í„°ë§ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

ì£¼ìš” ê¸°ëŠ¥:
- í•„í„°ë§ ì†ë„ ë° íš¨ìœ¨ì„± ì¸¡ì •
- ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ì¶”ì 
- ê°€ì¤‘ì¹˜ íš¨ê³¼ì„± ë¶„ì„
- ì£¼ê°„/ì›”ê°„ ë¦¬í¬íŠ¸ ìƒì„±
"""

import os
import json
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import logging
from pathlib import Path

from utils import setup_logger, safe_strftime

# ë¡œê±° ì„¤ì •
logger = setup_logger()

def safe_json_serialize(data):
    """numpy íƒ€ì…ì„ ì•ˆì „í•˜ê²Œ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(data, dict):
        return {k: safe_json_serialize(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [safe_json_serialize(item) for item in data]
    elif isinstance(data, (np.int64, np.int32, np.int_)):
        return int(data)
    elif isinstance(data, (np.float64, np.float32, np.float_)):
        return float(data)
    elif isinstance(data, np.ndarray):
        return data.tolist()
    elif hasattr(data, 'item'):  # numpy scalar
        return data.item()
    else:
        return data

class HybridFilteringMonitor:
    """
    í•˜ì´ë¸Œë¦¬ë“œ í•„í„°ë§ ì„±ëŠ¥ì„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§í•˜ëŠ” í´ë˜ìŠ¤
    
    ê¸°ëŠ¥:
    - í•„í„°ë§ ì†ë„ ì¸¡ì •
    - ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ì¶”ì 
    - ê°€ì¤‘ì¹˜ íš¨ê³¼ì„± ë¶„ì„
    """
    
    def __init__(self, metrics_dir: str = "metrics"):
        self.metrics_dir = Path(metrics_dir)
        self.metrics_dir.mkdir(exist_ok=True)
        
        self.filtering_metrics = []
        self.data_quality_history = []
        self.weight_effectiveness = {}
        
        # ë©”íŠ¸ë¦­ìŠ¤ íŒŒì¼ ê²½ë¡œ
        self.metrics_file = self.metrics_dir / "filtering_metrics.json"
        self.quality_file = self.metrics_dir / "data_quality.json"
        self.weights_file = self.metrics_dir / "weight_effectiveness.json"
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        self._load_existing_metrics()
        
    def _load_existing_metrics(self):
        """ê¸°ì¡´ ë©”íŠ¸ë¦­ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            if self.metrics_file.exists():
                with open(self.metrics_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.filtering_metrics = data.get('metrics', [])
                    
            if self.quality_file.exists():
                with open(self.quality_file, 'r', encoding='utf-8') as f:
                    self.data_quality_history = json.load(f)
                    
            if self.weights_file.exists():
                with open(self.weights_file, 'r', encoding='utf-8') as f:
                    self.weight_effectiveness = json.load(f)
                    
            logger.info(f"ğŸ“Š ê¸°ì¡´ ë©”íŠ¸ë¦­ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(self.filtering_metrics)}ê°œ ì„¸ì…˜")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ê¸°ì¡´ ë©”íŠ¸ë¦­ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _save_metrics(self):
        """ë©”íŠ¸ë¦­ìŠ¤ ë°ì´í„°ë¥¼ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            # í•„í„°ë§ ë©”íŠ¸ë¦­ìŠ¤ ì €ì¥ (ì•ˆì „í•œ JSON ì§ë ¬í™” ì ìš©)
            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                json.dump(safe_json_serialize({
                    'metrics': self.filtering_metrics,
                    'last_updated': datetime.now().isoformat()
                }), f, indent=2, ensure_ascii=False)
            
            # ë°ì´í„° í’ˆì§ˆ íˆìŠ¤í† ë¦¬ ì €ì¥ (ì•ˆì „í•œ JSON ì§ë ¬í™” ì ìš©)
            with open(self.quality_file, 'w', encoding='utf-8') as f:
                json.dump(safe_json_serialize(self.data_quality_history), f, indent=2, ensure_ascii=False)
            
            # ê°€ì¤‘ì¹˜ íš¨ê³¼ì„± ì €ì¥ (ì•ˆì „í•œ JSON ì§ë ¬í™” ì ìš©)
            with open(self.weights_file, 'w', encoding='utf-8') as f:
                json.dump(safe_json_serialize(self.weight_effectiveness), f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"âŒ ë©”íŠ¸ë¦­ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
        
    def record_filtering_session(self, session_data: Dict):
        """
        í•„í„°ë§ ì„¸ì…˜ ë°ì´í„°ë¥¼ ê¸°ë¡í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            session_data (dict): {
                'total_tickers': int,
                'filtered_tickers': int, 
                'processing_time': float,
                'hybrid_mode_count': int,
                'static_only_count': int,
                'data_quality_score': float,
                'static_weight': float,
                'dynamic_weight': float,
                'filter_config': dict
            }
        """
        # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
        session_data['timestamp'] = datetime.now().isoformat()
        session_data['date'] = safe_strftime(datetime.now(), '%Y-%m-%d')
        
        # ë©”íŠ¸ë¦­ìŠ¤ ê³„ì‚°
        efficiency = session_data['filtered_tickers'] / max(session_data['total_tickers'], 1)
        speed = session_data['total_tickers'] / max(session_data['processing_time'], 0.001)
        
        session_data['efficiency'] = efficiency
        session_data['speed'] = speed
        
        # ë©”íŠ¸ë¦­ìŠ¤ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        self.filtering_metrics.append(session_data)
        
        # ë°ì´í„° í’ˆì§ˆ íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
        quality_entry = {
            'timestamp': session_data['timestamp'],
            'score': session_data['data_quality_score'],
            'hybrid_ratio': session_data['hybrid_mode_count'] / max(session_data['total_tickers'], 1)
        }
        self.data_quality_history.append(quality_entry)
        
        # ê°€ì¤‘ì¹˜ íš¨ê³¼ì„± ë¶„ì„
        weight_key = f"{session_data['static_weight']:.1f}_{session_data['dynamic_weight']:.1f}"
        if weight_key not in self.weight_effectiveness:
            self.weight_effectiveness[weight_key] = []
        
        self.weight_effectiveness[weight_key].append({
            'timestamp': session_data['timestamp'],
            'efficiency': efficiency,
            'quality': session_data['data_quality_score'],
            'filtered_count': session_data['filtered_tickers']
        })
        
        # ë¡œê¹…
        logger.info(f"ğŸ“Š í•„í„°ë§ ì„¸ì…˜ ì™„ë£Œ:")
        logger.info(f"   - íš¨ìœ¨ì„±: {efficiency:.2%}")
        logger.info(f"   - ì²˜ë¦¬ì†ë„: {speed:.1f} í‹°ì»¤/ì´ˆ")
        logger.info(f"   - ë°ì´í„° í’ˆì§ˆ: {session_data['data_quality_score']:.2f}")
        logger.info(f"   - í•˜ì´ë¸Œë¦¬ë“œ ë¹„ìœ¨: {quality_entry['hybrid_ratio']:.1%}")
        
        # ë©”íŠ¸ë¦­ìŠ¤ ì €ì¥
        self._save_metrics()
        
        return {
            'efficiency': efficiency,
            'speed': speed,
            'quality_score': session_data['data_quality_score']
        }
    
    def _calculate_hybrid_ratio(self) -> float:
        """í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ì‚¬ìš© ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not self.filtering_metrics:
            return 0.0
            
        total_hybrid = sum(m['hybrid_mode_count'] for m in self.filtering_metrics)
        total_tickers = sum(m['total_tickers'] for m in self.filtering_metrics)
        
        return total_hybrid / max(total_tickers, 1)
    
    def _calculate_avg_quality(self) -> float:
        """í‰ê·  ë°ì´í„° í’ˆì§ˆì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if not self.data_quality_history:
            return 0.0
            
        return np.mean([q['score'] for q in self.data_quality_history])
    
    def _generate_recommendations(self) -> str:
        """ì„±ëŠ¥ ë¶„ì„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        recommendations = []
        
        if not self.filtering_metrics:
            return "ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        # ìµœê·¼ 7ì¼ ë°ì´í„° ë¶„ì„
        recent_data = self._get_recent_metrics(days=7)
        
        if recent_data:
            avg_efficiency = np.mean([m['efficiency'] for m in recent_data])
            avg_quality = np.mean([m['data_quality_score'] for m in recent_data])
            avg_speed = np.mean([m['speed'] for m in recent_data])
            
            # íš¨ìœ¨ì„± ê¶Œì¥ì‚¬í•­
            if avg_efficiency < 0.1:
                recommendations.append("â€¢ í•„í„°ë§ íš¨ìœ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ ì™„í™”í•´ë³´ì„¸ìš”.")
            elif avg_efficiency > 0.5:
                recommendations.append("â€¢ í•„í„°ë§ì´ ë„ˆë¬´ ê´€ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ê°•í™”í•´ë³´ì„¸ìš”.")
            
            # í’ˆì§ˆ ê¶Œì¥ì‚¬í•­
            if avg_quality < 0.7:
                recommendations.append("â€¢ ë°ì´í„° í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì ê²€í•˜ì„¸ìš”.")
            
            # ì†ë„ ê¶Œì¥ì‚¬í•­  
            if avg_speed < 5.0:
                recommendations.append("â€¢ ì²˜ë¦¬ ì†ë„ê°€ ëŠë¦½ë‹ˆë‹¤. ì¿¼ë¦¬ ìµœì í™”ë‚˜ ì¸ë±ìŠ¤ ì¶”ê°€ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            
            # ê°€ì¤‘ì¹˜ ìµœì í™” ê¶Œì¥ì‚¬í•­
            best_weights = self._find_optimal_weights()
            if best_weights:
                recommendations.append(f"â€¢ ìµœì  ê°€ì¤‘ì¹˜: ì •ì  {best_weights['static']:.1f}, ë™ì  {best_weights['dynamic']:.1f}")
        
        return "\n".join(recommendations) if recommendations else "í˜„ì¬ ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤."
    
    def _get_recent_metrics(self, days: int = 7) -> List[Dict]:
        """ìµœê·¼ Nì¼ê°„ì˜ ë©”íŠ¸ë¦­ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        cutoff_date = datetime.now() - timedelta(days=days)
        
        recent_metrics = []
        for metric in self.filtering_metrics:
            try:
                metric_date = datetime.fromisoformat(metric['timestamp'])
                if metric_date >= cutoff_date:
                    recent_metrics.append(metric)
            except:
                continue
                
        return recent_metrics
    
    def _find_optimal_weights(self) -> Optional[Dict]:
        """ê°€ì¥ íš¨ê³¼ì ì¸ ê°€ì¤‘ì¹˜ ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤."""
        if not self.weight_effectiveness:
            return None
        
        best_score = 0
        best_weights = None
        
        for weight_key, results in self.weight_effectiveness.items():
            if len(results) < 3:  # ìµœì†Œ 3íšŒ ì´ìƒ ì‚¬ìš©ëœ ê°€ì¤‘ì¹˜ë§Œ ê³ ë ¤
                continue
                
            avg_efficiency = np.mean([r['efficiency'] for r in results])
            avg_quality = np.mean([r['quality'] for r in results])
            
            # ì¢…í•© ì ìˆ˜ (íš¨ìœ¨ì„± 70% + í’ˆì§ˆ 30%)
            combined_score = avg_efficiency * 0.7 + avg_quality * 0.3
            
            if combined_score > best_score:
                best_score = combined_score
                static_weight, dynamic_weight = map(float, weight_key.split('_'))
                best_weights = {
                    'static': static_weight,
                    'dynamic': dynamic_weight,
                    'score': combined_score
                }
        
        return best_weights
    
    def generate_weekly_report(self) -> str:
        """ì£¼ê°„ ì„±ëŠ¥ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.filtering_metrics:
            return "ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        # ìµœê·¼ 7ì¼ ë°ì´í„°
        recent_metrics = self._get_recent_metrics(days=7)
        
        if not recent_metrics:
            return "ìµœê·¼ 7ì¼ê°„ ì‹¤í–‰ëœ í•„í„°ë§ ì„¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤."
        
        # ì„±ëŠ¥ í†µê³„ ê³„ì‚°
        total_sessions = len(recent_metrics)
        avg_efficiency = np.mean([m['efficiency'] for m in recent_metrics])
        avg_speed = np.mean([m['speed'] for m in recent_metrics])
        avg_quality = np.mean([m['data_quality_score'] for m in recent_metrics])
        
        total_tickers_processed = sum(m['total_tickers'] for m in recent_metrics)
        total_tickers_filtered = sum(m['filtered_tickers'] for m in recent_metrics)
        
        hybrid_ratio = self._calculate_hybrid_ratio()
        
        # íŠ¸ë Œë“œ ë¶„ì„
        if len(recent_metrics) >= 2:
            early_metrics = recent_metrics[:len(recent_metrics)//2]
            late_metrics = recent_metrics[len(recent_metrics)//2:]
            
            early_avg_efficiency = np.mean([m['efficiency'] for m in early_metrics])
            late_avg_efficiency = np.mean([m['efficiency'] for m in late_metrics])
            
            efficiency_trend = "â†—ï¸ ìƒìŠ¹" if late_avg_efficiency > early_avg_efficiency else "â†˜ï¸ í•˜ë½"
        else:
            efficiency_trend = "ğŸ“Š ë°ì´í„° ë¶€ì¡±"
        
        report = f"""
ğŸ“ˆ í•˜ì´ë¸Œë¦¬ë“œ í•„í„°ë§ ì£¼ê°„ ì„±ëŠ¥ ë¦¬í¬íŠ¸
=======================================
ê¸°ê°„: {safe_strftime(datetime.now() - timedelta(days=7))} ~ {safe_strftime(datetime.now())}

ğŸ“Š ê¸°ë³¸ í†µê³„
- ì‹¤í–‰ íšŸìˆ˜: {total_sessions}íšŒ
- ì²˜ë¦¬ëœ ì´ í‹°ì»¤ ìˆ˜: {total_tickers_processed:,}ê°œ
- ì„ ë³„ëœ ì´ í‹°ì»¤ ìˆ˜: {total_tickers_filtered:,}ê°œ

ğŸ¯ ì„±ëŠ¥ ì§€í‘œ  
- í‰ê·  íš¨ìœ¨ì„±: {avg_efficiency:.2%} {efficiency_trend}
- í‰ê·  ì²˜ë¦¬ì†ë„: {avg_speed:.1f} í‹°ì»¤/ì´ˆ
- í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ë¹„ìœ¨: {hybrid_ratio:.1%}
- ë°ì´í„° í’ˆì§ˆ í‰ê· : {avg_quality:.2f}/1.0

ğŸ’¡ ê¶Œì¥ì‚¬í•­
{self._generate_recommendations()}

ğŸ” ê°€ì¤‘ì¹˜ ë¶„ì„
{self._generate_weight_analysis()}
        """
        
        # ë¦¬í¬íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        report_file = self.metrics_dir / f"weekly_report_{safe_strftime(datetime.now(), '%Y%m%d')}.txt"
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"ğŸ“„ ì£¼ê°„ ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")
        except Exception as e:
            logger.error(f"âŒ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return report
    
    def _generate_weight_analysis(self) -> str:
        """ê°€ì¤‘ì¹˜ íš¨ê³¼ì„± ë¶„ì„ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.weight_effectiveness:
            return "ê°€ì¤‘ì¹˜ ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        analysis = []
        
        for weight_key, results in self.weight_effectiveness.items():
            if len(results) < 2:
                continue
                
            static_weight, dynamic_weight = map(float, weight_key.split('_'))
            avg_efficiency = np.mean([r['efficiency'] for r in results])
            avg_quality = np.mean([r['quality'] for r in results])
            usage_count = len(results)
            
            analysis.append(f"ì •ì  {static_weight:.1f}/ë™ì  {dynamic_weight:.1f}: "
                          f"íš¨ìœ¨ì„± {avg_efficiency:.2%}, í’ˆì§ˆ {avg_quality:.2f} ({usage_count}íšŒ)")
        
        if not analysis:
            return "ê°€ì¤‘ì¹˜ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        return "\n".join(analysis)
    
    def record_backtest_session(self, backtest_metrics: Dict):
        """ë°±í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ë°ì´í„°ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤."""
        try:
            backtest_metrics['timestamp'] = datetime.now().isoformat()
            backtest_metrics['date'] = safe_strftime(datetime.now(), '%Y-%m-%d')
            
            # ë°±í…ŒìŠ¤íŠ¸ ì „ìš© ë©”íŠ¸ë¦­ìŠ¤ íŒŒì¼
            backtest_file = self.metrics_dir / "backtest_sessions.json"
            
            # ê¸°ì¡´ ë°±í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ë¡œë“œ
            backtest_sessions = []
            if backtest_file.exists():
                with open(backtest_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    backtest_sessions = data.get('sessions', [])
            
            # ìƒˆ ì„¸ì…˜ ì¶”ê°€
            backtest_sessions.append(backtest_metrics)
            
            # ë°±í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì €ì¥
            with open(backtest_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'sessions': backtest_sessions,
                    'last_updated': datetime.now().isoformat()
                }, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ê¸°ë¡ ì™„ë£Œ:")
            logger.info(f"   - ì „ëµ ìˆ˜: {backtest_metrics.get('strategy_count', 0)}")
            logger.info(f"   - í…ŒìŠ¤íŠ¸ ì¡°í•©: {backtest_metrics.get('total_combos_tested', 0)}")
            logger.info(f"   - í•˜ì´ë¸Œë¦¬ë“œ ì¡°í•©: {backtest_metrics.get('hybrid_combos_tested', 0)}")
            
        except Exception as e:
            logger.error(f"âŒ ë°±í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ê¸°ë¡ ì‹¤íŒ¨: {e}")

    def _analyze_backtest_performance(self) -> Dict:
        """ë°±í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            backtest_file = self.metrics_dir / "backtest_sessions.json"
            if not backtest_file.exists():
                return {'status': 'no_data'}
            
            with open(backtest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                sessions = data.get('sessions', [])
            
            if not sessions:
                return {'status': 'no_sessions'}
            
            # ìµœê·¼ 7ì¼ ì„¸ì…˜ ë¶„ì„
            recent_sessions = [
                s for s in sessions 
                if datetime.fromisoformat(s['timestamp']) > datetime.now() - timedelta(days=7)
            ]
            
            return {
                'total_sessions': len(sessions),
                'recent_sessions': len(recent_sessions),
                'avg_strategy_count': np.mean([s.get('strategy_count', 0) for s in recent_sessions]) if recent_sessions else 0,
                'avg_hybrid_ratio': np.mean([
                    s.get('hybrid_combos_tested', 0) / max(s.get('total_combos_tested', 1), 1) 
                    for s in recent_sessions
                ]) if recent_sessions else 0,
                'status': 'active'
            }
            
        except Exception as e:
            logger.error(f"âŒ ë°±í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'status': 'error', 'error': str(e)}

    def get_backtest_summary(self) -> Dict:
        """ë°±í…ŒìŠ¤íŠ¸ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self._analyze_backtest_performance()

    def get_performance_summary(self) -> Dict:
        """í˜„ì¬ ì„±ëŠ¥ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        recent_metrics = self._get_recent_metrics(days=7)
        
        if not recent_metrics:
            return {
                'status': 'NO_DATA',
                'message': 'ìµœê·¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
            }
        
        avg_efficiency = np.mean([m['efficiency'] for m in recent_metrics])
        avg_speed = np.mean([m['speed'] for m in recent_metrics])
        avg_quality = np.mean([m['data_quality_score'] for m in recent_metrics])
        
        # ì„±ëŠ¥ ìƒíƒœ íŒì •
        if avg_efficiency >= 0.15 and avg_quality >= 0.8 and avg_speed >= 10:
            status = 'EXCELLENT'
        elif avg_efficiency >= 0.1 and avg_quality >= 0.7 and avg_speed >= 5:
            status = 'GOOD'
        elif avg_efficiency >= 0.05 and avg_quality >= 0.6 and avg_speed >= 2:
            status = 'FAIR'
        else:
            status = 'POOR'
        
        return {
            'status': status,
            'efficiency': avg_efficiency,
            'speed': avg_speed,
            'quality': avg_quality,
            'sessions_count': len(recent_metrics),
            'optimal_weights': self._find_optimal_weights()
        }

# ì „ì—­ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
_monitor_instance = None

def get_performance_monitor() -> HybridFilteringMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _monitor_instance
    if _monitor_instance is None:
        _monitor_instance = HybridFilteringMonitor()
    return _monitor_instance

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    monitor = get_performance_monitor()
    
    # ìƒ˜í”Œ ì„¸ì…˜ ë°ì´í„° ê¸°ë¡
    sample_session = {
        'total_tickers': 200,
        'filtered_tickers': 25,
        'processing_time': 8.5,
        'hybrid_mode_count': 180,
        'static_only_count': 20,
        'data_quality_score': 0.85,
        'static_weight': 0.6,
        'dynamic_weight': 0.4,
        'filter_config': {'enable_hybrid': True}
    }
    
    monitor.record_filtering_session(sample_session)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report = monitor.generate_weekly_report()
    print(report) 