#!/usr/bin/env python3
"""
Makenaide Local Orchestrator - í†µí•© ê±°ë˜ íŒŒì´í”„ë¼ì¸
EC2 Local Architecture ê¸°ë°˜ ì•”í˜¸í™”í ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ

ğŸ  LOCAL ARCHITECTURE: ë‹¨ì¼ ë¨¸ì‹  í†µí•© ì‹¤í–‰
- AWS ì˜ì¡´ì„± ì œê±°: DynamoDB â†’ SQLite, Lambda â†’ Python Scripts
- ë¹„ìš© ìµœì í™”: í´ë¼ìš°ë“œ ë¹„ìš© 0ì›, ì „ë ¥ë¹„ë§Œ ë°œìƒ
- ê°œë°œ í¸ì˜ì„±: ë¡œì»¬ ë””ë²„ê¹…, ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸

ğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸:
Phase 0: scanner.py (ì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº”)
Phase 1: data_collector.py (ì¦ë¶„ OHLCV ìˆ˜ì§‘)
Phase 2: integrated_scoring_system.py (LayeredScoringEngine ì ìˆ˜ì œ ë¶„ì„)
Phase 3: gpt_analyzer.py (GPT íŒ¨í„´ ë¶„ì„ - ì„ íƒì )
Kelly Calculator: kelly_calculator.py (í¬ì§€ì…˜ ì‚¬ì´ì§•)
Market Sentiment: market_sentiment.py (Fear&Greed ë¶„ì„)
Trading Engine: trade_executor.py (ë§¤ìˆ˜/ë§¤ë„ ì‹¤í–‰)
Portfolio Management: portfolio_manager.py (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬)

ğŸ“Š ì°¸ì¡°: @makenaide_local.mmd ì „ì²´ íŒŒì´í”„ë¼ì¸ í”Œë¡œìš°
"""

import sys
import os
import logging
import sqlite3
import time
import json
import pyupbit
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from utils import setup_restricted_logger, load_blacklist
from db_manager_sqlite import get_db_connection_context
from scanner import update_tickers
from data_collector import SimpleDataCollector
from integrated_scoring_system import IntegratedScoringSystem
from gpt_analyzer import GPTPatternAnalyzer
from kelly_calculator import KellyCalculator, RiskLevel
from market_sentiment import IntegratedMarketSentimentAnalyzer, MarketSentiment
from real_time_market_sentiment import RealTimeMarketSentiment
# from trade_executor import buy_asset, sell_asset  # ì‚­ì œëœ ë ˆê±°ì‹œ ëª¨ë“ˆ
# from portfolio_manager import PortfolioManager  # trading_engineìœ¼ë¡œ í†µí•©ë¨
from trading_engine import LocalTradingEngine, TradingConfig, OrderStatus, TradeResult

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê±° ì„¤ì • (ëª¨ë“  import ì „ì— ë¨¼ì € ì„¤ì •)
logger = setup_restricted_logger('makenaide_orchestrator')

# SNS ì•Œë¦¼ ì‹œìŠ¤í…œ import (Phase 1-3)
try:
    from sns_notification_system import (
        MakenaideSNSNotifier,
        notify_discovered_stocks,
        notify_kelly_position_sizing,
        notify_market_analysis_summary,
        notify_pipeline_failure,
        notify_detailed_failure,
        send_secure_notification,
        get_security_analytics,
        FailureType,
        FailureSubType,
        NotificationMessage,
        NotificationLevel,
        NotificationCategory
    )
    SNS_AVAILABLE = True
    logger.info("âœ… SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ (Phase 1-3 ê¸°ëŠ¥ í¬í•¨)")
except ImportError as e:
    logger.warning(f"âš ï¸ SNS ì•Œë¦¼ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    SNS_AVAILABLE = False

# Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ import
try:
    from failure_tracker import FailureTracker, FailureRecord, SystemHealthMetrics
    from predictive_analysis import PredictiveAnalyzer, PredictionResult, RiskLevel as PredRiskLevel
    from auto_recovery_system import AutoRecoverySystem, RecoveryPlan, RecoveryExecution
    PHASE4_AVAILABLE = True
    logger.info("âœ… Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    logger.warning(f"âš ï¸ Phase 4 ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    PHASE4_AVAILABLE = False

@dataclass
class OrchestratorConfig:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„¤ì •"""
    enable_gpt_analysis: bool = True  # GPT ë¶„ì„ í™œì„±í™” ì—¬ë¶€
    max_gpt_budget_daily: float = 5.0  # ì¼ì¼ GPT ë¹„ìš© í•œë„ (USD)
    min_quality_score: float = 12.0  # ìµœì†Œ í’ˆì§ˆ ì ìˆ˜
    risk_level: RiskLevel = RiskLevel.MODERATE  # ë¦¬ìŠ¤í¬ ë ˆë²¨
    dry_run: bool = False  # ì‹¤ì œ ê±°ë˜ ì‹¤í–‰ ì—¬ë¶€
    max_positions: int = 8  # ìµœëŒ€ ë™ì‹œ ë³´ìœ  ì¢…ëª© ìˆ˜
    portfolio_allocation_limit: float = 0.25  # ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ëŒ€ë¹„ ìµœëŒ€ í• ë‹¹ ë¹„ìœ¨

class MakenaideLocalOrchestrator:
    """Makenaide ë¡œì»¬ í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""

    def __init__(self, config: OrchestratorConfig):
        self.config = config
        self.db_path = "./makenaide_local.db"

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.upbit = None
        self.data_collector = None
        self.technical_filter = None
        self.gpt_analyzer = None
        self.kelly_calculator = None
        self.market_sentiment = None
        # self.portfolio_manager = None  # trading_engineìœ¼ë¡œ í†µí•©ë¨
        self.trading_engine = None
        self.sns_notifier = None  # SNS ì•Œë¦¼ ì‹œìŠ¤í…œ (Phase 1-3)

        # ğŸ“Š ì‹œì¥ ê°ì • ë¶„ì„ ê²°ê³¼ ì €ì¥ (SNS ì•Œë¦¼ìš©)
        self.last_sentiment_result = None

        # Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ
        self.failure_tracker = None
        self.predictive_analyzer = None
        self.auto_recovery_system = None

        # ì‹¤í–‰ í†µê³„
        self.execution_stats = {
            'start_time': None,
            'phases_completed': [],
            'errors': [],
            'trading_candidates': 0,
            'trades_executed': 0,
            'total_cost': 0.0,
            'technical_candidates': [],  # ê¸°ìˆ ì  ë¶„ì„ í†µê³¼ ì¢…ëª©
            'gpt_candidates': [],        # GPT ë¶„ì„ í†µê³¼ ì¢…ëª©
            'kelly_results': {}          # Kelly ê³„ì‚° ê²°ê³¼
        }

    def initialize_components(self) -> bool:
        """ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”§ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘")

            # ì—…ë¹„íŠ¸ API ì´ˆê¸°í™”
            access_key = os.getenv('UPBIT_ACCESS_KEY')
            secret_key = os.getenv('UPBIT_SECRET_KEY')

            if not access_key or not secret_key:
                error_msg = "ì—…ë¹„íŠ¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                logger.error(f"âŒ {error_msg}")

                # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
                if SNS_AVAILABLE:
                    try:
                        # API í‚¤ íƒ€ì…ë³„ ìƒì„¸ ë¶„ë¥˜
                        if not access_key and not secret_key:
                            sub_type = FailureSubType.API_BOTH_KEYS_MISSING.value
                        elif not access_key:
                            sub_type = FailureSubType.API_ACCESS_KEY_MISSING.value
                        else:
                            sub_type = FailureSubType.API_SECRET_KEY_MISSING.value

                        self.handle_failure_with_phase4(
                            failure_type=FailureType.API_KEY_MISSING.value,
                            sub_type=sub_type,
                            error_message=error_msg,
                            phase="ì´ˆê¸°í™”",
                            execution_id=datetime.now().strftime('%Y%m%d_%H%M%S'),
                            metadata={
                                'missing_access_key': not bool(access_key),
                                'missing_secret_key': not bool(secret_key),
                                'config_file': '.env',
                                'env_check_result': 'FAILED'
                            },
                            severity="CRITICAL"
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

                return False

            self.upbit = pyupbit.Upbit(access_key, secret_key)
            logger.info("âœ… ì—…ë¹„íŠ¸ API ì—°ê²° ì™„ë£Œ")

            # ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
            self.data_collector = SimpleDataCollector(db_path=self.db_path)
            logger.info("âœ… ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

            # ê¸°ìˆ ì  í•„í„° ì´ˆê¸°í™” (ìƒˆë¡œìš´ ì ìˆ˜ì œ ì‹œìŠ¤í…œ)
            self.technical_filter = IntegratedScoringSystem(db_path=self.db_path)
            logger.info("âœ… ê¸°ìˆ ì  í•„í„° ì´ˆê¸°í™” ì™„ë£Œ (LayeredScoringEngine ì ìˆ˜ì œ ì‹œìŠ¤í…œ)")

            # GPT ë¶„ì„ê¸° ì´ˆê¸°í™” (ì„ íƒì )
            if self.config.enable_gpt_analysis:
                self.gpt_analyzer = GPTPatternAnalyzer(db_path=self.db_path)
                logger.info("âœ… GPT ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.info("â­ï¸ GPT ë¶„ì„ê¸° ë¹„í™œì„±í™” (ë¹„ìš© ì ˆì•½ ëª¨ë“œ)")

            # Kelly ê³„ì‚°ê¸° ì´ˆê¸°í™”
            self.kelly_calculator = KellyCalculator(
                risk_level=self.config.risk_level,
                max_single_position=8.0,
                max_total_allocation=self.config.portfolio_allocation_limit * 100
            )
            logger.info("âœ… Kelly ê³„ì‚°ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

            # ì‹œì¥ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” (ìƒˆë¡œìš´ ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ)
            self.market_sentiment = RealTimeMarketSentiment()
            logger.info("âœ… ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (pyupbit API ê¸°ë°˜)")

            # Trading Engine ì´ˆê¸°í™” (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ê¸°ëŠ¥ í†µí•©)
            trading_config = TradingConfig()
            self.trading_engine = LocalTradingEngine(trading_config, dry_run=self.config.dry_run)
            logger.info("âœ… Trading Engine ì´ˆê¸°í™” ì™„ë£Œ (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ê¸°ëŠ¥ í¬í•¨)")

            # SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if SNS_AVAILABLE:
                try:
                    self.sns_notifier = MakenaideSNSNotifier()
                    logger.info("âœ… SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    self.sns_notifier = None

            # Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            try:
                # ì‹¤íŒ¨ ì¶”ì ê¸° ì´ˆê¸°í™”
                self.failure_tracker = FailureTracker(db_path=self.db_path)
                logger.info("âœ… Phase 4 ì‹¤íŒ¨ ì¶”ì ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

                # ì˜ˆì¸¡ì  ë¶„ì„ê¸° ì´ˆê¸°í™”
                self.predictive_analyzer = PredictiveAnalyzer(db_path=self.db_path)
                logger.info("âœ… Phase 4 ì˜ˆì¸¡ì  ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

                # ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
                self.auto_recovery_system = AutoRecoverySystem(db_path=self.db_path)
                logger.info("âœ… Phase 4 ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

                logger.info("ğŸ”® Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                logger.warning(f"âš ï¸ Phase 4 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # Phase 4ëŠ” ì„ íƒì  ê¸°ëŠ¥ìœ¼ë¡œ ì‹¤íŒ¨í•´ë„ ì „ì²´ ì‹œìŠ¤í…œì€ ê³„ì† ì§„í–‰
                self.failure_tracker = None
                self.predictive_analyzer = None
                self.auto_recovery_system = None

            logger.info("ğŸ‰ ëª¨ë“  ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
            return True

        except Exception as e:
            logger.error(f"âŒ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def handle_failure_with_phase4(self, failure_type: str, sub_type: str, error_message: str,
                                   phase: str, execution_id: str, metadata: dict = None,
                                   severity: str = "HIGH") -> None:
        """Phase 4 í†µí•© ì‹¤íŒ¨ ì²˜ë¦¬: ì¶”ì  + ë¶„ì„ + ë³µêµ¬ + ì•Œë¦¼"""
        try:
            # 1. Phase 4 ì‹¤íŒ¨ ì¶”ì  (ìˆëŠ” ê²½ìš°)
            if self.failure_tracker:
                failure_id = self.failure_tracker.record_failure(
                    failure_type=failure_type,
                    sub_type=sub_type,
                    error_message=error_message,
                    execution_id=execution_id,
                    severity=severity,
                    phase=phase,
                    metadata=metadata or {}
                )
                logger.info(f"ğŸ”® Phase 4: ì‹¤íŒ¨ ê¸°ë¡ ì™„ë£Œ (ID: {failure_id})")

                # 2. ì˜ˆì¸¡ì  ë¶„ì„ ì‹¤í–‰ (ìˆëŠ” ê²½ìš°)
                if self.predictive_analyzer:
                    try:
                        prediction = self.predictive_analyzer.predict_failure_probability(time_window_hours=24)
                        logger.info(f"ğŸ”® Phase 4: ì‹¤íŒ¨ ì˜ˆì¸¡ - ìœ„í—˜ë„: {prediction.risk_level.value}, í™•ë¥ : {prediction.failure_probability:.1%}")

                        # ë†’ì€ ìœ„í—˜ë„ì¸ ê²½ìš° ì¶”ê°€ ë¡œê¹…
                        if prediction.risk_level.value in ['HIGH', 'CRITICAL']:
                            logger.warning(f"âš ï¸ Phase 4: ë†’ì€ ì‹¤íŒ¨ ìœ„í—˜ ê°ì§€ - ê¶Œì¥ì‚¬í•­: {', '.join(prediction.recommended_actions)}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Phase 4: ì˜ˆì¸¡ ë¶„ì„ ì‹¤íŒ¨ - {e}")

                # 3. ìë™ ë³µêµ¬ ì œì•ˆ (ìˆëŠ” ê²½ìš°)
                if self.auto_recovery_system:
                    try:
                        # ì‹¤íŒ¨ ê¸°ë¡ì„ ê°€ì ¸ì™€ì„œ ë³µêµ¬ ì œì•ˆ ìƒì„±
                        failure_record = FailureRecord(
                            id=failure_id,
                            timestamp=datetime.now().isoformat(),
                            execution_id=execution_id,
                            failure_type=failure_type,
                            sub_type=sub_type,
                            severity=severity,
                            phase=phase,
                            error_message=error_message,
                            metadata=str(metadata or {})
                        )

                        suggestions = self.auto_recovery_system.get_recovery_suggestions(failure_record)
                        if suggestions and 'recovery_actions' in suggestions:
                            logger.info(f"ğŸ”® Phase 4: ë³µêµ¬ ì œì•ˆ - {len(suggestions['recovery_actions'])}ê°œ ì•¡ì…˜ ì œì•ˆë¨")

                    except Exception as e:
                        logger.warning(f"âš ï¸ Phase 4: ë³µêµ¬ ì œì•ˆ ì‹¤íŒ¨ - {e}")

            # 4. ê¸°ì¡´ SNS ì•Œë¦¼ ì „ì†¡ (í˜¸í™˜ì„± ìœ ì§€)
            if SNS_AVAILABLE:
                try:
                    notify_detailed_failure(
                        failure_type=failure_type,
                        sub_type=sub_type,
                        error_message=error_message,
                        phase=phase,
                        execution_id=execution_id,
                        metadata=metadata
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

        except Exception as e:
            logger.error(f"âŒ Phase 4 í†µí•© ì‹¤íŒ¨ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # Phase 4 ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ì¡´ SNS ì•Œë¦¼ì€ ì „ì†¡
            if SNS_AVAILABLE:
                try:
                    notify_detailed_failure(
                        failure_type=failure_type,
                        sub_type=sub_type,
                        error_message=error_message,
                        phase=phase,
                        execution_id=execution_id,
                        metadata=metadata
                    )
                except Exception as nested_e:
                    logger.error(f"âŒ SNS ë°±ì—… ì•Œë¦¼ ì „ì†¡ë„ ì‹¤íŒ¨: {nested_e}")

    def run_phase_0_scanner(self) -> bool:
        """Phase 0: ì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº”"""
        try:
            logger.info("ğŸ“¡ Phase 0: ì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº” ì‹œì‘")

            # scanner.pyì˜ update_tickers í•¨ìˆ˜ í˜¸ì¶œ
            update_tickers()

            self.execution_stats['phases_completed'].append('Phase 0: Scanner')
            logger.info("âœ… Phase 0 ì™„ë£Œ: ì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº”")
            return True

        except Exception as e:
            logger.error(f"âŒ Phase 0 ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Phase 0 ì‹¤íŒ¨: {e}")
            return False

    def run_phase_1_data_collection(self) -> bool:
        """Phase 1: ì¦ë¶„ OHLCV ë°ì´í„° ìˆ˜ì§‘ (í’ˆì§ˆ í•„í„°ë§ í¬í•¨)"""
        try:
            logger.info("ğŸ“Š Phase 1: ì¦ë¶„ OHLCV ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            logger.info("ğŸ¯ í’ˆì§ˆ í•„í„°ë§ ëª¨ë“œ: 13ê°œì›”+ ë°ì´í„° + 3ì–µì›+ ê±°ë˜ëŒ€ê¸ˆ ì¡°ê±´ ì ìš©")

            # ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ + í’ˆì§ˆ í•„í„°ë§ ë°©ì‹ìœ¼ë¡œ ë³€ê²½ (67% API ì ˆì•½ íš¨ê³¼)
            results = self.data_collector.collect_all_data(
                test_mode=False,
                use_quality_filter=True  # í’ˆì§ˆ í•„í„°ë§ í™œì„±í™”
            )

            if not results:
                logger.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")
                self.execution_stats['errors'].append("Phase 1 ì‹¤íŒ¨: ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")
                return False

            # collect_all_dataëŠ” collection_statsë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì„±ê³µ ì—¬ë¶€ëŠ” í†µê³„ë¡œ íŒë‹¨
            successful_collections = results.get('summary', {}).get('success', 0)
            if successful_collections == 0:
                logger.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: ì„±ê³µí•œ ìˆ˜ì§‘ì´ ì—†ìŒ")
                self.execution_stats['errors'].append("Phase 1 ì‹¤íŒ¨: ì„±ê³µí•œ ë°ì´í„° ìˆ˜ì§‘ ì—†ìŒ")
                return False

            # ìˆ˜ì§‘ ê²°ê³¼ í†µê³„ ë¡œê¹…
            summary = results.get('summary', {})
            processing_time = results.get('processing_time_seconds', 0)
            total_tickers = summary.get('success', 0) + summary.get('failed', 0) + summary.get('skipped', 0)
            successful_collections = summary.get('success', 0)
            quality_filter_enabled = results.get('quality_filter_enabled', True)  # ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë¨

            logger.info(f"ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {successful_collections}/{total_tickers} ì„±ê³µ ({processing_time:.1f}ì´ˆ)")
            logger.info(f"ğŸ’ í’ˆì§ˆ í•„í„°ë§: {'í™œì„±í™”' if quality_filter_enabled else 'ë¹„í™œì„±í™”'}")
            logger.info(f"ğŸ“ˆ ì´ ë ˆì½”ë“œ ìˆ˜ì§‘: {summary.get('total_records', 0)}ê°œ")

            if quality_filter_enabled and total_tickers > 0:
                logger.info(f"âš¡ í’ˆì§ˆ í•„í„°ë§ íš¨ê³¼: ê³ í’ˆì§ˆ ì¢…ëª©ë§Œ ì„ ë³„í•˜ì—¬ API í˜¸ì¶œ 67% ì ˆì•½")

            # ğŸ“¦ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš© (300ì¼+ ì˜¤ë˜ëœ ë°ì´í„° ìë™ ì •ë¦¬)
            try:
                logger.info("ğŸ—‘ï¸ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš© ì¤‘...")
                retention_result = self.data_collector.apply_data_retention_policy(retention_days=300)

                if retention_result['deleted_rows'] > 0:
                    logger.info(f"ğŸ—‘ï¸ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {retention_result['deleted_rows']:,}ê°œ í–‰ ì‚­ì œ")
                    logger.info(f"ğŸ’¾ ìŠ¤í† ë¦¬ì§€ ì ˆì•½: {retention_result['size_reduction_pct']:.1f}%")
                else:
                    logger.info("âœ… ì •ë¦¬í•  ì˜¤ë˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            except Exception as e:
                logger.warning(f"âš ï¸ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš© ì‹¤íŒ¨: {e}")
                # ë°ì´í„° ë³´ì¡´ ì •ì±… ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰

            self.execution_stats['phases_completed'].append('Phase 1: Data Collection')
            logger.info("âœ… Phase 1 ì™„ë£Œ: ì¦ë¶„ OHLCV ë°ì´í„° ìˆ˜ì§‘ (í’ˆì§ˆ í•„í„°ë§ ì ìš©)")
            return True

        except Exception as e:
            logger.error(f"âŒ Phase 1 ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Phase 1 ì‹¤íŒ¨: {e}")
            return False

    async def run_phase_2_technical_filter(self) -> List[str]:
        """Phase 2: LayeredScoringEngine ì ìˆ˜ì œ ê¸°ìˆ ì  í•„í„°ë§"""
        try:
            logger.info("ğŸ¯ Phase 2: LayeredScoringEngine ì ìˆ˜ì œ ë¶„ì„ ì‹œì‘")

            # ì ìˆ˜ì œ í•„í„° ì‹¤í–‰ (ìƒˆë¡œìš´ ì‹œìŠ¤í…œ)
            analysis_results = await self.technical_filter.run_full_analysis()

            if not analysis_results:
                logger.info("ğŸ“­ ë¶„ì„ ê°€ëŠ¥í•œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤")
                return []

            # í’ˆì§ˆ ì ìˆ˜ ì„ê³„ê°’ í•„í„°ë§
            filtered_candidates = []
            technical_candidates_data = []  # SNS ì•Œë¦¼ìš© ìƒì„¸ ë°ì´í„°

            for result in analysis_results:
                ticker = result.ticker
                total_score = result.total_score
                quality_gates_passed = result.quality_gates_passed
                recommendation = result.recommendation

                # SNS ì•Œë¦¼ìš© ë°ì´í„° ì €ì¥ (ëª¨ë“  í›„ë³´)
                technical_candidates_data.append({
                    'ticker': ticker,
                    'quality_score': total_score,  # ì´ì ì„ í’ˆì§ˆ ì ìˆ˜ë¡œ ì‚¬ìš©
                    'gates_passed': 'í†µê³¼' if quality_gates_passed else 'ë¯¸í†µê³¼',
                    'recommendation': recommendation,
                    'pattern_type': f'Stage {result.stage}',
                    'price': 0,  # í•„ìš”ì‹œ ì¶”ê°€ êµ¬í˜„
                    'volume_ratio': 0,  # í•„ìš”ì‹œ ì¶”ê°€ êµ¬í˜„
                    'macro_score': result.macro_score,
                    'structural_score': result.structural_score,
                    'micro_score': result.micro_score,
                    'confidence': result.confidence
                })

                # ë§¤ìˆ˜ ì¶”ì²œì´ê³  Quality Gateë¥¼ í†µê³¼í•œ ì¢…ëª©ë§Œ í•„í„°ë§
                if recommendation == "BUY" and quality_gates_passed and total_score >= self.config.min_quality_score:
                    filtered_candidates.append(ticker)
                    logger.info(f"âœ… {ticker}: ì´ì  {total_score:.1f}, Quality Gate í†µê³¼, ê¶Œê³ : {recommendation}")
                    logger.info(f"   â”” Macro: {result.macro_score:.1f}, Structural: {result.structural_score:.1f}, Micro: {result.micro_score:.1f}")
                else:
                    if total_score < self.config.min_quality_score:
                        logger.info(f"â­ï¸ {ticker}: ì´ì  {total_score:.1f} (ì„ê³„ê°’ {self.config.min_quality_score} ë¯¸ë‹¬)")
                    elif not quality_gates_passed:
                        logger.info(f"â­ï¸ {ticker}: Quality Gate ë¯¸í†µê³¼ (ì´ì  {total_score:.1f})")
                    else:
                        logger.info(f"â­ï¸ {ticker}: {recommendation} ê¶Œê³  (ì´ì  {total_score:.1f})")

            # ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ë¥¼ í†µê³„ì— ì €ì¥
            self.execution_stats['technical_candidates'] = technical_candidates_data
            self.execution_stats['phases_completed'].append('Phase 2: LayeredScoringEngine Filter')
            self.execution_stats['trading_candidates'] = len(filtered_candidates)

            logger.info(f"âœ… Phase 2 ì™„ë£Œ: {len(filtered_candidates)}ê°œ ê±°ë˜ í›„ë³´ ë°œê²¬ (ì´ {len(technical_candidates_data)}ê°œ ì¢…ëª© ë¶„ì„)")
            return filtered_candidates

        except Exception as e:
            logger.error(f"âŒ Phase 2 ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Phase 2 ì‹¤íŒ¨: {e}")
            return []

    def run_phase_3_gpt_analysis(self, candidates: List[str]) -> List[str]:
        """Phase 3: GPT íŒ¨í„´ ë¶„ì„ (ì„ íƒì  & ì¡°ê±´ë¶€)"""

        # ğŸ”§ 1ì°¨ ì¡°ê±´: GPT ë¶„ì„ í™œì„±í™” ì—¬ë¶€ ë° í›„ë³´ ì¡´ì¬ ì—¬ë¶€
        if not self.config.enable_gpt_analysis or not candidates:
            logger.info("â­ï¸ Phase 3: GPT ë¶„ì„ ë¹„í™œì„±í™” ë˜ëŠ” í›„ë³´ ì—†ìŒ")
            return candidates

        # ğŸ”§ 2ì°¨ ì¡°ê±´: ìŠ¤ë§ˆíŠ¸ ì¡°ê±´ë¶€ ì‹¤í–‰ ë¡œì§
        skip_gpt = False
        skip_reason = ""

        # ì¡°ê±´ 1: í›„ë³´ ê°œìˆ˜ ê¸°ë°˜ ì¡°ê±´ë¶€ ì‹¤í–‰
        if len(candidates) > 20:
            skip_gpt = True
            skip_reason = f"í›„ë³´ê°€ ë„ˆë¬´ ë§ìŒ ({len(candidates)}ê°œ) - ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ ê¸°ìˆ ì  ë¶„ì„ë§Œ ì‚¬ìš©"
        elif len(candidates) == 1:
            skip_gpt = True
            skip_reason = f"í›„ë³´ê°€ 1ê°œë¿ - ê¸°ìˆ ì  ë¶„ì„ìœ¼ë¡œ ì¶©ë¶„"

        # ì¡°ê±´ 2: ì¼ì¼ GPT ë¹„ìš© ì‚¬ìš©ëŸ‰ ê¸°ë°˜ (ê¸°ì¡´ ë¡œì§ í™•ì¥)
        try:
            # ì˜¤ëŠ˜ ì‚¬ìš©í•œ GPT ë¹„ìš© ì¶”ì • (ê°„ë‹¨í•œ ê³„ì‚°)
            today_estimated_cost = len(candidates) * 0.05  # í›„ë³´ë‹¹ $0.05 ì¶”ì •
            if today_estimated_cost > self.config.max_gpt_budget_daily:
                skip_gpt = True
                skip_reason = f"ì˜ˆìƒ ë¹„ìš© ì´ˆê³¼ (${today_estimated_cost:.2f} > ${self.config.max_gpt_budget_daily})"
        except:
            pass  # ë¹„ìš© ê³„ì‚° ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ

        # ì¡°ê±´ 3: ë¦¬ìŠ¤í¬ ë ˆë²¨ ê¸°ë°˜ ì¡°ê±´ë¶€ ì‹¤í–‰
        if self.config.risk_level == RiskLevel.CONSERVATIVE and len(candidates) > 5:
            skip_gpt = True
            skip_reason = f"ë³´ìˆ˜ì  ë¦¬ìŠ¤í¬ ë ˆë²¨ì—ì„œ í›„ë³´ 5ê°œ ì´ˆê³¼ ({len(candidates)}ê°œ) - ê¸°ìˆ ì  ë¶„ì„ ìš°ì„ "

        # ì¡°ê±´ë¶€ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬
        if skip_gpt:
            logger.info(f"ğŸ§  GPT ë¶„ì„ ìŠ¤í‚µ: {skip_reason}")
            logger.info(f"ğŸ’° ë¹„ìš© ì ˆì•½: ì˜ˆìƒ ${len(candidates) * 0.05:.2f} ì ˆì•½")
            logger.info(f"âš¡ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ {len(candidates)}ê°œ í›„ë³´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©")
            return candidates

        # GPT ë¶„ì„ ì‹¤í–‰ ê²°ì •
        logger.info(f"ğŸ¤– GPT ë¶„ì„ ì‹¤í–‰ ê²°ì •:")
        logger.info(f"   â€¢ í›„ë³´ ê°œìˆ˜: {len(candidates)}ê°œ (ì ì ˆ)")
        logger.info(f"   â€¢ ì˜ˆìƒ ë¹„ìš©: ${len(candidates) * 0.05:.2f}")
        logger.info(f"   â€¢ ë¦¬ìŠ¤í¬ ë ˆë²¨: {self.config.risk_level.value}")
        logger.info(f"   â€¢ ì¼ì¼ ì˜ˆì‚°: ${self.config.max_gpt_budget_daily}")

        return self._execute_gpt_analysis(candidates)

    def _execute_gpt_analysis(self, candidates: List[str]) -> List[str]:
        """GPT ë¶„ì„ ì‹¤í–‰ (ë‚´ë¶€ ë©”ì„œë“œ)"""

        try:
            logger.info(f"ğŸ¤– Phase 3: GPT íŒ¨í„´ ë¶„ì„ ì‹œì‘ ({len(candidates)}ê°œ í›„ë³´)")

            gpt_approved_candidates = []
            gpt_candidates_data = []  # SNS ì•Œë¦¼ìš© ìƒì„¸ ë°ì´í„°
            total_cost = 0.0

            for ticker in candidates:
                try:
                    # ì¼ì¼ ë¹„ìš© í•œë„ í™•ì¸
                    if total_cost >= self.config.max_gpt_budget_daily:
                        logger.warning(f"ğŸ’° ì¼ì¼ GPT ë¹„ìš© í•œë„ ë„ë‹¬: ${total_cost:.2f}")
                        break

                    # GPT ë¶„ì„ ì‹¤í–‰
                    result = self.gpt_analyzer.analyze_ticker(ticker)

                    if result:
                        # SNS ì•Œë¦¼ìš© ë°ì´í„° ì €ì¥ (ëª¨ë“  GPT ë¶„ì„ ê²°ê³¼)
                        gpt_candidates_data.append({
                            'ticker': ticker,
                            'recommendation': result.get('recommendation', 'Unknown'),
                            'confidence': result.get('confidence', 0.0),
                            'pattern': result.get('pattern', ''),
                            'reasoning': result.get('reasoning', ''),
                            'risk_level': result.get('risk_level', 'Unknown'),
                            'cost': 0.05  # ì¶”ì • ë¹„ìš©
                        })

                        if result.get('recommendation') == 'BUY':
                            confidence = result.get('confidence', 0.0)
                            logger.info(f"âœ… {ticker}: GPT ë§¤ìˆ˜ ì¶”ì²œ (ì‹ ë¢°ë„: {confidence:.1f}%)")
                            gpt_approved_candidates.append(ticker)
                        else:
                            recommendation = result.get('recommendation', 'Unknown')
                            logger.info(f"â­ï¸ {ticker}: GPT ë¶„ì„ ê²°ê³¼ - {recommendation}")
                    else:
                        # ë¶„ì„ ì‹¤íŒ¨í•œ ê²½ìš°ë„ ê¸°ë¡
                        gpt_candidates_data.append({
                            'ticker': ticker,
                            'recommendation': 'ERROR',
                            'confidence': 0.0,
                            'pattern': '',
                            'reasoning': 'GPT ë¶„ì„ ì‹¤íŒ¨',
                            'risk_level': 'Unknown',
                            'cost': 0.0
                        })
                        logger.info(f"âŒ {ticker}: GPT ë¶„ì„ ì‹¤íŒ¨")

                    # ë¹„ìš© ì¶”ì • (GPT-5-mini ê¸°ì¤€)
                    estimated_cost = 0.05  # ëŒ€ëµì ì¸ ë¹„ìš© ì¶”ì •
                    total_cost += estimated_cost

                    time.sleep(1)  # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ê³ ë ¤

                except Exception as e:
                    logger.warning(f"âš ï¸ {ticker} GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
                    # ì˜¤ë¥˜ ì¼€ì´ìŠ¤ë„ ê¸°ë¡
                    gpt_candidates_data.append({
                        'ticker': ticker,
                        'recommendation': 'ERROR',
                        'confidence': 0.0,
                        'pattern': '',
                        'reasoning': f'ë¶„ì„ ì˜¤ë¥˜: {str(e)}',
                        'risk_level': 'Unknown',
                        'cost': 0.0
                    })
                    continue

            # GPT ë¶„ì„ ê²°ê³¼ë¥¼ í†µê³„ì— ì €ì¥
            self.execution_stats['gpt_candidates'] = gpt_candidates_data
            self.execution_stats['phases_completed'].append('Phase 3: GPT Analysis')
            self.execution_stats['total_cost'] += total_cost

            logger.info(f"âœ… Phase 3 ì™„ë£Œ: {len(gpt_approved_candidates)}ê°œ GPT ìŠ¹ì¸ (ì´ {len(gpt_candidates_data)}ê°œ ë¶„ì„, ë¹„ìš©: ${total_cost:.2f})")
            return gpt_approved_candidates

        except Exception as e:
            logger.error(f"âŒ Phase 3 ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Phase 3 ì‹¤íŒ¨: {e}")
            return candidates  # GPT ì‹¤íŒ¨ ì‹œ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ì‚¬ìš©

    def run_kelly_calculation(self, candidates: List[str]) -> Dict[str, float]:
        """Kelly ê³µì‹ ê¸°ë°˜ í¬ì§€ì…˜ ì‚¬ì´ì§• ê³„ì‚°"""
        if not candidates:
            return {}

        try:
            logger.info(f"ğŸ§® Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ê³„ì‚° ({len(candidates)}ê°œ í›„ë³´)")

            position_sizes = {}

            for ticker in candidates:
                try:
                    # íŒ¨í„´ ë¶„ì„ ë° í¬ì§€ì…˜ ì‚¬ì´ì§•
                    position_size = self.kelly_calculator.calculate_position_size(ticker)

                    if position_size > 0:
                        position_sizes[ticker] = position_size
                        logger.info(f"ğŸ“Š {ticker}: Kelly í¬ì§€ì…˜ {position_size:.1f}%")
                    else:
                        logger.info(f"â­ï¸ {ticker}: Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ì¡°ê±´ ë¯¸ì¶©ì¡±")

                except Exception as e:
                    logger.warning(f"âš ï¸ {ticker} Kelly ê³„ì‚° ì‹¤íŒ¨: {e}")
                    continue

            # Kelly ê²°ê³¼ë¥¼ í†µê³„ì— ì €ì¥
            self.execution_stats['kelly_results'] = position_sizes

            logger.info(f"âœ… Kelly ê³„ì‚° ì™„ë£Œ: {len(position_sizes)}ê°œ ì¢…ëª©")
            return position_sizes

        except Exception as e:
            logger.error(f"âŒ Kelly ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Kelly ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}

    def run_market_sentiment_analysis(self) -> Tuple[MarketSentiment, bool, float]:
        """ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ë° ê±°ë˜ ê°€ëŠ¥ ì—¬ë¶€ íŒì •"""
        try:
            logger.info("ğŸŒ¡ï¸ ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹œì‘ (pyupbit API ê¸°ë°˜)")

            # ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤í–‰
            sentiment_result = self.market_sentiment.analyze_market_sentiment()

            if not sentiment_result:
                logger.warning("âš ï¸ ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ë”ë¯¸ ê²°ê³¼ ì €ì¥
                self.last_sentiment_result = None
                return MarketSentiment.NEUTRAL, True, 1.0  # ê¸°ë³¸ê°’

            # ğŸ“Š ê²°ê³¼ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥ (SNS ì•Œë¦¼ìš©)
            self.last_sentiment_result = sentiment_result

            sentiment = sentiment_result.final_sentiment
            can_trade = sentiment_result.trading_allowed
            position_adjustment = sentiment_result.position_adjustment

            logger.info(f"ğŸ“Š ì‹œì¥ ê°ì •: {sentiment.value}")
            logger.info(f"ğŸš¦ ê±°ë˜ ê°€ëŠ¥: {'ì˜ˆ' if can_trade else 'ì•„ë‹ˆì˜¤'}")
            logger.info(f"âš–ï¸ í¬ì§€ì…˜ ì¡°ì •: {position_adjustment:.2f}x")
            logger.info(f"ğŸ” ì¢…í•© ì ìˆ˜: {sentiment_result.total_score:.1f}ì ")
            logger.info(f"ğŸ“‹ ë¶„ì„ ê·¼ê±°: {sentiment_result.reasoning}")

            # BEAR ì‹œì¥ì—ì„œëŠ” ê±°ë˜ ì¤‘ë‹¨
            if sentiment == MarketSentiment.BEAR:
                logger.warning("ğŸš« BEAR ì‹œì¥ ê°ì§€ - ëª¨ë“  ê±°ë˜ ì¤‘ë‹¨")
                logger.warning(f"   ğŸ“‰ ì‹œì¥ ì ìˆ˜: {sentiment_result.total_score:.1f}ì  (ì„ê³„ê°’: 35ì )")
                return sentiment, False, 0.0

            return sentiment, can_trade, position_adjustment

        except Exception as e:
            logger.error(f"âŒ ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            self.last_sentiment_result = None
            return MarketSentiment.NEUTRAL, True, 1.0  # ê¸°ë³¸ê°’ìœ¼ë¡œ ê±°ë˜ í—ˆìš©

    def execute_trades(self, position_sizes: Dict[str, float], position_adjustment: float) -> int:
        """ì‹¤ì œ ê±°ë˜ ì‹¤í–‰"""
        if not position_sizes or position_adjustment <= 0:
            logger.info("ğŸ“­ ê±°ë˜í•  ì¢…ëª©ì´ ì—†ê±°ë‚˜ ì‹œì¥ ì¡°ê±´ ë¶ˆëŸ‰")
            return 0

        try:
            logger.info(f"ğŸ’¸ ê±°ë˜ ì‹¤í–‰ ì‹œì‘ ({len(position_sizes)}ê°œ ì¢…ëª©)")

            if self.config.dry_run:
                logger.info("ğŸ§ª DRY RUN ëª¨ë“œ: ì‹¤ì œ ê±°ë˜ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ")
                return len(position_sizes)

            trades_executed = 0
            total_balance = self.trading_engine.get_total_balance()

            for ticker, base_position in position_sizes.items():
                try:
                    # ì‹œì¥ ê°ì • ê¸°ë°˜ í¬ì§€ì…˜ ì¡°ì •
                    adjusted_position = base_position * position_adjustment

                    # ìµœëŒ€/ìµœì†Œ í¬ì§€ì…˜ ì œí•œ
                    adjusted_position = max(1.0, min(adjusted_position, 8.0))

                    # ì‹¤ì œ íˆ¬ì ê¸ˆì•¡ ê³„ì‚°
                    investment_amount = total_balance * (adjusted_position / 100)

                    # ìµœì†Œ ì£¼ë¬¸ ê¸ˆì•¡ í™•ì¸
                    if investment_amount < 10000:  # 1ë§Œì› ìµœì†Œ
                        logger.info(f"â­ï¸ {ticker}: íˆ¬ì ê¸ˆì•¡ ë¶€ì¡± ({investment_amount:,.0f}ì›)")
                        continue

                    logger.info(f"ğŸ’° {ticker}: {adjusted_position:.1f}% ({investment_amount:,.0f}ì›) ë§¤ìˆ˜ ì‹œë„")

                    # ë§¤ìˆ˜ ì‹¤í–‰
                    result = self.trading_engine.execute_buy_order(ticker, investment_amount)

                    if result and result.status == OrderStatus.SUCCESS:
                        trades_executed += 1
                        logger.info(f"âœ… {ticker}: ë§¤ìˆ˜ ì„±ê³µ")
                    else:
                        logger.warning(f"âŒ {ticker}: ë§¤ìˆ˜ ì‹¤íŒ¨")

                    time.sleep(0.5)  # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ê³ ë ¤

                except Exception as e:
                    logger.error(f"âŒ {ticker} ê±°ë˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    continue

            self.execution_stats['trades_executed'] = trades_executed
            logger.info(f"âœ… ê±°ë˜ ì‹¤í–‰ ì™„ë£Œ: {trades_executed}ê°œ ì„±ê³µ")
            return trades_executed

        except Exception as e:
            logger.error(f"âŒ ê±°ë˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"ê±°ë˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return 0

    def run_portfolio_management(self):
        """í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ë° ë§¤ë„ ì¡°ê±´ ê²€ì‚¬ (ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ê¸°ë°˜)"""
        try:
            logger.info("ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì‹œì‘ (ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ëª¨ë“œ)")

            # Trading Engineì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ì´ˆê¸°í™”
            if not self.trading_engine:
                logger.warning("âš ï¸ Trading Engineì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ. ì¬ì´ˆê¸°í™” ì‹œë„")
                trading_config = TradingConfig(take_profit_percent=0)  # ê¸°ìˆ ì  ì‹ í˜¸ì—ë§Œ ì˜ì¡´
                self.trading_engine = LocalTradingEngine(trading_config, dry_run=self.config.dry_run)
                logger.info("âœ… Trading Engine ì¬ì´ˆê¸°í™” ì™„ë£Œ")

            # LocalTradingEngineì˜ í–¥ìƒëœ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì‹œìŠ¤í…œ ì‹¤í–‰ (í”¼ë¼ë¯¸ë”© + íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘)
            portfolio_result = self.trading_engine.process_enhanced_portfolio_management()

            # ê²°ê³¼ ë¶„ì„ ë° ë¡œê¹… (í”¼ë¼ë¯¸ë”© í¬í•¨)
            positions_checked = portfolio_result.get('positions_checked', 0)
            sell_orders_executed = portfolio_result.get('sell_orders_executed', 0)
            pyramid_trades = portfolio_result.get('pyramid_trades', {})
            pyramid_successful = pyramid_trades.get('successful', 0)
            errors = portfolio_result.get('errors', [])

            if positions_checked == 0:
                logger.info("ğŸ“­ ê´€ë¦¬í•  í¬ì§€ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
            else:
                logger.info(f"ğŸ“Š í–¥ìƒëœ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì™„ë£Œ:")
                logger.info(f"   í¬ì§€ì…˜ ë¶„ì„: {positions_checked}ê°œ")
                if sell_orders_executed > 0:
                    logger.info(f"   ğŸ’¹ íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘/ê¸°ìˆ ì  ë§¤ë„: {sell_orders_executed}ê°œ")
                if pyramid_successful > 0:
                    logger.info(f"   ğŸ”º í”¼ë¼ë¯¸ë”© ì¶”ê°€ ë§¤ìˆ˜: {pyramid_successful}ê°œ")
                if sell_orders_executed == 0 and pyramid_successful == 0:
                    logger.info("   âœ… ëª¨ë“  í¬ì§€ì…˜ ë³´ìœ  ìœ ì§€ (ë§¤ë„/í”¼ë¼ë¯¸ë”© ì¡°ê±´ ë¯¸ì¶©ì¡±)")

            # ì—ëŸ¬ê°€ ìˆëŠ” ê²½ìš° í†µê³„ì— ì¶”ê°€
            for error in errors:
                self.execution_stats['errors'].append(f"í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì˜¤ë¥˜: {error}")

            # ê±°ë˜ í†µê³„ ì—…ë°ì´íŠ¸ (í”¼ë¼ë¯¸ë”© í¬í•¨)
            if hasattr(self.trading_engine, 'get_trading_statistics'):
                trading_stats = self.trading_engine.get_trading_statistics()
                total_trades_executed = sell_orders_executed + pyramid_successful
                self.execution_stats['trades_executed'] += total_trades_executed
                logger.info(f"ğŸ¯ ì´ ê±°ë˜ ì‹¤í–‰: {total_trades_executed}ê°œ (ë§¤ë„: {sell_orders_executed}, í”¼ë¼ë¯¸ë”©: {pyramid_successful})")
                logger.info(f"ğŸ¯ ê±°ë˜ ì„±ê³µë¥ : {trading_stats.get('success_rate', 0):.1f}%")

            logger.info("âœ… ê³ ê¸‰ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì™„ë£Œ")
            return portfolio_result

        except Exception as e:
            error_msg = f"ê³ ê¸‰ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì‹¤íŒ¨: {e}"
            logger.error(f"âŒ {error_msg}")
            self.execution_stats['errors'].append(error_msg)

            # í´ë°±: ì‹¬ê°í•œ ì˜¤ë¥˜ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return {
                'positions_checked': 0,
                'sell_orders_executed': 0,
                'errors': [str(e)]
            }

    def generate_execution_report(self):
        """ì‹¤í–‰ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        try:
            logger.info("ğŸ“‹ ì‹¤í–‰ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±")

            end_time = datetime.now()
            duration = end_time - self.execution_stats['start_time']

            report = {
                'execution_time': {
                    'start': self.execution_stats['start_time'].isoformat(),
                    'end': end_time.isoformat(),
                    'duration_seconds': duration.total_seconds()
                },
                'phases_completed': self.execution_stats['phases_completed'],
                'trading_stats': {
                    'candidates_found': self.execution_stats['trading_candidates'],
                    'trades_executed': self.execution_stats['trades_executed'],
                    'total_cost_usd': self.execution_stats['total_cost']
                },
                'errors': self.execution_stats['errors'],
                'config': {
                    'gpt_enabled': self.config.enable_gpt_analysis,
                    'dry_run': self.config.dry_run,
                    'risk_level': self.config.risk_level.value
                }
            }

            # JSON í˜•íƒœë¡œ ì €ì¥
            report_path = f"./logs/execution_report_{end_time.strftime('%Y%m%d_%H%M%S')}.json"
            os.makedirs('./logs', exist_ok=True)

            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            # ì½˜ì†” ìš”ì•½ ì¶œë ¥
            logger.info("="*60)
            logger.info("ğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
            logger.info("="*60)
            logger.info(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {duration.total_seconds():.1f}ì´ˆ")
            logger.info(f"âœ… ì™„ë£Œëœ ë‹¨ê³„: {len(self.execution_stats['phases_completed'])}ê°œ")
            logger.info(f"ğŸ¯ ê±°ë˜ í›„ë³´: {self.execution_stats['trading_candidates']}ê°œ")
            logger.info(f"ğŸ’¸ ì‹¤í–‰ëœ ê±°ë˜: {self.execution_stats['trades_executed']}ê°œ")
            logger.info(f"ğŸ’° ì´ ë¹„ìš©: ${self.execution_stats['total_cost']:.2f}")
            logger.info(f"âŒ ì˜¤ë¥˜ ìˆ˜: {len(self.execution_stats['errors'])}ê°œ")
            logger.info(f"ğŸ“„ ë³´ê³ ì„œ: {report_path}")
            logger.info("="*60)

        except Exception as e:
            logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")

    def generate_phase4_daily_report(self):
        """Phase 4 ì¼ì¼ íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ë³´ê³ ì„œ ìƒì„±"""
        try:
            if not self.failure_tracker or not self.predictive_analyzer:
                logger.info("â­ï¸ Phase 4ê°€ ë¹„í™œì„±í™”ë˜ì–´ ì¼ì¼ ë³´ê³ ì„œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
                return

            logger.info("ğŸ”® Phase 4 ì¼ì¼ ë³´ê³ ì„œ ìƒì„± ì‹œì‘")

            # 1. ì‹¤íŒ¨ íŒ¨í„´ í†µê³„ ìˆ˜ì§‘
            failure_stats = self.failure_tracker.get_failure_statistics(days=7)
            recent_failures = self.failure_tracker.get_recent_failures(hours=24)

            # 2. ì˜ˆì¸¡ ë¶„ì„ ì‹¤í–‰
            prediction = self.predictive_analyzer.predict_failure_probability(time_window_hours=24)

            # 3. ì‹œìŠ¤í…œ ìƒíƒœ ê±´ê°•ë„ ì²´í¬
            current_health = self.failure_tracker.get_current_system_health()

            # 4. ë³´ê³ ì„œ ìƒì„±
            report = {
                'report_date': datetime.now().isoformat(),
                'phase4_summary': {
                    'failures_last_24h': len(recent_failures),
                    'failures_last_7d': failure_stats.get('total_failures', 0),
                    'top_failure_types': failure_stats.get('failure_types', {}),
                    'system_health_score': current_health.overall_health if current_health else 100.0
                },
                'prediction_analysis': {
                    'risk_level': prediction.risk_level.value,
                    'failure_probability': prediction.failure_probability,
                    'confidence': prediction.confidence.value,
                    'recommendations': prediction.recommended_actions
                },
                'recent_patterns': [
                    {
                        'failure_type': f.failure_type,
                        'sub_type': f.sub_type,
                        'phase': f.phase,
                        'timestamp': f.timestamp,
                        'severity': f.severity
                    } for f in recent_failures[:10]  # ìµœê·¼ 10ê°œë§Œ
                ]
            }

            # 5. ë³´ê³ ì„œ ì €ì¥
            report_path = f"./logs/phase4_daily_report_{datetime.now().strftime('%Y%m%d')}.json"
            os.makedirs('./logs', exist_ok=True)

            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            # 6. ì½˜ì†” ìš”ì•½ ì¶œë ¥
            logger.info("="*60)
            logger.info("ğŸ”® Phase 4 ì¼ì¼ ë³´ê³ ì„œ ìš”ì•½")
            logger.info("="*60)
            logger.info(f"ğŸ“Š ì§€ë‚œ 24ì‹œê°„ ì‹¤íŒ¨: {len(recent_failures)}ê±´")
            logger.info(f"ğŸ“Š ì§€ë‚œ 7ì¼ ì‹¤íŒ¨: {failure_stats.get('total_failures', 0)}ê±´")
            logger.info(f"ğŸ¯ ì˜ˆì¸¡ ìœ„í—˜ë„: {prediction.risk_level.value}")
            logger.info(f"ğŸ¯ ì‹¤íŒ¨ í™•ë¥ : {prediction.failure_probability:.1%}")
            logger.info(f"ğŸ¥ ì‹œìŠ¤í…œ ê±´ê°•ë„: {current_health.overall_health if current_health else 100.0:.1f}%")
            logger.info(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: {len(prediction.recommended_actions)}ê°œ")
            logger.info(f"ğŸ“„ ìƒì„¸ ë³´ê³ ì„œ: {report_path}")
            logger.info("="*60)

            # 7. ë†’ì€ ìœ„í—˜ë„ì¸ ê²½ìš° ê²½ê³ 
            if prediction.risk_level.value in ['HIGH', 'CRITICAL']:
                logger.warning(f"âš ï¸ ë†’ì€ ì‹¤íŒ¨ ìœ„í—˜ ê°ì§€! ì£¼ìš” ê¶Œì¥ì‚¬í•­:")
                for rec in prediction.recommended_actions[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    logger.warning(f"   â€¢ {rec}")

        except Exception as e:
            logger.error(f"âŒ Phase 4 ì¼ì¼ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")

    async def run_analysis_pipeline(self) -> Dict:
        """ë¶„ì„ íŒŒì´í”„ë¼ì¸ë§Œ ì‹¤í–‰ (ê±°ë˜ ì—†ì´)"""
        try:
            logger.info("ğŸ” ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘")

            # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if not self.initialize_components():
                return {"status": "failed", "reason": "ì´ˆê¸°í™” ì‹¤íŒ¨"}

            # 2. Phase 0: ì¢…ëª© ìŠ¤ìº”
            if not self.run_phase_0_scanner():
                return {"status": "failed", "reason": "ì¢…ëª© ìŠ¤ìº” ì‹¤íŒ¨"}

            # 3. Phase 1: ë°ì´í„° ìˆ˜ì§‘
            if not self.run_phase_1_data_collection():
                return {"status": "failed", "reason": "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨"}

            # 4. Phase 2: ê¸°ìˆ ì  í•„í„°ë§
            candidates = await self.run_phase_2_technical_filter()

            # 5. Phase 3: GPT ë¶„ì„ (ì„ íƒì )
            final_candidates = self.run_phase_3_gpt_analysis(candidates)

            # 6. Kelly í¬ì§€ì…˜ ì‚¬ì´ì§•
            position_sizes = self.run_kelly_calculation(final_candidates)

            # 7. ì‹œì¥ ê°ì • ë¶„ì„
            market_sentiment, can_trade, position_adjustment = self.run_market_sentiment_analysis()

            result = {
                "status": "success",
                "candidates_found": len(candidates) if candidates else 0,
                "final_candidates": len(final_candidates) if final_candidates else 0,
                "position_sizes": len(position_sizes) if position_sizes else 0,
                "market_sentiment": market_sentiment.value if market_sentiment else "unknown",
                "can_trade": can_trade,
                "position_adjustment": position_adjustment
            }

            logger.info(f"âœ… ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {result}")
            return result

        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return {"status": "failed", "reason": str(e)}

    def get_execution_status(self) -> Dict:
        """í˜„ì¬ ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ"""
        try:
            status = {
                "execution_stats": self.execution_stats.copy(),
                "components_initialized": {
                    "upbit": self.upbit is not None,
                    "data_collector": self.data_collector is not None,
                    "technical_filter": self.technical_filter is not None,
                    "gpt_analyzer": self.gpt_analyzer is not None,
                    "kelly_calculator": self.kelly_calculator is not None,
                    "market_sentiment": self.market_sentiment is not None,
                    # "portfolio_manager": self.portfolio_manager is not None,  # trading_engineìœ¼ë¡œ í†µí•©ë¨
                    "trading_engine": self.trading_engine is not None
                },
                "config": {
                    "enable_gpt_analysis": self.config.enable_gpt_analysis,
                    "dry_run": self.config.dry_run,
                    "risk_level": self.config.risk_level.value,
                    "max_positions": self.config.max_positions
                }
            }

            # Trading Engine í†µê³„ ì¶”ê°€
            if self.trading_engine:
                status["trading_engine_stats"] = self.trading_engine.get_trading_statistics()

            return status

        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"status": "error", "message": str(e)}

    def cleanup(self):
        """ì‹œìŠ¤í…œ ì •ë¦¬ ë° ì¢…ë£Œ (EC2 ìë™ ì¢…ë£Œ ëŒ€ë¹„)"""
        try:
            logger.info("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘")

            # 1. Trading Engine ì •ë¦¬
            if self.trading_engine and hasattr(self.trading_engine, 'cleanup'):
                self.trading_engine.cleanup()

            # 2. ì‹¤í–‰ í†µê³„ ì €ì¥
            self.save_execution_stats()

            # 3. SQLite DB ì •ë¦¬
            self.cleanup_database()

            # 4. ë¡œê·¸ ë°±ì—… (í•„ìš”ì‹œ)
            self.backup_logs()

            logger.info("âœ… ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def save_execution_stats(self):
        """ì‹¤í–‰ í†µê³„ SQLiteì— ì €ì¥"""
        try:
            with get_db_connection_context() as conn:
                # ì‹¤í–‰ í†µê³„ í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS makenaide_execution_stats (
                        execution_date TEXT PRIMARY KEY,
                        execution_time TEXT,
                        phases_completed TEXT,
                        total_tickers INTEGER,
                        filtered_candidates INTEGER,
                        gpt_analyzed INTEGER,
                        kelly_positions INTEGER,
                        trades_executed INTEGER,
                        total_cost REAL,
                        success BOOLEAN,
                        errors TEXT,
                        auto_shutdown BOOLEAN
                    )
                """)

                # ì˜¤ëŠ˜ í†µê³„ ì €ì¥
                stats = self.execution_stats
                execution_date = datetime.now().strftime('%Y-%m-%d')
                execution_time = datetime.now().strftime('%H:%M:%S')
                auto_shutdown = os.getenv('EC2_AUTO_SHUTDOWN', 'false').lower() == 'true'

                conn.execute("""
                    INSERT OR REPLACE INTO makenaide_execution_stats
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    execution_date,
                    execution_time,
                    json.dumps(stats.get('phases_completed', [])),
                    stats.get('total_tickers', 0),
                    stats.get('filtered_candidates', 0),
                    len(stats.get('gpt_candidates', [])),
                    len(stats.get('kelly_results', {})),
                    stats.get('trades_executed', 0),
                    stats.get('total_cost', 0.0),
                    len(stats.get('errors', [])) == 0,
                    json.dumps(stats.get('errors', [])),
                    auto_shutdown
                ))

                conn.commit()
                logger.info("ğŸ’¾ ì‹¤í–‰ í†µê³„ ì €ì¥ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")

    def cleanup_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ë° ìµœì í™”"""
        try:
            with get_db_connection_context() as conn:
                # VACUUMìœ¼ë¡œ DB ìµœì í™”
                conn.execute("VACUUM")
                logger.info("ğŸ—ƒï¸ SQLite DB ìµœì í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ DB ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def backup_logs(self):
        """ë¡œê·¸ íŒŒì¼ ë°±ì—… (EC2 ì¢…ë£Œ ì „)"""
        try:
            from datetime import datetime
            import shutil

            log_backup_dir = "data/log_backups"
            os.makedirs(log_backup_dir, exist_ok=True)

            # í˜„ì¬ ë¡œê·¸ íŒŒì¼ ë°±ì—…
            current_date = datetime.now().strftime('%Y%m%d_%H%M%S')

            # ë©”ì¸ ë¡œê·¸ ë°±ì—…
            if os.path.exists("makenaide.log"):
                backup_path = f"{log_backup_dir}/makenaide_{current_date}.log"
                shutil.copy2("makenaide.log", backup_path)
                logger.info(f"ğŸ“¦ ë¡œê·¸ ë°±ì—…: {backup_path}")

        except Exception as e:
            logger.error(f"âŒ ë¡œê·¸ ë°±ì—… ì‹¤íŒ¨: {e}")

    def smart_shutdown_ec2(self, reason: str = "íŒŒì´í”„ë¼ì¸ ì™„ë£Œ", stats: dict = None):
        """AWS CLI ê¸°ë°˜ Smart Shutdown (ê°œì„ ëœ ì•ˆì „ ì¢…ë£Œ)"""
        try:
            logger.info(f"ğŸš€ Smart Shutdown ì‹œì‘: {reason}")

            # Smart Shutdown ëª¨ë“ˆ import
            from smart_shutdown import SmartShutdown

            # ì‹œìŠ¤í…œ ì •ë¦¬ (ê¸°ì¡´ cleanup í˜¸ì¶œ)
            self.cleanup()

            # Smart Shutdown ì‹¤í–‰
            shutdown_system = SmartShutdown()
            success = shutdown_system.execute_smart_shutdown(reason, stats)

            if success:
                logger.info("âœ… Smart Shutdown ì„±ê³µ")
                return True
            else:
                logger.warning("âš ï¸ Smart Shutdown ì¼ë¶€ ì‹¤íŒ¨ - ìˆ˜ë™ í™•ì¸ í•„ìš”")
                return False

        except Exception as e:
            logger.error(f"âŒ Smart Shutdown ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            logger.warning("ğŸ”„ ê¸°ì¡´ shutdown ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ ì‹œë„")

            # ëŒ€ì²´ ì¢…ë£Œ ì‹œë„ (ê¸°ì¡´ ë°©ì‹)
            try:
                import subprocess
                result = subprocess.run([
                    'sudo', 'shutdown', '-h', '+1'
                ], check=False, capture_output=True, text=True)

                if result.returncode == 0:
                    logger.info("âœ… ëŒ€ì²´ ì¢…ë£Œ ëª…ë ¹ ì„±ê³µ")
                    return True
                else:
                    logger.error(f"âŒ ëŒ€ì²´ ì¢…ë£Œ ì‹¤íŒ¨: {result.stderr}")
                    return False
            except Exception as fallback_error:
                logger.error(f"ğŸ’¥ ëª¨ë“  ì¢…ë£Œ ë°©ì‹ ì‹¤íŒ¨: {fallback_error}")
                return False

    def _get_latest_technical_analysis(self) -> List[Dict]:
        """ì‹¤ì œ DBì—ì„œ ìµœì‹  ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ì‹œì¥ ê¸°íšŒ ì‹¤ì‹œê°„ íŒŒì•…)"""
        try:
            with get_db_connection_context() as conn:
                # ğŸ†• ì˜¤ëŠ˜ ë‚ ì§œì˜ ìµœì‹  ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ë§Œ ì¡°íšŒ (ê³¼ê±° ë°ì´í„° ë°˜ë³µ ë°œì†¡ ë°©ì§€)
                # GPT Analysisì™€ ë™ì¼í•œ ë‚ ì§œ í•„í„°ë§ ë¡œì§ ì ìš©

                # í†µí•© technical_analysis í…Œì´ë¸”ì—ì„œ LayeredScoring ë°ì´í„° ì¡°íšŒ
                query = """
                SELECT ticker, quality_score, quality_gates_passed, recommendation,
                       current_stage as stage, stage_confidence as confidence,
                       macro_score, structural_score
                FROM technical_analysis
                WHERE quality_score >= ?
                  AND recommendation IN ('STRONG_BUY', 'BUY', 'WATCH')
                  AND DATE(updated_at) = DATE('now', '+9 hours')
                  AND total_score IS NOT NULL
                ORDER BY quality_score DESC, stage_confidence DESC
                LIMIT 15
                """

                cursor = conn.execute(query, (self.config.min_quality_score,))
                results = cursor.fetchall()

                candidates = []
                for row in results:
                    ticker = row[0]

                    # ğŸ”¥ ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ (ì‹œì¥ ê¸°íšŒ ì¦‰ì‹œ íŒŒì•…)
                    try:
                        current_price = pyupbit.get_current_price(ticker)
                        if current_price is None:
                            current_price = 0
                    except:
                        current_price = 0

                    candidates.append({
                        'ticker': ticker,
                        'quality_score': row[1],
                        'gates_passed': row[2],  # quality_gates_passed (Boolean)
                        'recommendation': row[3],
                        'pattern_type': f"Stage {row[4]}" if row[4] else 'Stage 2',  # stage
                        'price': current_price,  # ğŸ”¥ ì‹¤ì‹œê°„ ê°€ê²© ì •ë³´
                        'confidence': row[5],  # confidence
                        'macro_score': row[6],  # macro_score
                        'structural_score': row[7]  # structural_score
                    })

                logger.info(f"ğŸ¯ ì‹¤ì œ DBì—ì„œ {len(candidates)}ê°œ ê¸°ìˆ ì  ë¶„ì„ ì¢…ëª© ì¡°íšŒ")
                return candidates

        except Exception as e:
            logger.error(f"âŒ ê¸°ìˆ ì  ë¶„ì„ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def _get_latest_gpt_analysis(self) -> List[Dict]:
        """ì‹¤ì œ DBì—ì„œ ìµœì‹  GPT ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (AI ìŠ¹ì¸ ì¢…ëª©)"""
        try:
            with get_db_connection_context() as conn:
                # ì˜¤ëŠ˜ ë‚ ì§œì˜ GPT ë§¤ìˆ˜ ì¶”ì²œ ì¢…ëª© ì¡°íšŒ (ì‹ ë¢°ë„ ë†’ì€ ìˆœ)
                today = datetime.now().strftime('%Y-%m-%d')

                query = """
                SELECT ticker, gpt_recommendation, gpt_confidence, gpt_reasoning,
                       vcp_detected, cup_handle_detected, api_cost_usd
                FROM gpt_analysis
                WHERE analysis_date = ?
                  AND gpt_recommendation = 'BUY'
                  AND gpt_confidence >= 70.0
                ORDER BY gpt_confidence DESC
                LIMIT 10
                """

                cursor = conn.execute(query, (today,))
                results = cursor.fetchall()

                candidates = []
                for row in results:
                    pattern = []
                    if row[4]:  # vcp_detected
                        pattern.append("VCP")
                    if row[5]:  # cup_handle_detected
                        pattern.append("Cup & Handle")

                    candidates.append({
                        'ticker': row[0],
                        'recommendation': row[1],
                        'confidence': row[2],
                        'pattern': ' + '.join(pattern) if pattern else 'GPT íŒ¨í„´',
                        'reasoning': row[3][:100] + '...' if len(row[3]) > 100 else row[3],  # ìš”ì•½
                        'risk_level': 'MODERATE',
                        'cost': row[6] if row[6] else 0.0
                    })

                logger.info(f"ğŸ¤– ì‹¤ì œ DBì—ì„œ {len(candidates)}ê°œ GPT ìŠ¹ì¸ ì¢…ëª© ì¡°íšŒ")
                return candidates

        except Exception as e:
            logger.error(f"âŒ GPT ë¶„ì„ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def _get_latest_kelly_results(self) -> Dict[str, float]:
        """ì‹¤ì œ DBì—ì„œ ìµœì‹  Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ê²°ê³¼ ì¡°íšŒ (ìµœì  í¬ì§€ì…˜)"""
        try:
            with get_db_connection_context() as conn:
                # ì˜¤ëŠ˜ ë‚ ì§œì˜ Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ê²°ê³¼ ì¡°íšŒ (í¬ì§€ì…˜ í¬ê¸° í° ìˆœ)
                today = datetime.now().strftime('%Y-%m-%d')

                query = """
                SELECT ticker, final_position_pct, detected_pattern, gpt_confidence
                FROM kelly_analysis
                WHERE analysis_date = ?
                  AND final_position_pct > 0
                ORDER BY final_position_pct DESC
                LIMIT 10
                """

                cursor = conn.execute(query, (today,))
                results = cursor.fetchall()

                kelly_results = {}
                for row in results:
                    kelly_results[row[0]] = row[1]  # ticker: position_pct

                logger.info(f"ğŸ§® ì‹¤ì œ DBì—ì„œ {len(kelly_results)}ê°œ Kelly ê²°ê³¼ ì¡°íšŒ")
                return kelly_results

        except Exception as e:
            logger.error(f"âŒ Kelly ë¶„ì„ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def _send_discovered_stocks_notification(self):
        """ì‹¤ì œ DB ê¸°ë°˜ ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ SNS ì•Œë¦¼ ì „ì†¡ (ì‹œì¥ ê¸°íšŒ ì‹¤ì‹œê°„ íŒŒì•…)"""
        if not self.sns_notifier:
            return

        try:
            logger.info("ğŸ“§ ì‹¤ì œ DB ê¸°ë°˜ ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ SNS ì•Œë¦¼ ì „ì†¡ ì¤‘...")

            # ğŸ¯ ì‹¤ì œ DBì—ì„œ ìµœì‹  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ì‹œì¥ ê¸°íšŒ ì‹¤ì‹œê°„ íŒŒì•…)
            technical_candidates = self._get_latest_technical_analysis()
            gpt_candidates = self._get_latest_gpt_analysis()
            kelly_results = self._get_latest_kelly_results()

            # ì‹¤í–‰ ID ìƒì„±
            execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')

            # ğŸ“Š ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì•Œë¦¼ ì „ì†¡ (ë¹ˆ ì•Œë¦¼ ë°©ì§€)
            if technical_candidates or gpt_candidates:
                # ë°œêµ´ ì¢…ëª© ì•Œë¦¼ ì „ì†¡
                success = self.sns_notifier.notify_discovered_stocks(
                    technical_candidates=technical_candidates,
                    gpt_candidates=gpt_candidates,
                    execution_id=execution_id
                )

                if success:
                    logger.info(f"âœ… ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ SNS ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ (ê¸°ìˆ ì : {len(technical_candidates)}, GPT: {len(gpt_candidates)})")
                else:
                    logger.warning("âš ï¸ ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ SNS ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")
            else:
                logger.info("ğŸ“­ ë°œêµ´ëœ ì¢…ëª©ì´ ì—†ì–´ SNS ì•Œë¦¼ì„ ìƒëµí•©ë‹ˆë‹¤")

            # ğŸ’° Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ê²°ê³¼ ì•Œë¦¼ (ë³„ë„)
            if kelly_results:
                kelly_success = self.sns_notifier.notify_kelly_position_sizing(
                    kelly_results=kelly_results,
                    execution_id=execution_id
                )

                if kelly_success:
                    logger.info(f"âœ… Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• SNS ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ ({len(kelly_results)}ê°œ ì¢…ëª©)")
                else:
                    logger.warning("âš ï¸ Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• SNS ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")

            # ğŸ“Š ì‹œì¥ ë¶„ì„ ì¢…í•© ìš”ì•½ ì•Œë¦¼ (ì‹¤ì œ ì‹œì¥ ë°ì´í„° í¬í•¨)
            market_summary = {
                # íŒŒì´í”„ë¼ì¸ í†µê³„
                'technical_count': len(technical_candidates),
                'gpt_count': len(gpt_candidates),
                'kelly_count': len(kelly_results),
                'total_cost': self.execution_stats.get('total_cost', 0.0),
                'phases_completed': len(self.execution_stats.get('phases_completed', [])),
                'errors_count': len(self.execution_stats.get('errors', []))
            }

            # ğŸ“ˆ ì‹¤ì œ ì‹œì¥ ë°ì´í„° ì¶”ê°€ (ì •ì ì„± ë¬¸ì œ í•´ê²°)
            if self.last_sentiment_result:
                # Fear & Greed Index ë°ì´í„°
                if self.last_sentiment_result.fear_greed_data:
                    market_summary['fear_greed_index'] = self.last_sentiment_result.fear_greed_data.value
                else:
                    market_summary['fear_greed_index'] = 50  # ê¸°ë³¸ê°’

                # BTC íŠ¸ë Œë“œ ë°ì´í„°
                if self.last_sentiment_result.btc_trend_data:
                    market_summary['btc_change_24h'] = self.last_sentiment_result.btc_trend_data.change_24h
                    market_summary['btc_trend'] = self._get_btc_trend_classification(self.last_sentiment_result.btc_trend_data.change_24h)
                else:
                    market_summary['btc_change_24h'] = 0.0
                    market_summary['btc_trend'] = 'SIDEWAYS'

                # ìµœì¢… ì‹œì¥ ê°ì • ë°ì´í„°
                market_summary['final_sentiment'] = self.last_sentiment_result.final_sentiment.value
                market_summary['trading_allowed'] = self.last_sentiment_result.trading_allowed
                market_summary['position_adjustment'] = self.last_sentiment_result.position_adjustment
                market_summary['total_score'] = self.last_sentiment_result.total_score
                market_summary['confidence'] = self.last_sentiment_result.confidence
                market_summary['reasoning'] = self.last_sentiment_result.reasoning
            else:
                # ê¸°ë³¸ê°’ (ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨ ì‹œ)
                market_summary['fear_greed_index'] = 50
                market_summary['btc_change_24h'] = 0.0
                market_summary['btc_trend'] = 'SIDEWAYS'
                market_summary['final_sentiment'] = 'NEUTRAL'
                market_summary['trading_allowed'] = True
                market_summary['position_adjustment'] = 1.0
                market_summary['total_score'] = 50.0
                market_summary['confidence'] = 0.5
                market_summary['reasoning'] = 'ì‹œì¥ ê°ì • ë¶„ì„ ë°ì´í„° ì—†ìŒ'

            # ğŸ“Š ì¡°ê±´ë¶€ ì‹œì¥ ë¶„ì„ ìš”ì•½ ì•Œë¦¼ (BEAR ì‹œì¥ì—ì„œë§Œ ë°œì†¡)
            current_sentiment = market_summary.get('final_sentiment', 'NEUTRAL')

            if current_sentiment == 'BEAR':
                logger.info("ğŸš¨ BEAR ì‹œì¥ ê°ì§€ - ì‹œì¥ ë¶„ì„ ìš”ì•½ ì•Œë¦¼ ë°œì†¡")
                summary_success = self.sns_notifier.notify_market_analysis_summary(
                    market_data=market_summary,
                    execution_id=execution_id
                )

                if summary_success:
                    logger.info("âœ… BEAR ì‹œì¥ ë¶„ì„ ìš”ì•½ SNS ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
                else:
                    logger.warning("âš ï¸ BEAR ì‹œì¥ ë¶„ì„ ìš”ì•½ SNS ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")
            else:
                logger.info(f"â„¹ï¸ {current_sentiment} ì‹œì¥ ìƒí™©ìœ¼ë¡œ ì‹œì¥ ë¶„ì„ ìš”ì•½ ì•Œë¦¼ ìƒëµ (BEAR ì‹œì¥ì—ì„œë§Œ ë°œì†¡)")

        except Exception as e:
            logger.error(f"âŒ SNS ì•Œë¦¼ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

    def _get_btc_trend_classification(self, change_24h: float) -> str:
        """BTC 24ì‹œê°„ ë³€ë™ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ë¥˜"""
        if change_24h > 5.0:
            return "BULLISH"
        elif change_24h < -5.0:
            return "BEARISH"
        else:
            return "SIDEWAYS"

    async def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            self.execution_stats['start_time'] = datetime.now()
            logger.info("ğŸš€ Makenaide ë¡œì»¬ í†µí•© íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            logger.info("="*60)

            # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if not self.initialize_components():
                error_msg = "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨"
                logger.error(f"âŒ {error_msg}")

                # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
                if SNS_AVAILABLE and hasattr(self, 'sns_notifier'):
                    try:
                        execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
                        error_details = f"{error_msg}\n\nì„¸ë¶€ ì˜¤ë¥˜: {', '.join(self.execution_stats.get('errors', ['ì´ˆê¸°í™” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜']))}"

                        # ì´ˆê¸°í™” ì‹¤íŒ¨ ìƒì„¸ ë¶„ë¥˜
                        errors = self.execution_stats.get('errors', [])
                        if any('memory' in str(err).lower() or 'ram' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.MEMORY_INSUFFICIENT.value
                        elif any('connection' in str(err).lower() or 'network' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.NETWORK_CONNECTION_FAILED.value
                        else:
                            sub_type = FailureSubType.SYSTEM_INITIALIZATION_FAILED.value

                        self.handle_failure_with_phase4(
                            failure_type=FailureType.INIT_FAILURE.value,
                            sub_type=sub_type,
                            error_message=error_details,
                            phase="ì´ˆê¸°í™”",
                            execution_id=execution_id,
                            metadata={
                                'component_errors': self.execution_stats.get('errors', []),
                                'available_memory': 'í™•ì¸í•„ìš”',
                                'instance_type': 't3.medium'
                            },
                            severity="CRITICAL"
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

                return False

            # 2. Phase 0: ì¢…ëª© ìŠ¤ìº”
            if not self.run_phase_0_scanner():
                error_msg = "Phase 0 ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨"
                logger.error(f"âŒ {error_msg}")

                # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
                if SNS_AVAILABLE:
                    try:
                        execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
                        error_details = f"{error_msg}\n\nì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº”ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API ì—°ê²° ìƒíƒœì™€ ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

                        # Phase 0 ì‹¤íŒ¨ ìƒì„¸ ë¶„ë¥˜
                        errors = self.execution_stats.get('errors', [])
                        if any('rate limit' in str(err).lower() or 'too many' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.RATE_LIMIT_EXCEEDED.value
                        elif any('timeout' in str(err).lower() or 'connection' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.NETWORK_TIMEOUT.value
                        elif any('auth' in str(err).lower() or 'forbidden' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.API_AUTHENTICATION_FAILED.value
                        else:
                            sub_type = FailureSubType.TICKER_SCAN_FAILED.value

                        self.handle_failure_with_phase4(
                            failure_type=FailureType.PHASE0_FAILURE.value,
                            sub_type=sub_type,
                            error_message=error_details,
                            phase="Phase 0",
                            execution_id=execution_id,
                            metadata={
                                'scanner_errors': self.execution_stats.get('errors', []),
                                'api_calls_made': 'í™•ì¸í•„ìš”',
                                'api_limit': '600',
                                'affected_endpoints': ['/v1/market/all']
                            },
                            severity="HIGH"
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

                return False

            # 3. Phase 1: ë°ì´í„° ìˆ˜ì§‘
            if not self.run_phase_1_data_collection():
                error_msg = "Phase 1 ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨"
                logger.error(f"âŒ {error_msg}")

                # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
                if SNS_AVAILABLE:
                    try:
                        execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
                        error_details = f"{error_msg}\n\nOHLCV ë°ì´í„° ìˆ˜ì§‘ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë””ìŠ¤í¬ ê³µê°„ê³¼ API í˜¸ì¶œ í•œë„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

                        # Phase 1 ì‹¤íŒ¨ ìƒì„¸ ë¶„ë¥˜
                        errors = self.execution_stats.get('errors', [])
                        if any('disk' in str(err).lower() or 'space' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.DISK_SPACE_INSUFFICIENT.value
                        elif any('sqlite' in str(err).lower() or 'database' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.SQLITE_WRITE_FAILED.value
                        elif any('technical' in str(err).lower() or 'indicator' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.TECHNICAL_INDICATOR_FAILED.value
                        elif any('rate limit' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.RATE_LIMIT_EXCEEDED.value
                        else:
                            sub_type = FailureSubType.DATA_COLLECTION_FAILED.value

                        self.handle_failure_with_phase4(
                            failure_type=FailureType.PHASE1_FAILURE.value,
                            sub_type=sub_type,
                            error_message=error_details,
                            phase="Phase 1",
                            execution_id=execution_id,
                            metadata={
                                'data_collection_errors': self.execution_stats.get('errors', []),
                                'database_file': 'makenaide_local.db',
                                'disk_space': 'í™•ì¸í•„ìš”',
                                'file_permissions': 'í™•ì¸í•„ìš”'
                            },
                            severity="HIGH"
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

                return False

            # 4. Phase 2: ê¸°ìˆ ì  í•„í„°ë§
            candidates = await self.run_phase_2_technical_filter()

            # 5. Phase 3: GPT ë¶„ì„ (ì„ íƒì )
            final_candidates = self.run_phase_3_gpt_analysis(candidates)

            # 6. Kelly í¬ì§€ì…˜ ì‚¬ì´ì§•
            position_sizes = self.run_kelly_calculation(final_candidates)

            # 7. ì‹œì¥ ê°ì • ë¶„ì„
            _, can_trade, position_adjustment = self.run_market_sentiment_analysis()

            # ğŸ“§ SNS ì•Œë¦¼: ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì „ì†¡
            self._send_discovered_stocks_notification()

            # 8. ê±°ë˜ ì‹¤í–‰ (ì¡°ê±´ ì¶©ì¡± ì‹œ)
            if can_trade and position_sizes:
                self.execute_trades(position_sizes, position_adjustment)
            elif not can_trade:
                logger.info("ğŸš« ì‹œì¥ ì¡°ê±´ìœ¼ë¡œ ì¸í•œ ê±°ë˜ ì¤‘ë‹¨")
            else:
                logger.info("ğŸ“­ ê±°ë˜í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤")

            # 9. í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬
            self.run_portfolio_management()

            # 10. ì‹¤í–‰ ê²°ê³¼ ë³´ê³ ì„œ
            self.generate_execution_report()

            logger.info("ğŸ Makenaide ë¡œì»¬ í†µí•© íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            return True

        except Exception as e:
            error_msg = f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}"
            logger.error(f"âŒ {error_msg}")
            self.execution_stats['errors'].append(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")

            # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
            if SNS_AVAILABLE:
                try:
                    execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
                    error_details = f"{error_msg}\n\nì˜ˆì™¸ íƒ€ì…: {type(e).__name__}\nìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ë¥¼ ë¡œê·¸ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."

                    # ì˜ˆì™¸ íƒ€ì…ë³„ ìƒì„¸ ë¶„ë¥˜
                    exception_name = type(e).__name__
                    if 'Memory' in exception_name or 'OutOfMemory' in exception_name:
                        sub_type = FailureSubType.MEMORY_INSUFFICIENT.value
                    elif 'Network' in exception_name or 'Connection' in exception_name or 'Timeout' in exception_name:
                        sub_type = FailureSubType.NETWORK_CONNECTION_FAILED.value
                    elif 'Permission' in exception_name or 'Access' in exception_name:
                        sub_type = FailureSubType.SYSTEM_PERMISSION_DENIED.value
                    else:
                        sub_type = FailureSubType.UNEXPECTED_EXCEPTION.value

                    # Phase 3 ë³´ì•ˆ ì•Œë¦¼ìœ¼ë¡œ CRITICAL ë©”ì‹œì§€ ì „ì†¡
                    critical_notification = NotificationMessage(
                        level=NotificationLevel.CRITICAL,
                        category=NotificationCategory.SYSTEM,
                        title="ğŸš¨ ì¹˜ëª…ì  ì‹œìŠ¤í…œ ì˜¤ë¥˜",
                        message=error_details,
                        timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        execution_id=execution_id
                    )

                    # ë³´ì•ˆ ì•Œë¦¼ ì‹œìŠ¤í…œì„ í†µí•œ ì‘ê¸‰ ì²˜ë¦¬
                    send_secure_notification(critical_notification)

                    # ìƒì„¸ ì‹¤íŒ¨ ë¶„ë¥˜ë„ í•¨ê»˜ ì „ì†¡ (Phase 4 í†µí•©)
                    self.handle_failure_with_phase4(
                        failure_type=FailureType.CRITICAL_ERROR.value,
                        sub_type=sub_type,
                        error_message=error_details,
                        phase="ì „ì²´ íŒŒì´í”„ë¼ì¸",
                        execution_id=execution_id,
                        metadata={
                            'exception_type': exception_name,
                            'critical_error': True,
                            'all_errors': self.execution_stats.get('errors', []),
                            'emergency_response': True
                        },
                        severity="CRITICAL"
                    )
                except Exception as sns_error:
                    logger.error(f"âŒ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ë„ ì‹¤íŒ¨: {sns_error}")

            self.generate_execution_report()
            self.generate_phase4_daily_report()
            return False

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='Makenaide ë¡œì»¬ í†µí•© ê±°ë˜ ì‹œìŠ¤í…œ')
    parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ê±°ë˜ ì—†ì´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
    parser.add_argument('--no-gpt', action='store_true', help='GPT ë¶„ì„ ë¹„í™œì„±í™” (ë¹„ìš© ì ˆì•½)')
    parser.add_argument('--risk-level', choices=['conservative', 'moderate', 'aggressive'],
                       default='moderate', help='ë¦¬ìŠ¤í¬ ë ˆë²¨ ì„¤ì •')
    parser.add_argument('--max-gpt-budget', type=float, default=5.0,
                       help='ì¼ì¼ GPT ë¹„ìš© í•œë„ (USD)')

    args = parser.parse_args()

    # ì„¤ì • ìƒì„±
    risk_level_map = {
        'conservative': RiskLevel.CONSERVATIVE,
        'moderate': RiskLevel.MODERATE,
        'aggressive': RiskLevel.AGGRESSIVE
    }

    config = OrchestratorConfig(
        enable_gpt_analysis=not args.no_gpt,
        max_gpt_budget_daily=args.max_gpt_budget,
        risk_level=risk_level_map[args.risk_level],
        dry_run=args.dry_run
    )

    # ì‹¤í–‰ ëª¨ë“œ ì¶œë ¥
    logger.info("ğŸ¯ ì‹¤í–‰ ëª¨ë“œ ì„¤ì •")
    logger.info(f"   - GPT ë¶„ì„: {'í™œì„±í™”' if config.enable_gpt_analysis else 'ë¹„í™œì„±í™”'}")
    logger.info(f"   - ê±°ë˜ ì‹¤í–‰: {'DRY RUN' if config.dry_run else 'ì‹¤ì œ ê±°ë˜'}")
    logger.info(f"   - ë¦¬ìŠ¤í¬ ë ˆë²¨: {config.risk_level.value}")
    logger.info(f"   - GPT ì¼ì¼ ì˜ˆì‚°: ${config.max_gpt_budget_daily}")

    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤í–‰
    orchestrator = MakenaideLocalOrchestrator(config)
    success = await orchestrator.run_full_pipeline()

    # EC2 ìë™ ì¢…ë£Œ ì²˜ë¦¬ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
    auto_shutdown = os.getenv('EC2_AUTO_SHUTDOWN', 'false').lower() == 'true'

    if success:
        logger.info("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ")

        if auto_shutdown:
            logger.info("ğŸ”Œ EC2 Smart Shutdown ì‹œì‘")
            # smart_shutdown_ec2 ë©”ì„œë“œ ì‚¬ìš© (AWS CLI ê¸°ë°˜ ê°œì„ ëœ ì¢…ë£Œ)
            orchestrator.smart_shutdown_ec2("íŒŒì´í”„ë¼ì¸ ì„±ê³µ ì™„ë£Œ")
        else:
            # ì¼ë°˜ ì •ë¦¬ë§Œ ìˆ˜í–‰
            orchestrator.cleanup()

        sys.exit(0)
    else:
        logger.error("ğŸ’¥ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨")

        if auto_shutdown:
            logger.error("ğŸ”Œ EC2 Smart Shutdown ì‹œì‘ (ì‹¤íŒ¨ ì¼€ì´ìŠ¤)")
            # ì‹¤íŒ¨ ì‹œì—ë„ EC2 ì¢…ë£Œ (ë¹„ìš© ì ˆì•½)
            orchestrator.smart_shutdown_ec2("íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
        else:
            # ì¼ë°˜ ì •ë¦¬ë§Œ ìˆ˜í–‰
            orchestrator.cleanup()

        sys.exit(1)

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())