#!/usr/bin/env python3
"""
Makenaide Local Orchestrator - í†µí•© ê±°ë˜ íŒŒì´í”„ë¼ì¸
EC2 Local Architecture ê¸°ë°˜ ì•”í˜¸í™”í ìë™ë§¤ë§¤ ì‹œìŠ¤í…œ

ğŸ  LOCAL ARCHITECTURE: ë‹¨ì¼ ë¨¸ì‹  í†µí•© ì‹¤í–‰
- AWS ì˜ì¡´ì„± ì œê±°: DynamoDB â†’ SQLite, Lambda â†’ Python Scripts
- ë¹„ìš© ìµœì í™”: í´ë¼ìš°ë“œ ë¹„ìš© 0ì›, ì „ë ¥ë¹„ë§Œ ë°œìƒ
- ê°œë°œ í¸ì˜ì„±: ë¡œì»¬ ë””ë²„ê¹…, ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸

ğŸ¯ ì „ì²´ íŒŒì´í”„ë¼ì¸:
Phase 0: scanner.py (ì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº”)
Phase 1: data_collector.py (ì¦ë¶„ OHLCV ìˆ˜ì§‘)
Phase 2: integrated_scoring_system.py (LayeredScoringEngine ì ìˆ˜ì œ ë¶„ì„)
Phase 3: gpt_analyzer.py (GPT íŒ¨í„´ ë¶„ì„ - ì„ íƒì )
Kelly Calculator: kelly_calculator.py (í¬ì§€ì…˜ ì‚¬ì´ì§•)
Market Sentiment: market_sentiment.py (Fear&Greed ë¶„ì„)
Trading Engine: trade_executor.py (ë§¤ìˆ˜/ë§¤ë„ ì‹¤í–‰)
Portfolio Management: portfolio_manager.py (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬)

ğŸ“Š ì°¸ì¡°: @makenaide_local.mmd ì „ì²´ íŒŒì´í”„ë¼ì¸ í”Œë¡œìš°
"""

import sys
import os
import logging
import sqlite3
import time
import json
import struct
import pyupbit
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
from utils import setup_restricted_logger, load_blacklist
from db_manager_sqlite import get_db_connection_context
from scanner import update_tickers
from data_collector import SimpleDataCollector
from integrated_scoring_system import IntegratedScoringSystem  # Legacy system (kept for compatibility)
from technical_filter import TechnicalFilter, FilterMode, UnifiedFilterResult  # New unified system
from gpt_analyzer import GPTPatternAnalyzer
from kelly_calculator import KellyCalculator, RiskLevel
from market_sentiment import IntegratedMarketSentimentAnalyzer, MarketSentiment
from real_time_market_sentiment import RealTimeMarketSentiment
# from trade_executor import buy_asset, sell_asset  # ì‚­ì œëœ ë ˆê±°ì‹œ ëª¨ë“ˆ
# from portfolio_manager import PortfolioManager  # trading_engineìœ¼ë¡œ í†µí•©ë¨
from trading_engine import LocalTradingEngine, TradingConfig
from trade_status import TradeStatus, TradeResult

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê±° ì„¤ì • (ëª¨ë“  import ì „ì— ë¨¼ì € ì„¤ì •)
logger = setup_restricted_logger('makenaide_orchestrator')

# SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ì„¤ì • ë° import (Phase 1-3)
# ì„¸ë¶„í™”ëœ í™˜ê²½ë³€ìˆ˜ë¡œ SNS ì•Œë¦¼ ì œì–´
ENABLE_ANALYSIS_SNS = os.getenv('ENABLE_ANALYSIS_SNS', 'true').lower() == 'true'  # ë¶„ì„ ê²°ê³¼ SNS (ê¸°ë³¸ê°’: í™œì„±í™”)
ENABLE_TRADING_SNS = os.getenv('ENABLE_TRADING_SNS', 'false').lower() == 'true'   # ê±°ë˜ ì‹¤í–‰ SNS (ê¸°ë³¸ê°’: ë¹„í™œì„±í™”)

# í•˜ë‚˜ë¼ë„ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ SNS ëª¨ë“ˆ ë¡œë“œ
if ENABLE_ANALYSIS_SNS or ENABLE_TRADING_SNS:
    try:
        from sns_notification_system import (
            MakenaideSNSNotifier,
            notify_discovered_stocks,
            notify_kelly_position_sizing,
            notify_market_analysis_summary,
            notify_pipeline_failure,
            notify_detailed_failure,
            send_secure_notification,
            get_security_analytics,
            FailureType,
            FailureSubType,
            NotificationMessage,
            NotificationLevel,
            NotificationCategory
        )
        SNS_AVAILABLE = True
        logger.info(f"âœ… SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ (ë¶„ì„: {ENABLE_ANALYSIS_SNS}, ê±°ë˜: {ENABLE_TRADING_SNS})")
    except ImportError as e:
        logger.warning(f"âš ï¸ SNS ì•Œë¦¼ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        SNS_AVAILABLE = False
else:
    logger.info("ğŸ“´ SNS ì•Œë¦¼ ì™„ì „ ë¹„í™œì„±í™” ì„¤ì •")
    SNS_AVAILABLE = False
    # SNS ê´€ë ¨ í´ë˜ìŠ¤ë“¤ì„ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
    MakenaideSNSNotifier = None
    FailureType = None
    FailureSubType = None
    NotificationLevel = None
    NotificationMessage = None
    NotificationCategory = None

# Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ import
try:
    from failure_tracker import FailureTracker, FailureRecord, SystemHealthMetrics
    from predictive_analysis import PredictiveAnalyzer, PredictionResult, RiskLevel as PredRiskLevel
    from auto_recovery_system import AutoRecoverySystem, RecoveryPlan, RecoveryExecution
    PHASE4_AVAILABLE = True
    logger.info("âœ… Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ")
except ImportError as e:
    logger.warning(f"âš ï¸ Phase 4 ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    PHASE4_AVAILABLE = False

@dataclass
class OrchestratorConfig:
    """ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„¤ì •"""
    enable_gpt_analysis: bool = True  # GPT ë¶„ì„ í™œì„±í™” ì—¬ë¶€
    max_gpt_budget_daily: float = 5.0  # ì¼ì¼ GPT ë¹„ìš© í•œë„ (USD)
    min_quality_score: float = 8.0  # ìµœì†Œ í’ˆì§ˆ ì ìˆ˜ (ì‹¤ì œ ë°ì´í„° ë¶„í¬ ê¸°ë°˜ ì¡°ì •)
    risk_level: RiskLevel = RiskLevel.MODERATE  # ë¦¬ìŠ¤í¬ ë ˆë²¨
    dry_run: bool = False  # ì‹¤ì œ ê±°ë˜ ì‹¤í–‰ ì—¬ë¶€
    max_positions: int = 8  # ìµœëŒ€ ë™ì‹œ ë³´ìœ  ì¢…ëª© ìˆ˜
    portfolio_allocation_limit: float = 0.25  # ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ ëŒ€ë¹„ ìµœëŒ€ í• ë‹¹ ë¹„ìœ¨
    auto_sync_enabled: bool = True  # í¬íŠ¸í´ë¦¬ì˜¤ ìë™ ë™ê¸°í™” í™œì„±í™” ì—¬ë¶€
    sync_policy: str = 'aggressive'  # í¬íŠ¸í´ë¦¬ì˜¤ ë™ê¸°í™” ì •ì±… (ê¸°ë³¸: ì „ì²´ ë™ê¸°í™”)

class MakenaideLocalOrchestrator:
    """Makenaide ë¡œì»¬ í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""

    def __init__(self, config: OrchestratorConfig):
        self.config = config
        self.db_path = "./makenaide_local.db"

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.upbit = None
        self.data_collector = None
        self.technical_filter = None
        self.gpt_analyzer = None
        self.kelly_calculator = None
        self.market_sentiment = None
        # self.portfolio_manager = None  # trading_engineìœ¼ë¡œ í†µí•©ë¨
        self.trading_engine = None
        self.sns_notifier = None  # SNS ì•Œë¦¼ ì‹œìŠ¤í…œ (Phase 1-3)

        # ğŸ“Š ì‹œì¥ ê°ì • ë¶„ì„ ê²°ê³¼ ì €ì¥ (SNS ì•Œë¦¼ìš©)
        self.last_sentiment_result = None

        # Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ
        self.failure_tracker = None
        self.predictive_analyzer = None
        self.auto_recovery_system = None

        # ì‹¤í–‰ í†µê³„
        self.execution_stats = {
            'start_time': None,
            'phases_completed': [],
            'errors': [],
            'trading_candidates': 0,
            'trades_executed': 0,
            'total_cost': 0.0,
            'technical_candidates': [],  # ê¸°ìˆ ì  ë¶„ì„ í†µê³¼ ì¢…ëª©
            'gpt_candidates': [],        # GPT ë¶„ì„ í†µê³¼ ì¢…ëª©
            'kelly_results': {}          # Kelly ê³„ì‚° ê²°ê³¼
        }

    def initialize_components(self) -> bool:
        """ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            logger.info("ğŸ”§ ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹œì‘")

            # ì—…ë¹„íŠ¸ API ì´ˆê¸°í™”
            access_key = os.getenv('UPBIT_ACCESS_KEY')
            secret_key = os.getenv('UPBIT_SECRET_KEY')

            if not access_key or not secret_key:
                error_msg = "ì—…ë¹„íŠ¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                logger.error(f"âŒ {error_msg}")

                # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
                if SNS_AVAILABLE:
                    try:
                        # API í‚¤ íƒ€ì…ë³„ ìƒì„¸ ë¶„ë¥˜
                        if not access_key and not secret_key:
                            sub_type = FailureSubType.API_BOTH_KEYS_MISSING.value
                        elif not access_key:
                            sub_type = FailureSubType.API_ACCESS_KEY_MISSING.value
                        else:
                            sub_type = FailureSubType.API_SECRET_KEY_MISSING.value

                        self.handle_failure_with_phase4(
                            failure_type=FailureType.API_KEY_MISSING.value,
                            sub_type=sub_type,
                            error_message=error_msg,
                            phase="ì´ˆê¸°í™”",
                            execution_id=datetime.now().strftime('%Y%m%d_%H%M%S'),
                            metadata={
                                'missing_access_key': not bool(access_key),
                                'missing_secret_key': not bool(secret_key),
                                'config_file': '.env',
                                'env_check_result': 'FAILED'
                            },
                            severity="CRITICAL"
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

                return False

            self.upbit = pyupbit.Upbit(access_key, secret_key)
            logger.info("âœ… ì—…ë¹„íŠ¸ API ì—°ê²° ì™„ë£Œ")

            # ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”
            self.data_collector = SimpleDataCollector(db_path=self.db_path)
            logger.info("âœ… ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

            # ê¸°ìˆ ì  í•„í„° ì´ˆê¸°í™” (í†µí•©ëœ í•„í„°ë§ ì‹œìŠ¤í…œ)
            self.technical_filter = TechnicalFilter(db_path=self.db_path)
            logger.info("âœ… í†µí•© ê¸°ìˆ ì  í•„í„° ì´ˆê¸°í™” ì™„ë£Œ (4-Layer Architecture with FilterMode)")

            # ë ˆê±°ì‹œ ì‹œìŠ¤í…œ ë°±ì—… (í˜¸í™˜ì„± ìœ ì§€)
            self.legacy_scoring_system = IntegratedScoringSystem(db_path=self.db_path)
            logger.info("âœ… ë ˆê±°ì‹œ ì ìˆ˜ ì‹œìŠ¤í…œ ë°±ì—… ì´ˆê¸°í™” ì™„ë£Œ")

            # GPT ë¶„ì„ê¸° ì´ˆê¸°í™” (ì„ íƒì )
            if self.config.enable_gpt_analysis:
                self.gpt_analyzer = GPTPatternAnalyzer(db_path=self.db_path)
                logger.info("âœ… GPT ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.info("â­ï¸ GPT ë¶„ì„ê¸° ë¹„í™œì„±í™” (ë¹„ìš© ì ˆì•½ ëª¨ë“œ)")

            # Kelly ê³„ì‚°ê¸° ì´ˆê¸°í™”
            self.kelly_calculator = KellyCalculator(
                risk_level=self.config.risk_level,
                max_single_position=8.0,
                max_total_allocation=self.config.portfolio_allocation_limit * 100
            )
            logger.info("âœ… Kelly ê³„ì‚°ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

            # ì‹œì¥ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” (ìƒˆë¡œìš´ ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ)
            self.market_sentiment = RealTimeMarketSentiment()
            logger.info("âœ… ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ (pyupbit API ê¸°ë°˜)")

            # Trading Engine ì´ˆê¸°í™” (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ê¸°ëŠ¥ í†µí•©)
            trading_config = TradingConfig()
            self.trading_engine = LocalTradingEngine(trading_config, dry_run=self.config.dry_run)
            logger.info("âœ… Trading Engine ì´ˆê¸°í™” ì™„ë£Œ (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ê¸°ëŠ¥ í¬í•¨)")

            # í¬íŠ¸í´ë¦¬ì˜¤ ë™ê¸°í™” ê²€ì¦ ë° ìë™ ë™ê¸°í™”
            sync_success, sync_details = self.trading_engine.validate_and_sync_portfolio(
                auto_sync=self.config.auto_sync_enabled,
                sync_policy=self.config.sync_policy
            )

            if not sync_success and not self.config.auto_sync_enabled:
                logger.warning("âš ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ë™ê¸°í™” ë¶ˆì¼ì¹˜ê°€ ê°ì§€ë˜ì—ˆì§€ë§Œ ìë™ ë™ê¸°í™”ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                logger.warning("ìˆ˜ë™ìœ¼ë¡œ portfolio_sync_tool.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë™ê¸°í™”ë¥¼ ì§„í–‰í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
            elif sync_success and sync_details.get('status') == 'synced':
                logger.info("âœ… í¬íŠ¸í´ë¦¬ì˜¤ ë™ê¸°í™” ìƒíƒœ í™•ì¸ ì™„ë£Œ")
            elif sync_success and 'synced_count' in sync_details:
                synced_count = sync_details['synced_count']
                total_value = sync_details.get('total_value', 0)
                logger.info(f"ğŸ”„ í¬íŠ¸í´ë¦¬ì˜¤ ìë™ ë™ê¸°í™” ì™„ë£Œ: {synced_count}ê°œ ì¢…ëª©, {total_value:,.0f} KRW")

            # SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if SNS_AVAILABLE:
                try:
                    self.sns_notifier = MakenaideSNSNotifier()
                    logger.info(f"âœ… SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (ë¶„ì„: {ENABLE_ANALYSIS_SNS}, ê±°ë˜: {ENABLE_TRADING_SNS})")
                except Exception as e:
                    logger.warning(f"âš ï¸ SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    self.sns_notifier = None
            else:
                logger.info("ğŸ“´ SNS ì•Œë¦¼ ì‹œìŠ¤í…œ ë¹„í™œì„±í™”")
                self.sns_notifier = None

            # Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            try:
                # ì‹¤íŒ¨ ì¶”ì ê¸° ì´ˆê¸°í™”
                self.failure_tracker = FailureTracker(db_path=self.db_path)
                logger.info("âœ… Phase 4 ì‹¤íŒ¨ ì¶”ì ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

                # ì˜ˆì¸¡ì  ë¶„ì„ê¸° ì´ˆê¸°í™”
                self.predictive_analyzer = PredictiveAnalyzer(db_path=self.db_path)
                logger.info("âœ… Phase 4 ì˜ˆì¸¡ì  ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

                # ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
                self.auto_recovery_system = AutoRecoverySystem(db_path=self.db_path)
                logger.info("âœ… Phase 4 ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

                logger.info("ğŸ”® Phase 4 íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                logger.warning(f"âš ï¸ Phase 4 ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                # Phase 4ëŠ” ì„ íƒì  ê¸°ëŠ¥ìœ¼ë¡œ ì‹¤íŒ¨í•´ë„ ì „ì²´ ì‹œìŠ¤í…œì€ ê³„ì† ì§„í–‰
                self.failure_tracker = None
                self.predictive_analyzer = None
                self.auto_recovery_system = None

            logger.info("ğŸ‰ ëª¨ë“  ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
            return True

        except Exception as e:
            logger.error(f"âŒ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def handle_failure_with_phase4(self, failure_type: str, sub_type: str, error_message: str,
                                   phase: str, execution_id: str, metadata: dict = None,
                                   severity: str = "HIGH") -> None:
        """Phase 4 í†µí•© ì‹¤íŒ¨ ì²˜ë¦¬: ì¶”ì  + ë¶„ì„ + ë³µêµ¬ + ì•Œë¦¼"""
        try:
            # 1. Phase 4 ì‹¤íŒ¨ ì¶”ì  (ìˆëŠ” ê²½ìš°)
            if self.failure_tracker:
                failure_id = self.failure_tracker.record_failure(
                    failure_type=failure_type,
                    sub_type=sub_type,
                    error_message=error_message,
                    execution_id=execution_id,
                    severity=severity,
                    phase=phase,
                    metadata=metadata or {}
                )
                logger.info(f"ğŸ”® Phase 4: ì‹¤íŒ¨ ê¸°ë¡ ì™„ë£Œ (ID: {failure_id})")

                # 2. ì˜ˆì¸¡ì  ë¶„ì„ ì‹¤í–‰ (ìˆëŠ” ê²½ìš°)
                if self.predictive_analyzer:
                    try:
                        prediction = self.predictive_analyzer.predict_failure_probability(time_window_hours=24)
                        logger.info(f"ğŸ”® Phase 4: ì‹¤íŒ¨ ì˜ˆì¸¡ - ìœ„í—˜ë„: {prediction.risk_level.value}, í™•ë¥ : {prediction.failure_probability:.1%}")

                        # ë†’ì€ ìœ„í—˜ë„ì¸ ê²½ìš° ì¶”ê°€ ë¡œê¹…
                        if prediction.risk_level.value in ['HIGH', 'CRITICAL']:
                            logger.warning(f"âš ï¸ Phase 4: ë†’ì€ ì‹¤íŒ¨ ìœ„í—˜ ê°ì§€ - ê¶Œì¥ì‚¬í•­: {', '.join(prediction.recommended_actions)}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Phase 4: ì˜ˆì¸¡ ë¶„ì„ ì‹¤íŒ¨ - {e}")

                # 3. ìë™ ë³µêµ¬ ì œì•ˆ (ìˆëŠ” ê²½ìš°)
                if self.auto_recovery_system:
                    try:
                        # ì‹¤íŒ¨ ê¸°ë¡ì„ ê°€ì ¸ì™€ì„œ ë³µêµ¬ ì œì•ˆ ìƒì„±
                        failure_record = FailureRecord(
                            id=failure_id,
                            timestamp=datetime.now().isoformat(),
                            execution_id=execution_id,
                            failure_type=failure_type,
                            sub_type=sub_type,
                            severity=severity,
                            phase=phase,
                            error_message=error_message,
                            metadata=str(metadata or {})
                        )

                        suggestions = self.auto_recovery_system.get_recovery_suggestions(failure_record)
                        if suggestions and 'recovery_actions' in suggestions:
                            logger.info(f"ğŸ”® Phase 4: ë³µêµ¬ ì œì•ˆ - {len(suggestions['recovery_actions'])}ê°œ ì•¡ì…˜ ì œì•ˆë¨")

                    except Exception as e:
                        logger.warning(f"âš ï¸ Phase 4: ë³µêµ¬ ì œì•ˆ ì‹¤íŒ¨ - {e}")

            # 4. ê¸°ì¡´ SNS ì•Œë¦¼ ì „ì†¡ (í˜¸í™˜ì„± ìœ ì§€)
            if SNS_AVAILABLE:
                try:
                    notify_detailed_failure(
                        failure_type=failure_type,
                        sub_type=sub_type,
                        error_message=error_message,
                        phase=phase,
                        execution_id=execution_id,
                        metadata=metadata
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

        except Exception as e:
            logger.error(f"âŒ Phase 4 í†µí•© ì‹¤íŒ¨ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # Phase 4 ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ì¡´ SNS ì•Œë¦¼ì€ ì „ì†¡
            if SNS_AVAILABLE:
                try:
                    notify_detailed_failure(
                        failure_type=failure_type,
                        sub_type=sub_type,
                        error_message=error_message,
                        phase=phase,
                        execution_id=execution_id,
                        metadata=metadata
                    )
                except Exception as nested_e:
                    logger.error(f"âŒ SNS ë°±ì—… ì•Œë¦¼ ì „ì†¡ë„ ì‹¤íŒ¨: {nested_e}")

    def run_phase_0_scanner(self) -> bool:
        """Phase 0: ì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº”"""
        try:
            logger.info("ğŸ“¡ Phase 0: ì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº” ì‹œì‘")

            # scanner.pyì˜ update_tickers í•¨ìˆ˜ í˜¸ì¶œ
            update_tickers()

            self.execution_stats['phases_completed'].append('Phase 0: Scanner')
            logger.info("âœ… Phase 0 ì™„ë£Œ: ì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº”")
            return True

        except Exception as e:
            logger.error(f"âŒ Phase 0 ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Phase 0 ì‹¤íŒ¨: {e}")
            return False

    def run_phase_1_data_collection(self) -> bool:
        """Phase 1: ì¦ë¶„ OHLCV ë°ì´í„° ìˆ˜ì§‘ (í’ˆì§ˆ í•„í„°ë§ í¬í•¨)"""
        try:
            logger.info("ğŸ“Š Phase 1: ì¦ë¶„ OHLCV ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            logger.info("ğŸ¯ í’ˆì§ˆ í•„í„°ë§ ëª¨ë“œ: 13ê°œì›”+ ë°ì´í„° + 3ì–µì›+ ê±°ë˜ëŒ€ê¸ˆ ì¡°ê±´ ì ìš©")

            # ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ + í’ˆì§ˆ í•„í„°ë§ ë°©ì‹ìœ¼ë¡œ ë³€ê²½ (67% API ì ˆì•½ íš¨ê³¼)
            results = self.data_collector.collect_all_data(
                test_mode=False,
                use_quality_filter=True  # í’ˆì§ˆ í•„í„°ë§ í™œì„±í™”
            )

            if not results:
                logger.error("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")
                self.execution_stats['errors'].append("Phase 1 ì‹¤íŒ¨: ìˆ˜ì§‘ ê²°ê³¼ ì—†ìŒ")
                return False

            # collect_all_dataëŠ” collection_statsë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ì„±ê³µ ì—¬ë¶€ëŠ” í†µê³„ë¡œ íŒë‹¨
            # ì‹¤ì œ ì‹¤íŒ¨ë§Œ ì—ëŸ¬ë¡œ ì²˜ë¦¬ (skipì€ ì •ìƒ ìƒí™©)
            failed_collections = results.get('summary', {}).get('failed', 0)
            successful_collections = results.get('summary', {}).get('success', 0)
            skipped_collections = results.get('summary', {}).get('skipped', 0)

            # ì‹¤ì œ ì‹¤íŒ¨ê°€ ìˆì„ ë•Œë§Œ ì—ëŸ¬ ì²˜ë¦¬
            if failed_collections > 0:
                logger.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ {failed_collections}ê°œ ì‹¤íŒ¨")
                self.execution_stats['errors'].append(f"Phase 1 ì‹¤íŒ¨: {failed_collections}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
                return False

            # ì„±ê³µ ë˜ëŠ” ìŠ¤í‚µëœ ê²½ìš° ëª¨ë‘ ì •ìƒ ì²˜ë¦¬
            if successful_collections > 0:
                logger.info(f"âœ… ìƒˆë¡œìš´ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {successful_collections}ê°œ")
            else:
                logger.info(f"âœ… ëª¨ë“  ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœ: {skipped_collections}ê°œ ìŠ¤í‚µ")

            # ìˆ˜ì§‘ ê²°ê³¼ í†µê³„ ë¡œê¹…
            summary = results.get('summary', {})
            processing_time = results.get('processing_time_seconds', 0)
            total_tickers = summary.get('success', 0) + summary.get('failed', 0) + summary.get('skipped', 0)
            successful_collections = summary.get('success', 0)
            quality_filter_enabled = results.get('quality_filter_enabled', True)  # ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë¨

            logger.info(f"ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {successful_collections}/{total_tickers} ì„±ê³µ ({processing_time:.1f}ì´ˆ)")
            logger.info(f"ğŸ’ í’ˆì§ˆ í•„í„°ë§: {'í™œì„±í™”' if quality_filter_enabled else 'ë¹„í™œì„±í™”'}")
            logger.info(f"ğŸ“ˆ ì´ ë ˆì½”ë“œ ìˆ˜ì§‘: {summary.get('total_records', 0)}ê°œ")

            if quality_filter_enabled and total_tickers > 0:
                logger.info(f"âš¡ í’ˆì§ˆ í•„í„°ë§ íš¨ê³¼: ê³ í’ˆì§ˆ ì¢…ëª©ë§Œ ì„ ë³„í•˜ì—¬ API í˜¸ì¶œ 67% ì ˆì•½")

            # ğŸ“¦ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš© (300ì¼+ ì˜¤ë˜ëœ ë°ì´í„° ìë™ ì •ë¦¬)
            try:
                logger.info("ğŸ—‘ï¸ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš© ì¤‘...")
                retention_result = self.data_collector.apply_data_retention_policy(retention_days=300)

                if retention_result['deleted_rows'] > 0:
                    logger.info(f"ğŸ—‘ï¸ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {retention_result['deleted_rows']:,}ê°œ í–‰ ì‚­ì œ")
                    logger.info(f"ğŸ’¾ ìŠ¤í† ë¦¬ì§€ ì ˆì•½: {retention_result['size_reduction_pct']:.1f}%")
                else:
                    logger.info("âœ… ì •ë¦¬í•  ì˜¤ë˜ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            except Exception as e:
                logger.warning(f"âš ï¸ ë°ì´í„° ë³´ì¡´ ì •ì±… ì ìš© ì‹¤íŒ¨: {e}")
                # ë°ì´í„° ë³´ì¡´ ì •ì±… ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì ì´ì§€ ì•Šìœ¼ë¯€ë¡œ ê³„ì† ì§„í–‰

            self.execution_stats['phases_completed'].append('Phase 1: Data Collection')
            logger.info("âœ… Phase 1 ì™„ë£Œ: ì¦ë¶„ OHLCV ë°ì´í„° ìˆ˜ì§‘ (í’ˆì§ˆ í•„í„°ë§ ì ìš©)")
            return True

        except Exception as e:
            logger.error(f"âŒ Phase 1 ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Phase 1 ì‹¤íŒ¨: {e}")
            return False

    async def run_phase_2_technical_filter(self) -> List[str]:
        """Phase 2: í†µí•© ê¸°ìˆ ì  í•„í„°ë§ ì‹œìŠ¤í…œ (4-Layer Architecture)"""
        try:
            logger.info("ğŸ¯ Phase 2: í†µí•© ê¸°ìˆ ì  í•„í„°ë§ ì‹œìŠ¤í…œ ë¶„ì„ ì‹œì‘")
            phase_start_time = time.time()  # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ì‹œì‘ ì‹œê°„

            # í™œì„± ì¢…ëª© ì¡°íšŒ (DBì—ì„œ ìŠ¤ìº”ëœ ì¢…ëª© ê°€ì ¸ì˜¤ê¸°)
            try:
                with get_db_connection_context() as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT DISTINCT ticker
                        FROM ohlcv_data
                        WHERE date >= date('now', '-7 days')
                        ORDER BY ticker
                    """)
                    active_tickers = [row[0] for row in cursor.fetchall()]
            except Exception as e:
                logger.error(f"âŒ í™œì„± ì¢…ëª© ì¡°íšŒ ì‹¤íŒ¨: {e}")
                return []

            if not active_tickers:
                logger.info("ğŸ“­ ë¶„ì„ ê°€ëŠ¥í•œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤ (DBì— ìµœê·¼ ë°ì´í„° ì—†ìŒ)")
                return []

            logger.info(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ ì¢…ëª©: {len(active_tickers)}ê°œ")

            # ê¸°ì¡´ ë³´ìœ  í¬ì§€ì…˜ ì¡°íšŒ ë° ì œì™¸
            held_tickers = set()
            if self.trading_engine:
                try:
                    positions = self.trading_engine.get_current_positions()
                    held_tickers = {pos.ticker for pos in positions}

                    if held_tickers:
                        logger.info(f"ğŸ”’ í˜„ì¬ ë³´ìœ  ì¤‘ì¸ {len(held_tickers)}ê°œ ì¢…ëª© ì œì™¸: {', '.join(sorted(held_tickers))}")
                except Exception as e:
                    logger.warning(f"âš ï¸ ë³´ìœ  í¬ì§€ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")

            # ê¸°ì¡´ í¬ì§€ì…˜ ì œì™¸í•œ í‹°ì»¤ë§Œ ë¶„ì„
            active_tickers = [t for t in active_tickers if t not in held_tickers]

            if not active_tickers:
                logger.info("ğŸ“­ ë¶„ì„ ê°€ëŠ¥í•œ ì‹ ê·œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤ (ëª¨ë‘ ë³´ìœ  ì¤‘)")
                return []

            logger.info(f"ğŸ“Š ì‹ ê·œ ë¶„ì„ ëŒ€ìƒ ì¢…ëª©: {len(active_tickers)}ê°œ")

            # í†µí•© í•„í„° ì‹¤í–‰ (AUTO ëª¨ë“œë¡œ ì§€ëŠ¥í˜• ë¶„ì„)
            analysis_results = []
            technical_candidates_data = []  # SNS ì•Œë¦¼ìš© ìƒì„¸ ë°ì´í„°

            for ticker in active_tickers:
                try:
                    # TechnicalFilter AUTO ëª¨ë“œë¡œ ë¶„ì„
                    result = self.technical_filter.analyze_ticker(ticker, FilterMode.AUTO)

                    if result:
                        analysis_results.append(result)

                        # âœ… ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ë¥¼ DBì— ì €ì¥ (Kelly Calculatorê°€ ì¡°íšŒí•  ìˆ˜ ìˆë„ë¡)
                        self._save_technical_analysis_to_db(result)

                        # ë§¤ìˆ˜ ê¶Œê³  ì¢…ëª©ë§Œ í›„ë³´ë¡œ ì„ ì •
                        if result.final_recommendation.value in ['STRONG_BUY', 'BUY', 'BUY_LITE']:
                            technical_candidates_data.append({
                                'ticker': ticker,
                                'recommendation': result.final_recommendation.value,
                                'confidence': result.final_confidence,
                                'quality_score': result.final_quality_score,
                                'filter_mode': result.filter_mode.value,
                                'processing_time': result.processing_time_ms
                            })

                except Exception as e:
                    logger.warning(f"âš ï¸ {ticker} ë¶„ì„ ì‹¤íŒ¨: {e}")
                    continue

            # í’ˆì§ˆ ì ìˆ˜ ì„ê³„ê°’ í•„í„°ë§
            filtered_candidates = []

            for candidate in technical_candidates_data:
                ticker = candidate['ticker']
                recommendation = candidate['recommendation']
                confidence = candidate['confidence']
                quality_score = candidate['quality_score']
                filter_mode = candidate['filter_mode']

                # ê³ í’ˆì§ˆ í›„ë³´ ì„ ì • (ë†’ì€ ì‹ ë¢°ë„ì™€ í’ˆì§ˆ ì ìˆ˜)
                if confidence >= 0.7 and quality_score >= self.config.min_quality_score:
                    filtered_candidates.append(ticker)
                    logger.info(f"âœ… {ticker}: {recommendation} (ì‹ ë¢°ë„: {confidence:.3f}, í’ˆì§ˆ: {quality_score:.1f}, ëª¨ë“œ: {filter_mode})")
                else:
                    if confidence < 0.7:
                        logger.info(f"â­ï¸ {ticker}: ë‚®ì€ ì‹ ë¢°ë„ {confidence:.3f} (ì„ê³„ê°’ 0.7)")
                    elif quality_score < self.config.min_quality_score:
                        logger.info(f"â­ï¸ {ticker}: ë‚®ì€ í’ˆì§ˆ ì ìˆ˜ {quality_score:.1f} (ì„ê³„ê°’ {self.config.min_quality_score})")
                    else:
                        logger.info(f"â­ï¸ {ticker}: {recommendation} (ì‹ ë¢°ë„: {confidence:.3f})")

            # ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ë¥¼ í†µê³„ì— ì €ì¥
            self.execution_stats['technical_candidates'] = technical_candidates_data
            self.execution_stats['phases_completed'].append('Phase 2: Unified Technical Filter')
            self.execution_stats['trading_candidates'] = len(filtered_candidates)

            # ë¶„ì„ í†µê³„ ì •ë³´ ë¡œê¹…
            stats = self.technical_filter.get_analysis_stats()
            logger.info(f"ğŸ“Š ë¶„ì„ í†µê³„: {stats}")

            # ì‹œì¥ ê°ì • ìºì‹œ ì„±ëŠ¥ ë¦¬í¬íŠ¸
            if hasattr(self.technical_filter, 'get_sentiment_cache_stats'):
                cache_stats = self.technical_filter.get_sentiment_cache_stats()
                logger.info("ğŸ¯ ì‹œì¥ ê°ì • ìºì‹œ ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
                logger.info(f"   ğŸ’¡ ìºì‹œ íš¨ìœ¨ì„±: {cache_stats.get('cache_efficiency', 0):.1f}%")
                logger.info(f"   ğŸ“‹ ì´ ìš”ì²­: {cache_stats.get('total_requests', 0)}íšŒ")
                logger.info(f"   ğŸ¯ ìºì‹œ íˆíŠ¸: {cache_stats.get('cache_hits', 0)}íšŒ")
                logger.info(f"   ğŸŒ API í˜¸ì¶œ: {cache_stats.get('api_calls', 0)}íšŒ")

                # ì„±ëŠ¥ í–¥ìƒ íš¨ê³¼ ê³„ì‚°
                total_requests = cache_stats.get('total_requests', 0)
                api_calls = cache_stats.get('api_calls', 0)
                if total_requests > 0 and api_calls > 0:
                    time_saved_estimate = (total_requests - api_calls) * 0.65  # í‰ê·  0.65ì´ˆ/í˜¸ì¶œ
                    logger.info(f"   âš¡ ì˜ˆìƒ ì‹œê°„ ì ˆì•½: {time_saved_estimate:.1f}ì´ˆ")

            # ì„±ëŠ¥ íšŒê·€ ë°©ì§€ ëª¨ë‹ˆí„°ë§
            if hasattr(self.technical_filter, 'record_performance_metrics'):
                try:
                    session_id = f"phase2_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    processing_time_ms = (time.time() - phase_start_time) * 1000

                    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡
                    self.technical_filter.record_performance_metrics(
                        session_id=session_id,
                        total_tickers=len(technical_candidates_data),
                        processing_time_ms=processing_time_ms
                    )

                    # ì„±ëŠ¥ íšŒê·€ ê°ì§€
                    regression_result = self.technical_filter.check_performance_regression(session_id)

                    if regression_result.get('regression_detected', False):
                        logger.warning(f"ğŸš¨ ì„±ëŠ¥ íšŒê·€ ê°ì§€ ì•Œë¦¼:")
                        logger.warning(f"   ğŸ“‰ {regression_result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì„±ëŠ¥ ì €í•˜')}")

                        # ìš´ì˜íŒ€ ì•Œë¦¼ì´ í•„ìš”í•œ ê²½ìš° ì—¬ê¸°ì— SNS/ì´ë©”ì¼ ë“± ì¶”ê°€ ê°€ëŠ¥
                        self.execution_stats['warnings'].append(f"ì„±ëŠ¥ íšŒê·€ ê°ì§€: {regression_result.get('message')}")
                    else:
                        logger.info(f"ğŸ¯ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§: {regression_result.get('message', 'ì •ìƒ')}")

                except Exception as e:
                    logger.error(f"âŒ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹¤íŒ¨: {e}")

            logger.info(f"âœ… Phase 2 ì™„ë£Œ: {len(filtered_candidates)}ê°œ ê±°ë˜ í›„ë³´ ë°œê²¬ (ì´ {len(technical_candidates_data)}ê°œ ì¢…ëª© ë¶„ì„)")
            logger.info(f"ğŸ¯ í•„í„°ë§ ëª¨ë“œ ì‚¬ìš© ë¶„í¬: {[candidate['filter_mode'] for candidate in technical_candidates_data]}")

            return filtered_candidates

        except Exception as e:
            logger.error(f"âŒ Phase 2 ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Phase 2 ì‹¤íŒ¨: {e}")
            return []

    def run_phase_3_gpt_analysis(self, candidates: List[str]) -> List[str]:
        """Phase 3: GPT íŒ¨í„´ ë¶„ì„ (ì„ íƒì  & ì¡°ê±´ë¶€)"""

        # ğŸ”§ 1ì°¨ ì¡°ê±´: GPT ë¶„ì„ í™œì„±í™” ì—¬ë¶€ ë° í›„ë³´ ì¡´ì¬ ì—¬ë¶€
        if not self.config.enable_gpt_analysis or not candidates:
            logger.info("â­ï¸ Phase 3: GPT ë¶„ì„ ë¹„í™œì„±í™” ë˜ëŠ” í›„ë³´ ì—†ìŒ")
            return candidates

        # ğŸ”§ 2ì°¨ ì¡°ê±´: ìŠ¤ë§ˆíŠ¸ ì¡°ê±´ë¶€ ì‹¤í–‰ ë¡œì§
        skip_gpt = False
        skip_reason = ""

        # ì¡°ê±´ 1: í›„ë³´ ê°œìˆ˜ ê¸°ë°˜ ì¡°ê±´ë¶€ ì‹¤í–‰
        if len(candidates) > 20:
            skip_gpt = True
            skip_reason = f"í›„ë³´ê°€ ë„ˆë¬´ ë§ìŒ ({len(candidates)}ê°œ) - ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ ê¸°ìˆ ì  ë¶„ì„ë§Œ ì‚¬ìš©"
        elif len(candidates) == 1:
            skip_gpt = True
            skip_reason = f"í›„ë³´ê°€ 1ê°œë¿ - ê¸°ìˆ ì  ë¶„ì„ìœ¼ë¡œ ì¶©ë¶„"

        # ì¡°ê±´ 2: ì¼ì¼ GPT ë¹„ìš© ì‚¬ìš©ëŸ‰ ê¸°ë°˜ (ê¸°ì¡´ ë¡œì§ í™•ì¥)
        try:
            # ì˜¤ëŠ˜ ì‚¬ìš©í•œ GPT ë¹„ìš© ì¶”ì • (ê°„ë‹¨í•œ ê³„ì‚°)
            today_estimated_cost = len(candidates) * 0.05  # í›„ë³´ë‹¹ $0.05 ì¶”ì •
            if today_estimated_cost > self.config.max_gpt_budget_daily:
                skip_gpt = True
                skip_reason = f"ì˜ˆìƒ ë¹„ìš© ì´ˆê³¼ (${today_estimated_cost:.2f} > ${self.config.max_gpt_budget_daily})"
        except:
            pass  # ë¹„ìš© ê³„ì‚° ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ

        # ì¡°ê±´ 3: ë¦¬ìŠ¤í¬ ë ˆë²¨ ê¸°ë°˜ ì¡°ê±´ë¶€ ì‹¤í–‰
        if self.config.risk_level == RiskLevel.CONSERVATIVE and len(candidates) > 5:
            skip_gpt = True
            skip_reason = f"ë³´ìˆ˜ì  ë¦¬ìŠ¤í¬ ë ˆë²¨ì—ì„œ í›„ë³´ 5ê°œ ì´ˆê³¼ ({len(candidates)}ê°œ) - ê¸°ìˆ ì  ë¶„ì„ ìš°ì„ "

        # ì¡°ê±´ë¶€ ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬
        if skip_gpt:
            logger.info(f"ğŸ§  GPT ë¶„ì„ ìŠ¤í‚µ: {skip_reason}")
            logger.info(f"ğŸ’° ë¹„ìš© ì ˆì•½: ì˜ˆìƒ ${len(candidates) * 0.05:.2f} ì ˆì•½")
            logger.info(f"âš¡ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ {len(candidates)}ê°œ í›„ë³´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©")
            return candidates

        # GPT ë¶„ì„ ì‹¤í–‰ ê²°ì •
        logger.info(f"ğŸ¤– GPT ë¶„ì„ ì‹¤í–‰ ê²°ì •:")
        logger.info(f"   â€¢ í›„ë³´ ê°œìˆ˜: {len(candidates)}ê°œ (ì ì ˆ)")
        logger.info(f"   â€¢ ì˜ˆìƒ ë¹„ìš©: ${len(candidates) * 0.05:.2f}")
        logger.info(f"   â€¢ ë¦¬ìŠ¤í¬ ë ˆë²¨: {self.config.risk_level.value}")
        logger.info(f"   â€¢ ì¼ì¼ ì˜ˆì‚°: ${self.config.max_gpt_budget_daily}")

        return self._execute_gpt_analysis(candidates)

    def _execute_gpt_analysis(self, candidates: List[str]) -> List[str]:
        """GPT ë¶„ì„ ì‹¤í–‰ (ë‚´ë¶€ ë©”ì„œë“œ)"""

        try:
            logger.info(f"ğŸ¤– Phase 3: GPT íŒ¨í„´ ë¶„ì„ ì‹œì‘ ({len(candidates)}ê°œ í›„ë³´)")

            gpt_approved_candidates = []
            gpt_candidates_data = []  # SNS ì•Œë¦¼ìš© ìƒì„¸ ë°ì´í„°
            total_cost = 0.0

            for ticker in candidates:
                try:
                    # ì¼ì¼ ë¹„ìš© í•œë„ í™•ì¸
                    if total_cost >= self.config.max_gpt_budget_daily:
                        logger.warning(f"ğŸ’° ì¼ì¼ GPT ë¹„ìš© í•œë„ ë„ë‹¬: ${total_cost:.2f}")
                        break

                    # GPT ë¶„ì„ ì‹¤í–‰
                    result = self.gpt_analyzer.analyze_ticker(ticker)

                    if result:
                        # SNS ì•Œë¦¼ìš© ë°ì´í„° ì €ì¥ (ëª¨ë“  GPT ë¶„ì„ ê²°ê³¼)
                        gpt_candidates_data.append({
                            'ticker': ticker,
                            'recommendation': result.recommendation.value,
                            'confidence': result.confidence,
                            'pattern': 'VCP' if result.vcp_analysis.detected else 'Cup&Handle' if result.cup_handle_analysis.detected else 'None',
                            'reasoning': result.reasoning,
                            'risk_level': 'moderate',  # GPT ë¶„ì„ì€ ê¸°ë³¸ moderate
                            'cost': result.api_cost_usd
                        })

                        if result.recommendation.value in ['BUY', 'STRONG_BUY']:
                            confidence = result.confidence * 100  # 0.8 â†’ 80%
                            logger.info(f"âœ… {ticker}: GPT ë§¤ìˆ˜ ì¶”ì²œ (ì‹ ë¢°ë„: {confidence:.1f}%)")
                            gpt_approved_candidates.append(ticker)
                        else:
                            recommendation = result.recommendation.value
                            logger.info(f"â­ï¸ {ticker}: GPT ë¶„ì„ ê²°ê³¼ - {recommendation}")
                    else:
                        # ë¶„ì„ ì‹¤íŒ¨í•œ ê²½ìš°ë„ ê¸°ë¡
                        gpt_candidates_data.append({
                            'ticker': ticker,
                            'recommendation': 'ERROR',
                            'confidence': 0.0,
                            'pattern': '',
                            'reasoning': 'GPT ë¶„ì„ ì‹¤íŒ¨',
                            'risk_level': 'Unknown',
                            'cost': 0.0
                        })
                        logger.info(f"âŒ {ticker}: GPT ë¶„ì„ ì‹¤íŒ¨")

                    # ì‹¤ì œ ë¹„ìš© ëˆ„ì 
                    if result:
                        total_cost += result.api_cost_usd
                    else:
                        total_cost += 0.0  # ì‹¤íŒ¨í•œ ê²½ìš° ë¹„ìš© ì—†ìŒ

                    time.sleep(1)  # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ê³ ë ¤

                except Exception as e:
                    logger.warning(f"âš ï¸ {ticker} GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
                    # ì˜¤ë¥˜ ì¼€ì´ìŠ¤ë„ ê¸°ë¡
                    gpt_candidates_data.append({
                        'ticker': ticker,
                        'recommendation': 'ERROR',
                        'confidence': 0.0,
                        'pattern': '',
                        'reasoning': f'ë¶„ì„ ì˜¤ë¥˜: {str(e)}',
                        'risk_level': 'Unknown',
                        'cost': 0.0
                    })
                    continue

            # GPT ë¶„ì„ ê²°ê³¼ë¥¼ í†µê³„ì— ì €ì¥
            self.execution_stats['gpt_candidates'] = gpt_candidates_data
            self.execution_stats['phases_completed'].append('Phase 3: GPT Analysis')
            self.execution_stats['total_cost'] += total_cost

            logger.info(f"âœ… Phase 3 ì™„ë£Œ: {len(gpt_approved_candidates)}ê°œ GPT ìŠ¹ì¸ (ì´ {len(gpt_candidates_data)}ê°œ ë¶„ì„, ë¹„ìš©: ${total_cost:.2f})")
            return gpt_approved_candidates

        except Exception as e:
            logger.error(f"âŒ Phase 3 ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Phase 3 ì‹¤íŒ¨: {e}")
            return candidates  # GPT ì‹¤íŒ¨ ì‹œ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ì‚¬ìš©

    def run_kelly_calculation(self, candidates: List[str]) -> Dict[str, float]:
        """Kelly ê³µì‹ ê¸°ë°˜ í¬ì§€ì…˜ ì‚¬ì´ì§• ê³„ì‚°"""
        if not candidates:
            logger.info("â­ï¸ Kelly ê³„ì‚° ìŠ¤í‚µ: ê±°ë˜ í›„ë³´ ì—†ìŒ (BUY ì¶”ì²œ ì¢…ëª© 0ê°œ)")
            return {}

        try:
            logger.info(f"ğŸ§® Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ê³„ì‚° ({len(candidates)}ê°œ í›„ë³´)")

            # ğŸ” ë””ë²„ê¹…: DBì— ì €ì¥ëœ ìµœê·¼ ê¸°ìˆ ì  ë¶„ì„ ë°ì´í„° í™•ì¸
            try:
                with get_db_connection_context() as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT ticker, created_at, recommendation, quality_score
                        FROM technical_analysis
                        WHERE created_at >= datetime('now', '-1 hour')
                        ORDER BY created_at DESC
                    """)
                    recent_analyses = cursor.fetchall()
                    if recent_analyses:
                        logger.info(f"ğŸ“Š ìµœê·¼ 1ì‹œê°„ DB ì €ì¥ ë¶„ì„: {len(recent_analyses)}ê±´")
                        for row in recent_analyses[:3]:  # ìµœê·¼ 3ê±´ë§Œ í‘œì‹œ
                            logger.debug(f"   - {row[0]}: {row[2]} (í’ˆì§ˆ: {row[3]}, ì‹œê°: {row[1]})")
                    else:
                        logger.warning("âš ï¸ ìµœê·¼ 1ì‹œê°„ ë‚´ DB ì €ì¥ ë¶„ì„ ì—†ìŒ - Phase 2 DB ì €ì¥ í™•ì¸ í•„ìš”")
            except Exception as debug_error:
                logger.debug(f"ë””ë²„ê¹… ì¿¼ë¦¬ ì‹¤íŒ¨ (ë¬´ì‹œ): {debug_error}")

            position_sizes = {}

            for ticker in candidates:
                try:
                    # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
                    technical_result = self._get_technical_analysis_for_kelly(ticker)

                    if not technical_result:
                        logger.warning(f"âš ï¸ {ticker}: ê¸°ìˆ ì  ë¶„ì„ ë°ì´í„° ì—†ìŒ")
                        continue

                    # GPT ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ìˆì„ ê²½ìš°)
                    gpt_result = self._get_gpt_analysis_for_kelly(ticker)

                    # Kelly ê³„ì‚° ì‹¤í–‰
                    kelly_result = self.kelly_calculator.calculate_position_size(technical_result, gpt_result)

                    if kelly_result and kelly_result.final_position_pct > 0:
                        position_sizes[ticker] = kelly_result.final_position_pct
                        logger.info(f"ğŸ“Š {ticker}: Kelly í¬ì§€ì…˜ {kelly_result.final_position_pct:.1f}%")
                    else:
                        logger.info(f"â­ï¸ {ticker}: Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ì¡°ê±´ ë¯¸ì¶©ì¡±")

                except Exception as e:
                    logger.warning(f"âš ï¸ {ticker} Kelly ê³„ì‚° ì‹¤íŒ¨: {e}")
                    continue

            # Kelly ê²°ê³¼ë¥¼ í†µê³„ì— ì €ì¥
            self.execution_stats['kelly_results'] = position_sizes

            logger.info(f"âœ… Kelly ê³„ì‚° ì™„ë£Œ: {len(position_sizes)}ê°œ ì¢…ëª©")
            return position_sizes

        except Exception as e:
            logger.error(f"âŒ Kelly ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"Kelly ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {}

    def run_market_sentiment_analysis(self) -> Tuple[MarketSentiment, bool, float]:
        """ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ë° ê±°ë˜ ê°€ëŠ¥ ì—¬ë¶€ íŒì •"""
        try:
            logger.info("ğŸŒ¡ï¸ ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹œì‘ (pyupbit API ê¸°ë°˜)")

            # ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤í–‰
            sentiment_result = self.market_sentiment.analyze_market_sentiment()

            if not sentiment_result:
                logger.warning("âš ï¸ ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ë”ë¯¸ ê²°ê³¼ ì €ì¥
                self.last_sentiment_result = None
                return MarketSentiment.NEUTRAL, True, 1.0  # ê¸°ë³¸ê°’

            # ğŸ“Š ê²°ê³¼ë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥ (SNS ì•Œë¦¼ìš©)
            self.last_sentiment_result = sentiment_result

            sentiment = sentiment_result.final_sentiment
            can_trade = sentiment_result.trading_allowed
            position_adjustment = sentiment_result.position_adjustment

            logger.info(f"ğŸ“Š ì‹œì¥ ê°ì •: {sentiment.value}")
            logger.info(f"ğŸš¦ ê±°ë˜ ê°€ëŠ¥: {'ì˜ˆ' if can_trade else 'ì•„ë‹ˆì˜¤'}")
            logger.info(f"âš–ï¸ í¬ì§€ì…˜ ì¡°ì •: {position_adjustment:.2f}x")
            logger.info(f"ğŸ” ì¢…í•© ì ìˆ˜: {sentiment_result.total_score:.1f}ì ")
            logger.info(f"ğŸ“‹ ë¶„ì„ ê·¼ê±°: {sentiment_result.reasoning}")

            # BEAR ì‹œì¥ì—ì„œëŠ” ê±°ë˜ ì¤‘ë‹¨
            if sentiment == MarketSentiment.BEAR:
                logger.warning("ğŸš« BEAR ì‹œì¥ ê°ì§€ - ëª¨ë“  ê±°ë˜ ì¤‘ë‹¨")
                logger.warning(f"   ğŸ“‰ ì‹œì¥ ì ìˆ˜: {sentiment_result.total_score:.1f}ì  (ì„ê³„ê°’: 35ì )")
                return sentiment, False, 0.0

            return sentiment, can_trade, position_adjustment

        except Exception as e:
            logger.error(f"âŒ ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"ì‹¤ì‹œê°„ ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
            self.last_sentiment_result = None
            return MarketSentiment.NEUTRAL, True, 1.0  # ê¸°ë³¸ê°’ìœ¼ë¡œ ê±°ë˜ í—ˆìš©

    def execute_trades(self, position_sizes: Dict[str, float], position_adjustment: float) -> int:
        """ì‹¤ì œ ê±°ë˜ ì‹¤í–‰"""
        if not position_sizes or position_adjustment <= 0:
            logger.info("ğŸ“­ ê±°ë˜í•  ì¢…ëª©ì´ ì—†ê±°ë‚˜ ì‹œì¥ ì¡°ê±´ ë¶ˆëŸ‰")
            return 0

        try:
            logger.info(f"ğŸ’¸ ê±°ë˜ ì‹¤í–‰ ì‹œì‘ ({len(position_sizes)}ê°œ ì¢…ëª©)")

            if self.config.dry_run:
                logger.info("ğŸ§ª DRY RUN ëª¨ë“œ: ì‹¤ì œ ê±°ë˜ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ")
                return len(position_sizes)

            trades_executed = 0
            total_balance = self.trading_engine.get_total_balance_krw()  # ğŸ”§ ë©”ì„œë“œ ì´ë¦„ ìˆ˜ì •: get_total_balance â†’ get_total_balance_krw

            for ticker, base_position in position_sizes.items():
                try:
                    # ì‹œì¥ ê°ì • ê¸°ë°˜ í¬ì§€ì…˜ ì¡°ì •
                    adjusted_position = base_position * position_adjustment

                    # ìµœëŒ€/ìµœì†Œ í¬ì§€ì…˜ ì œí•œ
                    adjusted_position = max(1.0, min(adjusted_position, 8.0))

                    # ì‹¤ì œ íˆ¬ì ê¸ˆì•¡ ê³„ì‚°
                    investment_amount = total_balance * (adjusted_position / 100)

                    # ìµœì†Œ ì£¼ë¬¸ ê¸ˆì•¡ í™•ì¸ ë° ì¡°ì •
                    if investment_amount < 10000:  # 1ë§Œì› ìµœì†Œ
                        original_amount = investment_amount
                        investment_amount = 10000  # ìµœì†Œ ê±°ë˜ë‹¨ìœ„ë¡œ ìë™ ì¡°ì •
                        logger.info(f"ğŸ”„ {ticker}: í¬ì§€ì…˜ ì‚¬ì´ì§• ìë™ ì¡°ì • ({original_amount:,.0f}ì› â†’ {investment_amount:,.0f}ì›)")


                    logger.info(f"ğŸ’° {ticker}: {adjusted_position:.1f}% ({investment_amount:,.0f}ì›) ë§¤ìˆ˜ ì‹œë„")

                    # ë§¤ìˆ˜ ì‹¤í–‰
                    result = self.trading_engine.execute_buy_order(ticker, investment_amount, is_pyramid=False)

                    if result and result.status in [TradeStatus.FULL_FILLED, TradeStatus.PARTIAL_FILLED]:
                        trades_executed += 1
                        logger.info(f"âœ… {ticker}: ë§¤ìˆ˜ ì„±ê³µ ({result.status.korean_name})")
                    else:
                        status_msg = result.status.korean_name if result else "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
                        logger.warning(f"âŒ {ticker}: ë§¤ìˆ˜ ì‹¤íŒ¨ ({status_msg})")

                    time.sleep(0.5)  # API ë ˆì´íŠ¸ ë¦¬ë¯¸íŠ¸ ê³ ë ¤

                except Exception as e:
                    logger.error(f"âŒ {ticker} ê±°ë˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    continue

            self.execution_stats['trades_executed'] = trades_executed
            logger.info(f"âœ… ê±°ë˜ ì‹¤í–‰ ì™„ë£Œ: {trades_executed}ê°œ ì„±ê³µ")
            return trades_executed

        except Exception as e:
            logger.error(f"âŒ ê±°ë˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            self.execution_stats['errors'].append(f"ê±°ë˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return 0

    def run_portfolio_management(self):
        """í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ë° ë§¤ë„ ì¡°ê±´ ê²€ì‚¬ (ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ê¸°ë°˜)"""
        try:
            logger.info("ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì‹œì‘ (ê³ ê¸‰ ê¸°ìˆ ì  ë¶„ì„ ëª¨ë“œ)")

            # Trading Engineì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ì´ˆê¸°í™”
            if not self.trading_engine:
                logger.warning("âš ï¸ Trading Engineì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ. ì¬ì´ˆê¸°í™” ì‹œë„")
                trading_config = TradingConfig(take_profit_percent=0)  # ê¸°ìˆ ì  ì‹ í˜¸ì—ë§Œ ì˜ì¡´
                self.trading_engine = LocalTradingEngine(trading_config, dry_run=self.config.dry_run)
                logger.info("âœ… Trading Engine ì¬ì´ˆê¸°í™” ì™„ë£Œ")

            # ğŸ” ì§ì ‘ ë§¤ìˆ˜ ì¢…ëª© ê°ì§€ ë° ìë™ ì´ˆê¸°í™” (í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì „ ì‹¤í–‰)
            logger.info("ğŸ” ì§ì ‘ ë§¤ìˆ˜ ì¢…ëª© ê°ì§€ ë° ì´ˆê¸°í™” ì‹œì‘")
            direct_purchases = self.trading_engine.detect_and_initialize_direct_purchases()

            if direct_purchases:
                logger.warning(f"âš ï¸ ì§ì ‘ ë§¤ìˆ˜ ì¢…ëª© {len(direct_purchases)}ê°œ ê°ì§€ ë° ì´ˆê¸°í™”: {', '.join(direct_purchases)}")
                # SNS ì•Œë¦¼ ë°œì†¡ (ê±°ë˜ ê´€ë ¨ ì•Œë¦¼)
                if self.sns_notifier and ENABLE_TRADING_SNS:
                    try:
                        self.sns_notifier.notify_direct_purchase_detected(
                            tickers=direct_purchases,
                            execution_id=self.execution_id
                        )
                        logger.info("ğŸ“± ì§ì ‘ ë§¤ìˆ˜ ì¢…ëª© ê°ì§€ SNS ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")
                    except Exception as e:
                        logger.error(f"âŒ ì§ì ‘ ë§¤ìˆ˜ ì¢…ëª© SNS ì•Œë¦¼ ë°œì†¡ ì‹¤íŒ¨: {e}")
                else:
                    logger.debug("ğŸ“´ ê±°ë˜ SNS ë¹„í™œì„±í™”ë¡œ ì§ì ‘ ë§¤ìˆ˜ ì¢…ëª© ê°ì§€ ì•Œë¦¼ ìŠ¤í‚µ")
            else:
                logger.info("âœ… ì§ì ‘ ë§¤ìˆ˜ ì¢…ëª© ê°ì§€ ì™„ë£Œ - ëª¨ë“  í¬ì§€ì…˜ì´ ì‹œìŠ¤í…œì„ í†µí•´ ê´€ë¦¬ë¨")

            # LocalTradingEngineì˜ í–¥ìƒëœ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì‹œìŠ¤í…œ ì‹¤í–‰ (í”¼ë¼ë¯¸ë”© + íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘)
            portfolio_result = self.trading_engine.process_enhanced_portfolio_management()

            # ê²°ê³¼ ë¶„ì„ ë° ë¡œê¹… (í”¼ë¼ë¯¸ë”© í¬í•¨)
            positions_checked = portfolio_result.get('positions_checked', 0)
            sell_orders_executed = portfolio_result.get('sell_orders_executed', 0)
            pyramid_trades = portfolio_result.get('pyramid_trades', {})
            pyramid_successful = pyramid_trades.get('successful', 0)
            errors = portfolio_result.get('errors', [])

            if positions_checked == 0:
                logger.info("ğŸ“­ ê´€ë¦¬í•  í¬ì§€ì…˜ì´ ì—†ìŠµë‹ˆë‹¤")
            else:
                logger.info(f"ğŸ“Š í–¥ìƒëœ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì™„ë£Œ:")
                logger.info(f"   í¬ì§€ì…˜ ë¶„ì„: {positions_checked}ê°œ")
                if sell_orders_executed > 0:
                    logger.info(f"   ğŸ’¹ íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘/ê¸°ìˆ ì  ë§¤ë„: {sell_orders_executed}ê°œ")
                if pyramid_successful > 0:
                    logger.info(f"   ğŸ”º í”¼ë¼ë¯¸ë”© ì¶”ê°€ ë§¤ìˆ˜: {pyramid_successful}ê°œ")
                if sell_orders_executed == 0 and pyramid_successful == 0:
                    logger.info("   âœ… ëª¨ë“  í¬ì§€ì…˜ ë³´ìœ  ìœ ì§€ (ë§¤ë„/í”¼ë¼ë¯¸ë”© ì¡°ê±´ ë¯¸ì¶©ì¡±)")

            # ì—ëŸ¬ê°€ ìˆëŠ” ê²½ìš° í†µê³„ì— ì¶”ê°€
            for error in errors:
                self.execution_stats['errors'].append(f"í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì˜¤ë¥˜: {error}")

            # ê±°ë˜ í†µê³„ ì—…ë°ì´íŠ¸ (í”¼ë¼ë¯¸ë”© í¬í•¨)
            if hasattr(self.trading_engine, 'get_trading_statistics'):
                trading_stats = self.trading_engine.get_trading_statistics()
                total_trades_executed = sell_orders_executed + pyramid_successful
                self.execution_stats['trades_executed'] += total_trades_executed
                logger.info(f"ğŸ¯ ì´ ê±°ë˜ ì‹¤í–‰: {total_trades_executed}ê°œ (ë§¤ë„: {sell_orders_executed}, í”¼ë¼ë¯¸ë”©: {pyramid_successful})")
                logger.info(f"ğŸ¯ ê±°ë˜ ì„±ê³µë¥ : {trading_stats.get('success_rate', 0):.1f}%")

            logger.info("âœ… ê³ ê¸‰ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì™„ë£Œ")
            return portfolio_result

        except Exception as e:
            error_msg = f"ê³ ê¸‰ í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬ ì‹¤íŒ¨: {e}"
            logger.error(f"âŒ {error_msg}")
            self.execution_stats['errors'].append(error_msg)

            # í´ë°±: ì‹¬ê°í•œ ì˜¤ë¥˜ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return {
                'positions_checked': 0,
                'sell_orders_executed': 0,
                'errors': [str(e)]
            }

    def generate_execution_report(self):
        """ì‹¤í–‰ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        try:
            logger.info("ğŸ“‹ ì‹¤í–‰ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±")

            end_time = datetime.now()
            duration = end_time - self.execution_stats['start_time']

            report = {
                'execution_time': {
                    'start': self.execution_stats['start_time'].isoformat(),
                    'end': end_time.isoformat(),
                    'duration_seconds': duration.total_seconds()
                },
                'phases_completed': self.execution_stats['phases_completed'],
                'trading_stats': {
                    'candidates_found': self.execution_stats['trading_candidates'],
                    'trades_executed': self.execution_stats['trades_executed'],
                    'total_cost_usd': self.execution_stats['total_cost']
                },
                'errors': self.execution_stats['errors'],
                'config': {
                    'gpt_enabled': self.config.enable_gpt_analysis,
                    'dry_run': self.config.dry_run,
                    'risk_level': self.config.risk_level.value
                }
            }

            # JSON í˜•íƒœë¡œ ì €ì¥
            report_path = f"./logs/execution_report_{end_time.strftime('%Y%m%d_%H%M%S')}.json"
            os.makedirs('./logs', exist_ok=True)

            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            # ì½˜ì†” ìš”ì•½ ì¶œë ¥
            logger.info("="*60)
            logger.info("ğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½")
            logger.info("="*60)
            logger.info(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {duration.total_seconds():.1f}ì´ˆ")
            logger.info(f"âœ… ì™„ë£Œëœ ë‹¨ê³„: {len(self.execution_stats['phases_completed'])}ê°œ")
            logger.info(f"ğŸ¯ ê±°ë˜ í›„ë³´: {self.execution_stats['trading_candidates']}ê°œ")
            logger.info(f"ğŸ’¸ ì‹¤í–‰ëœ ê±°ë˜: {self.execution_stats['trades_executed']}ê°œ")
            logger.info(f"ğŸ’° ì´ ë¹„ìš©: ${self.execution_stats['total_cost']:.2f}")
            logger.info(f"âŒ ì˜¤ë¥˜ ìˆ˜: {len(self.execution_stats['errors'])}ê°œ")
            logger.info(f"ğŸ“„ ë³´ê³ ì„œ: {report_path}")
            logger.info("="*60)

        except Exception as e:
            logger.error(f"âŒ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")

    def generate_phase4_daily_report(self):
        """Phase 4 ì¼ì¼ íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ë³´ê³ ì„œ ìƒì„±"""
        try:
            if not self.failure_tracker or not self.predictive_analyzer:
                logger.info("â­ï¸ Phase 4ê°€ ë¹„í™œì„±í™”ë˜ì–´ ì¼ì¼ ë³´ê³ ì„œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
                return

            logger.info("ğŸ”® Phase 4 ì¼ì¼ ë³´ê³ ì„œ ìƒì„± ì‹œì‘")

            # 1. ì‹¤íŒ¨ íŒ¨í„´ í†µê³„ ìˆ˜ì§‘
            failure_stats = self.failure_tracker.get_failure_statistics(days=7)
            recent_failures = self.failure_tracker.get_recent_failures(hours=24)

            # 2. ì˜ˆì¸¡ ë¶„ì„ ì‹¤í–‰
            prediction = self.predictive_analyzer.predict_failure_probability(time_window_hours=24)

            # 3. ì‹œìŠ¤í…œ ìƒíƒœ ê±´ê°•ë„ ì²´í¬
            current_health = self.failure_tracker.get_current_system_health()

            # 4. ë³´ê³ ì„œ ìƒì„±
            report = {
                'report_date': datetime.now().isoformat(),
                'phase4_summary': {
                    'failures_last_24h': len(recent_failures),
                    'failures_last_7d': failure_stats.get('total_failures', 0),
                    'top_failure_types': failure_stats.get('failure_types', {}),
                    'system_health_score': current_health.overall_health if current_health else 100.0
                },
                'prediction_analysis': {
                    'risk_level': prediction.risk_level.value,
                    'failure_probability': prediction.failure_probability,
                    'confidence': prediction.confidence.value,
                    'recommendations': prediction.recommended_actions
                },
                'recent_patterns': [
                    {
                        'failure_type': f.failure_type,
                        'sub_type': f.sub_type,
                        'phase': f.phase,
                        'timestamp': f.timestamp,
                        'severity': f.severity
                    } for f in recent_failures[:10]  # ìµœê·¼ 10ê°œë§Œ
                ]
            }

            # 5. ë³´ê³ ì„œ ì €ì¥
            report_path = f"./logs/phase4_daily_report_{datetime.now().strftime('%Y%m%d')}.json"
            os.makedirs('./logs', exist_ok=True)

            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)

            # 6. ì½˜ì†” ìš”ì•½ ì¶œë ¥
            logger.info("="*60)
            logger.info("ğŸ”® Phase 4 ì¼ì¼ ë³´ê³ ì„œ ìš”ì•½")
            logger.info("="*60)
            logger.info(f"ğŸ“Š ì§€ë‚œ 24ì‹œê°„ ì‹¤íŒ¨: {len(recent_failures)}ê±´")
            logger.info(f"ğŸ“Š ì§€ë‚œ 7ì¼ ì‹¤íŒ¨: {failure_stats.get('total_failures', 0)}ê±´")
            logger.info(f"ğŸ¯ ì˜ˆì¸¡ ìœ„í—˜ë„: {prediction.risk_level.value}")
            logger.info(f"ğŸ¯ ì‹¤íŒ¨ í™•ë¥ : {prediction.failure_probability:.1%}")
            logger.info(f"ğŸ¥ ì‹œìŠ¤í…œ ê±´ê°•ë„: {current_health.overall_health if current_health else 100.0:.1f}%")
            logger.info(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: {len(prediction.recommended_actions)}ê°œ")
            logger.info(f"ğŸ“„ ìƒì„¸ ë³´ê³ ì„œ: {report_path}")
            logger.info("="*60)

            # 7. ë†’ì€ ìœ„í—˜ë„ì¸ ê²½ìš° ê²½ê³ 
            if prediction.risk_level.value in ['HIGH', 'CRITICAL']:
                logger.warning(f"âš ï¸ ë†’ì€ ì‹¤íŒ¨ ìœ„í—˜ ê°ì§€! ì£¼ìš” ê¶Œì¥ì‚¬í•­:")
                for rec in prediction.recommended_actions[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                    logger.warning(f"   â€¢ {rec}")

        except Exception as e:
            logger.error(f"âŒ Phase 4 ì¼ì¼ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")

    async def run_analysis_pipeline(self) -> Dict:
        """ë¶„ì„ íŒŒì´í”„ë¼ì¸ë§Œ ì‹¤í–‰ (ê±°ë˜ ì—†ì´)"""
        try:
            logger.info("ğŸ” ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘")

            # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if not self.initialize_components():
                return {"status": "failed", "reason": "ì´ˆê¸°í™” ì‹¤íŒ¨"}

            # 2. Phase 0: ì¢…ëª© ìŠ¤ìº”
            if not self.run_phase_0_scanner():
                return {"status": "failed", "reason": "ì¢…ëª© ìŠ¤ìº” ì‹¤íŒ¨"}

            # 3. Phase 1: ë°ì´í„° ìˆ˜ì§‘
            if not self.run_phase_1_data_collection():
                return {"status": "failed", "reason": "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨"}

            # 4. Phase 2: ê¸°ìˆ ì  í•„í„°ë§
            candidates = await self.run_phase_2_technical_filter()

            # 5. Phase 3: GPT ë¶„ì„ (ì„ íƒì )
            final_candidates = self.run_phase_3_gpt_analysis(candidates)

            # 6. Kelly í¬ì§€ì…˜ ì‚¬ì´ì§•
            position_sizes = self.run_kelly_calculation(final_candidates)

            # 7. ì‹œì¥ ê°ì • ë¶„ì„
            market_sentiment, can_trade, position_adjustment = self.run_market_sentiment_analysis()

            result = {
                "status": "success",
                "candidates_found": len(candidates) if candidates else 0,
                "final_candidates": len(final_candidates) if final_candidates else 0,
                "position_sizes": len(position_sizes) if position_sizes else 0,
                "market_sentiment": market_sentiment.value if market_sentiment else "unknown",
                "can_trade": can_trade,
                "position_adjustment": position_adjustment
            }

            logger.info(f"âœ… ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {result}")
            return result

        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return {"status": "failed", "reason": str(e)}

    def get_execution_status(self) -> Dict:
        """í˜„ì¬ ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ"""
        try:
            status = {
                "execution_stats": self.execution_stats.copy(),
                "components_initialized": {
                    "upbit": self.upbit is not None,
                    "data_collector": self.data_collector is not None,
                    "technical_filter": self.technical_filter is not None,
                    "gpt_analyzer": self.gpt_analyzer is not None,
                    "kelly_calculator": self.kelly_calculator is not None,
                    "market_sentiment": self.market_sentiment is not None,
                    # "portfolio_manager": self.portfolio_manager is not None,  # trading_engineìœ¼ë¡œ í†µí•©ë¨
                    "trading_engine": self.trading_engine is not None
                },
                "config": {
                    "enable_gpt_analysis": self.config.enable_gpt_analysis,
                    "dry_run": self.config.dry_run,
                    "risk_level": self.config.risk_level.value,
                    "max_positions": self.config.max_positions
                }
            }

            # Trading Engine í†µê³„ ì¶”ê°€
            if self.trading_engine:
                status["trading_engine_stats"] = self.trading_engine.get_trading_statistics()

            return status

        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"status": "error", "message": str(e)}

    def cleanup(self):
        """ì‹œìŠ¤í…œ ì •ë¦¬ ë° ì¢…ë£Œ (EC2 ìë™ ì¢…ë£Œ ëŒ€ë¹„)"""
        try:
            logger.info("ğŸ§¹ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹œì‘")

            # 1. Trading Engine ì •ë¦¬
            if self.trading_engine and hasattr(self.trading_engine, 'cleanup'):
                self.trading_engine.cleanup()

            # 2. ì‹¤í–‰ í†µê³„ ì €ì¥
            self.save_execution_stats()

            # 3. SQLite DB ì •ë¦¬
            self.cleanup_database()

            # 4. ë¡œê·¸ ë°±ì—… (í•„ìš”ì‹œ)
            self.backup_logs()

            logger.info("âœ… ì‹œìŠ¤í…œ ì •ë¦¬ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def save_execution_stats(self):
        """ì‹¤í–‰ í†µê³„ SQLiteì— ì €ì¥"""
        try:
            with get_db_connection_context() as conn:
                # ì‹¤í–‰ í†µê³„ í…Œì´ë¸” ìƒì„± (ì—†ìœ¼ë©´)
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS makenaide_execution_stats (
                        execution_date TEXT PRIMARY KEY,
                        execution_time TEXT,
                        phases_completed TEXT,
                        total_tickers INTEGER,
                        filtered_candidates INTEGER,
                        gpt_analyzed INTEGER,
                        kelly_positions INTEGER,
                        trades_executed INTEGER,
                        total_cost REAL,
                        success BOOLEAN,
                        errors TEXT,
                        auto_shutdown BOOLEAN
                    )
                """)

                # ì˜¤ëŠ˜ í†µê³„ ì €ì¥
                stats = self.execution_stats
                execution_date = datetime.now().strftime('%Y-%m-%d')
                execution_time = datetime.now().strftime('%H:%M:%S')
                auto_shutdown = os.getenv('EC2_AUTO_SHUTDOWN', 'false').lower() == 'true'

                conn.execute("""
                    INSERT OR REPLACE INTO makenaide_execution_stats
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    execution_date,
                    execution_time,
                    json.dumps(stats.get('phases_completed', [])),
                    stats.get('total_tickers', 0),
                    stats.get('filtered_candidates', 0),
                    len(stats.get('gpt_candidates', [])),
                    len(stats.get('kelly_results', {})),
                    stats.get('trades_executed', 0),
                    stats.get('total_cost', 0.0),
                    len(stats.get('errors', [])) == 0,
                    json.dumps(stats.get('errors', [])),
                    auto_shutdown
                ))

                conn.commit()
                logger.info("ğŸ’¾ ì‹¤í–‰ í†µê³„ ì €ì¥ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ì‹¤í–‰ í†µê³„ ì €ì¥ ì‹¤íŒ¨: {e}")

    def cleanup_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ë° ìµœì í™”"""
        try:
            with get_db_connection_context() as conn:
                # VACUUMìœ¼ë¡œ DB ìµœì í™”
                conn.execute("VACUUM")
                logger.info("ğŸ—ƒï¸ SQLite DB ìµœì í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ DB ì •ë¦¬ ì‹¤íŒ¨: {e}")

    def backup_logs(self):
        """ë¡œê·¸ íŒŒì¼ ë°±ì—… (EC2 ì¢…ë£Œ ì „)"""
        try:
            from datetime import datetime
            import shutil

            log_backup_dir = "data/log_backups"
            os.makedirs(log_backup_dir, exist_ok=True)

            # í˜„ì¬ ë¡œê·¸ íŒŒì¼ ë°±ì—…
            current_date = datetime.now().strftime('%Y%m%d_%H%M%S')

            # ë©”ì¸ ë¡œê·¸ ë°±ì—…
            if os.path.exists("makenaide.log"):
                backup_path = f"{log_backup_dir}/makenaide_{current_date}.log"
                shutil.copy2("makenaide.log", backup_path)
                logger.info(f"ğŸ“¦ ë¡œê·¸ ë°±ì—…: {backup_path}")

        except Exception as e:
            logger.error(f"âŒ ë¡œê·¸ ë°±ì—… ì‹¤íŒ¨: {e}")

    def smart_shutdown_ec2(self, reason: str = "íŒŒì´í”„ë¼ì¸ ì™„ë£Œ", stats: dict = None):
        """AWS CLI ê¸°ë°˜ Smart Shutdown (ê°œì„ ëœ ì•ˆì „ ì¢…ë£Œ)"""
        try:
            logger.info(f"ğŸš€ Smart Shutdown ì‹œì‘: {reason}")

            # Smart Shutdown ëª¨ë“ˆ import
            from smart_shutdown import SmartShutdown

            # ì‹œìŠ¤í…œ ì •ë¦¬ (ê¸°ì¡´ cleanup í˜¸ì¶œ)
            self.cleanup()

            # Smart Shutdown ì‹¤í–‰
            shutdown_system = SmartShutdown()
            success = shutdown_system.execute_smart_shutdown(reason, stats)

            if success:
                logger.info("âœ… Smart Shutdown ì„±ê³µ")
                return True
            else:
                logger.warning("âš ï¸ Smart Shutdown ì¼ë¶€ ì‹¤íŒ¨ - ìˆ˜ë™ í™•ì¸ í•„ìš”")
                return False

        except Exception as e:
            logger.error(f"âŒ Smart Shutdown ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            logger.warning("ğŸ”„ ê¸°ì¡´ shutdown ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ ì‹œë„")

            # ëŒ€ì²´ ì¢…ë£Œ ì‹œë„ (ê¸°ì¡´ ë°©ì‹)
            try:
                import subprocess
                result = subprocess.run([
                    'sudo', 'shutdown', '-h', '+1'
                ], check=False, capture_output=True, text=True)

                if result.returncode == 0:
                    logger.info("âœ… ëŒ€ì²´ ì¢…ë£Œ ëª…ë ¹ ì„±ê³µ")
                    return True
                else:
                    logger.error(f"âŒ ëŒ€ì²´ ì¢…ë£Œ ì‹¤íŒ¨: {result.stderr}")
                    return False
            except Exception as fallback_error:
                logger.error(f"ğŸ’¥ ëª¨ë“  ì¢…ë£Œ ë°©ì‹ ì‹¤íŒ¨: {fallback_error}")
                return False

    def _get_latest_technical_analysis(self) -> List[Dict]:
        """ì‹¤ì œ DBì—ì„œ ìµœì‹  ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (TechnicalFilter ì‹œìŠ¤í…œ ì—°ë™)"""
        import sqlite3
        try:
            # ì§ì ‘ SQLite ì—°ê²° ì‚¬ìš© (ì—°ê²° í’€ ë¬¸ì œ íšŒí”¼)
            conn = sqlite3.connect(self.db_path)

            # ğŸ†• ìƒˆë¡œìš´ unified_technical_analysis í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¡°íšŒ
            # TechnicalFilter ì‹œìŠ¤í…œê³¼ ì™„ì „ í˜¸í™˜

            query = """
                SELECT ticker, quality_score, gates_passed, final_recommendation,
                       current_stage, final_confidence, filter_mode,
                       breakout_strength, technical_bonus
                FROM unified_technical_analysis
                WHERE quality_score >= ?
                  AND final_recommendation IN ('STRONG_BUY', 'BUY', 'BUY_LITE')
                  AND DATE(analysis_date) = DATE('now', '+9 hours')
                  AND final_confidence IS NOT NULL
                ORDER BY quality_score DESC, final_confidence DESC
                LIMIT 15
                """

            cursor = conn.execute(query, (self.config.min_quality_score,))
            results = cursor.fetchall()

            candidates = []
            for row in results:
                ticker = row[0]

                # ğŸ”¥ ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ (ì‹œì¥ ê¸°íšŒ ì¦‰ì‹œ íŒŒì•…)
                try:
                    current_price = pyupbit.get_current_price(ticker)
                    if current_price is None:
                        current_price = 0
                except:
                    current_price = 0

                # ğŸ“Š ì¢…ëª© ì •ë³´ êµ¬ì„± (ìƒˆë¡œìš´ TechnicalFilter í•„ë“œ ì‚¬ìš©) - ì•ˆì „í•œ íƒ€ì… ë³€í™˜ ì ìš©
                candidates.append({
                    'ticker': ticker,
                    'quality_score': self._safe_convert_to_float(row[1], 0.0),
                    'gates_passed': self._safe_convert_to_int(row[2], 0),  # ğŸ”§ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì•ˆì „ ì²˜ë¦¬
                    'recommendation': row[3] if row[3] else 'HOLD',  # final_recommendation
                    'pattern_type': f"Stage {row[4]}" if row[4] else 'Stage 2',
                    'price': current_price,  # ğŸ”¥ ì‹¤ì‹œê°„ ê°€ê²© ì •ë³´
                    'confidence': self._safe_convert_to_float(row[5], 0.0),  # final_confidence
                    'filter_mode': row[6] if row[6] else 'integrated',  # ìƒˆë¡œìš´ í•„ë“œ: ë¶„ì„ ëª¨ë“œ
                    'breakout_strength': self._safe_convert_to_float(row[7], 0.0),  # ìƒˆë¡œìš´ í•„ë“œ
                    'technical_bonus': self._safe_convert_to_float(row[8], 0.0),  # ìƒˆë¡œìš´ í•„ë“œ
                    'analysis_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                })

            conn.close()
            logger.info(f"âœ… TechnicalFilter ê¸°ë°˜ ê¸°ìˆ ì  ë¶„ì„ í›„ë³´ {len(candidates)}ê°œ ì¡°íšŒ ì™„ë£Œ")
            return candidates

        except Exception as e:
            logger.error(f"âŒ TechnicalFilter ê¸°ë°˜ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def _get_latest_gpt_analysis(self) -> List[Dict]:
        """ì‹¤ì œ DBì—ì„œ ìµœì‹  GPT ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (AI ìŠ¹ì¸ ì¢…ëª©)"""
        try:
            with get_db_connection_context() as conn:
                # ì˜¤ëŠ˜ ë‚ ì§œì˜ GPT ë§¤ìˆ˜ ì¶”ì²œ ì¢…ëª© ì¡°íšŒ (ì‹ ë¢°ë„ ë†’ì€ ìˆœ)
                today = datetime.now().strftime('%Y-%m-%d')

                query = """
                SELECT ticker, gpt_recommendation, gpt_confidence, gpt_reasoning,
                       vcp_detected, cup_handle_detected, api_cost_usd
                FROM gpt_analysis
                WHERE analysis_date = ?
                  AND gpt_recommendation = 'BUY'
                  AND gpt_confidence >= 70.0
                ORDER BY gpt_confidence DESC
                LIMIT 10
                """

                cursor = conn.execute(query, (today,))
                results = cursor.fetchall()

                candidates = []
                for row in results:
                    pattern = []
                    if row[4]:  # vcp_detected
                        pattern.append("VCP")
                    if row[5]:  # cup_handle_detected
                        pattern.append("Cup & Handle")

                    candidates.append({
                        'ticker': row[0],
                        'recommendation': row[1],
                        'confidence': row[2],
                        'pattern': ' + '.join(pattern) if pattern else 'GPT íŒ¨í„´',
                        'reasoning': row[3][:100] + '...' if len(row[3]) > 100 else row[3],  # ìš”ì•½
                        'risk_level': 'MODERATE',
                        'cost': row[6] if row[6] else 0.0
                    })

                logger.info(f"ğŸ¤– ì‹¤ì œ DBì—ì„œ {len(candidates)}ê°œ GPT ìŠ¹ì¸ ì¢…ëª© ì¡°íšŒ")
                return candidates

        except Exception as e:
            logger.error(f"âŒ GPT ë¶„ì„ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def _get_latest_kelly_results(self) -> Dict[str, float]:
        """ì‹¤ì œ DBì—ì„œ ìµœì‹  Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ê²°ê³¼ ì¡°íšŒ (ìµœì  í¬ì§€ì…˜)"""
        try:
            with get_db_connection_context() as conn:
                # ì˜¤ëŠ˜ ë‚ ì§œì˜ Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ê²°ê³¼ ì¡°íšŒ (í¬ì§€ì…˜ í¬ê¸° í° ìˆœ)
                today = datetime.now().strftime('%Y-%m-%d')

                query = """
                SELECT ticker, final_position_pct, detected_pattern, gpt_confidence
                FROM kelly_analysis
                WHERE analysis_date = ?
                  AND final_position_pct > 0
                ORDER BY final_position_pct DESC
                LIMIT 10
                """

                cursor = conn.execute(query, (today,))
                results = cursor.fetchall()

                kelly_results = {}
                for row in results:
                    kelly_results[row[0]] = row[1]  # ticker: position_pct

                logger.info(f"ğŸ§® ì‹¤ì œ DBì—ì„œ {len(kelly_results)}ê°œ Kelly ê²°ê³¼ ì¡°íšŒ")
                return kelly_results

        except Exception as e:
            logger.error(f"âŒ Kelly ë¶„ì„ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

    def _send_discovered_stocks_notification(self):
        """ì‹¤ì œ DB ê¸°ë°˜ ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ SNS ì•Œë¦¼ ì „ì†¡ (ì‹œì¥ ê¸°íšŒ ì‹¤ì‹œê°„ íŒŒì•…)"""
        if not self.sns_notifier:
            return

        try:
            logger.info("ğŸ“§ ì‹¤ì œ DB ê¸°ë°˜ ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ SNS ì•Œë¦¼ ì „ì†¡ ì¤‘...")

            # ğŸ¯ ì‹¤ì œ DBì—ì„œ ìµœì‹  ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ì‹œì¥ ê¸°íšŒ ì‹¤ì‹œê°„ íŒŒì•…)
            technical_candidates = self._get_latest_technical_analysis()
            gpt_candidates = self._get_latest_gpt_analysis()
            kelly_results = self._get_latest_kelly_results()

            # ì‹¤í–‰ ID ìƒì„±
            execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')

            # ğŸ“Š ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì•Œë¦¼ ì „ì†¡ (ë¹ˆ ì•Œë¦¼ ë°©ì§€)
            if technical_candidates or gpt_candidates:
                # ë°œêµ´ ì¢…ëª© ì•Œë¦¼ ì „ì†¡ (ë¶„ì„ ê´€ë ¨ ì•Œë¦¼)
                if self.sns_notifier and ENABLE_ANALYSIS_SNS:
                    success = self.sns_notifier.notify_discovered_stocks(
                        technical_candidates=technical_candidates,
                        gpt_candidates=gpt_candidates,
                        execution_id=execution_id
                    )

                    if success:
                        logger.info(f"âœ… ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ SNS ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ (ê¸°ìˆ ì : {len(technical_candidates)}, GPT: {len(gpt_candidates)})")
                    else:
                        logger.warning("âš ï¸ ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ SNS ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")
                else:
                    logger.debug("ğŸ“´ ë¶„ì„ SNS ë¹„í™œì„±í™”ë¡œ ë°œêµ´ ì¢…ëª© ì•Œë¦¼ ìŠ¤í‚µ")
            else:
                logger.info("ğŸ“­ ë°œêµ´ëœ ì¢…ëª©ì´ ì—†ì–´ SNS ì•Œë¦¼ì„ ìƒëµí•©ë‹ˆë‹¤")

            # ğŸ’° Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ê²°ê³¼ ì•Œë¦¼ (ë³„ë„) - ë¶„ì„ ê´€ë ¨ ì•Œë¦¼
            if kelly_results:
                if self.sns_notifier and ENABLE_ANALYSIS_SNS:
                    kelly_success = self.sns_notifier.notify_kelly_position_sizing(
                        position_sizes=kelly_results,  # ğŸ”§ ë§¤ê°œë³€ìˆ˜ ì´ë¦„ ìˆ˜ì •: kelly_results â†’ position_sizes
                        execution_id=execution_id
                    )

                    if kelly_success:
                        logger.info(f"âœ… Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• SNS ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ ({len(kelly_results)}ê°œ ì¢…ëª©)")
                    else:
                        logger.warning("âš ï¸ Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• SNS ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")
                else:
                    logger.debug("ğŸ“´ ë¶„ì„ SNS ë¹„í™œì„±í™”ë¡œ Kelly í¬ì§€ì…˜ ì‚¬ì´ì§• ì•Œë¦¼ ìŠ¤í‚µ")

            # ğŸ“Š ì‹œì¥ ë¶„ì„ ì¢…í•© ìš”ì•½ ì•Œë¦¼ (ì‹¤ì œ ì‹œì¥ ë°ì´í„° í¬í•¨)
            market_summary = {
                # íŒŒì´í”„ë¼ì¸ í†µê³„
                'technical_count': len(technical_candidates),
                'gpt_count': len(gpt_candidates),
                'kelly_count': len(kelly_results),
                'total_cost': self.execution_stats.get('total_cost', 0.0),
                'phases_completed': len(self.execution_stats.get('phases_completed', [])),
                'errors_count': len(self.execution_stats.get('errors', []))
            }

            # ğŸ“ˆ ì‹¤ì œ ì‹œì¥ ë°ì´í„° ì¶”ê°€ (ì •ì ì„± ë¬¸ì œ í•´ê²°)
            if self.last_sentiment_result:
                # Fear & Greed Index ë°ì´í„°
                if self.last_sentiment_result.fear_greed_data:
                    market_summary['fear_greed_index'] = self.last_sentiment_result.fear_greed_data.value
                else:
                    market_summary['fear_greed_index'] = 50  # ê¸°ë³¸ê°’

                # BTC íŠ¸ë Œë“œ ë°ì´í„°
                if self.last_sentiment_result.btc_trend_data:
                    market_summary['btc_change_24h'] = self.last_sentiment_result.btc_trend_data.change_24h
                    market_summary['btc_trend'] = self._get_btc_trend_classification(self.last_sentiment_result.btc_trend_data.change_24h)
                else:
                    market_summary['btc_change_24h'] = 0.0
                    market_summary['btc_trend'] = 'SIDEWAYS'

                # ìµœì¢… ì‹œì¥ ê°ì • ë°ì´í„°
                market_summary['final_sentiment'] = self.last_sentiment_result.final_sentiment.value
                market_summary['trading_allowed'] = self.last_sentiment_result.trading_allowed
                market_summary['position_adjustment'] = self.last_sentiment_result.position_adjustment
                market_summary['total_score'] = self.last_sentiment_result.total_score
                market_summary['confidence'] = self.last_sentiment_result.confidence
                market_summary['reasoning'] = self.last_sentiment_result.reasoning
            else:
                # ê¸°ë³¸ê°’ (ì‹œì¥ ê°ì • ë¶„ì„ ì‹¤íŒ¨ ì‹œ)
                market_summary['fear_greed_index'] = 50
                market_summary['btc_change_24h'] = 0.0
                market_summary['btc_trend'] = 'SIDEWAYS'
                market_summary['final_sentiment'] = 'NEUTRAL'
                market_summary['trading_allowed'] = True
                market_summary['position_adjustment'] = 1.0
                market_summary['total_score'] = 50.0
                market_summary['confidence'] = 0.5
                market_summary['reasoning'] = 'ì‹œì¥ ê°ì • ë¶„ì„ ë°ì´í„° ì—†ìŒ'

            # ğŸ“Š ì¡°ê±´ë¶€ ì‹œì¥ ë¶„ì„ ìš”ì•½ ì•Œë¦¼ (BEAR ì‹œì¥ì—ì„œë§Œ ë°œì†¡)
            current_sentiment = market_summary.get('final_sentiment', 'NEUTRAL')

            if current_sentiment == 'BEAR':
                logger.info("ğŸš¨ BEAR ì‹œì¥ ê°ì§€ - ì‹œì¥ ë¶„ì„ ìš”ì•½ ì•Œë¦¼ ë°œì†¡")
                if self.sns_notifier and ENABLE_ANALYSIS_SNS:
                    summary_success = self.sns_notifier.notify_market_analysis_summary(
                        market_data=market_summary,
                        execution_id=execution_id
                    )

                    if summary_success:
                        logger.info("âœ… BEAR ì‹œì¥ ë¶„ì„ ìš”ì•½ SNS ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
                    else:
                        logger.warning("âš ï¸ BEAR ì‹œì¥ ë¶„ì„ ìš”ì•½ SNS ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨")
                else:
                    logger.debug("ğŸ“´ ë¶„ì„ SNS ë¹„í™œì„±í™”ë¡œ BEAR ì‹œì¥ ë¶„ì„ ìš”ì•½ ì•Œë¦¼ ìŠ¤í‚µ")
            else:
                logger.info(f"â„¹ï¸ {current_sentiment} ì‹œì¥ ìƒí™©ìœ¼ë¡œ ì‹œì¥ ë¶„ì„ ìš”ì•½ ì•Œë¦¼ ìƒëµ (BEAR ì‹œì¥ì—ì„œë§Œ ë°œì†¡)")

        except Exception as e:
            logger.error(f"âŒ SNS ì•Œë¦¼ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

    def _get_btc_trend_classification(self, change_24h: float) -> str:
        """BTC 24ì‹œê°„ ë³€ë™ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ë¥˜"""
        if change_24h > 5.0:
            return "BULLISH"
        elif change_24h < -5.0:
            return "BEARISH"
        else:
            return "SIDEWAYS"

    async def run_full_pipeline(self):
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            self.execution_stats['start_time'] = datetime.now()
            logger.info("ğŸš€ Makenaide ë¡œì»¬ í†µí•© íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            logger.info("="*60)

            # 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if not self.initialize_components():
                error_msg = "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨"
                logger.error(f"âŒ {error_msg}")

                # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
                if SNS_AVAILABLE and hasattr(self, 'sns_notifier'):
                    try:
                        execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
                        error_details = f"{error_msg}\n\nì„¸ë¶€ ì˜¤ë¥˜: {', '.join(self.execution_stats.get('errors', ['ì´ˆê¸°í™” ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜']))}"

                        # ì´ˆê¸°í™” ì‹¤íŒ¨ ìƒì„¸ ë¶„ë¥˜
                        errors = self.execution_stats.get('errors', [])
                        if any('memory' in str(err).lower() or 'ram' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.MEMORY_INSUFFICIENT.value
                        elif any('connection' in str(err).lower() or 'network' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.NETWORK_CONNECTION_FAILED.value
                        else:
                            sub_type = FailureSubType.SYSTEM_INITIALIZATION_FAILED.value

                        self.handle_failure_with_phase4(
                            failure_type=FailureType.INIT_FAILURE.value,
                            sub_type=sub_type,
                            error_message=error_details,
                            phase="ì´ˆê¸°í™”",
                            execution_id=execution_id,
                            metadata={
                                'component_errors': self.execution_stats.get('errors', []),
                                'available_memory': 'í™•ì¸í•„ìš”',
                                'instance_type': 't3.medium'
                            },
                            severity="CRITICAL"
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

                return False

            # 2. Phase 0: ì¢…ëª© ìŠ¤ìº”
            if not self.run_phase_0_scanner():
                error_msg = "Phase 0 ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨"
                logger.error(f"âŒ {error_msg}")

                # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
                if SNS_AVAILABLE:
                    try:
                        execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
                        error_details = f"{error_msg}\n\nì—…ë¹„íŠ¸ ì¢…ëª© ìŠ¤ìº”ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API ì—°ê²° ìƒíƒœì™€ ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

                        # Phase 0 ì‹¤íŒ¨ ìƒì„¸ ë¶„ë¥˜
                        errors = self.execution_stats.get('errors', [])
                        if any('rate limit' in str(err).lower() or 'too many' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.RATE_LIMIT_EXCEEDED.value
                        elif any('timeout' in str(err).lower() or 'connection' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.NETWORK_TIMEOUT.value
                        elif any('auth' in str(err).lower() or 'forbidden' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.API_AUTHENTICATION_FAILED.value
                        else:
                            sub_type = FailureSubType.TICKER_SCAN_FAILED.value

                        self.handle_failure_with_phase4(
                            failure_type=FailureType.PHASE0_FAILURE.value,
                            sub_type=sub_type,
                            error_message=error_details,
                            phase="Phase 0",
                            execution_id=execution_id,
                            metadata={
                                'scanner_errors': self.execution_stats.get('errors', []),
                                'api_calls_made': 'í™•ì¸í•„ìš”',
                                'api_limit': '600',
                                'affected_endpoints': ['/v1/market/all']
                            },
                            severity="HIGH"
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

                return False

            # 3. Phase 1: ë°ì´í„° ìˆ˜ì§‘
            if not self.run_phase_1_data_collection():
                error_msg = "Phase 1 ì‹¤íŒ¨ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨"
                logger.error(f"âŒ {error_msg}")

                # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
                if SNS_AVAILABLE:
                    try:
                        execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
                        error_details = f"{error_msg}\n\nOHLCV ë°ì´í„° ìˆ˜ì§‘ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë””ìŠ¤í¬ ê³µê°„ê³¼ API í˜¸ì¶œ í•œë„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

                        # Phase 1 ì‹¤íŒ¨ ìƒì„¸ ë¶„ë¥˜
                        errors = self.execution_stats.get('errors', [])
                        if any('disk' in str(err).lower() or 'space' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.DISK_SPACE_INSUFFICIENT.value
                        elif any('sqlite' in str(err).lower() or 'database' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.SQLITE_WRITE_FAILED.value
                        elif any('technical' in str(err).lower() or 'indicator' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.TECHNICAL_INDICATOR_FAILED.value
                        elif any('rate limit' in str(err).lower() for err in errors):
                            sub_type = FailureSubType.RATE_LIMIT_EXCEEDED.value
                        else:
                            sub_type = FailureSubType.DATA_COLLECTION_FAILED.value

                        self.handle_failure_with_phase4(
                            failure_type=FailureType.PHASE1_FAILURE.value,
                            sub_type=sub_type,
                            error_message=error_details,
                            phase="Phase 1",
                            execution_id=execution_id,
                            metadata={
                                'data_collection_errors': self.execution_stats.get('errors', []),
                                'database_file': 'makenaide_local.db',
                                'disk_space': 'í™•ì¸í•„ìš”',
                                'file_permissions': 'í™•ì¸í•„ìš”'
                            },
                            severity="HIGH"
                        )
                    except Exception as e:
                        logger.warning(f"âš ï¸ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")

                return False

            # 4. Phase 2: ê¸°ìˆ ì  í•„í„°ë§
            candidates = await self.run_phase_2_technical_filter()

            # 5. Phase 3: GPT ë¶„ì„ (ì„ íƒì )
            final_candidates = self.run_phase_3_gpt_analysis(candidates)

            # 6. Kelly í¬ì§€ì…˜ ì‚¬ì´ì§•
            position_sizes = self.run_kelly_calculation(final_candidates)

            # 7. ì‹œì¥ ê°ì • ë¶„ì„
            _, can_trade, position_adjustment = self.run_market_sentiment_analysis()

            # ğŸ“§ SNS ì•Œë¦¼: ë°œêµ´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì „ì†¡
            self._send_discovered_stocks_notification()

            # 8. ê±°ë˜ ì‹¤í–‰ (ì¡°ê±´ ì¶©ì¡± ì‹œ)
            if can_trade and position_sizes:
                self.execute_trades(position_sizes, position_adjustment)
            elif not can_trade:
                logger.info("ğŸš« ì‹œì¥ ì¡°ê±´ìœ¼ë¡œ ì¸í•œ ê±°ë˜ ì¤‘ë‹¨")
            else:
                logger.info("ğŸ“­ ê±°ë˜í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤")

            # 9. í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬
            self.run_portfolio_management()

            # 10. ì‹¤í–‰ ê²°ê³¼ ë³´ê³ ì„œ
            self.generate_execution_report()

            logger.info("ğŸ Makenaide ë¡œì»¬ í†µí•© íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
            return True

        except Exception as e:
            error_msg = f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}"
            logger.error(f"âŒ {error_msg}")
            self.execution_stats['errors'].append(f"ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")

            # ğŸ”” Phase 2-3 ìƒì„¸ ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡
            if SNS_AVAILABLE:
                try:
                    execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
                    error_details = f"{error_msg}\n\nì˜ˆì™¸ íƒ€ì…: {type(e).__name__}\nìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ë¥¼ ë¡œê·¸ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”."

                    # ì˜ˆì™¸ íƒ€ì…ë³„ ìƒì„¸ ë¶„ë¥˜
                    exception_name = type(e).__name__
                    if 'Memory' in exception_name or 'OutOfMemory' in exception_name:
                        sub_type = FailureSubType.MEMORY_INSUFFICIENT.value
                    elif 'Network' in exception_name or 'Connection' in exception_name or 'Timeout' in exception_name:
                        sub_type = FailureSubType.NETWORK_CONNECTION_FAILED.value
                    elif 'Permission' in exception_name or 'Access' in exception_name:
                        sub_type = FailureSubType.SYSTEM_PERMISSION_DENIED.value
                    else:
                        sub_type = FailureSubType.UNEXPECTED_EXCEPTION.value

                    # Phase 3 ë³´ì•ˆ ì•Œë¦¼ìœ¼ë¡œ CRITICAL ë©”ì‹œì§€ ì „ì†¡
                    critical_notification = NotificationMessage(
                        level=NotificationLevel.CRITICAL,
                        category=NotificationCategory.SYSTEM,
                        title="ğŸš¨ ì¹˜ëª…ì  ì‹œìŠ¤í…œ ì˜¤ë¥˜",
                        message=error_details,
                        timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        execution_id=execution_id
                    )

                    # ë³´ì•ˆ ì•Œë¦¼ ì‹œìŠ¤í…œì„ í†µí•œ ì‘ê¸‰ ì²˜ë¦¬
                    send_secure_notification(critical_notification)

                    # ìƒì„¸ ì‹¤íŒ¨ ë¶„ë¥˜ë„ í•¨ê»˜ ì „ì†¡ (Phase 4 í†µí•©)
                    self.handle_failure_with_phase4(
                        failure_type=FailureType.CRITICAL_ERROR.value,
                        sub_type=sub_type,
                        error_message=error_details,
                        phase="ì „ì²´ íŒŒì´í”„ë¼ì¸",
                        execution_id=execution_id,
                        metadata={
                            'exception_type': exception_name,
                            'critical_error': True,
                            'all_errors': self.execution_stats.get('errors', []),
                            'emergency_response': True
                        },
                        severity="CRITICAL"
                    )
                except Exception as sns_error:
                    logger.error(f"âŒ SNS ì‹¤íŒ¨ ì•Œë¦¼ ì „ì†¡ë„ ì‹¤íŒ¨: {sns_error}")

            self.generate_execution_report()
            self.generate_phase4_daily_report()
            return False

    def _get_technical_analysis_for_kelly(self, ticker: str) -> Optional[Dict]:
        """íŠ¹ì • ì¢…ëª©ì˜ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ë¥¼ Kelly Calculatorìš©ìœ¼ë¡œ ì¡°íšŒ"""
        try:
            with get_db_connection_context() as conn:
                cursor = conn.cursor()

                # ğŸ”§ ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ì¡°íšŒ ì¿¼ë¦¬ ìˆ˜ì •
                query = """
                SELECT ticker, quality_score, total_gates_passed, recommendation,
                       stage_confidence, breakout_strength, current_stage, volume_surge
                FROM technical_analysis
                WHERE ticker = ?
                ORDER BY created_at DESC
                LIMIT 1
                """

                cursor.execute(query, (ticker,))
                row = cursor.fetchone()

                if not row:
                    return None

                # ğŸ”§ Kelly Calculatorê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜ - ì‹¤ì œ ì»¬ëŸ¼ì—ì„œ ë§¤í•‘
                technical_result = {
                    'ticker': row[0],
                    'quality_score': self._safe_convert_to_float(row[1], 10.0),
                    'stage_2_entry': (self._safe_convert_to_int(row[6], 1) == 2),  # current_stage == 2ì´ë©´ Stage 2 ì§„ì…
                    'volume_breakout': (self._safe_convert_to_float(row[7], 0.0) > 1.5),  # volume_surge > 1.5ë©´ volume breakout
                    'ma_trend_strength': self._safe_convert_to_float(row[4], 0.0),  # stage_confidenceë¥¼ ma_trend_strengthë¡œ ë§¤í•‘
                    'volatility_contraction': True,  # ê¸°ë³¸ê°’ True (VCP íŒ¨í„´ ê°€ì •)
                    'volume_dry_up': (self._safe_convert_to_float(row[7], 0.0) < 0.8),  # volume_surge < 0.8ì´ë©´ volume dry up
                    'recommendation': row[3] if row[3] else 'HOLD',
                    'confidence': self._safe_convert_to_float(row[4], 0.0),  # stage_confidence
                    'breakout_strength': self._safe_convert_to_float(row[5], 0.0),
                    'technical_bonus': max(0.0, self._safe_convert_to_float(row[1], 10.0) - 10.0),  # quality_score - 10ì„ bonusë¡œ ì‚¬ìš©
                }

                return technical_result

        except Exception as e:
            logger.error(f"âŒ {ticker} ê¸°ìˆ ì  ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def _get_gpt_analysis_for_kelly(self, ticker: str) -> Optional[Dict]:
        """íŠ¹ì • ì¢…ëª©ì˜ GPT ë¶„ì„ ê²°ê³¼ë¥¼ Kelly Calculatorìš©ìœ¼ë¡œ ì¡°íšŒ"""
        try:
            with get_db_connection_context() as conn:
                cursor = conn.cursor()

                # ê°€ì¥ ìµœì‹  GPT ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
                today = datetime.now().strftime('%Y-%m-%d')
                query = """
                SELECT gpt_recommendation, gpt_confidence
                FROM gpt_analysis
                WHERE ticker = ? AND analysis_date = ?
                ORDER BY created_at DESC
                LIMIT 1
                """

                cursor.execute(query, (ticker, today))
                row = cursor.fetchone()

                if not row:
                    return None

                # Kelly Calculatorê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜ - ì•ˆì „í•œ íƒ€ì… ë³€í™˜ ì ìš©
                gpt_result = {
                    'recommendation': row[0],
                    'confidence': self._safe_convert_to_float(row[1], 0.0)
                }

                return gpt_result

        except Exception as e:
            logger.warning(f"âš ï¸ {ticker} GPT ë¶„ì„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def _safe_convert_to_int(self, value, default: int = 0) -> int:
        """SQLiteì—ì„œ ì¡°íšŒëœ ê°’ì„ ì•ˆì „í•˜ê²Œ ì •ìˆ˜ë¡œ ë³€í™˜"""
        if value is None:
            return default

        # ì´ë¯¸ ì •ìˆ˜ì¸ ê²½ìš°
        if isinstance(value, int):
            return value

        # ë¬¸ìì—´ì¸ ê²½ìš°
        if isinstance(value, str):
            try:
                return int(value)
            except ValueError:
                logger.warning(f"âš ï¸ ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜ ì‹¤íŒ¨: '{value}' â†’ ê¸°ë³¸ê°’ {default} ì‚¬ìš©")
                return default

        # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ì¸ ê²½ìš°
        if isinstance(value, bytes):
            try:
                if len(value) == 8:
                    # 8ë°”ì´íŠ¸ ë°”ì´ë„ˆë¦¬ë¥¼ 64ë¹„íŠ¸ ë¦¬í‹€ ì—”ë””ì•ˆ ì •ìˆ˜ë¡œ í•´ì„
                    return struct.unpack('<Q', value)[0]
                elif len(value) == 4:
                    # 4ë°”ì´íŠ¸ ë°”ì´ë„ˆë¦¬ë¥¼ 32ë¹„íŠ¸ ë¦¬í‹€ ì—”ë””ì•ˆ ì •ìˆ˜ë¡œ í•´ì„
                    return struct.unpack('<I', value)[0]
                elif len(value) == 1:
                    # 1ë°”ì´íŠ¸ ë°”ì´ë„ˆë¦¬ë¥¼ ì •ìˆ˜ë¡œ í•´ì„
                    return struct.unpack('B', value)[0]
                else:
                    # ë‹¤ë¥¸ ê¸¸ì´ì˜ ë°”ì´ë„ˆë¦¬ëŠ” ì²« ë°”ì´íŠ¸ë§Œ ì‚¬ìš©
                    return value[0] if len(value) > 0 else default
            except (struct.error, IndexError) as e:
                logger.warning(f"âš ï¸ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ ì‹¤íŒ¨: {value.hex()} â†’ ê¸°ë³¸ê°’ {default} ì‚¬ìš© ({e})")
                return default

        # ë¶€ë™ì†Œìˆ˜ì ì¸ ê²½ìš°
        if isinstance(value, float):
            return int(value)

        # ê¸°íƒ€ íƒ€ì…ì¸ ê²½ìš°
        logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…ì„ ì •ìˆ˜ë¡œ ë³€í™˜: {type(value)} {value} â†’ ê¸°ë³¸ê°’ {default} ì‚¬ìš©")
        return default

    def _safe_convert_to_float(self, value, default: float = 0.0) -> float:
        """SQLiteì—ì„œ ì¡°íšŒëœ ê°’ì„ ì•ˆì „í•˜ê²Œ ë¶€ë™ì†Œìˆ˜ì ìœ¼ë¡œ ë³€í™˜"""
        if value is None:
            return default

        # ì´ë¯¸ ë¶€ë™ì†Œìˆ˜ì ì¸ ê²½ìš°
        if isinstance(value, float):
            return value

        # ì •ìˆ˜ì¸ ê²½ìš°
        if isinstance(value, int):
            return float(value)

        # ë¬¸ìì—´ì¸ ê²½ìš°
        if isinstance(value, str):
            try:
                return float(value)
            except ValueError:
                logger.warning(f"âš ï¸ ë¬¸ìì—´ì„ ë¶€ë™ì†Œìˆ˜ì ìœ¼ë¡œ ë³€í™˜ ì‹¤íŒ¨: '{value}' â†’ ê¸°ë³¸ê°’ {default} ì‚¬ìš©")
                return default

        # ë°”ì´ë„ˆë¦¬ ë°ì´í„°ì¸ ê²½ìš° (ì¼ë‹¨ ì •ìˆ˜ë¡œ ë³€í™˜ í›„ ë¶€ë™ì†Œìˆ˜ì ìœ¼ë¡œ)
        if isinstance(value, bytes):
            try:
                int_value = self._safe_convert_to_int(value, 0)
                return float(int_value)
            except Exception as e:
                logger.warning(f"âš ï¸ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ë¶€ë™ì†Œìˆ˜ì ìœ¼ë¡œ ë³€í™˜ ì‹¤íŒ¨: {value.hex()} â†’ ê¸°ë³¸ê°’ {default} ì‚¬ìš© ({e})")
                return default

        # ê¸°íƒ€ íƒ€ì…ì¸ ê²½ìš°
        logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…ì„ ë¶€ë™ì†Œìˆ˜ì ìœ¼ë¡œ ë³€í™˜: {type(value)} {value} â†’ ê¸°ë³¸ê°’ {default} ì‚¬ìš©")
        return default

    def _save_technical_analysis_to_db(self, result) -> bool:
        """
        ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ë¥¼ technical_analysis í…Œì´ë¸”ì— ì €ì¥

        Args:
            result: UnifiedFilterResult ê°ì²´ (technical_filter.pyì˜ analyze_ticker() ë°˜í™˜ê°’)

        Returns:
            bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            with get_db_connection_context() as conn:
                cursor = conn.cursor()

                # UnifiedFilterResultì—ì„œ í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
                ticker = result.ticker
                analysis_date = result.analysis_date

                # Weinstein Stage ë¶„ì„ ê²°ê³¼
                weinstein = result.weinstein_result
                current_stage = weinstein.current_stage if weinstein else None
                stage_confidence = weinstein.stage_confidence if weinstein else None
                ma200_trend = weinstein.ma200_trend if weinstein else None
                price_vs_ma200 = weinstein.price_vs_ma200 if weinstein else None
                breakout_strength = weinstein.breakout_strength if weinstein else None

                # 4-Gate í•„í„°ë§ ê²°ê³¼
                basic = result.basic_result
                total_gates_passed = basic.total_gates_passed if basic else None
                quality_score = result.final_quality_score

                # ìµœì¢… ê¶Œê³  ë° ì‹ ë¢°ë„
                recommendation = result.final_recommendation.value
                final_confidence = result.final_confidence

                # volume_surge ê³„ì‚° (basic_resultì—ì„œ ì¶”ì¶œ)
                volume_surge = None
                if basic and hasattr(basic, 'volume_surge_ratio'):
                    volume_surge = basic.volume_surge_ratio
                elif weinstein and hasattr(weinstein, 'volume_surge'):
                    volume_surge = weinstein.volume_surge

                # INSERT OR REPLACEë¡œ ì¤‘ë³µ ë°©ì§€
                cursor.execute("""
                    INSERT OR REPLACE INTO technical_analysis (
                        ticker, analysis_date,
                        current_stage, stage_confidence, ma200_trend, price_vs_ma200, breakout_strength,
                        total_gates_passed, quality_score, recommendation,
                        volume_surge,
                        source_table, created_at, updated_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'), datetime('now'))
                """, (
                    ticker, analysis_date,
                    current_stage, stage_confidence, ma200_trend, price_vs_ma200, breakout_strength,
                    total_gates_passed, quality_score, recommendation,
                    volume_surge,
                    'UnifiedTechnicalFilter'  # ë°ì´í„° ì¶œì²˜ í‘œì‹œ
                ))

                conn.commit()
                logger.debug(f"âœ… {ticker} ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ")
                return True

        except Exception as e:
            logger.warning(f"âš ï¸ {result.ticker if hasattr(result, 'ticker') else 'Unknown'} DB ì €ì¥ ì‹¤íŒ¨ (íŒŒì´í”„ë¼ì¸ ê³„ì† ì§„í–‰): {e}")
            return False

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='Makenaide ë¡œì»¬ í†µí•© ê±°ë˜ ì‹œìŠ¤í…œ')
    parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ê±°ë˜ ì—†ì´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰')
    parser.add_argument('--no-gpt', action='store_true', help='GPT ë¶„ì„ ë¹„í™œì„±í™” (ë¹„ìš© ì ˆì•½)')
    parser.add_argument('--risk-level', choices=['conservative', 'moderate', 'aggressive'],
                       default='moderate', help='ë¦¬ìŠ¤í¬ ë ˆë²¨ ì„¤ì •')
    parser.add_argument('--max-gpt-budget', type=float, default=5.0,
                       help='ì¼ì¼ GPT ë¹„ìš© í•œë„ (USD)')
    parser.add_argument('--auto-sync', action='store_true', default=True,
                       help='í¬íŠ¸í´ë¦¬ì˜¤ ìë™ ë™ê¸°í™” í™œì„±í™” (ê¸°ë³¸ê°’)')
    parser.add_argument('--no-auto-sync', action='store_true',
                       help='í¬íŠ¸í´ë¦¬ì˜¤ ìë™ ë™ê¸°í™” ë¹„í™œì„±í™”')
    parser.add_argument('--sync-policy', choices=['conservative', 'moderate', 'aggressive'],
                       default='aggressive', help='í¬íŠ¸í´ë¦¬ì˜¤ ë™ê¸°í™” ì •ì±… (ê¸°ë³¸: aggressive - ëª¨ë“  ê¸ˆì•¡ ë™ê¸°í™”)')

    args = parser.parse_args()

    # auto-sync ì„¤ì • ì¡°ì •
    if args.no_auto_sync:
        args.auto_sync = False

    # ì„¤ì • ìƒì„±
    risk_level_map = {
        'conservative': RiskLevel.CONSERVATIVE,
        'moderate': RiskLevel.MODERATE,
        'aggressive': RiskLevel.AGGRESSIVE
    }

    config = OrchestratorConfig(
        enable_gpt_analysis=not args.no_gpt,
        max_gpt_budget_daily=args.max_gpt_budget,
        risk_level=risk_level_map[args.risk_level],
        dry_run=args.dry_run,
        auto_sync_enabled=args.auto_sync,
        sync_policy=args.sync_policy
    )

    # ì‹¤í–‰ ëª¨ë“œ ì¶œë ¥
    logger.info("ğŸ¯ ì‹¤í–‰ ëª¨ë“œ ì„¤ì •")
    logger.info(f"   - GPT ë¶„ì„: {'í™œì„±í™”' if config.enable_gpt_analysis else 'ë¹„í™œì„±í™”'}")
    logger.info(f"   - ê±°ë˜ ì‹¤í–‰: {'DRY RUN' if config.dry_run else 'ì‹¤ì œ ê±°ë˜'}")
    logger.info(f"   - ë¦¬ìŠ¤í¬ ë ˆë²¨: {config.risk_level.value}")
    logger.info(f"   - GPT ì¼ì¼ ì˜ˆì‚°: ${config.max_gpt_budget_daily}")
    logger.info(f"   - í¬íŠ¸í´ë¦¬ì˜¤ ìë™ ë™ê¸°í™”: {'í™œì„±í™”' if config.auto_sync_enabled else 'ë¹„í™œì„±í™”'}")
    logger.info(f"   - ë™ê¸°í™” ì •ì±…: {config.sync_policy} ({'ëª¨ë“  ê¸ˆì•¡ ë™ê¸°í™”' if config.sync_policy == 'aggressive' else 'ì œí•œì  ë™ê¸°í™”'})")

    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‹¤í–‰
    orchestrator = MakenaideLocalOrchestrator(config)
    success = await orchestrator.run_full_pipeline()

    # EC2 ìë™ ì¢…ë£Œ ì²˜ë¦¬ (í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´)
    auto_shutdown = os.getenv('EC2_AUTO_SHUTDOWN', 'false').lower() == 'true'

    if success:
        logger.info("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ")

        if auto_shutdown:
            logger.info("ğŸ”Œ EC2 Smart Shutdown ì‹œì‘")
            # smart_shutdown_ec2 ë©”ì„œë“œ ì‚¬ìš© (AWS CLI ê¸°ë°˜ ê°œì„ ëœ ì¢…ë£Œ)
            orchestrator.smart_shutdown_ec2("íŒŒì´í”„ë¼ì¸ ì„±ê³µ ì™„ë£Œ")
        else:
            # ì¼ë°˜ ì •ë¦¬ë§Œ ìˆ˜í–‰
            orchestrator.cleanup()

        sys.exit(0)
    else:
        logger.error("ğŸ’¥ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨")

        if auto_shutdown:
            logger.error("ğŸ”Œ EC2 Smart Shutdown ì‹œì‘ (ì‹¤íŒ¨ ì¼€ì´ìŠ¤)")
            # ì‹¤íŒ¨ ì‹œì—ë„ EC2 ì¢…ë£Œ (ë¹„ìš© ì ˆì•½)
            orchestrator.smart_shutdown_ec2("íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
        else:
            # ì¼ë°˜ ì •ë¦¬ë§Œ ìˆ˜í–‰
            orchestrator.cleanup()

        sys.exit(1)

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())